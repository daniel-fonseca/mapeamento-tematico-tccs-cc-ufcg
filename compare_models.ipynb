{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comparação de Modelos de Tópicos (LDA × BERTopic × BERTopic-alt)\n",
        "\n",
        "Este notebook percorre os *runs/trials* salvos em `data/processed/{lda,bertopic}/run_*/trial_*`,\n",
        "recalcula métricas (C_npmi, C_v, diversidade, separação JSD), lê *outliers* (BERTopic) e consolida tudo\n",
        "em tabelas e gráficos prontos para o TCC.\n",
        "\n",
        "**Atenção:** defina o caminho do **corpus de referência tokenizado** (`REF_TEXTS_PATH`), um arquivo TXT onde cada linha contém\n",
        "uma lista de tokens separados por espaço. Essa referência é usada pelo Gensim para C_npmi/C_v.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Imports e paths\n",
        "from pathlib import Path\n",
        "import json, math, os, re, warnings\n",
        "from datetime import datetime, timezone\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from itertools import combinations\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "\n",
        "ROOT = Path.cwd()  # ajuste se necessário\n",
        "DATA = ROOT / \"data\"\n",
        "PROCESSED = DATA / \"processed\"\n",
        "RESULTS = ROOT / \"results\" / \"comparison\" / datetime.now(timezone.utc).strftime(\"run_%Y%m%dT%H%M%SZ\")\n",
        "RESULTS.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Caminho para corpus de referência tokenizado (um documento por linha; tokens separados por espaço)\n",
        "REF_TEXTS_PATH = DATA / \"interim\" / \"lda\" / \"ref_corpus_tokens.txt\"  # <-- AJUSTE AQUI\n",
        "if not REF_TEXTS_PATH.exists():\n",
        "    raise FileNotFoundError(f\"Defina REF_TEXTS_PATH corretamente. Arquivo não encontrado: {REF_TEXTS_PATH}\")\n",
        "\n",
        "# Carregar corpus de referência\n",
        "ref_texts = [line.strip().split() for line in open(REF_TEXTS_PATH, encoding=\"utf-8\")]\n",
        "ref_dict = Dictionary(ref_texts)\n",
        "ref_bow = [ref_dict.doc2bow(t) for t in ref_texts]\n",
        "print(f\"Corpus de referência: {len(ref_texts)} docs, vocabulário={len(ref_dict)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Funções auxiliares\n",
        "def load_vocab(path: Path):\n",
        "    return [line.strip() for line in open(path, encoding=\"utf-8\")] \n",
        "\n",
        "def top_words_from_matrix(mat: np.ndarray, vocab: list, topn: int = 10):\n",
        "    # mat: K x |V|\n",
        "    topics = []\n",
        "    for k in range(mat.shape[0]):\n",
        "        row = mat[k]\n",
        "        idx = np.argsort(-row)[:topn]\n",
        "        topics.append([(vocab[i], float(row[i])) for i in idx])\n",
        "    return topics\n",
        "\n",
        "def topic_diversity(topics_terms, topn=10):\n",
        "    uniq = set()\n",
        "    total = 0\n",
        "    for terms in topics_terms:\n",
        "        for w, _ in terms[:topn]:\n",
        "            uniq.add(w)\n",
        "        total += min(len(terms), topn)\n",
        "    return len(uniq)/total if total else np.nan\n",
        "\n",
        "def coherence_scores(topics_terms, measure: str):\n",
        "    # topics_terms: list[list[(word,weight)]]\n",
        "    topics = [[w for (w,_) in t] for t in topics_terms]\n",
        "    cm = CoherenceModel(topics=topics, texts=ref_texts, dictionary=ref_dict, coherence=measure)\n",
        "    return cm.get_coherence()\n",
        "\n",
        "def avg_jsd_between_topics(mat: np.ndarray, eps=1e-12):\n",
        "    # normaliza linhas para distribuição\n",
        "    row_sums = mat.sum(axis=1, keepdims=True) + eps\n",
        "    prob = mat / row_sums\n",
        "    K = prob.shape[0]\n",
        "    if K < 2:\n",
        "        return np.nan\n",
        "    ds = []\n",
        "    for i, j in combinations(range(K), 2):\n",
        "        d = jensenshannon(prob[i], prob[j])\n",
        "        ds.append(float(d))\n",
        "    return float(np.mean(ds)) if ds else np.nan\n",
        "\n",
        "def scan_trials(method_root: Path):\n",
        "    # retorna lista de paths trial dirs\n",
        "    trials = []\n",
        "    if not method_root.exists():\n",
        "        return trials\n",
        "    for run_dir in sorted(method_root.glob('run_*')):\n",
        "        for tdir in sorted(run_dir.glob('trial_*')):\n",
        "            trials.append(tdir)\n",
        "    return trials\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Varre LDA\n",
        "lda_trials = scan_trials(PROCESSED / \"lda\")\n",
        "print(f\"LDA trials encontrados: {len(lda_trials)}\")\n",
        "rows = []\n",
        "for tdir in lda_trials:\n",
        "    try:\n",
        "        phi = np.load(tdir/\"phi_topics.npy\")  # K x |V|\n",
        "        vocab = load_vocab(tdir.parent.parent / \"vocab.txt\") if (tdir.parent.parent/\"vocab.txt\").exists() else load_vocab(tdir/\"vocab.txt\")\n",
        "        topics_terms = top_words_from_matrix(phi, vocab, topn=10)\n",
        "        c_npmi = coherence_scores(topics_terms, \"c_npmi\")\n",
        "        c_v    = coherence_scores(topics_terms, \"c_v\")\n",
        "        div    = topic_diversity(topics_terms, topn=10)\n",
        "        sep    = avg_jsd_between_topics(phi)\n",
        "        theta_p = tdir/\"theta_docs.npy\"\n",
        "        ent_low = np.nan\n",
        "        if theta_p.exists():\n",
        "            theta = np.load(theta_p)\n",
        "            # entropia média por doc (natural log), proxy de nitidez\n",
        "            p = theta + 1e-12\n",
        "            ent = -np.sum(p*np.log(p), axis=1)\n",
        "            # porcentagem com entropia < ln(K)/2 (dominância razoável)\n",
        "            thr = (math.log(theta.shape[1]))/2.0\n",
        "            ent_low = float(np.mean(ent < thr))\n",
        "        rows.append({\n",
        "            \"method\":\"lda\",\n",
        "            \"run\": tdir.parent.name,\n",
        "            \"trial\": tdir.name,\n",
        "            \"K\": int(phi.shape[0]),\n",
        "            \"c_npmi\": c_npmi,\n",
        "            \"c_v\": c_v,\n",
        "            \"diversity@10\": div,\n",
        "            \"sep_jsd\": sep,\n",
        "            \"entropy_lt_halflnK_pct\": ent_low,\n",
        "        })\n",
        "    except Exception as e:\n",
        "        warnings.warn(f\"Falha ao processar {tdir}: {e}\")\n",
        "lda_df = pd.DataFrame(rows)\n",
        "display(lda_df.head())\n",
        "lda_df.to_csv(RESULTS/\"lda_trials.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Varre BERTopic\n",
        "bt_trials = scan_trials(PROCESSED / \"bertopic\")\n",
        "print(f\"BERTopic trials encontrados: {len(bt_trials)}\")\n",
        "rows = []\n",
        "for tdir in bt_trials:\n",
        "    try:\n",
        "        ctf = np.load(tdir/\"c_tf_idf.npy\")  # K x |V|\n",
        "        vocab = load_vocab(tdir/\"vocab.txt\") if (tdir/\"vocab.txt\").exists() else load_vocab(tdir.parent/\"vocab.txt\")\n",
        "        topics_terms = top_words_from_matrix(ctf, vocab, topn=10)\n",
        "        c_npmi = coherence_scores(topics_terms, \"c_npmi\")\n",
        "        c_v    = coherence_scores(topics_terms, \"c_v\")\n",
        "        div    = topic_diversity(topics_terms, topn=10)\n",
        "        sep    = avg_jsd_between_topics(ctf)\n",
        "        outliers_pct = np.nan\n",
        "        labels_p = tdir/\"doc_topics.csv\"\n",
        "        if labels_p.exists():\n",
        "            import pandas as _pd\n",
        "            lab = _pd.read_csv(labels_p)\n",
        "            if \"topic\" in lab.columns:\n",
        "                outliers_pct = float((lab[\"topic\"] == -1).mean())\n",
        "        rows.append({\n",
        "            \"method\":\"bertopic\",\n",
        "            \"run\": tdir.parent.name,\n",
        "            \"trial\": tdir.name,\n",
        "            \"K\": int(ctf.shape[0]),\n",
        "            \"c_npmi\": c_npmi,\n",
        "            \"c_v\": c_v,\n",
        "            \"diversity@10\": div,\n",
        "            \"sep_jsd\": sep,\n",
        "            \"outliers_pct\": outliers_pct,\n",
        "        })\n",
        "    except Exception as e:\n",
        "        warnings.warn(f\"Falha ao processar {tdir}: {e}\")\n",
        "bt_df = pd.DataFrame(rows)\n",
        "display(bt_df.head())\n",
        "bt_df.to_csv(RESULTS/\"bertopic_trials.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Consolidação e gráficos rápidos\n",
        "df = pd.concat([lda_df, bt_df], ignore_index=True)\n",
        "df.to_csv(RESULTS/\"all_trials.csv\", index=False)\n",
        "\n",
        "print(f\"Salvo: {RESULTS/'all_trials.csv'}\")\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "for m in sorted(df['method'].unique()):\n",
        "    sub = df[df['method']==m]\n",
        "    plt.scatter(sub['c_npmi'], sub['diversity@10'], label=m, alpha=0.7)\n",
        "plt.xlabel('c_npmi (ref)')\n",
        "plt.ylabel('diversity@10')\n",
        "plt.legend(); plt.title('c_npmi vs diversity@10')\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "df.boxplot(column='c_npmi', by='method')\n",
        "plt.suptitle(''); plt.title('Distribuição de c_npmi por método')\n",
        "plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Escreve na planilha-modelo (sheet Replicacoes)\n",
        "xlsx_out = ROOT / \"reports\" / \"tables\" / \"TCC_comparacao_resultados.xlsx\"\n",
        "xlsx_out.parent.mkdir(parents=True, exist_ok=True)\n",
        "with pd.ExcelWriter(xlsx_out, engine='openpyxl') as writer:\n",
        "    df.to_excel(writer, index=False, sheet_name='Replicacoes')\n",
        "print(f\"Planilha escrita em: {xlsx_out}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}