DOC_ID,ano,titulo,autor,orientador,resumo,url,RESUMO_PREP_BERTOPIC
0,2024,AGENDEVC: um sistema de agendamento para prestadores e consumidores de serviços diversos.,"FERREIRA, Williamberg de Albuquerque.","MASSONI, Tiago Lima.","Gerenciar a agenda e fornecer informações ao cliente são tarefas que oneram muito o tempo do pequeno empreendedor, que, em muitos casos, gerencia e opera um negócio sozinho, precisando maximizar seu tempo produzindo para obter melhores resultados e manter o seu empreendimento em atividade. Este trabalho tem como objetivo propor o desenvolvimento de um sistema web que oferece ao empreendedor um meio de fornecer as principais informações sobre seu negócio e visualizar os serviços agendados. O sistema provê ao consumidor dos serviços prestados uma forma de visualizar as informações sobre um determinado serviço e efetuar o agendamento em horário disponível e conveniente para si, dispensando a necessidade de qualquer tipo de contato prévio com o prestador do serviço. A solução foi avaliada por 23 usuários, obtendo um índice de satisfação médio de 4.7 entre os dois grupos de usuários (prestadores de serviços e consumidores), constatando ser uma proposta eficaz na solução do problema.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38362,"gerenciar a agenda e fornecer informações ao cliente são tarefas que oneram muito o tempo do pequeno empreendedor, que, em muitos casos, gerencia e opera um negócio sozinho, precisando maximizar seu tempo produzindo para obter melhores resultados e manter o seu empreendimento em atividade. este trabalho tem como objetivo propor o desenvolvimento de um sistema web que oferece ao empreendedor um meio de fornecer as principais informações sobre seu negócio e visualizar os serviços agendados. o sistema provê ao consumidor dos serviços prestados uma forma de visualizar as informações sobre um determinado serviço e efetuar o agendamento em horário disponível e conveniente para si, dispensando a necessidade de qualquer tipo de contato prévio com o prestador do serviço. a solução foi avaliada por usuários, obtendo um índice de satisfação médio de . entre os dois grupos de usuários (prestadores de serviços e consumidores), constatando ser uma proposta eficaz na solução do problema."
1,2024,"Análise de técnicas de explicabilidade em redes neurais convolucionais para diagnóstico de glaucoma, retinopatia diabética e catarata.","SILVA, Wendson Magalhães da.","GOMES, Herman Martins.","Doenças oftalmológicas, como catarata, glaucoma e retinopatia diabética, representam um desafio significativo para a saúde pública, com potencial de causar perda de visão. No entanto, a maioria desses casos poderia ser evitada ou tratada se diagnosticada precocemente. Neste contexto, a imagem de fundo de olho surge como uma ferramenta de diagnóstico eficaz, rápida e não invasiva. A interpretação manual de imagens oftalmológicas é repetitiva e sujeita a erros. Assim, sistemas computacionais podem ser utilizados para auxiliar os profissionais na triagem automatizada, reduzindo tempo, erros e esforço na análise das doenças. Os sistemas de aprendizado profundo provaram ser eficazes nesse contexto, entretanto, sua falta de transparência tem sido um desafio para a adoção clínica, o que destaca a importância da explicabilidade nos modelos de aprendizado de máquina. Este estudo contribui para o avanço da compreensão e interpre-tação de modelos de aprendizado profundo na área da saúde ocular, visando melhorar o diagnóstico e tratamento de condições oftalmológicas. Ele compara as técnicas LIME e Grad-CAM aplicadas a diferentes arquiteturas de redes neurais convolucionais (CNNs) treinadas para classificar condições oftalmológicas a partir de imagens de fundo de olho. Os resultados indicam que o modelo VGG16 se destaca, alcançando uma acurácia de 93,17% no treinamento e 87,16% na validação. Além disso, as técnicas de explicabilidade, embora distintas em abordagem, identificaram quase as mesmas regiões de interesse nas imagens oftalmológicas. Ainda assim, apesar de haver limitações, como a aleatoriedade do LIME e a necessidade de ajustes no Grad-CAM, o LIME destacou áreas críticas de forma mais sutil, enquanto o Grad-CAM forneceu representações visuais mais diretas e intuitivas.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38358,"doenças oftalmológicas, como catarata, glaucoma e retinopatia diabética, representam um desafio significativo para a saúde pública, com potencial de causar perda de visão. no entanto, a maioria desses casos poderia ser evitada ou tratada se diagnosticada precocemente. neste contexto, a imagem de fundo de olho surge como uma ferramenta de diagnóstico eficaz, rápida e não invasiva. a interpretação manual de imagens oftalmológicas é repetitiva e sujeita a erros. assim, sistemas computacionais podem ser utilizados para auxiliar os profissionais na triagem automatizada, reduzindo tempo, erros e esforço na análise das doenças. os sistemas de aprendizado profundo provaram ser eficazes nesse contexto, entretanto, sua falta de transparência tem sido um desafio para a adoção clínica, o que destaca a importância da explicabilidade nos modelos de aprendizado de máquina. este estudo contribui para o avanço da compreensão e interpre-tação de modelos de aprendizado profundo na área da saúde ocular, visando melhorar o diagnóstico e tratamento de condições oftalmológicas. ele compara as técnicas lime e grad-cam aplicadas a diferentes arquiteturas de redes neurais convolucionais (cnns) treinadas para classificar condições oftalmológicas a partir de imagens de fundo de olho. os resultados indicam que o modelo vgg16 se destaca, alcançando uma acurácia de , % no treinamento e , % na validação. além disso, as técnicas de explicabilidade, embora distintas em abordagem, identificaram quase as mesmas regiões de interesse nas imagens oftalmológicas. ainda assim, apesar de haver limitações, como a aleatoriedade do lime e a necessidade de ajustes no grad-cam, o lime destacou áreas críticas de forma mais sutil, enquanto o grad-cam forneceu representações visuais mais diretas e intuitivas."
2,2024,O impacto do uso de tags de rastreamento na performance de um E-commerce.,"RIBEIRO, Vinicius Trindade Rocha.","MONGIOVI, Melina.","O presente trabalho busca compreender se a utilização de tags do Google Tag Manager (GTM) interfere na performance de um e-commerce perfeitamente otimizado. Inicialmente, será analisado o conceito de performance, de tags, de GTM, bem como sua importância no contexto de um e-commerce. Em seguida, para alcançar os objetivos propostos, foram conduzidas análises de performance em um e-commerce otimizado sob três cenários distintos: sem o uso de tags, com a utilização das tags do GTM e com utilização de tags robustas do GTM. Em todos os cenários, foram excluídos os outliers na análise, com o objetivo de afastar possíveis inconsistências nos resultados. Os resultados demonstram que houve uma tendência de queda na performance à medida que a complexidade das tags aumenta. Constatou-se que a implementação de tags do GTM, embora útil para o rastreamento de dados, pode ter um impacto negativo na performance do site se não for gerenciada corretamente. Por causa disso, atestou-se que no contexto de e-commerce esse processo envolve tomar decisões estratégicas sobre quais tags são realmente necessárias e como podem ser implementadas de forma a minimizar seu impacto na performance do site, garantindo, ao mesmo tempo, uma experiência positiva para o usuário.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38356,"o presente trabalho busca compreender se a utilização de tags do google tag manager (gtm) interfere na performance de um e-commerce perfeitamente otimizado. inicialmente, será analisado o conceito de performance, de tags, de gtm, bem como sua importância no contexto de um e-commerce. em seguida, para alcançar os objetivos propostos, foram conduzidas análises de performance em um e-commerce otimizado sob três cenários distintos: sem o uso de tags, com a utilização das tags do gtm e com utilização de tags robustas do gtm. em todos os cenários, foram excluídos os outliers na análise, com o objetivo de afastar possíveis inconsistências nos resultados. os resultados demonstram que houve uma tendência de queda na performance à medida que a complexidade das tags aumenta. constatou-se que a implementação de tags do gtm, embora útil para o rastreamento de dados, pode ter um impacto negativo na performance do site se não for gerenciada corretamente. por causa disso, atestou-se que no contexto de e-commerce esse processo envolve tomar decisões estratégicas sobre quais tags são realmente necessárias e como podem ser implementadas de forma a minimizar seu impacto na performance do site, garantindo, ao mesmo tempo, uma experiência positiva para o usuário."
3,2024,O impacto das ferramentas baseadas em IA Generativa no mercado de desenvolvimento de software: uma avaliação com profissionais do setor.,"BRAGA, Victor Paz de Farias.","CAMPELO, Claudio Elízio Calazans.","Este estudo investiga o impacto de ferramentas baseadas em IA Generativa no mercado de trabalho para desenvolvedores de software, a partir de um questionário distribuído entre profissionais do setor, com diferentes níveis de experiência. Recentemente, tem-se observado o surgimento de Modelos de Linguagem de Larga Escala (LLM) cada vez mais poderosos, habilitando o desenvolvimento de ferramentas com grande capacidade de geração e análise automática de código em diferentes linguagens de programação. Com o rápido desenvolvimento da área, cresce também a preocupação dos profissionais acerca das implicações decorrentes da automação das tarefas que realizam, assim como da conseqüente redução dos postos de trabalho no setor de desenvolvimento de software. Embora a literatura apresente uma discussão substancial sobre a temática, observa-se uma escassez de estudos baseados na opinião dos profissionais do setor. As percepções obtidas a partir do nosso estudo sugerem que essas tecnologias tendem a ser mais eficazes em tarefas simples e repetitivas, especialmente para profissionais iniciantes. Por outro lado, sua efetividade parece diminuir em trabalhos mais subjetivos e complexos, especialmente à medida que a senioridade profissional aumenta. Os resultados observados visam subsidiar uma reflexão mais aprofundada sobre o impacto dessas ferramentas no mercado de trabalho, especialmente em relação à oferta de vagas para profissionais iniciantes.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38355,"este estudo investiga o impacto de ferramentas baseadas em ia generativa no mercado de trabalho para desenvolvedores de software, a partir de um questionário distribuído entre profissionais do setor, com diferentes níveis de experiência. recentemente, tem-se observado o surgimento de modelos de linguagem de larga escala (llm) cada vez mais poderosos, habilitando o desenvolvimento de ferramentas com grande capacidade de geração e análise automática de código em diferentes linguagens de programação. com o rápido desenvolvimento da área, cresce também a preocupação dos profissionais acerca das implicações decorrentes da automação das tarefas que realizam, assim como da conseqüente redução dos postos de trabalho no setor de desenvolvimento de software. embora a literatura apresente uma discussão substancial sobre a temática, observa-se uma escassez de estudos baseados na opinião dos profissionais do setor. as percepções obtidas a partir do nosso estudo sugerem que essas tecnologias tendem a ser mais eficazes em tarefas simples e repetitivas, especialmente para profissionais iniciantes. por outro lado, sua efetividade parece diminuir em trabalhos mais subjetivos e complexos, especialmente à medida que a senioridade profissional aumenta. os resultados observados visam subsidiar uma reflexão mais aprofundada sobre o impacto dessas ferramentas no mercado de trabalho, especialmente em relação à oferta de vagas para profissionais iniciantes."
4,2024,Soft Skills no desenvolvimento de software: identificação e relevância em diferentes etapas do Scrum.,"SANTOS, Victor Paiva dos.","ALMEIDA, Hyggo Oliveira de.","No cenário atual do desenvolvimento de software, apenas habilidades técnicas não são mais suficientes para garantir o sucesso de um projeto. As soft skills, habilidades socio-emocionais, emergem como elementos críticos para o desempenho eficaz das equipes. No entanto, a falta de ênfase e compreensão sobre essas habilidades tem sido um desafio persistente, levando a problemas de comunicação, colaboração ineficaz e, consequentemente, atrasos e falhas nos projetos. Este estudo busca identificar as soft skills mais relevantes em diferentes etapas do processo de desenvolvimento de software, especificamente sob o arcabouço ágil Scrum, visando fornecer informações importantes para profissionais e gestores, auxiliando-os no recrutamento, treinamento e desenvolvimento de equipes mais eficazes e adaptáveis às demandas do processo de desenvolvimento de software. Para isso, foi conduzida uma pesquisa com profissionais e líderes de equipes, visando entender as necessidades específicas de habilidades em cada fase do ciclo Scrum.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38353,"no cenário atual do desenvolvimento de software, apenas habilidades técnicas não são mais suficientes para garantir o sucesso de um projeto. as soft skills, habilidades socio-emocionais, emergem como elementos críticos para o desempenho eficaz das equipes. no entanto, a falta de ênfase e compreensão sobre essas habilidades tem sido um desafio persistente, levando a problemas de comunicação, colaboração ineficaz e, consequentemente, atrasos e falhas nos projetos. este estudo busca identificar as soft skills mais relevantes em diferentes etapas do processo de desenvolvimento de software, especificamente sob o arcabouço ágil scrum, visando fornecer informações importantes para profissionais e gestores, auxiliando-os no recrutamento, treinamento e desenvolvimento de equipes mais eficazes e adaptáveis às demandas do processo de desenvolvimento de software. para isso, foi conduzida uma pesquisa com profissionais e líderes de equipes, visando entender as necessidades específicas de habilidades em cada fase do ciclo scrum."
5,2024,Hora do fuxico.,"AQUINO, Victor Hugo Sousa Rocha de.","GARCIA, Francilene Procópio.","O envelhecimento populacional é um fenômeno global que traz consigo desafios significativos relacionados ao bem-estar e à qualidade de vida dos idosos. A solidão e o isolamento social são problemas complexos que afetam a saúde mental, emocional e social dessa parcela da população. Nesse contexto, o aplicativo ""Hora do Fuxico"" é apresentado como solução inovadora para lidar com a carência de entretenimento e interação social por parte dos idosos. O aplicativo permite que os idosos se organizem em grupos e agendem encontros presenciais ou virtuais com base em temas de seu interesse. Sendo assim, esses encontros servem como ambiente onde eles podem compartilhar histórias, experiências e interesses em comum. Isso promove um senso de comunidade e apoio mútuo dentro do aplicativo, contribuindo para a saúde mental dos idosos, ao combater o isolamento social e proporcionar uma experiência enriquecedora de interação social. Utilizando uma abordagem metodológica que incluiu pesquisa de mercado, design centrado na usabilidade, desenvolvimento de software e testes, o aplicativo foi desenvolvido com sucesso. Sua diferenciação se dá na sua abordagem centrada nas necessidades específicas da comunidade idosa, oferecendo uma experiência única de interação e entretenimento.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38352,"o envelhecimento populacional é um fenômeno global que traz consigo desafios significativos relacionados ao bem-estar e à qualidade de vida dos idosos. a solidão e o isolamento social são problemas complexos que afetam a saúde mental, emocional e social dessa parcela da população. nesse contexto, o aplicativo ""hora do fuxico"" é apresentado como solução inovadora para lidar com a carência de entretenimento e interação social por parte dos idosos. o aplicativo permite que os idosos se organizem em grupos e agendem encontros presenciais ou virtuais com base em temas de seu interesse. sendo assim, esses encontros servem como ambiente onde eles podem compartilhar histórias, experiências e interesses em comum. isso promove um senso de comunidade e apoio mútuo dentro do aplicativo, contribuindo para a saúde mental dos idosos, ao combater o isolamento social e proporcionar uma experiência enriquecedora de interação social. utilizando uma abordagem metodológica que incluiu pesquisa de mercado, design centrado na usabilidade, desenvolvimento de software e testes, o aplicativo foi desenvolvido com sucesso. sua diferenciação se dá na sua abordagem centrada nas necessidades específicas da comunidade idosa, oferecendo uma experiência única de interação e entretenimento."
6,2024,Evaluating the effect of retrieval augmented generation in Mistral-7b-Instruct-v0.2’s clojure’s code review.,"ANDRADE, Victor Brandão de.","MONTEIRO, João Arthur Brunet.","Revisão de código é uma das atividades mais importantes da engenharia de software, visto que visa garantir a qualidade e confiabilidade do código, mas esse processo é feito majoritariamente de maneira manual, o que pode demandar tempo e tornar o processo oneroso e suscetível a falhas. O processo de revisão de código é um forte candidato para automação com objetivo de torná-lo mais eficiente e menos suscetível a falhas devido ao componente humano do processo. Neste trabalho, nós desejamos explorar a automação do processo de revisão de código através da aplicação de Grandes Modelos de Linguagem e uma técnica de otimização no contexto de revisão de código Clojure, que é uma linguagem de programação emergente. O Grande Modelo de Linguagem escolhido foi o Mistral-7B-Instruct-v0.2 e a técnica de otimização foi a Retrieval Augmented Generation (RAG), ambos os tópicos são discutidos nas seções seguintes deste trabalho. Nossos resultados mostram que o Mistral com e sem o uso da otimização com RAG pode revisar código como humanos, mas RAG não melhorou a revisão do modelo.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38351,"revisão de código é uma das atividades mais importantes da engenharia de software, visto que visa garantir a qualidade e confiabilidade do código, mas esse processo é feito majoritariamente de maneira manual, o que pode demandar tempo e tornar o processo oneroso e suscetível a falhas. o processo de revisão de código é um forte candidato para automação com objetivo de torná-lo mais eficiente e menos suscetível a falhas devido ao componente humano do processo. neste trabalho, nós desejamos explorar a automação do processo de revisão de código através da aplicação de grandes modelos de linguagem e uma técnica de otimização no contexto de revisão de código clojure, que é uma linguagem de programação emergente. o grande modelo de linguagem escolhido foi o mistral-7b-instruct-v0. e a técnica de otimização foi a retrieval augmented generation (rag), ambos os tópicos são discutidos nas seções seguintes deste trabalho. nossos resultados mostram que o mistral com e sem o uso da otimização com rag pode revisar código como humanos, mas rag não melhorou a revisão do modelo."
7,2024,Promovendo a inclusão educacional: uma plataforma Web acessível para apoio a estudantes da UFCG.,"NUNES, Sonaly Katly Garcia.","ARAÚJO, Joseana Macêdo Fechine Régis de.","A Educação Inclusiva é de suma importância e um direito garantido por lei. Para alcançar uma inclusão de forma efetiva, a comunicação desempenha um papel primordial. Essa comunicação deve ser eficiente, transparente e centralizada, permitindo que todos os agentes envolvidos tenham acesso às informações, aos documentos e até mesmo a uma análise sobre dados que descrevem um determinado cenário. A dispersão de informações em diferentes canais pode comprometer a experiência do usuário e prejudicar a acessibilidade, afetando a concepção de um ambiente inclusivo. Dentre as ações voltadas à acessibilidade e inclusão, na Universidade Federal de Campina Grande (UFCG), destaca-se o Núcleo de Acessibilidade e Inclusão (NAI), que tem por finalidade o atendimento a pessoas com deficiência física, sensorial, mental ou intelectual, transtornos globais do desenvolvimento e altas habilidades – superdotação. Nesse contexto, torna-se relevante a construção de um sistema integrado para o acesso eficiente a documentos, artigos, comunicados e outros materiais relevantes, fundamentais para estimular práticas inclusivas e sensibilizar a comunidade acadêmica sobre questões de acessibilidade e inclusão. Diante do exposto, o objetivo do trabalho consiste em desenvolver uma plataforma web que ofereça uma base de conhecimento, a ser gerenciada pelo NAI, para comunicação e disponibilização de conteúdo, além de possibilitar uma análise dos dados que representam o cenário atual da acessibilidade e inclusão na UFCG. A construção da plataforma foi conduzida a partir da estruturação completa do backend e frontend, garantindo que o frontend esteja adaptado, conforme as regras de acessibilidade digital.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38329,"a educação inclusiva é de suma importância e um direito garantido por lei. para alcançar uma inclusão de forma efetiva, a comunicação desempenha um papel primordial. essa comunicação deve ser eficiente, transparente e centralizada, permitindo que todos os agentes envolvidos tenham acesso às informações, aos documentos e até mesmo a uma análise sobre dados que descrevem um determinado cenário. a dispersão de informações em diferentes canais pode comprometer a experiência do usuário e prejudicar a acessibilidade, afetando a concepção de um ambiente inclusivo. dentre as ações voltadas à acessibilidade e inclusão, na universidade federal de campina grande (ufcg), destaca-se o núcleo de acessibilidade e inclusão (nai), que tem por finalidade o atendimento a pessoas com deficiência física, sensorial, mental ou intelectual, transtornos globais do desenvolvimento e altas habilidades – superdotação. nesse contexto, torna-se relevante a construção de um sistema integrado para o acesso eficiente a documentos, artigos, comunicados e outros materiais relevantes, fundamentais para estimular práticas inclusivas e sensibilizar a comunidade acadêmica sobre questões de acessibilidade e inclusão. diante do exposto, o objetivo do trabalho consiste em desenvolver uma plataforma web que ofereça uma base de conhecimento, a ser gerenciada pelo nai, para comunicação e disponibilização de conteúdo, além de possibilitar uma análise dos dados que representam o cenário atual da acessibilidade e inclusão na ufcg. a construção da plataforma foi conduzida a partir da estruturação completa do backend e frontend, garantindo que o frontend esteja adaptado, conforme as regras de acessibilidade digital."
8,2024,Reestruturação da ferramenta do ComPensar.,"SILVA, Sheilla da.","CAMPOS, Lívia Maria Rodrigues Sampaio.","O Pensamento Computacional fundamenta-se nas competências adquiridas por meio da Ciência da Computação. Com base nisso, surgiu o ComPensar, uma ferramenta web voltada para o desenvolvimento do pensamento computacional em conjunto com a matemática, direcionada à educação básica. Sua estrutura baseia-se na classificação das questões matemáticas conforme as competências do pensamento computacional que podem ser estimuladas durante o processo de resolução. No entanto, diversos fatores contribuíram para sua transformação em um sistema legado e inoperante. A ausência de contribuições ao longo de mais de 4 anos resultou na obsolescência das tecnologias empregadas tanto no frontend quanto no backend da ferramenta. Além disso, a inatividade do serviço de hospedagem do ComPensar, devido à ausência de requisições por parte dos usuários, culminou na perda do banco de dados devido à falta de consultas. A identificação desses problemas ressaltou a necessidade de uma reengenharia de software em conjunto com a engenharia reversa, visando reconstruir o sistema com tecnologias mais recentes. Esse processo foi dividido em etapas que culminaram no desenvolvimento de uma nova versão do ComPensar, agora disponível para acesso público. Em uma dessas etapas, foram realizadas avaliações para compreender o nível de satisfação do cliente com o software entregue, bem como análises de desempenho e indexação em motores de busca. Os resultados obtidos foram positivos. Na análise de desempenho, o ComPensar recebeu boas avaliações em categorias como acessibilidade, práticas recomendadas e SEO (Search Engine Optimization). Esses resultados contribuíram para a visibilidade da ferramenta nos motores de busca, os quais utilizam dados dessas categorias, como o carregamento de conteúdo e a acessibilidade, na atribuição de pontuação do ComPensar nos motores de busca.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38328,"o pensamento computacional fundamenta-se nas competências adquiridas por meio da ciência da computação. com base nisso, surgiu o compensar, uma ferramenta web voltada para o desenvolvimento do pensamento computacional em conjunto com a matemática, direcionada à educação básica. sua estrutura baseia-se na classificação das questões matemáticas conforme as competências do pensamento computacional que podem ser estimuladas durante o processo de resolução. no entanto, diversos fatores contribuíram para sua transformação em um sistema legado e inoperante. a ausência de contribuições ao longo de mais de anos resultou na obsolescência das tecnologias empregadas tanto no frontend quanto no backend da ferramenta. além disso, a inatividade do serviço de hospedagem do compensar, devido à ausência de requisições por parte dos usuários, culminou na perda do banco de dados devido à falta de consultas. a identificação desses problemas ressaltou a necessidade de uma reengenharia de software em conjunto com a engenharia reversa, visando reconstruir o sistema com tecnologias mais recentes. esse processo foi dividido em etapas que culminaram no desenvolvimento de uma nova versão do compensar, agora disponível para acesso público. em uma dessas etapas, foram realizadas avaliações para compreender o nível de satisfação do cliente com o software entregue, bem como análises de desempenho e indexação em motores de busca. os resultados obtidos foram positivos. na análise de desempenho, o compensar recebeu boas avaliações em categorias como acessibilidade, práticas recomendadas e seo (search engine optimization). esses resultados contribuíram para a visibilidade da ferramenta nos motores de busca, os quais utilizam dados dessas categorias, como o carregamento de conteúdo e a acessibilidade, na atribuição de pontuação do compensar nos motores de busca."
9,2024,Desenvolvimento do Microgram: um aplicativo para uso do telegram em relógios com Wear OS.,"MAIA, Ricardo de Andrade.","MONGIOVI, Melina.","Um dos principais motivos para a concepção dos smartwatches e wearables em geral é permitir que o usuário tenha acesso rápido às informações de sua vida digital sem as distrações de utilizar um smartphone. Porém, a má integração da maioria dos smartwatches com aplicativos de mensagens instantâneas induzem o usuário a usar o telefone, limitando o potencial desses dispositivos. Diante do exposto, foi proposto o desenvolvimento de uma versão do mensageiro Telegram para o sistema Wear OS. O Telegram é o 6º mensageiro mais utilizado do mundo, de código aberto, e permite apps de terceiros. O objetivo do aplicativo é permitir ao usuário ler e responder as mensagens diretamente no smartwatch poupado-os das distrações de usar o smartphone.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38327,"um dos principais motivos para a concepção dos smartwatches e wearables em geral é permitir que o usuário tenha acesso rápido às informações de sua vida digital sem as distrações de utilizar um smartphone. porém, a má integração da maioria dos smartwatches com aplicativos de mensagens instantâneas induzem o usuário a usar o telefone, limitando o potencial desses dispositivos. diante do exposto, foi proposto o desenvolvimento de uma versão do mensageiro telegram para o sistema wear os. o telegram é o 6º mensageiro mais utilizado do mundo, de código aberto, e permite apps de terceiros. o objetivo do aplicativo é permitir ao usuário ler e responder as mensagens diretamente no smartwatch poupado-os das distrações de usar o smartphone."
10,2024,Análise do uso de transformers na predição de séries temporais Campina Grande – PB.,"SENA, Ricardo Adley da Silva.","MORAIS, Fábio Jorge Almeida.","A arquitetura baseada em Transformers, desenvolvida para resolver problemas de machine learning relacionados ao processamento de linguagem natural, expandiu-se para outras áreas, como a previsão de séries temporais. Diferentes modelos, baseados em regressão ou árvores de decisão, são utilizados nesse campo, como o ARIMA , XGBoost e Prophet, por exemplo. Cada abordagem possui suas especificidades em termos de precisão e eficiência computacional, o que requer estudos para determinar a melhor a ser adotada em diferentes cenários. Nesse contexto, este trabalho visa apresentar resultados comparativos e analíticos de diferentes abordagens para previsão de séries temporais. Para tal, foi realizado um estudo comparativo analisando o uso da arquitetura baseada em Transformers e seu desempenho frente a modelos tradicionais, utilizando dados referentes aos registros de consumo energético da Universidade Federal de Campina Grande (UFCG). A partir dessa análise, foi possível analisar as abordagens em relação à precisão e eficiência computacional, verificando se a complexidade de uma abordagem mais sofisticada, como a dos Transformers, para previsão de séries temporais, se mostra superior em relação às outras abordagens populares utilizadas para esse fim.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38325,"a arquitetura baseada em transformers, desenvolvida para resolver problemas de machine learning relacionados ao processamento de linguagem natural, expandiu-se para outras áreas, como a previsão de séries temporais. diferentes modelos, baseados em regressão ou árvores de decisão, são utilizados nesse campo, como o arima , xgboost e prophet, por exemplo. cada abordagem possui suas especificidades em termos de precisão e eficiência computacional, o que requer estudos para determinar a melhor a ser adotada em diferentes cenários. nesse contexto, este trabalho visa apresentar resultados comparativos e analíticos de diferentes abordagens para previsão de séries temporais. para tal, foi realizado um estudo comparativo analisando o uso da arquitetura baseada em transformers e seu desempenho frente a modelos tradicionais, utilizando dados referentes aos registros de consumo energético da universidade federal de campina grande (ufcg). a partir dessa análise, foi possível analisar as abordagens em relação à precisão e eficiência computacional, verificando se a complexidade de uma abordagem mais sofisticada, como a dos transformers, para previsão de séries temporais, se mostra superior em relação às outras abordagens populares utilizadas para esse fim."
11,2024,Interpretabilidade de redes neurais convolucionais aplicadas a imagens de ressonância magnética.,"FREITAS, Rennan Rocha de.","GOMES, Herman Martins.","As redes neurais convolucionais atingiram acurácia similar à humana em diversas tarefas de visão computacional, porém a complexidade desses modelos, assim como o número crescente de parâmetros, criam representações de conhecimento e decisões que não são facilmente compreensíveis. Portanto, essas redes estão sendo usadas, na maioria das vezes, como algoritmos de caixa-preta. Dessa forma, é difícil a adoção de tais modelos em ambientes críticos que necessitem de explicações sobre seus resultados, como o contexto médico. Este estudo tem como objetivo treinar um classificador de imagens de tumores cerebrais a partir de um dataset com imagens de ressonância magnética, além de aplicar, avaliar e comparar técnicas de interpretabilidade nesse classificador. Como resultado, obtivemos um classificador com taxa de acurácia de 95% e uma parte das imagens do conjunto de teste foram explicadas através de 11 técnicas de interpretabilidade na vertente de atribuição de características. Em seguida as técnicas foram comparadas de forma subjetiva e objetiva revelando que a técnica RISE obteve a melhor pontuação objetiva dentre as técnicas avaliadas.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38322,"as redes neurais convolucionais atingiram acurácia similar à humana em diversas tarefas de visão computacional, porém a complexidade desses modelos, assim como o número crescente de parâmetros, criam representações de conhecimento e decisões que não são facilmente compreensíveis. portanto, essas redes estão sendo usadas, na maioria das vezes, como algoritmos de caixa-preta. dessa forma, é difícil a adoção de tais modelos em ambientes críticos que necessitem de explicações sobre seus resultados, como o contexto médico. este estudo tem como objetivo treinar um classificador de imagens de tumores cerebrais a partir de um dataset com imagens de ressonância magnética, além de aplicar, avaliar e comparar técnicas de interpretabilidade nesse classificador. como resultado, obtivemos um classificador com taxa de acurácia de % e uma parte das imagens do conjunto de teste foram explicadas através de técnicas de interpretabilidade na vertente de atribuição de características. em seguida as técnicas foram comparadas de forma subjetiva e objetiva revelando que a técnica rise obteve a melhor pontuação objetiva dentre as técnicas avaliadas."
12,2024,Aplicativo para gerência de transporte escolar para cidades de pequeno porte.,"MELO, Renildo Dantas.","ARAÚJO, Eliane Cristina de.","Em pequenas cidades, o transporte escolar é essencial para o acesso à educação em níveis não atendidos pelo município. Por ser essencial, uma boa gerência é necessária para que os recursos disponíveis sejam utilizados de forma eficiente. Este trabalho visa o desenvolvimento de um aplicativo Android para auxiliar a gerência dos recursos utilizados no transporte escolar, com foco direcionado a cidades de pequeno porte. O objetivo do aplicativo é auxiliar os gestores responsáveis pelo transporte escolar na cidade, proporcionando um maior controle sobre os recursos disponíveis e como estão sendo utilizados. Além disso, deverá prover informações pertinentes aos usuários do transporte, como horários, pontos de parada e identificação de veículos.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38315,"em pequenas cidades, o transporte escolar é essencial para o acesso à educação em níveis não atendidos pelo município. por ser essencial, uma boa gerência é necessária para que os recursos disponíveis sejam utilizados de forma eficiente. este trabalho visa o desenvolvimento de um aplicativo android para auxiliar a gerência dos recursos utilizados no transporte escolar, com foco direcionado a cidades de pequeno porte. o objetivo do aplicativo é auxiliar os gestores responsáveis pelo transporte escolar na cidade, proporcionando um maior controle sobre os recursos disponíveis e como estão sendo utilizados. além disso, deverá prover informações pertinentes aos usuários do transporte, como horários, pontos de parada e identificação de veículos."
13,2024,Otimizando testes de GUI com Iterative Deepening URL-Based Search.,"FELIPE, Regina Letícia Santos.","ALVES, Everton Leandro Galdino.","Testes automáticos em aplicações web são amplamente adotados devido à sua eficiência e relação custo-benefício. Quando realizados pela GUI, esses testes podem simular cenários de uso, com o objetivo de expor falhas visíveis. O scriptless testing, uma abordagem que gera e executa casos de teste automaticamente, pode adotar uma exploração sistemática da GUI. Entretanto, essa abordagem pode demandar um tempo significativo em aplicações web, principalmente numa execução com repetição em visitas de estados. Neste estudo, apresentamos o algoritmo Iterative Deepening URL-Based Search (IDUBS), que se associado ao uso de testes de GUI, resulta em uma exploração otimizada, utilizada para a redução da redundância em visita de estados. Avaliamos a eficácia do algoritmo em um estudo empírico com quatro sistemas web de código aberto, analisando sua contribuição para otimização do tempo de execução e redução da redundância em visita de estados. O IDUBS reduziu o tempo de execução em 39,03% e a redundância de casos de teste em 36,01%. Em suma, o algoritmo IDUBS apresenta uma solução promissora para otimizar a execução de testes em aplicações web, oferecendo benefícios significativos em termos de eficiência e redução de redundâncias.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38314,"testes automáticos em aplicações web são amplamente adotados devido à sua eficiência e relação custo-benefício. quando realizados pela gui, esses testes podem simular cenários de uso, com o objetivo de expor falhas visíveis. o scriptless testing, uma abordagem que gera e executa casos de teste automaticamente, pode adotar uma exploração sistemática da gui. entretanto, essa abordagem pode demandar um tempo significativo em aplicações web, principalmente numa execução com repetição em visitas de estados. neste estudo, apresentamos o algoritmo iterative deepening url-based search (idubs), que se associado ao uso de testes de gui, resulta em uma exploração otimizada, utilizada para a redução da redundância em visita de estados. avaliamos a eficácia do algoritmo em um estudo empírico com quatro sistemas web de código aberto, analisando sua contribuição para otimização do tempo de execução e redução da redundância em visita de estados. o idubs reduziu o tempo de execução em , % e a redundância de casos de teste em , %. em suma, o algoritmo idubs apresenta uma solução promissora para otimizar a execução de testes em aplicações web, oferecendo benefícios significativos em termos de eficiência e redução de redundâncias."
14,2024,Análise comparativa entre Docker Swarm e Kubernetes em ambientes de nuvem.,"AGRA, Raphael Henrique de Lucena.","GOMES, Reinaldo Cézar de Morais.","Os contêineres são uma solução amplamente adotada na indústria de tecnologia, graças à sua flexibilidade e escalabilidade. Nesse contexto, a gestão eficiente dos contêineres é essencial para garantir a disponibilidade e o desempenho do sistema. Por esse motivo, há uma grande variedade de ferramentas de gerenciamento disponíveis, cada uma adequada para diferentes casos de uso. O objetivo deste estudo é analisar e comparar o desempenho de duas das principais ferramentas de orquestração de containers, o Docker Swarm e o Kubernetes, em ambientes de nuvem. Para realizar esta análise comparativa de desempenho, serão realizados testes de carga em ambas as plataformas e os resultados serão comparados. Os testes serão executados em um ambiente de nuvem pública, com diferentes tamanhos de cluster e cargas de trabalho. Os critérios de avaliação serão seis: complexidade de configuração, tempo de implantação de containers, escalabilidade, uso de recursos de CPU e memória e disponibilidade. Os resultados dessa análise comparativa de desempenho permitirão contribuir para a identificação de qual ferramenta é mais adequada para diferentes cenários e cargas de trabalho.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38302,"os contêineres são uma solução amplamente adotada na indústria de tecnologia, graças à sua flexibilidade e escalabilidade. nesse contexto, a gestão eficiente dos contêineres é essencial para garantir a disponibilidade e o desempenho do sistema. por esse motivo, há uma grande variedade de ferramentas de gerenciamento disponíveis, cada uma adequada para diferentes casos de uso. o objetivo deste estudo é analisar e comparar o desempenho de duas das principais ferramentas de orquestração de containers, o docker swarm e o kubernetes, em ambientes de nuvem. para realizar esta análise comparativa de desempenho, serão realizados testes de carga em ambas as plataformas e os resultados serão comparados. os testes serão executados em um ambiente de nuvem pública, com diferentes tamanhos de cluster e cargas de trabalho. os critérios de avaliação serão seis: complexidade de configuração, tempo de implantação de containers, escalabilidade, uso de recursos de cpu e memória e disponibilidade. os resultados dessa análise comparativa de desempenho permitirão contribuir para a identificação de qual ferramenta é mais adequada para diferentes cenários e cargas de trabalho."
15,2024,Sol proceedings: extensão chrome para a criação de proceedings para a sol.,"FONSECA, Raphael de Paula.","GHEYI, Rohit.","A Sociedade Brasileira de Computação (SBC) promove diversos eventos científicos e alguns deles são publicados na biblioteca digital SOL (SBC OpenLib). Após o processo de avaliação dos artigos ser concluído, os coordenadores de eventos (chairs) precisam preparar a documentação para enviar para a publicação dos anais dos eventos (proceedings) na biblioteca digital. No entanto, a quantidade de artigos e o trabalho manual envolvido na extração dos campos para a criação dos proceedings demandam muito tempo, tornando o processo lento e sujeito a erros humanos. Além disso, não existe uma ferramenta que extraia todos os campos de forma automatizada. Dessa forma, o objetivo deste trabalho é desenvolver uma ferramenta que reduza o máximo possível esse trabalho manual no contexto de trabalhos publicados na plataforma SOL e que seguem o estilo da SBC. Com isso, a maior parte da informação será extraída a partir do conteúdo da versão final dos artigos em formato PDF. E a SOL Proceedings é uma extensão do navegador Google Chrome devido a facilidade para o usuário que ela fornece. Alguns testes com proceedings já publicados foram realizados, e a ferramenta consegue reduzir o esforço na preparação dos proceedings.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38301,"a sociedade brasileira de computação (sbc) promove diversos eventos científicos e alguns deles são publicados na biblioteca digital sol (sbc openlib). após o processo de avaliação dos artigos ser concluído, os coordenadores de eventos (chairs) precisam preparar a documentação para enviar para a publicação dos anais dos eventos (proceedings) na biblioteca digital. no entanto, a quantidade de artigos e o trabalho manual envolvido na extração dos campos para a criação dos proceedings demandam muito tempo, tornando o processo lento e sujeito a erros humanos. além disso, não existe uma ferramenta que extraia todos os campos de forma automatizada. dessa forma, o objetivo deste trabalho é desenvolver uma ferramenta que reduza o máximo possível esse trabalho manual no contexto de trabalhos publicados na plataforma sol e que seguem o estilo da sbc. com isso, a maior parte da informação será extraída a partir do conteúdo da versão final dos artigos em formato pdf. e a sol proceedings é uma extensão do navegador google chrome devido a facilidade para o usuário que ela fornece. alguns testes com proceedings já publicados foram realizados, e a ferramenta consegue reduzir o esforço na preparação dos proceedings."
16,2024,Controle de acesso utilizando SPIRE e monitoramento de um cluster Kafka no ambiente do SmartCampus na UFCG.,"SOUTO, Raisson Adrian Grangeiro.","BRITO, Andrey Elisio Monteiro.","No contexto do projeto do SmartCampus, da Universidade Federal de Campina Grande (UFCG), a disponibilização de um Kafka contendo informações de consumo de energia apresenta desafios complexos relacionados à segurança e controle de acesso. Diversas entidades, incluindo desenvolvedores, usuários finais e operadores dos sistemas de produção, necessitam interagir com esse Kafka a partir de ambientes variados, criando a necessidade de diferenciar e controlar o acesso de maneira eficaz. Este trabalho explora estratégias fundamentadas no modelo Zero Trust, que preconiza a autenticação contínua e autorização granular, garantindo que cada acesso seja verificado e autenticado. Adotando o SPIRE em conjunto com uma série de outros microsserviços, busca-se assegurar a autenticação segura por meio de identidades SPIFFE, bem como configurar um serviço de autorização personalizado de acordo com o perfil do usuário. O objetivo é prevenir acesso inadequado, vazamento de dados e manipulações indevidas, visando obter um ambiente seguro e confiável para a implantação do projeto. Por fim, também é desejado obter métricas para monitoramento das ferramentas utilizadas, a fim de identificar anomalias e falhas rapidamente.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38300,"no contexto do projeto do smartcampus, da universidade federal de campina grande (ufcg), a disponibilização de um kafka contendo informações de consumo de energia apresenta desafios complexos relacionados à segurança e controle de acesso. diversas entidades, incluindo desenvolvedores, usuários finais e operadores dos sistemas de produção, necessitam interagir com esse kafka a partir de ambientes variados, criando a necessidade de diferenciar e controlar o acesso de maneira eficaz. este trabalho explora estratégias fundamentadas no modelo zero trust, que preconiza a autenticação contínua e autorização granular, garantindo que cada acesso seja verificado e autenticado. adotando o spire em conjunto com uma série de outros microsserviços, busca-se assegurar a autenticação segura por meio de identidades spiffe, bem como configurar um serviço de autorização personalizado de acordo com o perfil do usuário. o objetivo é prevenir acesso inadequado, vazamento de dados e manipulações indevidas, visando obter um ambiente seguro e confiável para a implantação do projeto. por fim, também é desejado obter métricas para monitoramento das ferramentas utilizadas, a fim de identificar anomalias e falhas rapidamente."
17,2024,Análise do desempenho de perceptrons multicamada modernos na classificação de objetos do cotidiano.,"SANTOS NETO, Pedro Raimundo dos.","GOMES, Herman Martins.","Dispositivos eletrônicos que auxiliam em tarefas domésticas vem ganhando popularidade nos últimos anos e ajudam as pessoas a ganhar tempo nas suas rotinas. Indivíduos com limitações físicas necessitam ainda mais de suporte nas suas atividades cotidianas. Contudo, não existem muitas soluções na atualidade que consigam desempenhar tarefas normalmente executadas por humanos, devido a limitações de hardware, por exemplo. Uma habilidade importante é o reconhecimento de objetos em uma cena visual. Dessa forma, esta pesquisa tem por objetivo avaliar o desempenho de alguns modelos baseados em perceptron multicamada (MLP) em classificar imagens de objetos comumente encontrados em ambientes domésticos, para verificar a eficácia dessas soluções nesse contexto de aplicação. Foram conduzidos experimentos de classificação com os modelos, observando as métricas obtidas, como acurácia, tempos de treinamento e teste, para qualificar o desempenho. A análise dos modelos confirmou a capacidade de classificar os objetos com uma boa taxa de acerto. Os resultados obtidos indicam que é possível aplicar MLPs em soluções de auxílio a atividades domésticas, reduzindo o custo computacional de implementação em relação a modelos mais complexos.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38299,"dispositivos eletrônicos que auxiliam em tarefas domésticas vem ganhando popularidade nos últimos anos e ajudam as pessoas a ganhar tempo nas suas rotinas. indivíduos com limitações físicas necessitam ainda mais de suporte nas suas atividades cotidianas. contudo, não existem muitas soluções na atualidade que consigam desempenhar tarefas normalmente executadas por humanos, devido a limitações de hardware, por exemplo. uma habilidade importante é o reconhecimento de objetos em uma cena visual. dessa forma, esta pesquisa tem por objetivo avaliar o desempenho de alguns modelos baseados em perceptron multicamada (mlp) em classificar imagens de objetos comumente encontrados em ambientes domésticos, para verificar a eficácia dessas soluções nesse contexto de aplicação. foram conduzidos experimentos de classificação com os modelos, observando as métricas obtidas, como acurácia, tempos de treinamento e teste, para qualificar o desempenho. a análise dos modelos confirmou a capacidade de classificar os objetos com uma boa taxa de acerto. os resultados obtidos indicam que é possível aplicar mlps em soluções de auxílio a atividades domésticas, reduzindo o custo computacional de implementação em relação a modelos mais complexos."
18,2024,Solução de IoT analytics para sensores ambientais.,"ALVES, Pedro Manoel Herminio.","BAPTISTA, Cláudio de Souza.","Em um mundo onde a preocupação com o meio ambiente e a saúde pública está em ascensão, a necessidade de sistemas de monitoramento ambiental é cada vez mais premente. Os sensores ambientais são fundamentais neste cenário, coletando uma variedade de métricas que espelham as condições do ambiente, incluindo qualidade do ar, temperatura, umidade e pressão atmosférica. A solução proposta neste estudo tem como objetivo coletar, analisar e visualizar dados em tempo real e históricos, proporcionando uma compreensão mais completa das condições ambientais e permitindo a implementação de medidas preventivas. Utilizando ferramentas de código aberto e uma abordagem baseada em containers, juntamente com os princípios de uma arquitetura em microsserviços, a solução busca aprimorar a eficiência e a precisão do monitoramento ambiental. Esta solução pode servir como um modelo replicável para desafios semelhantes em outras áreas ou contextos que requerem processamento e análises de dados em tempo real. Este estudo apresenta uma solução de IoT Analytics para sensores ambientais, focada na monitorização de métricas ambientais. A eficácia desta solução foi comprovada no estado do Acre, através de um estudo comparativo que a colocou à prova contra uma solução já existente.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38298,"em um mundo onde a preocupação com o meio ambiente e a saúde pública está em ascensão, a necessidade de sistemas de monitoramento ambiental é cada vez mais premente. os sensores ambientais são fundamentais neste cenário, coletando uma variedade de métricas que espelham as condições do ambiente, incluindo qualidade do ar, temperatura, umidade e pressão atmosférica. a solução proposta neste estudo tem como objetivo coletar, analisar e visualizar dados em tempo real e históricos, proporcionando uma compreensão mais completa das condições ambientais e permitindo a implementação de medidas preventivas. utilizando ferramentas de código aberto e uma abordagem baseada em containers, juntamente com os princípios de uma arquitetura em microsserviços, a solução busca aprimorar a eficiência e a precisão do monitoramento ambiental. esta solução pode servir como um modelo replicável para desafios semelhantes em outras áreas ou contextos que requerem processamento e análises de dados em tempo real. este estudo apresenta uma solução de iot analytics para sensores ambientais, focada na monitorização de métricas ambientais. a eficácia desta solução foi comprovada no estado do acre, através de um estudo comparativo que a colocou à prova contra uma solução já existente."
19,2024,Aplicando técnicas de aprendizado de máquina na previsão em tempo real de resultados de partidas de futebol: rocket e multirocket.,"RIBEIRO, Pedro Antônio Barboza.","MARINHO, Leandro Balby.","Dada a grande popularidade do futebol e do mercado de apostas associado, uma melhoria na precisão das previsões tem implicações significativas, tanto do ponto de vista técnico quanto econômico. Tendo isso em mente, o projeto proposto visa explorar, desenvolver e avaliar diversos algoritmos de aprendizado de máquina, incluindo diferentes arquiteturas de redes neurais, para a complexa tarefa de prever resultados de partidas de futebol em tempo real. Ao utilizar uma gama de variáveis estatísticas (como cartões, chutes a gol, faltas, ataques perigosos, escanteios e gols) em uma série temporal que representa o estado do jogo, o projeto contribui para o avanço do campo da análise de dados esportivos e tem o potencial de influenciar o mercado de apostas esportivas. Esse projeto, portanto, não é apenas acadêmicamente relevante, mas também tem um alto valor comercial e social, podendo influenciar a forma como estratégias de apostas são formuladas e talvez até mesmo como o jogo é jogado e analisado.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38291,"dada a grande popularidade do futebol e do mercado de apostas associado, uma melhoria na precisão das previsões tem implicações significativas, tanto do ponto de vista técnico quanto econômico. tendo isso em mente, o projeto proposto visa explorar, desenvolver e avaliar diversos algoritmos de aprendizado de máquina, incluindo diferentes arquiteturas de redes neurais, para a complexa tarefa de prever resultados de partidas de futebol em tempo real. ao utilizar uma gama de variáveis estatísticas (como cartões, chutes a gol, faltas, ataques perigosos, escanteios e gols) em uma série temporal que representa o estado do jogo, o projeto contribui para o avanço do campo da análise de dados esportivos e tem o potencial de influenciar o mercado de apostas esportivas. esse projeto, portanto, não é apenas acadêmicamente relevante, mas também tem um alto valor comercial e social, podendo influenciar a forma como estratégias de apostas são formuladas e talvez até mesmo como o jogo é jogado e analisado."
20,2024,Avaliação de performance de algoritmos de reconhecimento de acordes musicais.,"MARTINEZ, Pedro Adrian Pereira.","MARINHO, Leandro Balby.","No contexto musical, a progressão de acordes é capaz de capturar diversas características de mais alto nível de uma música, como por exemplo os possíveis sentimentos associados, o gênero, a tonalidade da música, o ritmo, etc. No entanto, a identificação da progressão de acordes é um processo que demanda a atuação de especialistas, e é um processo que se torna inviável de ser feito manualmente em grandes bases de dados. Assim, surgiu a necessidade da concepção de classificadores que pudessem extrair essa informação a partir de um sinal sonoro. O objetivo deste trabalho é realizar uma avaliação da performance de algoritmos voltados para esse fim que estão disponibilizados publicamente, verificando quais são as estratégias de aprendizagem utilizadas nos algoritmos que são mais promissoras, assim como identificar as maiores lacunas existentes nesses modelos, de modo a guiar futuros esforços na criação de novos classificadores, e datasets de treinamento.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38290,"no contexto musical, a progressão de acordes é capaz de capturar diversas características de mais alto nível de uma música, como por exemplo os possíveis sentimentos associados, o gênero, a tonalidade da música, o ritmo, etc. no entanto, a identificação da progressão de acordes é um processo que demanda a atuação de especialistas, e é um processo que se torna inviável de ser feito manualmente em grandes bases de dados. assim, surgiu a necessidade da concepção de classificadores que pudessem extrair essa informação a partir de um sinal sonoro. o objetivo deste trabalho é realizar uma avaliação da performance de algoritmos voltados para esse fim que estão disponibilizados publicamente, verificando quais são as estratégias de aprendizagem utilizadas nos algoritmos que são mais promissoras, assim como identificar as maiores lacunas existentes nesses modelos, de modo a guiar futuros esforços na criação de novos classificadores, e datasets de treinamento."
21,2024,Avaliação de embeddings geográficos em sistemas de recomendação de POIs.,"LEITE, Nícolas Moreira Nobre.","CAMPELO, Claudio Elízio Calazans.","A recomendação de Pontos de Interesse (POIs) ganha destaque no contexto de sistemas de recomendação (SRs), especialmente com o crescimento de Redes Sociais Baseadas em Localização, como Foursquare, Gowalla e Yelp. A qualidade dessas recomendações é essencial para enriquecer a experiência do usuário nessas plataformas, facilitando a sociabilidade e promovendo o turismo, além de levantar uma série de desafios para a comunidade. No entanto, os sistemas tradicionais de recomendação de POIs frequentemente se limitam a considerar informações como avaliações de locais, fotos, horários de acesso e check-ins, negligenciando dados geográficos relevantes, como feições geográficas que incluem rios, edifícios, ruas e lagos no contexto de um POI. Essas feições podem influenciar significativamente as preferências dos usuários, uma vez que eles podem visitar um POI por gostar das feições geográficas Presentes no ambiente. Como exemplo, algumas pessoas preferem cafeterias próximas a lagos e áreas arborizadas em vez de rodovias movimentadas. Neste estudo, propomos e avaliamos a utilização de embeddingsgegráficos que incorporam feições geográficas para aprimorar SRs de POIs. Os resultados indicaram que o uso dos embeddings que consideram as feições aumentou a acurácia e o MRR em até 1.65% na tarefa de recomendação do próximo POI no conjunto de dados utilizado, em comparação ao baseline, confirmando a importância das feições geográficas para melhorar SRs de POIs.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38289,"a recomendação de pontos de interesse (pois) ganha destaque no contexto de sistemas de recomendação (srs), especialmente com o crescimento de redes sociais baseadas em localização, como foursquare, gowalla e yelp. a qualidade dessas recomendações é essencial para enriquecer a experiência do usuário nessas plataformas, facilitando a sociabilidade e promovendo o turismo, além de levantar uma série de desafios para a comunidade. no entanto, os sistemas tradicionais de recomendação de pois frequentemente se limitam a considerar informações como avaliações de locais, fotos, horários de acesso e check-ins, negligenciando dados geográficos relevantes, como feições geográficas que incluem rios, edifícios, ruas e lagos no contexto de um poi. essas feições podem influenciar significativamente as preferências dos usuários, uma vez que eles podem visitar um poi por gostar das feições geográficas presentes no ambiente. como exemplo, algumas pessoas preferem cafeterias próximas a lagos e áreas arborizadas em vez de rodovias movimentadas. neste estudo, propomos e avaliamos a utilização de embeddingsgegráficos que incorporam feições geográficas para aprimorar srs de pois. os resultados indicaram que o uso dos embeddings que consideram as feições aumentou a acurácia e o mrr em até . % na tarefa de recomendação do próximo poi no conjunto de dados utilizado, em comparação ao baseline, confirmando a importância das feições geográficas para melhorar srs de pois."
22,2024,Os impactos presentes e futuros do avanço da IA na medicina: uma revisão integrativa.,"LUCENA, Natan Vinícius da Silva.","ARAÚJO, Joseana Macêdo Fechine Régis de.","O avanço da Inteligência Artificial (IA) está redefinindo as fronteiras da medicina contemporânea, oferecendo novas possibilidades e desafios. Este trabalho tem como objetivo analisar os impactos presentes e futuros da IA na prática médica, destacando sua influência transformadora. Ao definir IA como a capacidade de sistemas computacionais executarem tarefas que exigem inteligência humana, exploramos como essas tecnologias estão sendo aplicadas com sucesso na medicina, desde diagnósticos mais precisos até o desenvolvimento de terapias personalizadas. Ao longo deste estudo, será demonstrado que, embora a IA traga benefícios significativos para a prática médica, ela não substituirá completamente o papel dos médicos, principalmente pela falta de sentimentos inerentemente humanos. Utilizando uma variedade de fontes, e analisando o impacto da inteligência artificial em diferentes setores da medicina, faremos uma análise equilibrada para buscar compreender como a IA está moldando o presente e o futuro da medicina. Dessa forma, o presente trabalho busca contribuir para uma compreensão mais profunda das implicações da IA na área da saúde e fornecer insights valiosos para profissionais e pesquisadores interessados neste campo em rápida evolução.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38261,"o avanço da inteligência artificial (ia) está redefinindo as fronteiras da medicina contemporânea, oferecendo novas possibilidades e desafios. este trabalho tem como objetivo analisar os impactos presentes e futuros da ia na prática médica, destacando sua influência transformadora. ao definir ia como a capacidade de sistemas computacionais executarem tarefas que exigem inteligência humana, exploramos como essas tecnologias estão sendo aplicadas com sucesso na medicina, desde diagnósticos mais precisos até o desenvolvimento de terapias personalizadas. ao longo deste estudo, será demonstrado que, embora a ia traga benefícios significativos para a prática médica, ela não substituirá completamente o papel dos médicos, principalmente pela falta de sentimentos inerentemente humanos. utilizando uma variedade de fontes, e analisando o impacto da inteligência artificial em diferentes setores da medicina, faremos uma análise equilibrada para buscar compreender como a ia está moldando o presente e o futuro da medicina. dessa forma, o presente trabalho busca contribuir para uma compreensão mais profunda das implicações da ia na área da saúde e fornecer insights valiosos para profissionais e pesquisadores interessados neste campo em rápida evolução."
23,2024,Busca por produtos: um estudo comparativo de abordagens léxicas e semânticas.,"SILVA, Melquisedeque Carvalho.","BAPTISTA, Cláudio de Souza.","A busca por produtos é uma funcionalidade fundamental que permite aos usuários localizar e adquirir itens específicos, sendo aplicada em diversos contextos, como e-commerces e sites de comparação de preços. Este estudo compara abordagens léxicas e semânticas para a realização dessa funcionalidade. Embora a busca léxica possua vantagens em termos de tempo de resposta, ela não captura relações semânticas entre palavras além das similaridades léxicas. Por outro lado, a busca semântica destaca-se ao capturar semanticamente a relação entre os termos, porém, além de possuir maior complexidade, ela também pode ser mais lenta. Neste trabalho, analisamos as abordagens léxico-semânticas para dados de produtos, especificamente em dois conjuntos de dados: Catálogo de Materiais do Governo Federal e descrições de produtos presentes em notas fiscais. Comparamos as estratégias de busca considerando a relevância dos resultados e o tempo de resposta. Os conjuntos de dados possuem características distintas, com o catálogo de materiais sendo mais formal e estruturado, enquanto as notas fiscais contêm textos mais curtos e informais, frequentemente com siglas e abreviações. Este estudo comparativo busca identificar os trade-offs entre as abordagens léxicas e semânticas, bem como encontrar as estratégias mais adequadas para cada tipo de dado. Os resultados contribuem para a seleção de mecanismos de busca mais eficazes em catálogos de produtos, considerando diferentes formas de organização dos dados.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38259,"a busca por produtos é uma funcionalidade fundamental que permite aos usuários localizar e adquirir itens específicos, sendo aplicada em diversos contextos, como e-commerces e sites de comparação de preços. este estudo compara abordagens léxicas e semânticas para a realização dessa funcionalidade. embora a busca léxica possua vantagens em termos de tempo de resposta, ela não captura relações semânticas entre palavras além das similaridades léxicas. por outro lado, a busca semântica destaca-se ao capturar semanticamente a relação entre os termos, porém, além de possuir maior complexidade, ela também pode ser mais lenta. neste trabalho, analisamos as abordagens léxico-semânticas para dados de produtos, especificamente em dois conjuntos de dados: catálogo de materiais do governo federal e descrições de produtos presentes em notas fiscais. comparamos as estratégias de busca considerando a relevância dos resultados e o tempo de resposta. os conjuntos de dados possuem características distintas, com o catálogo de materiais sendo mais formal e estruturado, enquanto as notas fiscais contêm textos mais curtos e informais, frequentemente com siglas e abreviações. este estudo comparativo busca identificar os trade-offs entre as abordagens léxicas e semânticas, bem como encontrar as estratégias mais adequadas para cada tipo de dado. os resultados contribuem para a seleção de mecanismos de busca mais eficazes em catálogos de produtos, considerando diferentes formas de organização dos dados."
24,2024,Automação de testes de penetração em aplicações web em ambien-tes de integração contínua.,"MONTE, Maurício Marques da Silva.","ANDRADE, Wilkerson de Lucena.","As aplicações web são os principais alvos de ataques cibernéticos, por causa disso a realização de testes que identificam vulnerabilidades neste tipo de sistema é algo primordial. A realização destes testes costuma ser demorada se executada de forma totalmente manual, mas já existem ferramentas que automatizam partes desse tipo de teste. No entanto, ainda existe o problema de escolher qual ferramenta utilizar, dentre as várias disponíveis atualmente. Assim, foi realizado um estudo de caso para comparar várias ferramentas que identificam vulnerabilidades através de análise estática. Das ferramentas selecionadas, a ferramenta Bearer foi a que teve o melhor desempenho na detecção de vulnerabilidades descritas na lista OWASP Top Ten.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38258,"as aplicações web são os principais alvos de ataques cibernéticos, por causa disso a realização de testes que identificam vulnerabilidades neste tipo de sistema é algo primordial. a realização destes testes costuma ser demorada se executada de forma totalmente manual, mas já existem ferramentas que automatizam partes desse tipo de teste. no entanto, ainda existe o problema de escolher qual ferramenta utilizar, dentre as várias disponíveis atualmente. assim, foi realizado um estudo de caso para comparar várias ferramentas que identificam vulnerabilidades através de análise estática. das ferramentas selecionadas, a ferramenta bearer foi a que teve o melhor desempenho na detecção de vulnerabilidades descritas na lista owasp top ten."
25,2024,Vieses em algoritmos de reconhecimento facial: um mapeamento sistemático da literatura.,"SILVA, Matheus Thiago Domingos da.","MASSONI, Tiago Lima.","O reconhecimento facial é uma ferramenta bastante popular em aplicativos, utilizada princi-palmente na autenticação. Devido à sua popularidade, surgiu o questionamento se ela é justa em reconhecer faces de pessoas de diferentes gêneros e etnias. Então, foi desenvolvido um mapeamento sistemático para analisar viés em algoritmos de reconhecimento facial. Estudando diversos artigos científicos, foi possível identificar que os sistemas de uso comercial apresentam viés, evidenciando que a base de dados usada pelo algoritmo não é representativa o suficiente para pessoas de diferentes nacionalidades. Isso foi mostrado através de diversos experimentos, indicando que a solução mais eficiente para mitigar o viés é uma base de dados equilibrada. Este artigo serve como base para que estudos futuros busquem soluções práticas e eficientes.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38257,"o reconhecimento facial é uma ferramenta bastante popular em aplicativos, utilizada princi-palmente na autenticação. devido à sua popularidade, surgiu o questionamento se ela é justa em reconhecer faces de pessoas de diferentes gêneros e etnias. então, foi desenvolvido um mapeamento sistemático para analisar viés em algoritmos de reconhecimento facial. estudando diversos artigos científicos, foi possível identificar que os sistemas de uso comercial apresentam viés, evidenciando que a base de dados usada pelo algoritmo não é representativa o suficiente para pessoas de diferentes nacionalidades. isso foi mostrado através de diversos experimentos, indicando que a solução mais eficiente para mitigar o viés é uma base de dados equilibrada. este artigo serve como base para que estudos futuros busquem soluções práticas e eficientes."
26,2024,Automação de verificações manuais em processos de KYC.,"OLIVEIRA, Matheus Henrique Guedes de.","MONTEIRO, João Arthur Brunet.","Nos últimos anos, as apostas esportivas têm experimentado um crescimento rápido devido à digitalização e à acessibilidade das plataformas online. Contudo, esse aumento também gerou desafios, como a integridade do mercado, o combate a práticas de crime organizado, como lavagem de dinheiro, e a proteção dos consumidores. Nesse cenário, os processos de verificação e validação de documentos, conhecidos como KYC (Know Your Customer - Conheça seu Cliente), tornaram-se essenciais para garantir a conformidade regulatória e a segurança dos usuários. Este estudo se concentra nos desafios enfrentados pelas casas de apostas ao implementar os processos de KYC em conformidade com as regulamentações, especialmente na necessidade de análise manual para validar os processos de verificação de KYC. Essas verificações manuais são tipicamente demoradas e custosas. Diante desse cenário, foi desenvolvida uma ferramenta de automação que utiliza um modelo LLM (Large Language Model) para reduzir a dependência de intervenções humanas e aprimora a eficiência no processo de verificação de documentos de KYC. A metodologia utilizada abrangeu uma amostra de 163 dados de usuários do período de 26 de Dezembro de 2023 a 26 de Fevereiro de 2024, levando em consideração as principais falhas identificadas durante esse intervalo de tempo. Os resultados obtidos mostram uma melhoria significativa na performance das verificações de análises manuais. Dessa forma, da amostra realizada com 163 casos o algoritmo forneceu um veredito para 73.6% casos, com precisão de 81,05% na categorização correta do status da análise do usuário. Isso destaca a eficácia geral do algoritmo, tornando o processo mais ágil e eficiente, reduzindo significativamente a carga de trabalho humana e, em contra partida, 26.4% dos casos ainda exigiram análise manual para maior precisão, evidenciando situações em que o algoritmo não conseguiu tomar uma decisão automática. Contudo, a pesquisa não apenas oferece uma solução prática e tecnológica para os desafios enfrentados pelas casas de apostas, mas também contribui para o avanço na automação de processos de verificação de documentos em ambientes regulamentados.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38256,"nos últimos anos, as apostas esportivas têm experimentado um crescimento rápido devido à digitalização e à acessibilidade das plataformas online. contudo, esse aumento também gerou desafios, como a integridade do mercado, o combate a práticas de crime organizado, como lavagem de dinheiro, e a proteção dos consumidores. nesse cenário, os processos de verificação e validação de documentos, conhecidos como kyc (know your customer - conheça seu cliente), tornaram-se essenciais para garantir a conformidade regulatória e a segurança dos usuários. este estudo se concentra nos desafios enfrentados pelas casas de apostas ao implementar os processos de kyc em conformidade com as regulamentações, especialmente na necessidade de análise manual para validar os processos de verificação de kyc. essas verificações manuais são tipicamente demoradas e custosas. diante desse cenário, foi desenvolvida uma ferramenta de automação que utiliza um modelo llm (large language model) para reduzir a dependência de intervenções humanas e aprimora a eficiência no processo de verificação de documentos de kyc. a metodologia utilizada abrangeu uma amostra de dados de usuários do período de de dezembro de a de fevereiro de , levando em consideração as principais falhas identificadas durante esse intervalo de tempo. os resultados obtidos mostram uma melhoria significativa na performance das verificações de análises manuais. dessa forma, da amostra realizada com casos o algoritmo forneceu um veredito para . % casos, com precisão de , % na categorização correta do status da análise do usuário. isso destaca a eficácia geral do algoritmo, tornando o processo mais ágil e eficiente, reduzindo significativamente a carga de trabalho humana e, em contra partida, . % dos casos ainda exigiram análise manual para maior precisão, evidenciando situações em que o algoritmo não conseguiu tomar uma decisão automática. contudo, a pesquisa não apenas oferece uma solução prática e tecnológica para os desafios enfrentados pelas casas de apostas, mas também contribui para o avanço na automação de processos de verificação de documentos em ambientes regulamentados."
27,2024,STEQ: Sistema de Transporte Escolar de Queimadas.,"ANDRADE, Matheus Forlán Bezerra.","MASSONI, Tiago Lima.","Em Queimadas-PB, centenas de estudantes dependem do ônibus escolar diariamente para alcançar suas escolas e universidades em Campina Grande. As informações de horários, rotas e motoristas são atualmente compartilhadas por meio de grupos no WhatsApp e resultam em desinformação e estresse todos os dias devido ao grande número de mensagens, pois há centenas de alunos inseridos neles de diferentes escolas e faculdades, principalmente em dias quando há alguma mudança. O problema central é a ausência de uma plataforma que forneça informações unificadas e atualizadas sobre o transporte estudantil. Essa falta de informações organizadas impacta negativamente o desempenho escolar dos alunos, causando frustrações, faltas e gastos adicionais com transporte. A proposta consiste em desenvolver uma plataforma web acessível e responsiva, que sirva como fonte confiável para os estudantes obterem esses dados de forma precisa, eliminando a necessidade de depender de grupos de mensagens. A metodologia abrange entrevistar alunos, motoristas e a secretaria de transportes para levantar requisitos, juntamente com o desenvolvimento de uma plataforma web, com foco em usabilidade e interface intuitiva. Espera-se que a implementação reduza significativamente a desorganização, desinformação, o estresse e os atrasos enfrentados pelos estudantes, melhorando a frequência escolar e, consequentemente, o desempenho acadêmico.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38206,"em queimadas-pb, centenas de estudantes dependem do ônibus escolar diariamente para alcançar suas escolas e universidades em campina grande. as informações de horários, rotas e motoristas são atualmente compartilhadas por meio de grupos no whatsapp e resultam em desinformação e estresse todos os dias devido ao grande número de mensagens, pois há centenas de alunos inseridos neles de diferentes escolas e faculdades, principalmente em dias quando há alguma mudança. o problema central é a ausência de uma plataforma que forneça informações unificadas e atualizadas sobre o transporte estudantil. essa falta de informações organizadas impacta negativamente o desempenho escolar dos alunos, causando frustrações, faltas e gastos adicionais com transporte. a proposta consiste em desenvolver uma plataforma web acessível e responsiva, que sirva como fonte confiável para os estudantes obterem esses dados de forma precisa, eliminando a necessidade de depender de grupos de mensagens. a metodologia abrange entrevistar alunos, motoristas e a secretaria de transportes para levantar requisitos, juntamente com o desenvolvimento de uma plataforma web, com foco em usabilidade e interface intuitiva. espera-se que a implementação reduza significativamente a desorganização, desinformação, o estresse e os atrasos enfrentados pelos estudantes, melhorando a frequência escolar e, consequentemente, o desempenho acadêmico."
28,2024,Avaliando modelos de LLM para personalização de consultas e aumento de relevância no e-commerce.,"RIBEIRO, Mateus Matias.","MORAIS, Fábio Jorge Almeida.","A capacidade de fornecer resultados de pesquisa personalizados e relevantes em um ambiente de e-commerce altamente competitivo é crucial para a satisfação do cliente e o sucesso das lojas online. Neste trabalho, exploramos um método para melhorar a experiência de pesquisa no e-commerce usando modelos de aprendizado profundo para personalizar as consultas do usuário e melhorar a relevância dos itens retornados. O modelo de aprendizado de máquina apresentado foi projetado como uma prova de conceito para avaliar sua capacidade de entender o contexto e a intenção por trás das consultas de pesquisa do usuário e adaptá-las de forma inteligente antes de serem submetidas ao mecanismo de pesquisa. O modelo reescreve a consulta original para priorizar os produtos de interesse do cliente, descobrindo a intenção subjacente do usuário e o contexto da pesquisa. Além disso, também propomos um modelo classificador que é responsável por selecionar consultas passíveis de serem reescritas antes de usar o modelo de reescrita. Esta abordagem permite melhorar os resultados da pesquisa para destacar produtos de interesse, melhorando significativamente a relevância e a eficácia da pesquisa.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38205,"a capacidade de fornecer resultados de pesquisa personalizados e relevantes em um ambiente de e-commerce altamente competitivo é crucial para a satisfação do cliente e o sucesso das lojas online. neste trabalho, exploramos um método para melhorar a experiência de pesquisa no e-commerce usando modelos de aprendizado profundo para personalizar as consultas do usuário e melhorar a relevância dos itens retornados. o modelo de aprendizado de máquina apresentado foi projetado como uma prova de conceito para avaliar sua capacidade de entender o contexto e a intenção por trás das consultas de pesquisa do usuário e adaptá-las de forma inteligente antes de serem submetidas ao mecanismo de pesquisa. o modelo reescreve a consulta original para priorizar os produtos de interesse do cliente, descobrindo a intenção subjacente do usuário e o contexto da pesquisa. além disso, também propomos um modelo classificador que é responsável por selecionar consultas passíveis de serem reescritas antes de usar o modelo de reescrita. esta abordagem permite melhorar os resultados da pesquisa para destacar produtos de interesse, melhorando significativamente a relevância e a eficácia da pesquisa."
29,2024,DoeMed: promovendo a doação inteligente de medicamentos.,"FELIX, José Ricardo Galdino .","MASSONI, Tiago Lima.","O tempo é extremamente importante quando se necessita de um tratamento para a cura de doenças. Infelizmente, enfermos que não possuem condição financeira para comprar determinados medicamentos e/ou dependem do SUS para obtê-los, vêm a óbito por não conseguirem se tratar a tempo, o que torna imprescindível conectar possíveis doadores destes fármacos aos necessitados para combater esta triste realidade. Desse modo, neste trabalho proponho a criação de uma rede social crowdsourcing de doação de medicamentos que facilitará o contato entre doadores, instituições de saúde e enfermos, ajudando a combater este problema. A aplicação web, desenvolvida utilizando o Firebase como plataforma de serviços e o React como principal framework para o frontend, possui usuários que podem cadastrar e/ou remover suas necessidades, visualizar uma notificação caso sua necessidade seja atendida e pesquisar por instituições de saúde caso queiram doar medicamentos. As instituições de saúde, por sua vez, são responsáveis por verificar se os medicamentos estão aptos à doação, validar receitas e atender necessidades, o que gera uma notificação indicando o local em que o usuário deve buscar seus medicamentos.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38191,"o tempo é extremamente importante quando se necessita de um tratamento para a cura de doenças. infelizmente, enfermos que não possuem condição financeira para comprar determinados medicamentos e/ou dependem do sus para obtê-los, vêm a óbito por não conseguirem se tratar a tempo, o que torna imprescindível conectar possíveis doadores destes fármacos aos necessitados para combater esta triste realidade. desse modo, neste trabalho proponho a criação de uma rede social crowdsourcing de doação de medicamentos que facilitará o contato entre doadores, instituições de saúde e enfermos, ajudando a combater este problema. a aplicação web, desenvolvida utilizando o firebase como plataforma de serviços e o react como principal framework para o frontend, possui usuários que podem cadastrar e/ou remover suas necessidades, visualizar uma notificação caso sua necessidade seja atendida e pesquisar por instituições de saúde caso queiram doar medicamentos. as instituições de saúde, por sua vez, são responsáveis por verificar se os medicamentos estão aptos à doação, validar receitas e atender necessidades, o que gera uma notificação indicando o local em que o usuário deve buscar seus medicamentos."
30,2024,Análise de emoções e temas presentes na música popular brasileira com processamento de linguagem natural.,"GAMA, José Matheus do Nascimento.","OLIVEIRA, Maxwell Guimarães de.","Este trabalho consistiu na análise de letras da música popular brasileira ao longo das décadas, utilizando técnicas de Processamento de Linguagem Natural para identificar temas predominantes e emoções subjacentes. A importância desse tema residia na compreensão das transformações culturais e emocionais na sociedade brasileira ao longo do tempo, uma vez que a música reflete as emoções, preocupações e experiências da sociedade. Para produzir o trabalho, foram coletadas e pré-processadas 12.542 músicas distribuídas entre 1.318 artistas, abrangendo as décadas de 1960 a 2020. As principais tecnologias utilizadas incluíram o algoritmo de Alocação Latente de Dirichlet para Modelagem de Tópicos e o modelo BERTimbau para classificação de emoções. Os resultados revelaram temas recorrentes, como o amor, e padrões emocionais ao longo do tempo, fornecendo insights valiosos sobre as mudanças culturais e emocionais na sociedade brasileira. Em suma, o estudo destacou a constância do amor como tema central nas músicas, além das mudanças emocionais refletidas nas letras, contribuindo para uma compreensão mais profunda da mudança cultural no Brasil.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38190,"este trabalho consistiu na análise de letras da música popular brasileira ao longo das décadas, utilizando técnicas de processamento de linguagem natural para identificar temas predominantes e emoções subjacentes. a importância desse tema residia na compreensão das transformações culturais e emocionais na sociedade brasileira ao longo do tempo, uma vez que a música reflete as emoções, preocupações e experiências da sociedade. para produzir o trabalho, foram coletadas e pré-processadas . músicas distribuídas entre . artistas, abrangendo as décadas de a . as principais tecnologias utilizadas incluíram o algoritmo de alocação latente de dirichlet para modelagem de tópicos e o modelo bertimbau para classificação de emoções. os resultados revelaram temas recorrentes, como o amor, e padrões emocionais ao longo do tempo, fornecendo insights valiosos sobre as mudanças culturais e emocionais na sociedade brasileira. em suma, o estudo destacou a constância do amor como tema central nas músicas, além das mudanças emocionais refletidas nas letras, contribuindo para uma compreensão mais profunda da mudança cultural no brasil."
31,2024,Eficiência na busca por regiões geográficas similares: comparando diferentes manipulações nos embeddings de POI e feições geográficas.,"GOMES, José Igor de Farias.","CAMPELO, Claudio Elízio Calazans.","A representação de regiões geográficas tem sido alvo de pesquisas nos últimos tempos, pois é a peça chave para a realização de diversas tarefas, como a busca por regiões similares. Tal representação, porém, não é tarefa trivial, uma vez que pode envolver inúmeras variáveis no processo. A tendência atual é que essas representações sejam feitas através de vetores de alta dimensão, conhecidos como embeddings. Porém, operações de busca por estes costumam ser custosas para a máquina em termos de tempo de processamento e consumo de disco. Neste artigo experimentou-se diferentes manipulações nesses vetores a fim de diminuir o consumo de recursos computacionais no momento da busca sem comprometer significativamente a relevância dos resultados produzidos por ela. Técnicas de redução de dimensionalidade dos vetores e quantização de seus elementos foram executadas, além de comparações entre a busca exata por vizinhos mais próximos e a busca aproximada por estes. Observou-se que a busca aproximada por vizinhos mais próximos reduz o tempo de busca em aproximadamente 42,6%, mantendo uma boa aproximação com os resultados do baseline. A técnica de quantização dos embeddings apresentou a segunda maior interseção com o baseline e reduziu consideravelmente o consumo de disco pelos índices. Técnicas como a redução de dimensionalidades não apresentaram grandes alterações no tempo de busca e tiveram interseções baixíssimas com o baseline da pesquisa.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38189,"a representação de regiões geográficas tem sido alvo de pesquisas nos últimos tempos, pois é a peça chave para a realização de diversas tarefas, como a busca por regiões similares. tal representação, porém, não é tarefa trivial, uma vez que pode envolver inúmeras variáveis no processo. a tendência atual é que essas representações sejam feitas através de vetores de alta dimensão, conhecidos como embeddings. porém, operações de busca por estes costumam ser custosas para a máquina em termos de tempo de processamento e consumo de disco. neste artigo experimentou-se diferentes manipulações nesses vetores a fim de diminuir o consumo de recursos computacionais no momento da busca sem comprometer significativamente a relevância dos resultados produzidos por ela. técnicas de redução de dimensionalidade dos vetores e quantização de seus elementos foram executadas, além de comparações entre a busca exata por vizinhos mais próximos e a busca aproximada por estes. observou-se que a busca aproximada por vizinhos mais próximos reduz o tempo de busca em aproximadamente , %, mantendo uma boa aproximação com os resultados do baseline. a técnica de quantização dos embeddings apresentou a segunda maior interseção com o baseline e reduziu consideravelmente o consumo de disco pelos índices. técnicas como a redução de dimensionalidades não apresentaram grandes alterações no tempo de busca e tiveram interseções baixíssimas com o baseline da pesquisa."
32,2024,NodeGIS3D: simplificando o desenvolvimento e exploração de aplicações web GIS em 3D.,"COSTA, Jonatha Kennedy Monteiro da.","BAPTISTA, Cláudio de Souza.","Atualmente, com o crescente impacto da informação geoespacial em nosso cotidiano, foram surgindo diversas ferramentas para o desenvolvimento de aplicações web de Sistemas de Informações Geográficas (SIG), dentre elas a NodeGIS. O NodeGIS3D representa uma evolução ao NodeGIS, adicionando funcionalidades de visualização e análise de dados geoespaciais em três dimensões, sem a necessidade de uma configuração complexa. O NodeGIS3D faz uso de uma integração de contêineres Docker, dessa forma simplificando o processo de deployment, possui também uma interface intuitiva, que permite uma interação fácil com as funcionalidades do sistema. A solução oferece ferramentas de consulta espacial, adição de recursos 3D e um ambiente tridimensional, permitindo uma navegação mais imersiva ao mapa. O NodeGIS3D também pode ser utilizado no ensino e aprendizagem de SIG, oferecendo uma aplicação robusta que pode ser inicializada facilmente.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38188,"atualmente, com o crescente impacto da informação geoespacial em nosso cotidiano, foram surgindo diversas ferramentas para o desenvolvimento de aplicações web de sistemas de informações geográficas (sig), dentre elas a nodegis. o nodegis3d representa uma evolução ao nodegis, adicionando funcionalidades de visualização e análise de dados geoespaciais em três dimensões, sem a necessidade de uma configuração complexa. o nodegis3d faz uso de uma integração de contêineres docker, dessa forma simplificando o processo de deployment, possui também uma interface intuitiva, que permite uma interação fácil com as funcionalidades do sistema. a solução oferece ferramentas de consulta espacial, adição de recursos 3d e um ambiente tridimensional, permitindo uma navegação mais imersiva ao mapa. o nodegis3d também pode ser utilizado no ensino e aprendizagem de sig, oferecendo uma aplicação robusta que pode ser inicializada facilmente."
33,2024,Terrascratch: aprendendo Terraform de maneira interativa.,"LIMA, Jonatas Ferreira de.","PEREIRA, Thiago Emmanuel da Cunha Silva.","Terraform é uma ferramenta popular que permite o provisionamento de infraestrutura através de código. Pelo fato de ser algo recente, materiais intuitivos e de aprendizado são escassos, se limitando a vídeos tutoriais e documentações tradicionais, o que afasta o usuário iniciante que tem interesse em aprender essa ferramenta. Com base nesse fato, foi desenvolvido o Terrascratch: uma ferramenta intuitiva que facilita o processo de aprendizado. O Terrascratch permite o uso de recursos visuais que representam componentes de infraestrutura da nuvem da Amazon Web Services (AWS) e gera o seu código Terraform correspondente. O levantamento de requisitos para a ferramenta foi realizado por meio de um workshop, e a eficácia da ferramenta foi avaliada mediante experimentos qualitativos com usuários potenciais em um segundo workshop. Realizamos uma apresentação e uma série de entrevistas com os participantes. Como resultados, observamos que o Terrascratch é eficaz para usuários sem conhecimento prévio de Terraform, com destaque para os usuários com noções básicas de AWS, mas não tão útil para usuários de conhecimento intermediário ou avançado.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38187,"terraform é uma ferramenta popular que permite o provisionamento de infraestrutura através de código. pelo fato de ser algo recente, materiais intuitivos e de aprendizado são escassos, se limitando a vídeos tutoriais e documentações tradicionais, o que afasta o usuário iniciante que tem interesse em aprender essa ferramenta. com base nesse fato, foi desenvolvido o terrascratch: uma ferramenta intuitiva que facilita o processo de aprendizado. o terrascratch permite o uso de recursos visuais que representam componentes de infraestrutura da nuvem da amazon web services (aws) e gera o seu código terraform correspondente. o levantamento de requisitos para a ferramenta foi realizado por meio de um workshop, e a eficácia da ferramenta foi avaliada mediante experimentos qualitativos com usuários potenciais em um segundo workshop. realizamos uma apresentação e uma série de entrevistas com os participantes. como resultados, observamos que o terrascratch é eficaz para usuários sem conhecimento prévio de terraform, com destaque para os usuários com noções básicas de aws, mas não tão útil para usuários de conhecimento intermediário ou avançado."
34,2024,O impacto psicológico das aplicações de vídeos curtos e a sua relação com as características das aplicações: um mapeamento sistemático.,"FIGUEIRÊDO, João Vitor Moura.","MASSONI, Tiago Lima.","Este trabalho apresenta uma revisão sistemática sobre o impacto das aplicações de vídeos curtos, como Tiktok e Kwai, por exemplo, na saúde mental e bem-estar dos usuários, analisando suas relações com as características dessas aplicações. O rápido crescimento e a difusão global dessas plataformas de mídia social levantaram preocupações sobre seus efeitos psicológicos, especialmente entre os jovens. Posto isso, essa revisão se baseia em uma análise criteriosa de estudos acadêmicos, pesquisas empíricas e evidências, empregados para examinar os aspectos negativos associados ao uso dessas plataformas. O intuito é analisar aspectos centrais dessas aplicações, entre eles, o scroll infinito, o compartilhamento de vídeos curtos com conteúdos que representam um estímulo significativo para o cérebro e os algoritmos de recomendação, analisando a forma como esses aspectos impactam a saúde mental do usuário. Em síntese, esta revisão sistemática contribui para um entendimento mais aprofundado dos efeitos psicológicos desse tipo de aplicação, fornecendo uma base sólida para a reflexão sobre práticas e políticas que visem",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38185,"este trabalho apresenta uma revisão sistemática sobre o impacto das aplicações de vídeos curtos, como tiktok e kwai, por exemplo, na saúde mental e bem-estar dos usuários, analisando suas relações com as características dessas aplicações. o rápido crescimento e a difusão global dessas plataformas de mídia social levantaram preocupações sobre seus efeitos psicológicos, especialmente entre os jovens. posto isso, essa revisão se baseia em uma análise criteriosa de estudos acadêmicos, pesquisas empíricas e evidências, empregados para examinar os aspectos negativos associados ao uso dessas plataformas. o intuito é analisar aspectos centrais dessas aplicações, entre eles, o scroll infinito, o compartilhamento de vídeos curtos com conteúdos que representam um estímulo significativo para o cérebro e os algoritmos de recomendação, analisando a forma como esses aspectos impactam a saúde mental do usuário. em síntese, esta revisão sistemática contribui para um entendimento mais aprofundado dos efeitos psicológicos desse tipo de aplicação, fornecendo uma base sólida para a reflexão sobre práticas e políticas que visem"
35,2024,Analisando erros cometidos por iniciantes em programação orientada a objetos no Curso de Ciência da Computação da UFCG.,"MELO, João Pedro Silva de.","CAMPOS, Lívia Maria Rodrigues Sampaio.","Cursos introdutórios de programação costumam ser desafiadores, especialmente para aqueles sem experiência prévia em lógica de programação. Ao ingressar em um curso de tecnologia, é necessário o aprendizado de terminologias relacionadas à Ciência da Computação e adaptar-se aos diferentes conceitos e paradigmas. Se tratando de Programação Orientada a Objetos (POO), utilizando Java como linguagem de programação, a dificuldade é ainda maior. Seu amplo conjunto de conceitos e sua sintaxe verbosa fazem parte de uma transição desafiadora, seguida de erros quanto aos conceitos aprendidos, refletindo muitas vezes a permanência do aluno no curso. Sendo assim, com o objetivo de compreender e analisar estes erros, este trabalho se propõe a seguir os mesmos passos de um estudo anterior conduzido em uma turma da disciplina de Laboratório de Programação II no curso de Ciência da Computação da Universidade Federal de Campina Grande. A dificuldade de assimilação de conceitos de Java implica na observação de erros em atividades práticas e avaliativas, como foi constatado no estudo mencionado, que analisou principalmente o volume de código das submissões dos alunos. A intenção é fazer um comparativo entre os resultados, investigando padrões e tendências que possam variar conforme há mudança de amostra. Uma vez identificando tais erros, bem como a sua frequência e impacto na nota do aluno, este estudo pode contribuir para potenciais adaptações nos métodos de ensino para que haja uma melhor aproximação na solução destes problemas, fortalecendo a compreensão dos conceitos fundamentais de Programação Orientada a Objetos, uma vez que é recorrente em outras disciplinas da grade curricular.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38183,"cursos introdutórios de programação costumam ser desafiadores, especialmente para aqueles sem experiência prévia em lógica de programação. ao ingressar em um curso de tecnologia, é necessário o aprendizado de terminologias relacionadas à ciência da computação e adaptar-se aos diferentes conceitos e paradigmas. se tratando de programação orientada a objetos (poo), utilizando java como linguagem de programação, a dificuldade é ainda maior. seu amplo conjunto de conceitos e sua sintaxe verbosa fazem parte de uma transição desafiadora, seguida de erros quanto aos conceitos aprendidos, refletindo muitas vezes a permanência do aluno no curso. sendo assim, com o objetivo de compreender e analisar estes erros, este trabalho se propõe a seguir os mesmos passos de um estudo anterior conduzido em uma turma da disciplina de laboratório de programação ii no curso de ciência da computação da universidade federal de campina grande. a dificuldade de assimilação de conceitos de java implica na observação de erros em atividades práticas e avaliativas, como foi constatado no estudo mencionado, que analisou principalmente o volume de código das submissões dos alunos. a intenção é fazer um comparativo entre os resultados, investigando padrões e tendências que possam variar conforme há mudança de amostra. uma vez identificando tais erros, bem como a sua frequência e impacto na nota do aluno, este estudo pode contribuir para potenciais adaptações nos métodos de ensino para que haja uma melhor aproximação na solução destes problemas, fortalecendo a compreensão dos conceitos fundamentais de programação orientada a objetos, uma vez que é recorrente em outras disciplinas da grade curricular."
36,2024,Avaliando modelos de linguagem grande na resolução de problemas de lógica da OBI.,"SOUZA, João Vitor de Melo Cavalcante e.","GHEYI, Rohit.","Modelos de Linguagem Grande (LLM) se tornaram populares, com modelos de fácil acesso e cada vez mais perspicazes, tais como Chat GPT, Gemini, Claude, Mistral, dentre outros. Com uma grande gama de possíveis utilizações em uma era digital, os LLMs tem uma crescente utilização, sendo possíveis suas atuações em diversos campos, inclusive no de aprendizado humano. Mediante isto, é considerável saber e ponderar sobre tais ferramentas e como podem ajudar na resolução de problemas lógicos encontrados na Olimpíada Brasileira de Informática (OBI) para alunos do ensino fundamental. Neste trabalho avaliamos o Chat GPT 3.5 e o Le Chat Mistral com 100 questões de lógica da OBI. O Chat GPT acertou 23% delas, enquanto que o Mistral Le Chat acertou 36%das questões, ambos na primeira tentativa.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38165,"modelos de linguagem grande (llm) se tornaram populares, com modelos de fácil acesso e cada vez mais perspicazes, tais como chat gpt, gemini, claude, mistral, dentre outros. com uma grande gama de possíveis utilizações em uma era digital, os llms tem uma crescente utilização, sendo possíveis suas atuações em diversos campos, inclusive no de aprendizado humano. mediante isto, é considerável saber e ponderar sobre tais ferramentas e como podem ajudar na resolução de problemas lógicos encontrados na olimpíada brasileira de informática (obi) para alunos do ensino fundamental. neste trabalho avaliamos o chat gpt . e o le chat mistral com questões de lógica da obi. o chat gpt acertou % delas, enquanto que o mistral le chat acertou %das questões, ambos na primeira tentativa."
37,2024,Pertencimento de alunos com necessidades educacionais especiais em cursos de ciência da computação: uma revisão de literatura.,"OLIVEIRA, José Guilherme Coelho de","ARAÚJO, Eliane Cristina de.","O pertencimento é um componente importante para o sucesso acadêmico e pessoal dos estudantes, especialmente para aqueles com necessidades educacionais especiais (NEE), que enfrentam barreiras adicionais nos ambientes de aprendizagem. Nos cursos de Ciências da Computação, esse sentimento é ainda mais relevante devido às exigências cognitivas dessas disciplinas. Esta revisão de literatura visa investigar como o pertencimento tem sido abordado nos estudos sobre estudantes com NEE nos cursos de Ciências da Computação. Para tanto, foi realizada uma busca sistemática em bases de dados, como Scopus e ScienceDirect, de artigos publicados entre 2014 e 2024, utilizando palavras-chave como ""necessidades educacionais especiais"", ""ensino superior"" e ""ciências da computação"". Foram excluídas resenhas, dissertações e teses, resultando na seleção de 18 artigos para análise. Os resultados indicam que as principais barreiras enfrentadas pelos estudantes incluem o acesso a tecnologias assistivas, barreiras financeiras e burocráticas, estigma e falta de treinamento pedagógico para professores. Os estudos também destacam a necessidade de currículos adaptados, ambientes de apoio social e emocional, e a criação de redes de suporte. As conclusões evidenciam a importância do design universal, práticas pedagógicas inclusivas e políticas institucionais claras que garantam a inclusão plena de estudantes com NEE nos cursos de Ciências da Computação. A revisão fornece recomendações para orientar educadores e instituições na construção de ambientes mais inclusivos, equitativos e acolhedores.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38164,"o pertencimento é um componente importante para o sucesso acadêmico e pessoal dos estudantes, especialmente para aqueles com necessidades educacionais especiais (nee), que enfrentam barreiras adicionais nos ambientes de aprendizagem. nos cursos de ciências da computação, esse sentimento é ainda mais relevante devido às exigências cognitivas dessas disciplinas. esta revisão de literatura visa investigar como o pertencimento tem sido abordado nos estudos sobre estudantes com nee nos cursos de ciências da computação. para tanto, foi realizada uma busca sistemática em bases de dados, como scopus e sciencedirect, de artigos publicados entre e , utilizando palavras-chave como ""necessidades educacionais especiais"", ""ensino superior"" e ""ciências da computação"". foram excluídas resenhas, dissertações e teses, resultando na seleção de artigos para análise. os resultados indicam que as principais barreiras enfrentadas pelos estudantes incluem o acesso a tecnologias assistivas, barreiras financeiras e burocráticas, estigma e falta de treinamento pedagógico para professores. os estudos também destacam a necessidade de currículos adaptados, ambientes de apoio social e emocional, e a criação de redes de suporte. as conclusões evidenciam a importância do design universal, práticas pedagógicas inclusivas e políticas institucionais claras que garantam a inclusão plena de estudantes com nee nos cursos de ciências da computação. a revisão fornece recomendações para orientar educadores e instituições na construção de ambientes mais inclusivos, equitativos e acolhedores."
38,2024,Uma visão da trajetória de desempenho acadêmico no Curso de Ciência da Computação da UFCG sob a perspectiva de gênero.,"NASCIMENTO, Mariana Silva.","CAMPOS, Lívia Maria Rodrigues Sampaio.","A disparidade de gênero representada por uma desproporção da representação masculina sobre a feminina, tanto entre os ingressantes quanto aos egressos dos cursos nas áreas das ciências exatas no Brasil é uma realidade que perdura ao longo dos séculos. No curso de Ciência da Computação da Universidade Federal de Campina Grande (UFCG), essa disparidade é particularmente evidenciada pela baixa presença de mulheres, que compõem apenas 16% dos ingressantes nos últimos anos. Este estudo é um recorte baseado na dissertação de mestrado de uma aluna do programa de pós-graduação da UFCG, que analisou o desempenho e a trajetória de estudantes do curso de graduação a partir do recorte de gênero. Nosso objetivo é criar uma, a partir dos dados estruturados e analisados por esse amplo estudo, uma série de visualizações que demonstrem a trajetória desses estudantes, incorporando uma lente de gênero, para determinar se este é um fator determinante na experiência acadêmica ou se, como consequência, exerce também alguma influência sobre a escassez de mulheres no curso de Ciência da Computação.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38161,"a disparidade de gênero representada por uma desproporção da representação masculina sobre a feminina, tanto entre os ingressantes quanto aos egressos dos cursos nas áreas das ciências exatas no brasil é uma realidade que perdura ao longo dos séculos. no curso de ciência da computação da universidade federal de campina grande (ufcg), essa disparidade é particularmente evidenciada pela baixa presença de mulheres, que compõem apenas % dos ingressantes nos últimos anos. este estudo é um recorte baseado na dissertação de mestrado de uma aluna do programa de pós-graduação da ufcg, que analisou o desempenho e a trajetória de estudantes do curso de graduação a partir do recorte de gênero. nosso objetivo é criar uma, a partir dos dados estruturados e analisados por esse amplo estudo, uma série de visualizações que demonstrem a trajetória desses estudantes, incorporando uma lente de gênero, para determinar se este é um fator determinante na experiência acadêmica ou se, como consequência, exerce também alguma influência sobre a escassez de mulheres no curso de ciência da computação."
39,2024,“ZoIA”: uma ferramenta para descrição automática de imagens no navegador.,"SILVA, Maria Eduarda de Azevedo.","GOMES, Herman Martins.","O bom funcionamento de leitores de tela, comumente utilizados por usuários com deficiência visual, está atrelado à responsabilidade dos desenvolvedores web em utilizar as tags de maneira correta e fornecer informações suficientes, como descricões de imagens, para garantir a acessibilidade e a inclusão desses usuários. Porém, o fornecimento de textos alternativos não é sempre garantido por diversos fatores, como, por exemplo, a ausência de descricões associadas às imagens, assim como de requisitos e funcionalidades que busquem garantir a existência desse dado. Diante dessa problemática, este trabalho propõe o “ZoIA”, um plugin para navegadores, fundamentado em Inteligência Artificial, que descreve e insere textos alternativos para imagens dispostas em páginas na internet. Uma análise comparativa entre a geração direta de descricções em português e a abordagem via sequência sugeriu que o ajuste do modelo para o idioma de interesse pode resultar em melhorias qualitativas no contexto, semântica e coesão gramatical das descricões automáticas. Neste trabalho buscou-se contribuir para a melhoria da interaçãoo e da experiência de pessoas com deficiência visual na utilização de aplicações web com o uso de estratégias do estado da arte da Inteligência Artificial.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38158,"o bom funcionamento de leitores de tela, comumente utilizados por usuários com deficiência visual, está atrelado à responsabilidade dos desenvolvedores web em utilizar as tags de maneira correta e fornecer informações suficientes, como descricões de imagens, para garantir a acessibilidade e a inclusão desses usuários. porém, o fornecimento de textos alternativos não é sempre garantido por diversos fatores, como, por exemplo, a ausência de descricões associadas às imagens, assim como de requisitos e funcionalidades que busquem garantir a existência desse dado. diante dessa problemática, este trabalho propõe o “zoia”, um plugin para navegadores, fundamentado em inteligência artificial, que descreve e insere textos alternativos para imagens dispostas em páginas na internet. uma análise comparativa entre a geração direta de descricções em português e a abordagem via sequência sugeriu que o ajuste do modelo para o idioma de interesse pode resultar em melhorias qualitativas no contexto, semântica e coesão gramatical das descricões automáticas. neste trabalho buscou-se contribuir para a melhoria da interaçãoo e da experiência de pessoas com deficiência visual na utilização de aplicações web com o uso de estratégias do estado da arte da inteligência artificial."
40,2024,Performance evaluation of Openstack Swift.,"COSSON, Marcos Guillermo de Sá Catão.","SILVA, Thiago Emmanuel Pereira da Cunha.","Este estudo aborda a necessidade de uma avaliação abrangente do desempenho do Swift em ambientes OpenStack. Apesar da sua adoção generalizada, falta uma análise aprofundada nesta área. Através de testes, incluindo testes de carga e de stress, examinamos o comportamento do Swift em diversos níveis de procura. As nossas conclusões destacam as principais tendências: à medida que a carga de utilizadores aumentou, os tempos de resposta mostraram um aumento correspondente, atingindo um aumento máximo observado. Além disso, a variabilidade nos tempos de resposta também aumentou com cargas de utilizadores mais elevadas, enfatizando a importância da escalabilidade e da otimização de desempenho para o Swift em cenários práticos de implementação.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38157,"este estudo aborda a necessidade de uma avaliação abrangente do desempenho do swift em ambientes openstack. apesar da sua adoção generalizada, falta uma análise aprofundada nesta área. através de testes, incluindo testes de carga e de stress, examinamos o comportamento do swift em diversos níveis de procura. as nossas conclusões destacam as principais tendências: à medida que a carga de utilizadores aumentou, os tempos de resposta mostraram um aumento correspondente, atingindo um aumento máximo observado. além disso, a variabilidade nos tempos de resposta também aumentou com cargas de utilizadores mais elevadas, enfatizando a importância da escalabilidade e da otimização de desempenho para o swift em cenários práticos de implementação."
41,2024,Regulação de plataformas digitais: desafios e estratégias de governança.,"AGUIAR, Jackson Mateus Cunha de.","GARCIA, Francilene Procópio.","O estudo aborda os desafios regulatórios enfrentados pelas plataformas digitais em relação à privacidade de dados, segurança cibernética, concorrência, proteção ao consumidor e responsabilidade social. A transformação digital tem impulsionado a ascensão das plataformas digitais como elementos-chave na interconexão de atores e na facilitação de transações e interações de maneira inovadora e eficiente. No entanto, essa rápida evolução tecnológica levanta questões importantes que precisam ser abordadas para garantir um ambiente digital sustentável e equitativo. O estudo se propõe a analisar esses desafios regulatórios específicos e a explorar as estratégias de governança aplicáveis a esses ambientes, visando propor alguma melhora em um ambiente de negócios justo, transparente e seguro que promova a inovação e o desenvolvimento sustentável. As estratégias de governança incluem regulamentações específicas, autorregulação por parte das próprias plataformas digitais, cooperação entre empresas, governos e sociedade civil, transparência e desenvolvimento de tecnologias para promover a privacidade e a segurança dos usuários. O estudo utiliza uma metodologia que inclui entrevistas com especialistas, revisão da literatura acadêmica e técnica, proporcionando uma compreensão aprofundada das questões de regulação, governança e desafios enfrentados pelas plataformas digitais.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38152,"o estudo aborda os desafios regulatórios enfrentados pelas plataformas digitais em relação à privacidade de dados, segurança cibernética, concorrência, proteção ao consumidor e responsabilidade social. a transformação digital tem impulsionado a ascensão das plataformas digitais como elementos-chave na interconexão de atores e na facilitação de transações e interações de maneira inovadora e eficiente. no entanto, essa rápida evolução tecnológica levanta questões importantes que precisam ser abordadas para garantir um ambiente digital sustentável e equitativo. o estudo se propõe a analisar esses desafios regulatórios específicos e a explorar as estratégias de governança aplicáveis a esses ambientes, visando propor alguma melhora em um ambiente de negócios justo, transparente e seguro que promova a inovação e o desenvolvimento sustentável. as estratégias de governança incluem regulamentações específicas, autorregulação por parte das próprias plataformas digitais, cooperação entre empresas, governos e sociedade civil, transparência e desenvolvimento de tecnologias para promover a privacidade e a segurança dos usuários. o estudo utiliza uma metodologia que inclui entrevistas com especialistas, revisão da literatura acadêmica e técnica, proporcionando uma compreensão aprofundada das questões de regulação, governança e desafios enfrentados pelas plataformas digitais."
42,2024,Mensuração do custo da alocação de docentes aos cursos de graduação da Universidade Federal de Campina Grande.,"PASSOS, Iele Facundo.","BRASILEIRO, Francisco Vilar.","As Instituições de Ensino Superior (IES) desempenham um papel fundamental na formação de profissionais qualificados, contribuindo significativamente para o desenvolvimento do país. No entanto, elas enfrentam desafios que afetam sua capacidade de cumprir esse papel de forma adequada. A gestão eficiente de seus recursos é uma das preocupações mais persistentes. Muitos estudos avaliam a eficiência de vários aspectos da gestão através de uma avaliação do custo monetário associado a diferentes atividades. Embora seja crucial ter uma visão clara desses aspectos, é igualmente importante considerar fatores específicos, como, por exemplo, a carga horária de docentes dedicada diretamente à formação dos discentes. Apesar de existir um empenho significativo no sentido de otimizar esse custo, é notável a falta de estudos que detalhem como a trajetória acadêmica do discente afeta seu custo na IES. Compreender como esse custo interfere na eficiência da instituição é crucial para tomar medidas direcionadas à melhoria da gestão e otimização dos recursos disponíveis. Neste trabalho foram propostas métricas para medir a eficiência de 48 cursos de graduação da Universidade Federal de Campina Grande (UFCG), durante um período de 8 anos, no que diz respeito à alocação de docentes às atividades de ensino. Como resultado da mensuração realizada, pode-se observar que cursos com um número de ingressantes baixo, assim como cursos com altas taxas de evasão e de retenção, têm um custo alto, enfatizando a necessidade de tratar cuidadosamente cada um dos aspectos relacionados ao cálculo da eficiência dos cursos analisados.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38150,"as instituições de ensino superior (ies) desempenham um papel fundamental na formação de profissionais qualificados, contribuindo significativamente para o desenvolvimento do país. no entanto, elas enfrentam desafios que afetam sua capacidade de cumprir esse papel de forma adequada. a gestão eficiente de seus recursos é uma das preocupações mais persistentes. muitos estudos avaliam a eficiência de vários aspectos da gestão através de uma avaliação do custo monetário associado a diferentes atividades. embora seja crucial ter uma visão clara desses aspectos, é igualmente importante considerar fatores específicos, como, por exemplo, a carga horária de docentes dedicada diretamente à formação dos discentes. apesar de existir um empenho significativo no sentido de otimizar esse custo, é notável a falta de estudos que detalhem como a trajetória acadêmica do discente afeta seu custo na ies. compreender como esse custo interfere na eficiência da instituição é crucial para tomar medidas direcionadas à melhoria da gestão e otimização dos recursos disponíveis. neste trabalho foram propostas métricas para medir a eficiência de cursos de graduação da universidade federal de campina grande (ufcg), durante um período de anos, no que diz respeito à alocação de docentes às atividades de ensino. como resultado da mensuração realizada, pode-se observar que cursos com um número de ingressantes baixo, assim como cursos com altas taxas de evasão e de retenção, têm um custo alto, enfatizando a necessidade de tratar cuidadosamente cada um dos aspectos relacionados ao cálculo da eficiência dos cursos analisados."
43,2024,Desenvolvimento de um sistema para disponibilização de dados do DATASUS: uma abordagem de acesso simplificado.,"ALMEIDA, Ícaro Chagas de.","BRUNET, João Arthur Monteiro.","O Departamento de Informática do Sistema Único de Saúde (DATASUS) disponibiliza dados fundamentais para análises da situação sanitária do Brasil, embasando tomadas de decisão e o desenvolvimento de programas de intervenção em saúde. No entanto, esses dados são fornecidos em um formato não diretamente compatível com ferramentas populares, como Excel ou Google Sheets, dificultando sua acessibilidade para pesquisadores, analistas e profissionais da área médica. Além disso, enfrenta-se o desafio atrelado ao significativo volume dos dados, caracterizando-os a nível de Big Data. A escala massiva desses dados demanda abordagens eficientes de engenharia de dados para lidar com processamento e armazenamento, a fim de proporcionar uma estrutura robusta e escalável para a manipulação dos mesmos. Diante dessa problemática, este trabalho propõe o desenvolvimento de um processo automatizado para extração de 47 tabelas, disponíveis em arquivos no formato dbc e provenientes de 13 bases de dados do DATASUS, o armazenamento em um data warehouse e a disponibilização dos dados por meio de uma API. Espera-se que essa iniciativa facilite a análise de dados de saúde no Brasil, oferecendo acesso simplificado e dados prontos para análise a pesquisadores, analistas e profissionais da área médica.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38148,"o departamento de informática do sistema único de saúde (datasus) disponibiliza dados fundamentais para análises da situação sanitária do brasil, embasando tomadas de decisão e o desenvolvimento de programas de intervenção em saúde. no entanto, esses dados são fornecidos em um formato não diretamente compatível com ferramentas populares, como excel ou google sheets, dificultando sua acessibilidade para pesquisadores, analistas e profissionais da área médica. além disso, enfrenta-se o desafio atrelado ao significativo volume dos dados, caracterizando-os a nível de big data. a escala massiva desses dados demanda abordagens eficientes de engenharia de dados para lidar com processamento e armazenamento, a fim de proporcionar uma estrutura robusta e escalável para a manipulação dos mesmos. diante dessa problemática, este trabalho propõe o desenvolvimento de um processo automatizado para extração de tabelas, disponíveis em arquivos no formato dbc e provenientes de bases de dados do datasus, o armazenamento em um data warehouse e a disponibilização dos dados por meio de uma api. espera-se que essa iniciativa facilite a análise de dados de saúde no brasil, oferecendo acesso simplificado e dados prontos para análise a pesquisadores, analistas e profissionais da área médica."
44,2024,Uma análise comparativa entre Threads e Green Threads no Java.,"SOUTO, Hiarly Fernandes de","PEREIRA, Thiago Emmanuel.","Green thread é um modelo de thread no qual o escalonamento é realizado por runtimes ao invés de ser realizado pelo sistema operacional. Essa abordagem necessita de menos recursos, em termos de memória e ciclos de CPU, do que projetos tradicionais de threads. Recentemente, a linguagem Java, em sua versão 19, introduziu uma implementação de Green threads, chamada de Virtual Threads. Por ser ainda pouco utilizada, conhecemos pouco da eficiência desta implementação. Neste trabalho, avaliamos o desempenho da implementação de green threads de Java. Comparamos os resultados desta implementação com a implementação padrão já disponível na linguagem. Ao término deste trabalho, foi evidenciado que as Virtual Threads apresentam uma significativa melhoria de desempenho em comparação com a abordagem convencional de Threads em Java, sendo superior em todos os testes realizados. Os resultados deste estudo destacaram a disparidade de desempenho entre diferentes abordagens de manipulação de threads, com as Virtual Threads mostrando um desempenho excepcional em comparação com as threads convencionais em Java. Ficou claro que sistemas que possuem um grande número de threads, podem obter melhorias significativas de desempenho ao implementar as Virtual Threads em sua estrutura.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38147,"green thread é um modelo de thread no qual o escalonamento é realizado por runtimes ao invés de ser realizado pelo sistema operacional. essa abordagem necessita de menos recursos, em termos de memória e ciclos de cpu, do que projetos tradicionais de threads. recentemente, a linguagem java, em sua versão , introduziu uma implementação de green threads, chamada de virtual threads. por ser ainda pouco utilizada, conhecemos pouco da eficiência desta implementação. neste trabalho, avaliamos o desempenho da implementação de green threads de java. comparamos os resultados desta implementação com a implementação padrão já disponível na linguagem. ao término deste trabalho, foi evidenciado que as virtual threads apresentam uma significativa melhoria de desempenho em comparação com a abordagem convencional de threads em java, sendo superior em todos os testes realizados. os resultados deste estudo destacaram a disparidade de desempenho entre diferentes abordagens de manipulação de threads, com as virtual threads mostrando um desempenho excepcional em comparação com as threads convencionais em java. ficou claro que sistemas que possuem um grande número de threads, podem obter melhorias significativas de desempenho ao implementar as virtual threads em sua estrutura."
45,2024,Sistema automático móvel para gestão de presença com reconhecimento facial.,"LACERDA, Hiago Willyam Araújo.","FECHINE, Joseana Macêdo.","Diante da dinâmica evolução tecnológica que permeia nossa sociedade contemporânea, a interseção entre inovação e segurança tem se tornado um terreno fértil para a discussão de temas candentes, como é o caso do reconhecimento facial. Esse avanço tecnológico, que se destaca pela sua capacidade de identificar e autenticar pessoas por meio de características faciais únicas, tem atraído considerável atenção tanto do meio acadêmico quanto do público em geral, tornando-se um tema de interesse em discussões sobre privacidade, segurança e eficácia. Nesse contexto de amplo debate, o objetivo do trabalho ora descrito é o desenvolvimento de um sistema móvel para gerenciamento de presença baseado em reconhecimento facial. São abordados os aspectos técnicos de design e estratégias, incluindo seleção de algoritmos e arquitetura de sistemas. Especificamente, o modelo de autenticação facial será construído a partir de fotos de qualidade mediana, capturadas por uma câmera frontal convencional. Além disso, será desenvolvido um aplicativo móvel que utilize este modelo para gerenciar a presença em sala de aula. A pesquisa contribuirá com insights sobre as dimensões técnicas e éticas da integração do reconhecimento facial para registro de presença, oferecendo orientação para implementações futuras neste campo.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38146,"diante da dinâmica evolução tecnológica que permeia nossa sociedade contemporânea, a interseção entre inovação e segurança tem se tornado um terreno fértil para a discussão de temas candentes, como é o caso do reconhecimento facial. esse avanço tecnológico, que se destaca pela sua capacidade de identificar e autenticar pessoas por meio de características faciais únicas, tem atraído considerável atenção tanto do meio acadêmico quanto do público em geral, tornando-se um tema de interesse em discussões sobre privacidade, segurança e eficácia. nesse contexto de amplo debate, o objetivo do trabalho ora descrito é o desenvolvimento de um sistema móvel para gerenciamento de presença baseado em reconhecimento facial. são abordados os aspectos técnicos de design e estratégias, incluindo seleção de algoritmos e arquitetura de sistemas. especificamente, o modelo de autenticação facial será construído a partir de fotos de qualidade mediana, capturadas por uma câmera frontal convencional. além disso, será desenvolvido um aplicativo móvel que utilize este modelo para gerenciar a presença em sala de aula. a pesquisa contribuirá com insights sobre as dimensões técnicas e éticas da integração do reconhecimento facial para registro de presença, oferecendo orientação para implementações futuras neste campo."
46,2024,Using semantic cache to spare resources of LLM-powered features.,"NÓBREGA, Henrique Lopes.","BRUNET, João Arthur Monteiro.","Modelos de Linguagem de Grande Escala (LLMs), como o ChatGPT, Claude e Llama 2, revolucionaram o processamento de linguagem natural, criando novos casos de uso para aplicações que utilizam esses modelos em seus fluxos de trabalho. No entanto, os altos custos computacionais desses modelos acarretam problemas de custo e latência, impedindo a escalabilidade de funcionalidades baseadas em LLM para muitos serviços e produtos, especialmente quando dependem de modelos com melhores capacidades de raciocínio, como o GPT-4 ou o Claude 3 Opus. Além disso, muitas consultas a esses modelos são duplicadas. O cache tradicional é uma solução natural para esse problema, mas sua incapacidade de determinar se duas consultas são semanticamente equivalentes leva a baixas taxas de cache hit. Neste trabalho, propomos explorar o uso de cache semântico, que considera o significado das consultas em vez de sua formulação exata, para melhorar a eficiência de aplicações baseadas em LLM. Realizamos um experimento usando um conjunto de dados real da Alura, uma empresa brasileira de educação, em um cenário onde um aluno responde a uma pergunta e o GPT-4 corrige a resposta. Os resultados mostraram que 45,1% das solicitações feitas ao LLM poderiam ter sido atendidas a partir do cache usando um limiar de similaridade de 0.98, com uma melhoria de 4-10 vezes na latência. Esses resultados demonstram o potencial do cache semântico para melhorar a eficiência de funcionalidades baseadas em LLM, reduzindo custos e latência enquanto mantém os benefícios de modelos avançados de linguagem como o GPT-4. Essa abordagem poderia possibilitar a escalabilidade de funcionalidades baseadas em LLM para uma gama mais ampla de aplicações, avançando na adoção desses modelos poderosos em diversos domínios.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38145,"modelos de linguagem de grande escala (llms), como o chatgpt, claude e llama , revolucionaram o processamento de linguagem natural, criando novos casos de uso para aplicações que utilizam esses modelos em seus fluxos de trabalho. no entanto, os altos custos computacionais desses modelos acarretam problemas de custo e latência, impedindo a escalabilidade de funcionalidades baseadas em llm para muitos serviços e produtos, especialmente quando dependem de modelos com melhores capacidades de raciocínio, como o gpt- ou o claude opus. além disso, muitas consultas a esses modelos são duplicadas. o cache tradicional é uma solução natural para esse problema, mas sua incapacidade de determinar se duas consultas são semanticamente equivalentes leva a baixas taxas de cache hit. neste trabalho, propomos explorar o uso de cache semântico, que considera o significado das consultas em vez de sua formulação exata, para melhorar a eficiência de aplicações baseadas em llm. realizamos um experimento usando um conjunto de dados real da alura, uma empresa brasileira de educação, em um cenário onde um aluno responde a uma pergunta e o gpt- corrige a resposta. os resultados mostraram que , % das solicitações feitas ao llm poderiam ter sido atendidas a partir do cache usando um limiar de similaridade de . , com uma melhoria de - vezes na latência. esses resultados demonstram o potencial do cache semântico para melhorar a eficiência de funcionalidades baseadas em llm, reduzindo custos e latência enquanto mantém os benefícios de modelos avançados de linguagem como o gpt- . essa abordagem poderia possibilitar a escalabilidade de funcionalidades baseadas em llm para uma gama mais ampla de aplicações, avançando na adoção desses modelos poderosos em diversos domínios."
47,2024,Avaliação de grandes modelos de linguagem para detecção de tópicos e posicionamentos em debates: um estudo de caso no contexto do Senado Federal.,"CAVALCANTI, Helen Bento.","CAMPELO, Claudio Elízio Calazans.","O poder legislativo no Brasil é uma das três funções essenciais do Estado. No entanto, há um desafio evidente em relação ao acompanhamento das discussões nos órgãos públicos por parte da população. Isso se deve à extensão considerável e ao volume significativo dessas reuniões, tornando-as inacessíveis para muitos cidadãos. Para enfrentar esse desafio, este estudo utilizou as notas taquigráficas do Senado Federal do ano de 2023, que são transcrições dos debates parlamentares, com o objetivo de avaliar o potencial de Grandes Modelos de Linguagem (do inglês, Large Language Models-LLMs), de detectar tópicos relevantes discutidos pelos parlamentares e o posicionamento deles em relação a esses tópicos, classificando-os como a favor, neutro ou contra. Foram realizados experimentos, ambos utilizando o modelo GPT-3.5-Turbo, para as tarefas mencionadas. O primeiro experimento empregou uma técnica de compressão de dados antes de fornecer a entrada para o GPT e abrangeu reuniões de diferentes tamanhos. O segundo experimento não envolveu compressão e focou apenas em reuniões pequenas. Os resultados indicam que o modelo teve um desempenho superior para reuniões pequenas. Além disso, em um panorama geral para reuniões independentes de tamanho, o modelo teve um desempenho superior na tarefa de detecção de tópicos, com uma precisão média de aproximadamente 70%, enquanto na detecção de posicionamento teve um desempenho razoável com uma precisão média de aproximadamente 60%.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38144,"o poder legislativo no brasil é uma das três funções essenciais do estado. no entanto, há um desafio evidente em relação ao acompanhamento das discussões nos órgãos públicos por parte da população. isso se deve à extensão considerável e ao volume significativo dessas reuniões, tornando-as inacessíveis para muitos cidadãos. para enfrentar esse desafio, este estudo utilizou as notas taquigráficas do senado federal do ano de , que são transcrições dos debates parlamentares, com o objetivo de avaliar o potencial de grandes modelos de linguagem (do inglês, large language models-llms), de detectar tópicos relevantes discutidos pelos parlamentares e o posicionamento deles em relação a esses tópicos, classificando-os como a favor, neutro ou contra. foram realizados experimentos, ambos utilizando o modelo gpt- . -turbo, para as tarefas mencionadas. o primeiro experimento empregou uma técnica de compressão de dados antes de fornecer a entrada para o gpt e abrangeu reuniões de diferentes tamanhos. o segundo experimento não envolveu compressão e focou apenas em reuniões pequenas. os resultados indicam que o modelo teve um desempenho superior para reuniões pequenas. além disso, em um panorama geral para reuniões independentes de tamanho, o modelo teve um desempenho superior na tarefa de detecção de tópicos, com uma precisão média de aproximadamente %, enquanto na detecção de posicionamento teve um desempenho razoável com uma precisão média de aproximadamente %."
48,2024,Mosquito zero: uma plataforma web para gerenciamento das inspeções de vigilância para o controle de vetores.,"SILVA, Gustavo Farias de Souza.","MASSONI, Tiago Lima.","Os agentes de vigilância ambiental em saúde exercem um papel fundamental no controle da proliferação dos mosquitos transmissores de doenças como a dengue, a zika e a chikungunya. Esses profissionais atuam no combate das arboviroses através de ações de campo, visitas domiciliares e comunitárias. Essas atividades têm como principal função a identificação e o tratamento de focos de reprodução dos vetores. Atualmente, o registro dos dados das inspeções realizadas pelos agentes de vigilância da cidade de Campina Grande-PB, é feito utilizando um formulário de papel. Porém, esse formato de anotação pode apresentar diversos problemas na organização, na visualização e na segurança das informações. Sendo assim, visando auxiliar o serviço desses profissionais, este trabalho tem como objetivo desenvolver a primeira versão de uma plataforma web responsiva, para o registro e acompanhamento das pesquisas entomológicas realizadas pelo agente, o Mosquito Zero. A primeira versão da aplicação foi testada com alguns agentes de vigilância da cidade de Cabedelo no Estado da Paraíba, a fim de obter a avaliação desses usuários referente à usabilidade do sistema.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38143,"os agentes de vigilância ambiental em saúde exercem um papel fundamental no controle da proliferação dos mosquitos transmissores de doenças como a dengue, a zika e a chikungunya. esses profissionais atuam no combate das arboviroses através de ações de campo, visitas domiciliares e comunitárias. essas atividades têm como principal função a identificação e o tratamento de focos de reprodução dos vetores. atualmente, o registro dos dados das inspeções realizadas pelos agentes de vigilância da cidade de campina grande-pb, é feito utilizando um formulário de papel. porém, esse formato de anotação pode apresentar diversos problemas na organização, na visualização e na segurança das informações. sendo assim, visando auxiliar o serviço desses profissionais, este trabalho tem como objetivo desenvolver a primeira versão de uma plataforma web responsiva, para o registro e acompanhamento das pesquisas entomológicas realizadas pelo agente, o mosquito zero. a primeira versão da aplicação foi testada com alguns agentes de vigilância da cidade de cabedelo no estado da paraíba, a fim de obter a avaliação desses usuários referente à usabilidade do sistema."
49,2024,Uma abordagem para detecção e correção de vulnerabilidades em árvores de dependências de software.,"SOUTO, Gabriel Mareco Batista de.","BAPTISTA, Cláudio de Souza.","Vulnerabilidades em dependências de software, transitivas e indiretas, são uma realidade frequente devido ao uso intensivo de bibliotecas e frameworks. Esse cenário aumenta os riscos de falhas de segurança e compromete a integridade dos sistemas. Diante dessa problemática, neste artigo propõe-se o Safer, uma ferramenta automatizada projetada para detectar e corrigir vulnerabilidades nas árvores de dependências de software. O Safer não só identifica versões seguras das dependências, mas também verifica sua compatibilidade através de testes exploratórios. A metodologia adotada envolve uma análise comparativa de ferramentas existentes e a aplicação do Open Source Insights para diagnóstico de vulnerabilidades, complementada pelo uso do Randoop para os testes de compatibilidade. Os resultados obtidos com o Safer demonstram sua eficácia em reduzir significativamente as vulnerabilidades em todos os níveis de severidade, com uma redução geral aproximada de 90,46%. Destaca-se a capacidade da ferramenta de mitigar ameaças e indicar a viabilidade de sua expansão para outras linguagens e gerenciadores de dependências, fortalecendo assim a segurança e a confiabilidade dos sistemas de software.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38141,"vulnerabilidades em dependências de software, transitivas e indiretas, são uma realidade frequente devido ao uso intensivo de bibliotecas e frameworks. esse cenário aumenta os riscos de falhas de segurança e compromete a integridade dos sistemas. diante dessa problemática, neste artigo propõe-se o safer, uma ferramenta automatizada projetada para detectar e corrigir vulnerabilidades nas árvores de dependências de software. o safer não só identifica versões seguras das dependências, mas também verifica sua compatibilidade através de testes exploratórios. a metodologia adotada envolve uma análise comparativa de ferramentas existentes e a aplicação do open source insights para diagnóstico de vulnerabilidades, complementada pelo uso do randoop para os testes de compatibilidade. os resultados obtidos com o safer demonstram sua eficácia em reduzir significativamente as vulnerabilidades em todos os níveis de severidade, com uma redução geral aproximada de , %. destaca-se a capacidade da ferramenta de mitigar ameaças e indicar a viabilidade de sua expansão para outras linguagens e gerenciadores de dependências, fortalecendo assim a segurança e a confiabilidade dos sistemas de software."
50,2024,Evolução de sistema de apoio para disciplina de Laboratório de Estrutura de Dados e Algoritmos.,"BARROS, Gabriel de Sousa .","FARIAS, Adalberto Cajueiro de.","Na disciplina de Laboratório de Estrutura de Dados e Algoritmos (LEDA) do curso de Ciência da Computação na UFCG, os professores avaliam os alunos através de atividades práticas semanais e provas, também práticas, ao fim de cada unidade do semestre letivo. Dado o grande número de alunos e atividades realizadas, a disciplina utiliza de um sistema para automação de algumas tarefas e facilitação da correção por parte da equipe de avaliação. Esse sistema, apesar de bastante útil, apresenta alguns problemas, estes sendo a falta de privacidade para os dados disponibilizados pelo sistema, uma interface datada e o uso de tecnologias já obsoletas que dificultam a sua manutenção. Este trabalho propõe solucionar estes problemas ao reescrever o sistema utilizando tecnologias mais recentes, atualizando a sua interface e adicionando autenticação e autorização à nova versão. Através dessas adições foi possível verificar de forma qualitativa que o sistema agora oferece maior privacidade aos dados, apresenta uma interface mais agradável e, utilizando de tecnologias mais modernas, facilita a sua manutenção.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38138,"na disciplina de laboratório de estrutura de dados e algoritmos (leda) do curso de ciência da computação na ufcg, os professores avaliam os alunos através de atividades práticas semanais e provas, também práticas, ao fim de cada unidade do semestre letivo. dado o grande número de alunos e atividades realizadas, a disciplina utiliza de um sistema para automação de algumas tarefas e facilitação da correção por parte da equipe de avaliação. esse sistema, apesar de bastante útil, apresenta alguns problemas, estes sendo a falta de privacidade para os dados disponibilizados pelo sistema, uma interface datada e o uso de tecnologias já obsoletas que dificultam a sua manutenção. este trabalho propõe solucionar estes problemas ao reescrever o sistema utilizando tecnologias mais recentes, atualizando a sua interface e adicionando autenticação e autorização à nova versão. através dessas adições foi possível verificar de forma qualitativa que o sistema agora oferece maior privacidade aos dados, apresenta uma interface mais agradável e, utilizando de tecnologias mais modernas, facilita a sua manutenção."
51,2024,ACEV+: uma solução web eficiente para o gerenciamento e integração de uma instituição religiosa.,"COSTA, Gabriel Fernandes da.","FARIAS, Adalberto Cajueiro de.","As instituições religiosas desempenham um papel vital na vida comunitária de muitos indivíduos. No entanto, à medida que essas comunidades crescem em tamanho e complexidade, a necessidade de ferramentas de gestão eficientes torna-se ainda mais urgente. Este trabalho tem como objetivo apresentar um sistema que atenda a essa necessidade por meio de uma plataforma centralizada para gerenciar as entidades presentes no contexto da instituição ACEV em Campina Grande- PB. O sistema engloba uma variedade de funcionalidades, incluindo registro e gerenciamento de dados dos membros, grupos, ministérios, acompanhamento de reuniões, bem como gestão de séries de estudo e lições associadas. Esta solução visa facilitar a organização, colaboração e crescimento dentro da instituição, além de trazer uma abordagem mais automatizada e eficaz para a criação de planejamentos estratégicos.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38136,"as instituições religiosas desempenham um papel vital na vida comunitária de muitos indivíduos. no entanto, à medida que essas comunidades crescem em tamanho e complexidade, a necessidade de ferramentas de gestão eficientes torna-se ainda mais urgente. este trabalho tem como objetivo apresentar um sistema que atenda a essa necessidade por meio de uma plataforma centralizada para gerenciar as entidades presentes no contexto da instituição acev em campina grande- pb. o sistema engloba uma variedade de funcionalidades, incluindo registro e gerenciamento de dados dos membros, grupos, ministérios, acompanhamento de reuniões, bem como gestão de séries de estudo e lições associadas. esta solução visa facilitar a organização, colaboração e crescimento dentro da instituição, além de trazer uma abordagem mais automatizada e eficaz para a criação de planejamentos estratégicos."
52,2024,Relato de experiência: testes em sistemas distribuídos.,"LIMA, Gabriel Cavalcanti Leandro de.","MORAIS, Fábio Jorge Almeida.","No cenário atual de desenvolvimento de software, é evidente uma ampla adesão de modelos baseados em sistemas distribuídos, principalmente aqueles relacionados à computação na nuvem. Essa abordagem, embora ofereça benefícios de escalabilidade e flexibilidade, também introduz desafios significativos em relação à segurança, à conformidade, confiabilidade e à qualidade do serviço. Uma forma de garantir esses princípios é mediante a adoção de testes automáticos. No entanto, devido à complexidade inerente da arquitetura dos sistemas distribuídos e à sua necessidade de que todos componentes do sistema existam e persistam simultaneamente, extrair o comportamento do sistema torna-se uma atividade desafiadora. Serão abordados neste trabalho os desafios e soluções relacionados à criação de uma suíte de teste para ambientes naturalmente distribuídos, utilizando como exemplo um sistema open-source formado por servidores SPIRE que trabalham em conjunto com uma unidade federadora Galadriel, para estabelecer e gerenciar a confiança entre as entidades, ou seja, simulam a operação de federação confiável entre entidades, previamente desconhecidas.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38133,"no cenário atual de desenvolvimento de software, é evidente uma ampla adesão de modelos baseados em sistemas distribuídos, principalmente aqueles relacionados à computação na nuvem. essa abordagem, embora ofereça benefícios de escalabilidade e flexibilidade, também introduz desafios significativos em relação à segurança, à conformidade, confiabilidade e à qualidade do serviço. uma forma de garantir esses princípios é mediante a adoção de testes automáticos. no entanto, devido à complexidade inerente da arquitetura dos sistemas distribuídos e à sua necessidade de que todos componentes do sistema existam e persistam simultaneamente, extrair o comportamento do sistema torna-se uma atividade desafiadora. serão abordados neste trabalho os desafios e soluções relacionados à criação de uma suíte de teste para ambientes naturalmente distribuídos, utilizando como exemplo um sistema open-source formado por servidores spire que trabalham em conjunto com uma unidade federadora galadriel, para estabelecer e gerenciar a confiança entre as entidades, ou seja, simulam a operação de federação confiável entre entidades, previamente desconhecidas."
53,2024,Criptografia homomórfica no aprendizado de máquina.,"SILVA, Filipe Ramalho da.","PEREIRA, Eanes Torres.","A criptografia homomórfica representa uma mudança de paradigma no âmbito do processamento seguro de dados, permitindo cálculos em dados criptografados sem a necessidade de descriptografia. Essa propriedade promete enormes avanços para aprimorar a privacidade e segurança em diversos domínios, incluindo computação em nuvem, saúde, finanças e também no aprendizado de máquina. Este TCC adentra nos fundamentos da criptografia homomórfica no aprendizado de máquina, elucidando suas bases matemáticas e explorando suas aplicações práticas. Através de uma revisão da literatura existente e metodologias, esta pesquisa avalia os pontos fortes, fraquezas e desafios potenciais associados. Além disso, investiga as implicações de desempenho e sobrecargas computacionais incorridas por diferentes esquemas de criptografía homomórfica. O estudo também examina casos de uso do mundo real e cenários de implementação para avaliar a viabilidade e eficácia da criptografia homomórfica para processamento seguro de dados e tecnologias de preservação de privacidade.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38116,"a criptografia homomórfica representa uma mudança de paradigma no âmbito do processamento seguro de dados, permitindo cálculos em dados criptografados sem a necessidade de descriptografia. essa propriedade promete enormes avanços para aprimorar a privacidade e segurança em diversos domínios, incluindo computação em nuvem, saúde, finanças e também no aprendizado de máquina. este tcc adentra nos fundamentos da criptografia homomórfica no aprendizado de máquina, elucidando suas bases matemáticas e explorando suas aplicações práticas. através de uma revisão da literatura existente e metodologias, esta pesquisa avalia os pontos fortes, fraquezas e desafios potenciais associados. além disso, investiga as implicações de desempenho e sobrecargas computacionais incorridas por diferentes esquemas de criptografía homomórfica. o estudo também examina casos de uso do mundo real e cenários de implementação para avaliar a viabilidade e eficácia da criptografia homomórfica para processamento seguro de dados e tecnologias de preservação de privacidade."
54,2024,LSI analytics: simplificando o desenvolvimento de aplicações web de business intelligence.,"SILVA, Felipe Oliveira da.","BAPTISTA, Cláudio de Souza.","Este trabalho apresenta o LSI Analytics, uma plataforma de Business Intelligence (BI) projetada para permitir aos usuários a análise e visualização eficiente de dados a partir de diversas fontes. A plataforma oferece uma abordagem intuitiva e flexível para a criação de gráficos, facilitando a tomada de decisões informadas pelos usuários. O estudo aborda os desafios enfrentados no desenvolvimento da plataforma, incluindo a garantia de renderização dinâmica e manipulação eficiente de conjuntos de dados. Como perspectivas futuras, são propostas melhorias adicionais na plataforma, visando ampliar suas capacidades de análise de dados e visualização. Este estudo contribui para o avanço no campo do Business Intelligence, fornecendo uma solução acessível e eficaz para a análise de dados.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38114,"este trabalho apresenta o lsi analytics, uma plataforma de business intelligence (bi) projetada para permitir aos usuários a análise e visualização eficiente de dados a partir de diversas fontes. a plataforma oferece uma abordagem intuitiva e flexível para a criação de gráficos, facilitando a tomada de decisões informadas pelos usuários. o estudo aborda os desafios enfrentados no desenvolvimento da plataforma, incluindo a garantia de renderização dinâmica e manipulação eficiente de conjuntos de dados. como perspectivas futuras, são propostas melhorias adicionais na plataforma, visando ampliar suas capacidades de análise de dados e visualização. este estudo contribui para o avanço no campo do business intelligence, fornecendo uma solução acessível e eficaz para a análise de dados."
55,2024,Uma abordagem para a descoberta automática de elementos web acionáveis para teste sistemático de GUI.,"MENDES, Francisco Igor de Lima.","ALVES, Everton Leandro Galdino.","A geração automática de testes da interface gráfica do usuário (GUI) desempenha um papel crucial na detecção de faltas em aplicações web. Nesse contexto, scriptless testing automatiza a geração e execução de casos de teste com base nos elementos localizados da GUI. No entanto, a localização automática eficaz e não repetitiva dos elementos acionáveis em páginas complexas permanece um desafio. Técnicas existentes dependem de adaptações extensivas à aplicação sob teste, podendo ser onerosas e complexas. Como solução para essa problemática, propomos a utilização de uma técnica de localização automática, Unique Actionable Element Search (UAES), com o intuito de distinguir elementos acionáveis por meio do seu papel funcional, identificando-os unicamente sem intervenção no código-fonte. Nosso estudo empírico comparou e avaliou a eficácia da técnica de localização UAES comum a técnica de marcação explícita. Essa comparação foi conduzida em quatro aplicações open-source das quais testadores experientes destacaram os elementos acionáveis como parte da técnica de marcação explícita. Os resultados indicaram que nossa abordagem descobriu 79.81% dos elementos destacados, enquanto identificou novos elementos (8.1% de todos os elementos descobertos) que não foram evidenciados pelos testadores.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38108,"a geração automática de testes da interface gráfica do usuário (gui) desempenha um papel crucial na detecção de faltas em aplicações web. nesse contexto, scriptless testing automatiza a geração e execução de casos de teste com base nos elementos localizados da gui. no entanto, a localização automática eficaz e não repetitiva dos elementos acionáveis em páginas complexas permanece um desafio. técnicas existentes dependem de adaptações extensivas à aplicação sob teste, podendo ser onerosas e complexas. como solução para essa problemática, propomos a utilização de uma técnica de localização automática, unique actionable element search (uaes), com o intuito de distinguir elementos acionáveis por meio do seu papel funcional, identificando-os unicamente sem intervenção no código-fonte. nosso estudo empírico comparou e avaliou a eficácia da técnica de localização uaes comum a técnica de marcação explícita. essa comparação foi conduzida em quatro aplicações open-source das quais testadores experientes destacaram os elementos acionáveis como parte da técnica de marcação explícita. os resultados indicaram que nossa abordagem descobriu . % dos elementos destacados, enquanto identificou novos elementos ( . % de todos os elementos descobertos) que não foram evidenciados pelos testadores."
56,2024,Análise do impacto da pandemia na execução curricular dos estudantes do Curso de Ciência da Computação da UFCG.,"GONÇALVES, Eric Diego Matozo.","BRASILEIRO, Francisco Vilar.","Diante da atípica situação causada pela pandemia de COVID-19, ocorrida entre o final de 2019 e meados de 2022, o Ministério da Educação autorizou o ensino remoto em cursos outrora presenciais. Essa medida possuía o intuito de amenizar possíveis prejuízos causados ao sistema federal de ensino pela pandemia. Nesse contexto, a Unidade Acadêmica de Sistemas e Computação da Universidade Federal de Campina Grande, juntamente com seu corpo docente, se viu diante do desafio de adaptar sua execução curricular ao ambiente virtual. Passada a pandemia, surge a necessidade de analisar as consequências dela, em virtude da necessidade de adaptação das metodologias das aulas ao ensino remoto. Este trabalho propõe o emprego de técnicas de análise e visualização de dados, a partir da coleta dos dados do Sistema de Controle Acadêmico Online (SCAO), tendo como objetivo contribuir para a análise de efeitos e implicações exercidos pela pandemia de COVID-19 sobre os estudantes de graduação do curso Ciência da Computação da Universidade Federal de Campina Grande. Como resultados encontrados, pode-se citar o fato de que o desempenho acadêmico dos alunos, na maior parte das disciplinas, voltou a alcançar os mesmos níveis do período da pré-pandemia, com uma tendência de aumento de trancamentos durante o pós-pandemia, sendo este o período que possui a maior quantidade de trancamentos registrados.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38107,"diante da atípica situação causada pela pandemia de covid- , ocorrida entre o final de e meados de , o ministério da educação autorizou o ensino remoto em cursos outrora presenciais. essa medida possuía o intuito de amenizar possíveis prejuízos causados ao sistema federal de ensino pela pandemia. nesse contexto, a unidade acadêmica de sistemas e computação da universidade federal de campina grande, juntamente com seu corpo docente, se viu diante do desafio de adaptar sua execução curricular ao ambiente virtual. passada a pandemia, surge a necessidade de analisar as consequências dela, em virtude da necessidade de adaptação das metodologias das aulas ao ensino remoto. este trabalho propõe o emprego de técnicas de análise e visualização de dados, a partir da coleta dos dados do sistema de controle acadêmico online (scao), tendo como objetivo contribuir para a análise de efeitos e implicações exercidos pela pandemia de covid- sobre os estudantes de graduação do curso ciência da computação da universidade federal de campina grande. como resultados encontrados, pode-se citar o fato de que o desempenho acadêmico dos alunos, na maior parte das disciplinas, voltou a alcançar os mesmos níveis do período da pré-pandemia, com uma tendência de aumento de trancamentos durante o pós-pandemia, sendo este o período que possui a maior quantidade de trancamentos registrados."
57,2024,Avaliação de ferramentas de extração de texto em documentos PDF.,"NERY, Luiz Gustavo Alves.","BAPTISTA, Cláudio de Souza.","Este estudo aborda a importância da extração precisa de informações em documentos PDF, destacando os desafios enfrentados devido à falta de uniformidade na estrutura e layout desses documentos. A extração de texto em documentos PDF, especialmente em contextos como Diários Oficiais, é crucial para automatizar processos e otimizar a análise de informações relevantes. A métrica ROUGE é utilizada para avaliar a qualidade da extração de texto pelas ferramentas e a importância de extrair todas as informações do texto original preservando a ordem de leitura. Diante da ineficiência e alto custo associado à extração manual de texto de documentos em formato PDF, este estudo visa proporcionar percepções significativas que auxiliam na escolha da ferramenta mais adequada, considerando os diferentes cenários de aplicação na extração de texto. A avaliação das ferramentas escolhidas, juntamente com a mensuração dos resultados através de métricas pertinentes à avaliação dos textos extraídos, aprimora a eficácia e a eficiência na análise dessas ferramentas.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38065,"este estudo aborda a importância da extração precisa de informações em documentos pdf, destacando os desafios enfrentados devido à falta de uniformidade na estrutura e layout desses documentos. a extração de texto em documentos pdf, especialmente em contextos como diários oficiais, é crucial para automatizar processos e otimizar a análise de informações relevantes. a métrica rouge é utilizada para avaliar a qualidade da extração de texto pelas ferramentas e a importância de extrair todas as informações do texto original preservando a ordem de leitura. diante da ineficiência e alto custo associado à extração manual de texto de documentos em formato pdf, este estudo visa proporcionar percepções significativas que auxiliam na escolha da ferramenta mais adequada, considerando os diferentes cenários de aplicação na extração de texto. a avaliação das ferramentas escolhidas, juntamente com a mensuração dos resultados através de métricas pertinentes à avaliação dos textos extraídos, aprimora a eficácia e a eficiência na análise dessas ferramentas."
58,2024,Detecção de sobrepreço e subpreço em auditoria de licitações.,"COSTA, Lucian Julio Felix da.","BAPTISTA, Cláudio de Souza.","Auditar processos de licitação é crucial para garantir transparência e eficiência na gestão dos fundos públicos. No entanto, a crescente complexidade das licitações representa um desafio para os auditores, especialmente na detecção oportuna de irregularidades. Este trabalho apresenta um software de comparação de preços desenvolvido para facilitar a análise de sobrepreço e subpreço em licitações de obras públicas, fazendo uso de mineração de dados e busca semântica. A ferramenta tem como objetivo fornecer visualizações que auxiliem na detecção de possíveis fraudes, utilizando dados atualizados de mercado. Espera-se que essa ferramenta contribua para a eficiência da fiscalização em licitações de obras públicas, melhorando a análise financeira e dificultando práticas fraudulentas por parte dos licitantes.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38064,"auditar processos de licitação é crucial para garantir transparência e eficiência na gestão dos fundos públicos. no entanto, a crescente complexidade das licitações representa um desafio para os auditores, especialmente na detecção oportuna de irregularidades. este trabalho apresenta um software de comparação de preços desenvolvido para facilitar a análise de sobrepreço e subpreço em licitações de obras públicas, fazendo uso de mineração de dados e busca semântica. a ferramenta tem como objetivo fornecer visualizações que auxiliem na detecção de possíveis fraudes, utilizando dados atualizados de mercado. espera-se que essa ferramenta contribua para a eficiência da fiscalização em licitações de obras públicas, melhorando a análise financeira e dificultando práticas fraudulentas por parte dos licitantes."
59,2024,Senado aberto: dados abertos das votações nominais.,"OLIVEIRA, Emilly de Albuquerque.","MORAIS, Fábio Jorge Almeida.","Diante da crescente demanda por transparência política e participação pública, surge a necessidade de informações acessíveis sobre as votações no Senado brasileiro. No entanto, os registros dispersos em PDF ou páginas da web dificultam o acompanhamento. Este projeto visa preencher essa lacuna ao criar uma aplicação com uma API que coleta, processa e disponibiliza os dados das votações dos representantes no Senado. A metodologia abrange coleta de dados confiáveis, desenvolvimento de algoritmos para estruturação, criação da API, implementação de um watcher para novas votações e um front-end interativo. Os resultados esperados incluem uma aplicação amigável que permite aos cidadãos acompanhar as atividades de seus representantes, promovendo a transparência política ao facilitar o acesso às informações sobre as votações no Senado.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38063,"diante da crescente demanda por transparência política e participação pública, surge a necessidade de informações acessíveis sobre as votações no senado brasileiro. no entanto, os registros dispersos em pdf ou páginas da web dificultam o acompanhamento. este projeto visa preencher essa lacuna ao criar uma aplicação com uma api que coleta, processa e disponibiliza os dados das votações dos representantes no senado. a metodologia abrange coleta de dados confiáveis, desenvolvimento de algoritmos para estruturação, criação da api, implementação de um watcher para novas votações e um front-end interativo. os resultados esperados incluem uma aplicação amigável que permite aos cidadãos acompanhar as atividades de seus representantes, promovendo a transparência política ao facilitar o acesso às informações sobre as votações no senado."
60,2024,Desenvolvimento interativo de plugins para produção musical com testes em tempo real.,"MINÁ, Lucas da Rocha.","GUERRERO, Dalton Dario Serey.","Plugins, programas auxiliares na produção musical, são muito desejados por artistas nos dias de hoje por expandirem as possibilidades na criação de música. Em seu processo criativo, necessidades específicas aparecem frequentemente, então a idéia de criar seu próprio plugin pode ser muito atrativa. Porém, o processo de programação de plugins pode ser consideravelmente contra intuitivo, pois para sequer poder ouvir os resultados que estes podem trazer à composição, normalmente é necessário escrever e compilar o programa de forma separada, para somente então testar. Este projeto, então, visa demonstrar a viabilidade de uma alternativa existente, muito mais interativa, apropriada para músicos que tenham menos afinidade com tecnologias de programação. A solução proposta envolve utilizar dois programas, plugdata e hvcc, para criar plugins de diversos tipos, sem a necessidade de escrever código e podendo fazer os testes destes em tempo real. O plugdata fornece ao usuário um ambiente para construir diversas funcionalidades úteis para uma composição, sendo possível ouvir os resultados em tempo real. Utilizando então o outro programa, hvcc, é possível converter essa construção do plugdata em código na linguagem C++, compilar esse código e transformá-lo em um plugin nos formatos desejados. Assim, a criação de plugins torna-se muito mais acessível aos artistas musicais. Para demonstrar isso, foram criados três plugins, de funcionalidades diferentes, os quais foram utilizados na composição de uma faixa musical original.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38062,"plugins, programas auxiliares na produção musical, são muito desejados por artistas nos dias de hoje por expandirem as possibilidades na criação de música. em seu processo criativo, necessidades específicas aparecem frequentemente, então a idéia de criar seu próprio plugin pode ser muito atrativa. porém, o processo de programação de plugins pode ser consideravelmente contra intuitivo, pois para sequer poder ouvir os resultados que estes podem trazer à composição, normalmente é necessário escrever e compilar o programa de forma separada, para somente então testar. este projeto, então, visa demonstrar a viabilidade de uma alternativa existente, muito mais interativa, apropriada para músicos que tenham menos afinidade com tecnologias de programação. a solução proposta envolve utilizar dois programas, plugdata e hvcc, para criar plugins de diversos tipos, sem a necessidade de escrever código e podendo fazer os testes destes em tempo real. o plugdata fornece ao usuário um ambiente para construir diversas funcionalidades úteis para uma composição, sendo possível ouvir os resultados em tempo real. utilizando então o outro programa, hvcc, é possível converter essa construção do plugdata em código na linguagem c++, compilar esse código e transformá-lo em um plugin nos formatos desejados. assim, a criação de plugins torna-se muito mais acessível aos artistas musicais. para demonstrar isso, foram criados três plugins, de funcionalidades diferentes, os quais foram utilizados na composição de uma faixa musical original."
61,2024,Avaliando a capacidade de LLMS na identificação de erros de compilação em linhas de produto de software.,"ALBUQUERQUE, Lucas Brenner Herculano e.","GHEYI, Rohit.","A compilação é um processo essencial no desenvolvimento de linhas de produto de software, como o Linux. Entretanto, identificar erros de compilação em Linhas de Produto de Software (LPS) não é trivial, já que os compiladores tradicionais não são conscientes de variação. Abordagens anteriores foram propostas que identificam alguns desses erros de compilação usando técnicas avançadas que requerem um esforço dos programadores em usarem. Este estudo avalia a eficácia de Modelos de Linguagem de Grande Porte (LLMs), especificamente o ChatGPT 4 e Le Chat Mistral, na identificação de erros de compilação em LPS. Inicialmente foram testados 50 produtos nas linguagens C++, Java e C, e posteriormente 30 LPS em C, abrangendo 17 tipos diferentes de erros de compilação. Os dois LLMs foram avaliados com base na sua capacidade de reconhecer e diagnosticar corretamente os erros. O ChatGPT conseguiu identificar 82% e 95% dos erros de compilação em produtos e LPS, enquanto que o Le Chat Mistral obteve 56% e 78%, respectivamente. A análise revelou que, embora os LLMs possam identificar uma gama de erros de compilação, desafios específicos permanecem, especialmente em ambientes de LPS com alta variabilidade. O estudo sugere a necessidade de refinamentos contínuos nos modelos de LLM para melhorar sua precisão e utilidade em cenários de desenvolvimento de software complexos.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38061,"a compilação é um processo essencial no desenvolvimento de linhas de produto de software, como o linux. entretanto, identificar erros de compilação em linhas de produto de software (lps) não é trivial, já que os compiladores tradicionais não são conscientes de variação. abordagens anteriores foram propostas que identificam alguns desses erros de compilação usando técnicas avançadas que requerem um esforço dos programadores em usarem. este estudo avalia a eficácia de modelos de linguagem de grande porte (llms), especificamente o chatgpt e le chat mistral, na identificação de erros de compilação em lps. inicialmente foram testados produtos nas linguagens c++, java e c, e posteriormente lps em c, abrangendo tipos diferentes de erros de compilação. os dois llms foram avaliados com base na sua capacidade de reconhecer e diagnosticar corretamente os erros. o chatgpt conseguiu identificar % e % dos erros de compilação em produtos e lps, enquanto que o le chat mistral obteve % e %, respectivamente. a análise revelou que, embora os llms possam identificar uma gama de erros de compilação, desafios específicos permanecem, especialmente em ambientes de lps com alta variabilidade. o estudo sugere a necessidade de refinamentos contínuos nos modelos de llm para melhorar sua precisão e utilidade em cenários de desenvolvimento de software complexos."
62,2024,Avaliação de LLMS na resolução de questões do ENEM.,"RAPOSO, Lucas Brasileiro.","MORAIS, Fábio Jorge Almeida.","Grandes Modelos de Linguagem (LLMs do inglês, Large Language Models) surgiram como uma quebra de paradigma no uso da Inteligência Artificial (IA) e são amplamente usados em diferentes áreas. Um dos maiores responsáveis pela popularização desse termo é o ChatGPT, desenvolvido pela OpenAI. A partir da ascensão desse, outras empresas, como a Meta e a Google, desenvolveram seus próprios modelos como alternativas ao GPT. Essas ferramentas se apresentam como solução de problemas nos mais variados contextos. Entretanto, pouca atenção é voltada para medir a capacidade de corretude e eficiência de suas respostas. Somado a isso, a maioria dos estudos neste âmbito, se prendem ao contexto da língua inglesa, sem que os modelos sejam efetivamente testados em cenários globalizados. Logo, este estudo propõe submeter os sistemas da Meta, da OpenAI e da Google à avaliações de múltipla escolha objetivas sobre conteúdos de nível médio, por meio das provas do Exame Nacional do Ensino Médio (ENEM). Após colher as respostas dos modelos, análises foram realizadas, comparando desempenho, entre cada uma delas e com médias dos alunos brasileiros, considerando quantidade de acertos por prova. Então, surpreendentemente, este trabalho mostrou que todos os três modelos desempenharam melhor em áreas mais “subjetivas” que em áreas objetivas, indo contra o senso comum.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38059,"grandes modelos de linguagem (llms do inglês, large language models) surgiram como uma quebra de paradigma no uso da inteligência artificial (ia) e são amplamente usados em diferentes áreas. um dos maiores responsáveis pela popularização desse termo é o chatgpt, desenvolvido pela openai. a partir da ascensão desse, outras empresas, como a meta e a google, desenvolveram seus próprios modelos como alternativas ao gpt. essas ferramentas se apresentam como solução de problemas nos mais variados contextos. entretanto, pouca atenção é voltada para medir a capacidade de corretude e eficiência de suas respostas. somado a isso, a maioria dos estudos neste âmbito, se prendem ao contexto da língua inglesa, sem que os modelos sejam efetivamente testados em cenários globalizados. logo, este estudo propõe submeter os sistemas da meta, da openai e da google à avaliações de múltipla escolha objetivas sobre conteúdos de nível médio, por meio das provas do exame nacional do ensino médio (enem). após colher as respostas dos modelos, análises foram realizadas, comparando desempenho, entre cada uma delas e com médias dos alunos brasileiros, considerando quantidade de acertos por prova. então, surpreendentemente, este trabalho mostrou que todos os três modelos desempenharam melhor em áreas mais “subjetivas” que em áreas objetivas, indo contra o senso comum."
63,2024,FUBBY: um sistema informativo e interativo para o planejamento acadêmico do aluno de Ciência da Computação na UFCG.,"MELO, Emannuelly Larissa Freitas de.","MASSONI, Tiago Lima.","Ao ingressar na universidade, muitos alunos desconhecem os múltiplos campos profissionais vinculados ao curso, as horas complementares que devem ser cumpridas e a relevância das disciplinas oferecidas. Atualmente, no Curso de Ciência da Computação da UFCG, mesmo que algumas dessas questões estejam dispostas em portais oficiais do curso e de ser possível alcançá-las por meio do diálogo, elas ainda não são apresentadas de forma simples e centralizada. Esse contexto é problemático por diversos motivos, dentre eles, a disparidade de conhecimento entre as pessoas, a facilidade de propagação de afirmações incorretas e o consequente mau planejamento curricular. A fim de contribuir com a diminuição desse cenário de déficit informacional, este trabalho propõe um sistema web que apresenta áreas profissionais de acordo com as disciplinas ofertadas no curso, que interage com o aluno para oferecer informações individuais sobre horas complementares e disciplinas optativas, bem como provê um ambiente colaborativo e saudável de comentários sobre as disciplinas. Os resultados do sistema em uso refletem uma elevada satisfação com a facilidade na execução das tarefas e com a proposta da aplicação, contudo, indicam que a comunicação com o usuário pode ser melhor estabelecida e que são desejadas mais funcionalidades no sistema.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38057,"ao ingressar na universidade, muitos alunos desconhecem os múltiplos campos profissionais vinculados ao curso, as horas complementares que devem ser cumpridas e a relevância das disciplinas oferecidas. atualmente, no curso de ciência da computação da ufcg, mesmo que algumas dessas questões estejam dispostas em portais oficiais do curso e de ser possível alcançá-las por meio do diálogo, elas ainda não são apresentadas de forma simples e centralizada. esse contexto é problemático por diversos motivos, dentre eles, a disparidade de conhecimento entre as pessoas, a facilidade de propagação de afirmações incorretas e o consequente mau planejamento curricular. a fim de contribuir com a diminuição desse cenário de déficit informacional, este trabalho propõe um sistema web que apresenta áreas profissionais de acordo com as disciplinas ofertadas no curso, que interage com o aluno para oferecer informações individuais sobre horas complementares e disciplinas optativas, bem como provê um ambiente colaborativo e saudável de comentários sobre as disciplinas. os resultados do sistema em uso refletem uma elevada satisfação com a facilidade na execução das tarefas e com a proposta da aplicação, contudo, indicam que a comunicação com o usuário pode ser melhor estabelecida e que são desejadas mais funcionalidades no sistema."
64,2024,Reconhecimento de datas manuscritas em prescrições médicas: comparativo entre OCRs com Licença de Software Livre e uma solução comercial.,"LIMA, Leandro de Souto.","GOMES, Herman Martins.","O reconhecimento de datas em prescrições médicas é uma tarefa crítica para garantir a segurança do paciente e a eficiência dos processos médicos. Este estudo propõe uma análise comparativa entre modelos de reconhecimento óptico de caracteres (OCR) e modelos de reconhecimento de texto manuscritos para identificar e extrair datas de prescrições médicas. O reconhecimento preciso de datas é essencial para evitar erros de medicação e garantir a administração adequada de tratamentos. Avaliamos a precisão, a velocidade e a robustez dos modelos em diferentes cenários e tipos de caligrafia, considerando as variações comuns encontradas em prescrições médicas. Os resultados mostram que os modelos de OCR apresentam vantagens em termos de velocidade e precisão em textos impressos, enquanto os modelos de reconhecimento de texto manuscritos destacam-se na interpretação de caligrafias variadas. Essas descobertas fornecem insights valiosos para o desenvolvimento de sistemas de reconhecimento de datas mais eficazes em ambientes clínicos.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38055,"o reconhecimento de datas em prescrições médicas é uma tarefa crítica para garantir a segurança do paciente e a eficiência dos processos médicos. este estudo propõe uma análise comparativa entre modelos de reconhecimento óptico de caracteres (ocr) e modelos de reconhecimento de texto manuscritos para identificar e extrair datas de prescrições médicas. o reconhecimento preciso de datas é essencial para evitar erros de medicação e garantir a administração adequada de tratamentos. avaliamos a precisão, a velocidade e a robustez dos modelos em diferentes cenários e tipos de caligrafia, considerando as variações comuns encontradas em prescrições médicas. os resultados mostram que os modelos de ocr apresentam vantagens em termos de velocidade e precisão em textos impressos, enquanto os modelos de reconhecimento de texto manuscritos destacam-se na interpretação de caligrafias variadas. essas descobertas fornecem insights valiosos para o desenvolvimento de sistemas de reconhecimento de datas mais eficazes em ambientes clínicos."
65,2024,Detectando fraquezas usando modelos de linguagem de grande porte: uma avaliação comparativa.,"MAIA SOBRINHO, Kleber Reudo Filgueiras.","GHEYI, Rohit.","A era digital exige software seguro. Fraquezas no código-fonte podem ter consequências graves, desde falhas de software até ataques cibernéticos. Modelos de Linguagem de Grande Porte (LLMs) como ChatGPT 3.5, Gemini 1.0, Claude 3 Sonnet e Mistral Large surgem como ferramentas promissoras para auxiliar na detecção de fraquezas em código-fonte. Este projeto avalia o desempenho de LLMs na detecção de 56 exemplos de fraquezas em código-fonte. Os resultados demonstram que as LLMs podem ser ferramentas importantes para programadores. Na nossa avaliação, as LLMs detectaram 75% das fraquezas de diferentes tipos como: SQL Injection, Cross-site Scripting, Out-of-bounds Write e Null Pointer Dereference. O Claude 3 Sonnet foi a LLM com o melhor resultado.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38053,"a era digital exige software seguro. fraquezas no código-fonte podem ter consequências graves, desde falhas de software até ataques cibernéticos. modelos de linguagem de grande porte (llms) como chatgpt . , gemini . , claude sonnet e mistral large surgem como ferramentas promissoras para auxiliar na detecção de fraquezas em código-fonte. este projeto avalia o desempenho de llms na detecção de exemplos de fraquezas em código-fonte. os resultados demonstram que as llms podem ser ferramentas importantes para programadores. na nossa avaliação, as llms detectaram % das fraquezas de diferentes tipos como: sql injection, cross-site scripting, out-of-bounds write e null pointer dereference. o claude sonnet foi a llm com o melhor resultado."
66,2024,Uma abordagem de aprendizado de máquina comparando o desempenho preditivo e a interpretabilidade de modelos para prever o sucesso de jogadores de basquete da NCAA em alcançar a NBA.,"COSTA, Dante de Araújo.","FECHINE, Joseana Macêdo.","Modelos preditivos em aprendizado de máquina e processos de descoberta de conhecimento em bases de dados, particularmente em domínios como o basquete, são inestimáveis para obter insights sobre o desempenho dos jogadores. Este estudo compara abordagens de aprendizado de máquina supervisionado (modelos de caixa preta e caixa branca, incluindo métodos de conjunto) para analisar dados estatísticos de jogadores de basquete universitário (NCAA). Nosso objetivo é identificar jogadores da NCAA com alto potencial para sucesso na NBA, determinar quais características dos jogadores mais influenciam as decisões de seleção e como esses modelos chegam a tais conclusões para comparar seus desempenhos e a explicabilidade associada. Esta tarefa é desafiadora devido a fatores além das estatísticas, como o contexto do jogador e as considerações do elenco da equipe durante a seleção. O objetivo principal é fornecer aos tomadores de decisão insights cruciais para a seleção de jogadores, ajudar na melhor avaliação de jogadores e desenvolver jovens talentos enfatizando aspectos-chave do jogo. Comparamos os resultados de modelos de predição interpretáveis com níveis satisfatórios de precisão. Equilibrando interpretabilidade e precisão preditiva, empregamos métodos de classificação de caixa branca, caixa preta e de conjunto, como Árvores de Decisão, Regressão Logística, Máquina de Vetores de Suporte, Perceptron Multicamadas, Floresta Aleatória e XGBoost. Além disso, algoritmos genéticos foram usados para reduzir o conjunto de características de cada modelo, retendo apenas as características mais impactantes. Comparado aos procedimentos padrão sem seleção de características, todos os modelos mostraram desempenho melhorado. Encontramos diferenças mínimas na precisão preditiva entre os melhores modelos de caixa branca e caixa preta. A combinação de algoritmos genéticos e regressão logística superou a precisão preditiva de outros modelos, reduzindo significativamente as características e melhorando a interpretabilidade dos resultados. A análise também destaca as características mais influentes no modelo e como os modelos chegaram a tais conclusões.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38052,"modelos preditivos em aprendizado de máquina e processos de descoberta de conhecimento em bases de dados, particularmente em domínios como o basquete, são inestimáveis para obter insights sobre o desempenho dos jogadores. este estudo compara abordagens de aprendizado de máquina supervisionado (modelos de caixa preta e caixa branca, incluindo métodos de conjunto) para analisar dados estatísticos de jogadores de basquete universitário (ncaa). nosso objetivo é identificar jogadores da ncaa com alto potencial para sucesso na nba, determinar quais características dos jogadores mais influenciam as decisões de seleção e como esses modelos chegam a tais conclusões para comparar seus desempenhos e a explicabilidade associada. esta tarefa é desafiadora devido a fatores além das estatísticas, como o contexto do jogador e as considerações do elenco da equipe durante a seleção. o objetivo principal é fornecer aos tomadores de decisão insights cruciais para a seleção de jogadores, ajudar na melhor avaliação de jogadores e desenvolver jovens talentos enfatizando aspectos-chave do jogo. comparamos os resultados de modelos de predição interpretáveis com níveis satisfatórios de precisão. equilibrando interpretabilidade e precisão preditiva, empregamos métodos de classificação de caixa branca, caixa preta e de conjunto, como árvores de decisão, regressão logística, máquina de vetores de suporte, perceptron multicamadas, floresta aleatória e xgboost. além disso, algoritmos genéticos foram usados para reduzir o conjunto de características de cada modelo, retendo apenas as características mais impactantes. comparado aos procedimentos padrão sem seleção de características, todos os modelos mostraram desempenho melhorado. encontramos diferenças mínimas na precisão preditiva entre os melhores modelos de caixa branca e caixa preta. a combinação de algoritmos genéticos e regressão logística superou a precisão preditiva de outros modelos, reduzindo significativamente as características e melhorando a interpretabilidade dos resultados. a análise também destaca as características mais influentes no modelo e como os modelos chegaram a tais conclusões."
67,2024,Aplicações práticas dos algoritmos de fluxo máximo.,"FIGUEREDO, Daniel de Matos.","GHEYI, Rohit","Nos desafios enfrentados na resolução de problemas, a mudança de perspectiva pode revelar soluções mais simples. Uma abordagem comum envolve a representação de problemas complexos por meio de Redes de Fluxo, permitindo a aplicação de algoritmos de Fluxo Máximo. Algoritmos de fluxo possuem importância significativa para a resolução de problemas em várias áreas, tendo um papel imprescindível no que se diz respeito à otimização de soluções. Entretanto, existe uma certa dificuldade por parte dos desenvolvedores em saber quando e como utilizá-los. Neste trabalho, o objetivo é mostrar aplicações práticas do uso de algoritmos de Fluxo Máximo para ajudar os profissionais de software a entenderem mais cenários de aplicação. Este artigo se concentra na análise de problemas suscetíveis à modelagem por grafos e na resolução por meio de algoritmos de Fluxo Máximo, demonstrando como esses problemas podem ser formulados em termos de redes de fluxo. Entre os problemas analisados estão problemas de emparelhamento, como a atribuição de tasks para workers e distribuição balanceada de carros para passageiros em aplicativos de viagem. Além disso, será mostrado uma variação do problema Baseball Elimination visando calcular a possibilidade de vitória de competidores em um torneio de xadrez. Ao destacar aplicações práticas de algoritmos como Ford-Fulkerson e Edmonds-Karp, são oferecidos insights valiosos, como por exemplo a possibilidade de representar determinadas relações como grafos bipartidos. Desta forma mostrando a utilidade e eficiência desse tipo de abordagem na resolução de uma variedade de problemas do mundo real.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38049,"nos desafios enfrentados na resolução de problemas, a mudança de perspectiva pode revelar soluções mais simples. uma abordagem comum envolve a representação de problemas complexos por meio de redes de fluxo, permitindo a aplicação de algoritmos de fluxo máximo. algoritmos de fluxo possuem importância significativa para a resolução de problemas em várias áreas, tendo um papel imprescindível no que se diz respeito à otimização de soluções. entretanto, existe uma certa dificuldade por parte dos desenvolvedores em saber quando e como utilizá-los. neste trabalho, o objetivo é mostrar aplicações práticas do uso de algoritmos de fluxo máximo para ajudar os profissionais de software a entenderem mais cenários de aplicação. este artigo se concentra na análise de problemas suscetíveis à modelagem por grafos e na resolução por meio de algoritmos de fluxo máximo, demonstrando como esses problemas podem ser formulados em termos de redes de fluxo. entre os problemas analisados estão problemas de emparelhamento, como a atribuição de tasks para workers e distribuição balanceada de carros para passageiros em aplicativos de viagem. além disso, será mostrado uma variação do problema baseball elimination visando calcular a possibilidade de vitória de competidores em um torneio de xadrez. ao destacar aplicações práticas de algoritmos como ford-fulkerson e edmonds-karp, são oferecidos insights valiosos, como por exemplo a possibilidade de representar determinadas relações como grafos bipartidos. desta forma mostrando a utilidade e eficiência desse tipo de abordagem na resolução de uma variedade de problemas do mundo real."
68,2024,Avaliando a capacidade de LLMS na resolução de questões do POSCOMP.,"VIEGAS, Cayo Vinicíus.","GHEYI, Rohit Gheyi.","Avanços recentes em Modelos de Linguagem de Grande Escala (LLMs) expandiram significativamente as capacidades da inteligência artificial (IA) em tarefas de processamento de linguagem natural. No entanto, seu desempenho em domínios especializados, como a ciência da computação, permanece relativamente pouco explorado. Este estudo investiga se os LLMs podem igualar ou superar o desempenho humano no POSCOMP, um exame brasileiro prestigiado usado para admissões de pós-graduação em ciência da computação. Quatro LLMs-ChatGPT-4, Gemini 1.0 Advanced, Claude 3 Sonnet e Le Chat Mistral Large-foram avaliados nos exames POSCOMP de 2022 e 2023. A avaliação consistiu em duas análises: uma envolvendo interpretação de imagens e outra somente de texto, para determinar a proficiência dos modelos em lidar com questões complexas típicas do exame. Os resultados indicaram que os LLMs tiveram um desempenho significativamente melhor nas questões baseadas em texto, com a interpretação de imagens representando um grande desafio. Por exemplo, na avaliação baseada em imagens, o ChatGPT-4 respondeu corretamente 40 de 70 perguntas, enquanto o Gemini 1.0 Advanced conseguiu apenas 11 respostas corretas. Na avaliação baseada em texto de 2022, o ChatGPT-4 liderou com 57 respostas corretas, seguido por Gemini 1.0 Advanced (49), Le Chat Mistral (48) e Claude 3 Sonnet (44). O exame de 2023 mostrou tendências semelhantes.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38035,"avanços recentes em modelos de linguagem de grande escala (llms) expandiram significativamente as capacidades da inteligência artificial (ia) em tarefas de processamento de linguagem natural. no entanto, seu desempenho em domínios especializados, como a ciência da computação, permanece relativamente pouco explorado. este estudo investiga se os llms podem igualar ou superar o desempenho humano no poscomp, um exame brasileiro prestigiado usado para admissões de pós-graduação em ciência da computação. quatro llms-chatgpt- , gemini . advanced, claude sonnet e le chat mistral large-foram avaliados nos exames poscomp de e . a avaliação consistiu em duas análises: uma envolvendo interpretação de imagens e outra somente de texto, para determinar a proficiência dos modelos em lidar com questões complexas típicas do exame. os resultados indicaram que os llms tiveram um desempenho significativamente melhor nas questões baseadas em texto, com a interpretação de imagens representando um grande desafio. por exemplo, na avaliação baseada em imagens, o chatgpt- respondeu corretamente de perguntas, enquanto o gemini . advanced conseguiu apenas respostas corretas. na avaliação baseada em texto de , o chatgpt- liderou com respostas corretas, seguido por gemini . advanced ( ), le chat mistral ( ) e claude sonnet ( ). o exame de mostrou tendências semelhantes."
69,2024,Implementação e avaliação do ARGOCD no laboratório de sistemas distribuídos da UFCG.,"SILVA, Kássio Augusto de Moura.","SILVA, Thiago Emmanuel Pereira da Cunha.","Este trabalho aborda a implementação e avaliação do ArgoCD no Laboratório de Sistemas Distribuídos da UFCG, com foco na automação do ciclo de vida de aplicações em Kubernetes. Consideramos a avaliação da ferramenta ArgoCD para simplificar a automação do ciclo de vida de aplicações para permitir entregas contínuas baseadas em GitOps. O problema enfrentado reside na necessidade de manter a consistência entre o estado desejado e real dos recursos em uso, desafios presentes em ambientes que utilizam contêineres. A avaliação do ArgoCD demonstrou resultados positivos, incluindo uma configuração bem-sucedida e aprendizado prático. A integração da ferramenta melhorou a eficiência na gestão e automação do processo de implantação de aplicações, evidenciando sua relevância como solução para a orquestração de aplicações em ambientes Kubernetes.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38014,"este trabalho aborda a implementação e avaliação do argocd no laboratório de sistemas distribuídos da ufcg, com foco na automação do ciclo de vida de aplicações em kubernetes. consideramos a avaliação da ferramenta argocd para simplificar a automação do ciclo de vida de aplicações para permitir entregas contínuas baseadas em gitops. o problema enfrentado reside na necessidade de manter a consistência entre o estado desejado e real dos recursos em uso, desafios presentes em ambientes que utilizam contêineres. a avaliação do argocd demonstrou resultados positivos, incluindo uma configuração bem-sucedida e aprendizado prático. a integração da ferramenta melhorou a eficiência na gestão e automação do processo de implantação de aplicações, evidenciando sua relevância como solução para a orquestração de aplicações em ambientes kubernetes."
70,2024,Desvendando a poesia com IA: influência do ajuste de hiperparâmetros no RAG para a compreensão de texto poéticos.,"NERI, Carmem Izaura Germano Barbosa.","MORAIS, Fábio Jorge Almeida.","Este estudo explora a aplicação do sistema de Geração Aumentada por Recuperação (RAG) em textos poéticos, concentrando-se na customização de seus hiperparâmetros para otimizar a compreensão e geração textual em um gênero literário que desafia pela sua densidade semântica e estrutural. No contexto dos Grandes Modelos de Linguagem (LLMs), o RAG se apresenta como uma ferramenta valiosa para superar limitações de conhecimento fixo, integrando dinamicamente informações atualizadas de fontes externas. Este trabalho emprega uma metodologia quantitativa para avaliar a eficácia do RAG, utilizando métrica Correção (Correctness) para medir o desempenho e análises manuais para refinar os resultados obtidos automaticamente. Ao modificar hiperparâmetros como o chunk size, chunk overlap e modelo de geração, o estudo busca determinar a configuração ideal para a geração de respostas precisas e relevantes para perguntas sobre poesia. As descobertas revelam que ajustes precisos nesses parâmetros influenciam na qualidade da informação recuperada e das respostas geradas, destacando a capacidade do RAG de produzir respostas enriquecidas e contextualmente apropriadas",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38009,"este estudo explora a aplicação do sistema de geração aumentada por recuperação (rag) em textos poéticos, concentrando-se na customização de seus hiperparâmetros para otimizar a compreensão e geração textual em um gênero literário que desafia pela sua densidade semântica e estrutural. no contexto dos grandes modelos de linguagem (llms), o rag se apresenta como uma ferramenta valiosa para superar limitações de conhecimento fixo, integrando dinamicamente informações atualizadas de fontes externas. este trabalho emprega uma metodologia quantitativa para avaliar a eficácia do rag, utilizando métrica correção (correctness) para medir o desempenho e análises manuais para refinar os resultados obtidos automaticamente. ao modificar hiperparâmetros como o chunk size, chunk overlap e modelo de geração, o estudo busca determinar a configuração ideal para a geração de respostas precisas e relevantes para perguntas sobre poesia. as descobertas revelam que ajustes precisos nesses parâmetros influenciam na qualidade da informação recuperada e das respostas geradas, destacando a capacidade do rag de produzir respostas enriquecidas e contextualmente apropriadas"
71,2024,Classifying code smell reviews with semantic search.,"RIBEIRO, Carlos Henrique Gonçalves.","BRUNET, João Arthur Monteiro.","Contexto: Code smells referem-se a padrões no código-fonte que desviam dos princípios de design estabelecidos. Durante a revisão do código, os desenvolvedores têm a oportunidade de identificar e corrigir esses smells, assim melhorando a qualidade geral da base de código. Um exame mais aprofundado das discussões dentro das revisões de código pode revelar insights valiosos sobre como os code smells são discutidos. Objetivo: para permitir que pesquisas futuras entendam melhor o comportamento dos desenvolvedores em relação aos code smells, nos propusemos a construir um conjunto de dados de discussões relacionadas a code smells. Na prática, queremos classificar os comentários em duas categorias: comentários com code smell e comentários sem code smell. Método: Para fazer isso, conduzimos um experimento que alavancou a busca semântica como uma técnica de classificação. Os dados de treinamento foram extraídos de três repositórios populares do GitHub de código aberto e consistiram em mais de 100.000 entradas. Resultados: como resultado, classificamos automaticamente 4.058 comentários de revisão como relacionados a code smells. Embora empregando uma nova técnica e dispondo de recursos limitados, conseguimos atingir uma precisão de 0,41 para a tarefa de classificação.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/38005,"contexto: code smells referem-se a padrões no código-fonte que desviam dos princípios de design estabelecidos. durante a revisão do código, os desenvolvedores têm a oportunidade de identificar e corrigir esses smells, assim melhorando a qualidade geral da base de código. um exame mais aprofundado das discussões dentro das revisões de código pode revelar insights valiosos sobre como os code smells são discutidos. objetivo: para permitir que pesquisas futuras entendam melhor o comportamento dos desenvolvedores em relação aos code smells, nos propusemos a construir um conjunto de dados de discussões relacionadas a code smells. na prática, queremos classificar os comentários em duas categorias: comentários com code smell e comentários sem code smell. método: para fazer isso, conduzimos um experimento que alavancou a busca semântica como uma técnica de classificação. os dados de treinamento foram extraídos de três repositórios populares do github de código aberto e consistiram em mais de . entradas. resultados: como resultado, classificamos automaticamente . comentários de revisão como relacionados a code smells. embora empregando uma nova técnica e dispondo de recursos limitados, conseguimos atingir uma precisão de , para a tarefa de classificação."
72,2024,Classificação de risco de fracasso em obras públicas paraibanas.,"FERNANDES, Bruno Andrade.","BAPTISTA, Cláudio de Souza.","Diante da necessidade de administrar o capital público de forma eficiente e transparente e de uma elevada e crescente alocação de recursos no estado da Paraíba voltado às obras públicas, o trabalho sugere um facilitador à administração pública no estado e municípios que o compõem. Com o intuito de servir como um apoio às decisões de alocação do capital público, aumentando a eficiência do gasto da verba em obras públicas, esse estudo propõe treinar um modelo preditivo de fracasso de obras governamentais. Por meio da investigação dos “dados abertos do SAGRES - TCE/PB”, houve o treinamento de modelos de aprendizado de máquina via Extreme Gradient Boosting (XGBoost), com diferentes subconjuntos de features, tendo seus dados desbalanceados ou balanceados, capazes de realizar uma classificação binária entre sucesso ou fracasso do empreendimento. Apurou-se, também, uma melhora da acurácia dos modelos ao realizar treinamento com a agregação de algumas características.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37971,"diante da necessidade de administrar o capital público de forma eficiente e transparente e de uma elevada e crescente alocação de recursos no estado da paraíba voltado às obras públicas, o trabalho sugere um facilitador à administração pública no estado e municípios que o compõem. com o intuito de servir como um apoio às decisões de alocação do capital público, aumentando a eficiência do gasto da verba em obras públicas, esse estudo propõe treinar um modelo preditivo de fracasso de obras governamentais. por meio da investigação dos “dados abertos do sagres - tce/pb”, houve o treinamento de modelos de aprendizado de máquina via extreme gradient boosting (xgboost), com diferentes subconjuntos de features, tendo seus dados desbalanceados ou balanceados, capazes de realizar uma classificação binária entre sucesso ou fracasso do empreendimento. apurou-se, também, uma melhora da acurácia dos modelos ao realizar treinamento com a agregação de algumas características."
73,2024,Controle de acesso em API do projeto SmartCampus: uma abordagem usando SPIRE em conjunto com serviços de proxy.,"ALVES, Brenda Louisy Morais.","BRITO, Andrey Elisio Monteiro.","No contexto do projeto do SmartCampus, da Universidade Federal de Campina Grande (UFCG), a implementação de APIs que disponibilizam acesso a informações de eficiência energética apresenta desafios relacionados à segurança e ao controle de acesso. As partes interessadas, incluindo desenvolvedores, usuários finais e operadores de produção, necessitam interagir com essas APIs em ambientes variados, criando a necessidade de diferenciar e controlar o acesso de maneira eficaz. Este trabalho explora estratégias fundamentadas no modelo Zero Trust, que preconiza a autenticação contínua e autorização granular, garantindo que cada acesso seja verificado e autenticado. Adotando o SPIRE (SPIFFE Runtime Environment) em conjunto com serviços de proxy, busca-se assegurar a autenticação segura por meio de identidades criptográficas fornecidas pelo SPIRE, bem como implementar um serviço de autorização personalizado conforme o perfil do usuário. O objetivo é prevenir acesso inadequado, vazamento de dados e manipulações indevidas, garantindo um ambiente seguro e confiável para a implantação do projeto.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37970,"no contexto do projeto do smartcampus, da universidade federal de campina grande (ufcg), a implementação de apis que disponibilizam acesso a informações de eficiência energética apresenta desafios relacionados à segurança e ao controle de acesso. as partes interessadas, incluindo desenvolvedores, usuários finais e operadores de produção, necessitam interagir com essas apis em ambientes variados, criando a necessidade de diferenciar e controlar o acesso de maneira eficaz. este trabalho explora estratégias fundamentadas no modelo zero trust, que preconiza a autenticação contínua e autorização granular, garantindo que cada acesso seja verificado e autenticado. adotando o spire (spiffe runtime environment) em conjunto com serviços de proxy, busca-se assegurar a autenticação segura por meio de identidades criptográficas fornecidas pelo spire, bem como implementar um serviço de autorização personalizado conforme o perfil do usuário. o objetivo é prevenir acesso inadequado, vazamento de dados e manipulações indevidas, garantindo um ambiente seguro e confiável para a implantação do projeto."
74,2022,Abordagens para escrita de relatórios de bugs: um estudo qualitativo.,"TOSCANO, Thaís Nicoly Araújo.","MASSONI, Tiago Lima.","O sucesso de um software condiz com a atenção em todo processo de desenvolvimento que envolve uma série de etapas até que o produto esteja em produção. No contexto da qualidade deste software, a utilização de relatórios de bugs providos por usuários finais contribui em maior escala para um melhor entendimento para desenvolvedores, equipes de suporte e sustentação, por fornecerem informações cruciais para a execução de correções ou melhorias no sistema. Entretanto, a falta de informações dificultam a compreensão dos bugs, justamente por existir casos onde o usuário relata falsos bugs, com isso, para reconhecer esses casos e alcançar a proficiência para atender às necessidades , é essencial obter detalhamento, seja ele com título, descrições de cenários, passo a passo para execução, grau de severidade, anexos como planilhas, capturas de tela. Dessa forma, torna-se a leitura mais clara, objetiva e concisa. Dado este cenário, através de uma análise qualitativa, avaliamos a qualidade das informações contidas nesses relatórios, se dentre eles existem ou não padronização, procurar entender também a dificuldade dos usuários ao realizar o repasse dessas informações, e, a partir disso, indicar quais os formatos das abordagens que satisfazem as partes envolvidas para o correto funcionamento do software.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37944,"o sucesso de um software condiz com a atenção em todo processo de desenvolvimento que envolve uma série de etapas até que o produto esteja em produção. no contexto da qualidade deste software, a utilização de relatórios de bugs providos por usuários finais contribui em maior escala para um melhor entendimento para desenvolvedores, equipes de suporte e sustentação, por fornecerem informações cruciais para a execução de correções ou melhorias no sistema. entretanto, a falta de informações dificultam a compreensão dos bugs, justamente por existir casos onde o usuário relata falsos bugs, com isso, para reconhecer esses casos e alcançar a proficiência para atender às necessidades , é essencial obter detalhamento, seja ele com título, descrições de cenários, passo a passo para execução, grau de severidade, anexos como planilhas, capturas de tela. dessa forma, torna-se a leitura mais clara, objetiva e concisa. dado este cenário, através de uma análise qualitativa, avaliamos a qualidade das informações contidas nesses relatórios, se dentre eles existem ou não padronização, procurar entender também a dificuldade dos usuários ao realizar o repasse dessas informações, e, a partir disso, indicar quais os formatos das abordagens que satisfazem as partes envolvidas para o correto funcionamento do software."
75,2022,Apoio caridade: uma aplicação para intermédio entre organizações de terceiro setor e pessoas prestativas.,"BARBOSA FILHO, Redson Farias.","GARCIA, Francilene Procópio.","Instituições do terceiro setor são organizações comprometidas com problemas sociais, onde costumam contar com o apoio de pessoas prestativas que valorizam seus trabalhos e desejam ajudá-las através de doações. Porém, mesmo com o apoio dessas pessoas, muitas dessas organizações passam por dificuldades relacionadas com a escassez de recursos e materiais necessários para sua manutenção e continuidade. Diante disso, esse trabalho tem como objetivo o desenvolvimento de uma aplicação PWA(Progressive Web App)[3] para fornecer funcionalidades voltadas para criação de portfólio e publicações dessas organizações. No processo de desenvolvimento, foi utilizada a metodologia ágil baseada no scrum. Para avaliar sua usabilidade, foi utilizado o método baseado na escala Likert. Os resultados obtidos na avaliação da aplicação mostram um bom grau de satisfação dos usuários e seu potencial para servir como um ambiente digital para doadores e instituições do terceiro setor.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37943,"instituições do terceiro setor são organizações comprometidas com problemas sociais, onde costumam contar com o apoio de pessoas prestativas que valorizam seus trabalhos e desejam ajudá-las através de doações. porém, mesmo com o apoio dessas pessoas, muitas dessas organizações passam por dificuldades relacionadas com a escassez de recursos e materiais necessários para sua manutenção e continuidade. diante disso, esse trabalho tem como objetivo o desenvolvimento de uma aplicação pwa(progressive web app)[ ] para fornecer funcionalidades voltadas para criação de portfólio e publicações dessas organizações. no processo de desenvolvimento, foi utilizada a metodologia ágil baseada no scrum. para avaliar sua usabilidade, foi utilizado o método baseado na escala likert. os resultados obtidos na avaliação da aplicação mostram um bom grau de satisfação dos usuários e seu potencial para servir como um ambiente digital para doadores e instituições do terceiro setor."
76,2022,Implementação e análise de um bloqueador de Anúncios e servidor DNS recursivo em uma rede Doméstica utilizando Raspberry PI.,"SILVA, Wesley Santos.","ARAÚJO, Eliane Cristina de.","Em tempos de inclusão digital e globalização, onde o acesso à internet cresce de maneira acelerada, os anúncios online seguem a mesma tendência. Apesar de ser um método de venda efetivo para os anunciantes, os usuários dos sites são constantemente bombardeados com anúncios, ofuscando o real conteúdo que deseja-se visualizar. As soluções atuais de bloqueadores de anúncios são usualmente associadas a navegadores e a computadores pessoais. Este trabalho apresenta uma implementação e análise de um bloqueador de anúncios que abrange toda uma rede doméstica, utilizando um Raspberry Pi. Aproveitando do potencial do computador de dimensões reduzidas, além do bloqueio de anúncios, também foi realizada a implementação de um servidor DNS recursivo local, que visa o armazenamento de domínios em cache, diminuindo o tempo de resolução de nomes para todos os dispositivos conectados à rede.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37933,"em tempos de inclusão digital e globalização, onde o acesso à internet cresce de maneira acelerada, os anúncios online seguem a mesma tendência. apesar de ser um método de venda efetivo para os anunciantes, os usuários dos sites são constantemente bombardeados com anúncios, ofuscando o real conteúdo que deseja-se visualizar. as soluções atuais de bloqueadores de anúncios são usualmente associadas a navegadores e a computadores pessoais. este trabalho apresenta uma implementação e análise de um bloqueador de anúncios que abrange toda uma rede doméstica, utilizando um raspberry pi. aproveitando do potencial do computador de dimensões reduzidas, além do bloqueio de anúncios, também foi realizada a implementação de um servidor dns recursivo local, que visa o armazenamento de domínios em cache, diminuindo o tempo de resolução de nomes para todos os dispositivos conectados à rede."
77,2022,SafeTrip: uma ferramenta para detecção e notificação de acidentes em rodovias brasileiras a partir do Twitter.,"VASCONCELOS, Samuel Pereira de.","BAPTISTA, Cláudio de Souza.","O sistema rodoviário é o principal meio de transporte no Brasil. Os acidentes de trânsito são bastante comuns nesse modal de transporte, incorrendo em uma das maiores causa mortis no país. Perfis em redes sociais da Polícia Rodoviária Federal (PRF) e de outras fontes de informações, contribuem para alertar os motoristas sobre acidentes rodoviários ocorridos, no intuito de reduzir a frequência desta incidência. Porém, acessar essas informações por leitura ao dirigir, é ilegal e eleva ainda mais o risco de acidentes. Portanto, este trabalho se propõe a desenvolver um estudo a respeito de publicações em redes sociais, em particular o Twitter, para criação de um modelo de classificação, baseado em aprendizagem de máquina, que seja capaz de classificar tweets acerca de informações sobre a ocorrência ou não de acidentes rodoviários. Os resultados esperados incluem o modelo de classificação de tweets, bem como um aplicativo de celular que possa notificar os condutores sobre acidentes reportados no seu trajeto, em tempo real e através de áudio.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37931,"o sistema rodoviário é o principal meio de transporte no brasil. os acidentes de trânsito são bastante comuns nesse modal de transporte, incorrendo em uma das maiores causa mortis no país. perfis em redes sociais da polícia rodoviária federal (prf) e de outras fontes de informações, contribuem para alertar os motoristas sobre acidentes rodoviários ocorridos, no intuito de reduzir a frequência desta incidência. porém, acessar essas informações por leitura ao dirigir, é ilegal e eleva ainda mais o risco de acidentes. portanto, este trabalho se propõe a desenvolver um estudo a respeito de publicações em redes sociais, em particular o twitter, para criação de um modelo de classificação, baseado em aprendizagem de máquina, que seja capaz de classificar tweets acerca de informações sobre a ocorrência ou não de acidentes rodoviários. os resultados esperados incluem o modelo de classificação de tweets, bem como um aplicativo de celular que possa notificar os condutores sobre acidentes reportados no seu trajeto, em tempo real e através de áudio."
78,2022,A evasão estudantil no Curso de Ciência da Computação da UFCG.,"ARAÚJO, Matheus Silva.","BRASILEIRO, Francisco Vilar.","O número de alunos matriculados em instituições de ensino superior cresceu substancialmente nos últimos anos, notadamente devido a ações de ampliação de acesso, sobretudo para estudantes formados em escolas públicas e em condições de vulnerabilidade socioeconômica. Entretanto, apenas garantir o ingresso não é suficiente para estudantes nessas condições. É preciso que se garanta que esses discentes irão concluir sua formação de maneira adequada. Mesmo com programas de assistência estudantil e o esforço das coordenações de ensino para evitar a evasão de discentes, esta ainda é alta e suas causas ainda são em grande medida ignoradas. Nesse contexto, este trabalho se propõe a apresentar um panorama da situação de evasão dos discentes do curso de Ciência da Computação da UFCG, considerando fatores demográficos, através de uma abordagem quantitativa. Busca-se entender se há correlações entre esses fatores e a evasão de alunos do curso.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37930,"o número de alunos matriculados em instituições de ensino superior cresceu substancialmente nos últimos anos, notadamente devido a ações de ampliação de acesso, sobretudo para estudantes formados em escolas públicas e em condições de vulnerabilidade socioeconômica. entretanto, apenas garantir o ingresso não é suficiente para estudantes nessas condições. é preciso que se garanta que esses discentes irão concluir sua formação de maneira adequada. mesmo com programas de assistência estudantil e o esforço das coordenações de ensino para evitar a evasão de discentes, esta ainda é alta e suas causas ainda são em grande medida ignoradas. nesse contexto, este trabalho se propõe a apresentar um panorama da situação de evasão dos discentes do curso de ciência da computação da ufcg, considerando fatores demográficos, através de uma abordagem quantitativa. busca-se entender se há correlações entre esses fatores e a evasão de alunos do curso."
79,2022,Colaboração de mulheres na computação: um estudo de caso no grupo elas@computação da UFCG.,"SANTOS, Jardely Maris da Silva.","CAMPOS, Lívia Maria Rodrigues Sampaio.","Apesar das mulheres terem um papel importante no desenvolvimento da Ciência da Computação, existe uma baixa representação feminina nesta área. Na intenção de mudar essa realidade, surgiram algumas iniciativas. Nesse sentido, o Elas@Computação foi criado em 2017 como uma organização formada por graduandas, pós-graduandas e egressas do curso de Computação da Universidade Federal de Campina Grande/UFCG, com a intenção de gerar uma rede de apoio e dar visibilidade para as mulheres da área. Porém, apesar de todo o trabalho que o grupo exerce, não são analisados os impactos, nem quem são as participantes ou por que participam. Assim, o objetivo deste trabalho é traçar o perfil de mulheres que fazem parte desse grupo para responder tais questões. Para isso, foram feitos dois estudos quantitativos e descritivos baseados em surveys. O primeiro, para identificar os perfis dos alunos da graduação diferenciando por gênero e, o segundo, que busca extrair informações sobre formas de participação e impacto do grupo. Os resultados obtidos mostraram que os perfis entre os gêneros são parecidos. Além disso, o grupo gera impacto positivo em suas participantes, principalmente por fornecer uma forte rede de apoio que traz segurança e confiança através da representatividade.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37929,"apesar das mulheres terem um papel importante no desenvolvimento da ciência da computação, existe uma baixa representação feminina nesta área. na intenção de mudar essa realidade, surgiram algumas iniciativas. nesse sentido, o foi criado em como uma organização formada por graduandas, pós-graduandas e egressas do curso de computação da universidade federal de campina grande/ufcg, com a intenção de gerar uma rede de apoio e dar visibilidade para as mulheres da área. porém, apesar de todo o trabalho que o grupo exerce, não são analisados os impactos, nem quem são as participantes ou por que participam. assim, o objetivo deste trabalho é traçar o perfil de mulheres que fazem parte desse grupo para responder tais questões. para isso, foram feitos dois estudos quantitativos e descritivos baseados em surveys. o primeiro, para identificar os perfis dos alunos da graduação diferenciando por gênero e, o segundo, que busca extrair informações sobre formas de participação e impacto do grupo. os resultados obtidos mostraram que os perfis entre os gêneros são parecidos. além disso, o grupo gera impacto positivo em suas participantes, principalmente por fornecer uma forte rede de apoio que traz segurança e confiança através da representatividade."
80,2024,Quão eficaz é uma ferramenta de automação de análise de dados baseada em LLM? um estudo de caso com o Data Analyst do ChatGPT.,"MIRANDA, Beatriz Andrade de.","CAMPELO, Claudio Elízio Calazans.","Este artigo investiga a aplicação eficaz dos Grandes Modelos de Linguagem (LLMs), em particular o Generative Pre-trained Transformer (ChatGPT) da OpenAI, na análise de dados. A relevância desta pesquisa surge com a crescente adoção de ferramentas de Inteligência Artificial (IA) em processos analíticos, exigindo uma avaliação meticulosa de suas capacidades e limitações para aprimorar a tomada de decisões e a eficiência operacional. Utilizando o Data Analyst do ChatGPT como estudo de caso, este trabalho implementa um experimento estruturado com 36 perguntas distribuídas em análises Descritiva, Diagnóstica, Preditiva e Prescritiva, para mensurar sua eficácia. Os resultados apontam uma eficiência geral de 86,11%, com destaque para o desempenho em análises descritivas e diagnósticas, enquanto enfrenta desafios nas categorias mais complexas, como as preditivas e prescritivas. Apesar das limitações técnicas, tais como restrições no processamento de dados e falhas operacionais, o estudo destaca o potencial significativo do Data Analyst em auxiliar analistas de dados, estabelecendo um marco importante para futuras melhorias e pesquisas na aplicação prática de LLMs na análise de dados.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37922,"este artigo investiga a aplicação eficaz dos grandes modelos de linguagem (llms), em particular o generative pre-trained transformer (chatgpt) da openai, na análise de dados. a relevância desta pesquisa surge com a crescente adoção de ferramentas de inteligência artificial (ia) em processos analíticos, exigindo uma avaliação meticulosa de suas capacidades e limitações para aprimorar a tomada de decisões e a eficiência operacional. utilizando o data analyst do chatgpt como estudo de caso, este trabalho implementa um experimento estruturado com perguntas distribuídas em análises descritiva, diagnóstica, preditiva e prescritiva, para mensurar sua eficácia. os resultados apontam uma eficiência geral de , %, com destaque para o desempenho em análises descritivas e diagnósticas, enquanto enfrenta desafios nas categorias mais complexas, como as preditivas e prescritivas. apesar das limitações técnicas, tais como restrições no processamento de dados e falhas operacionais, o estudo destaca o potencial significativo do data analyst em auxiliar analistas de dados, estabelecendo um marco importante para futuras melhorias e pesquisas na aplicação prática de llms na análise de dados."
81,2024,ENTREVISTALAB: ferramenta para treinamento em entrevistas de processos seletivos na área de TI.,"SANTOS, Augusto Gomes dos.","ANDRADE, Wilkerson de Lucena.","A área de Tecnologia da Informação (TI) é uma das mais dinâmicas e competitivas do mercado de trabalho atual. O curso de Ciência da Computação da Universidade Federal de Campina Grande (UFCG) é excelente e oferece uma preparação sólida para os estudantes que desejam seguir carreiras nessa área. No entanto, a falta de habilidade em entrevistas pode representar um obstáculo significativo e fazer com que os estudantes percam oportunidades valiosas, dentro e fora da universidade. Diante disso, este trabalho se concentra no desenvolvimento de uma aplicação dedicada a auxiliar os alunos de Computação na UFCG e se prepararem de forma eficaz para entrevistas de processos seletivos. A aplicação oferece uma ampla variedade de perguntas em uma entrevista simulada, categorizadas por áreas de interesse, permitindo que os usuários enfrentem questões relacionadas à sua especialidade. Ao final da simulação, os usuários recebem um feedback personalizado para aprimorar suas habilidades de resposta. Espera-se que esta iniciativa não apenas ajude os alunos de Computação da UFCG a se destacarem nos processos seletivos, mas também contribua para a formação de profissionais mais preparados.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37919,"a área de tecnologia da informação (ti) é uma das mais dinâmicas e competitivas do mercado de trabalho atual. o curso de ciência da computação da universidade federal de campina grande (ufcg) é excelente e oferece uma preparação sólida para os estudantes que desejam seguir carreiras nessa área. no entanto, a falta de habilidade em entrevistas pode representar um obstáculo significativo e fazer com que os estudantes percam oportunidades valiosas, dentro e fora da universidade. diante disso, este trabalho se concentra no desenvolvimento de uma aplicação dedicada a auxiliar os alunos de computação na ufcg e se prepararem de forma eficaz para entrevistas de processos seletivos. a aplicação oferece uma ampla variedade de perguntas em uma entrevista simulada, categorizadas por áreas de interesse, permitindo que os usuários enfrentem questões relacionadas à sua especialidade. ao final da simulação, os usuários recebem um feedback personalizado para aprimorar suas habilidades de resposta. espera-se que esta iniciativa não apenas ajude os alunos de computação da ufcg a se destacarem nos processos seletivos, mas também contribua para a formação de profissionais mais preparados."
82,2024,Distinção entre imagens sintéticas de faces e imagens de faces reais.,"FERREIRA, Arthur Silva Cavalcante.","PEREIRA, Eanes Torres.","As Redes Adversárias Generativas (GAN's) têm aplicações amplas, desde a criação de imagens e vídeos até a geração de texto e design de produtos. No contexto deste estudo, serão avaliadas imagens de faces sintéticas geradas por GAN's. Há benefícios neste uso de GAN's como pesquisas voltadas a entender a complexidade e nuances de imagens de faces e formação de bases de dados anônimas para treinamento de redes neurais com imagens de faces. Entretanto, faces sintéticas podem ser usadas para criar identidades falsas, podendo levar a crimes como fraude de identidade e phishing, onde faces sintéticas são usadas para enganar sistemas de segurança baseados em reconhecimento facial. Além disso, também podem ser usadas para criar vídeos e imagens falsos com intenções maliciosas, como difamação, desinformação ou propaganda política. Neste trabalho, foi treinada uma Rede Neural Convolucional Profunda baseada na arquitetura EfficientViT utilizando um conjunto de dados composto por bases de dados disponíveis publicamente e imagens sintéticas geradas pela rede StyleGAN3. Os resultados obtidos indicam uma taxa de acurácia de 99%, semelhante a outros métodos na literatura, porém as bases de dados utilizadas para treinamento e avaliação diferem além da quantidade de imagens utilizadas na avaliação. Ademais, houve uma procura de bases de dados diversificadas a fim de mitigar viés e justiça do modelo em relação à idade/etnia, porém uma análise à parte seria necessária para avaliar o impacto dessa escolha das bases de dados em comparação com outros modelos já treinados na literatura.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37916,"as redes adversárias generativas (gan's) têm aplicações amplas, desde a criação de imagens e vídeos até a geração de texto e design de produtos. no contexto deste estudo, serão avaliadas imagens de faces sintéticas geradas por gan's. há benefícios neste uso de gan's como pesquisas voltadas a entender a complexidade e nuances de imagens de faces e formação de bases de dados anônimas para treinamento de redes neurais com imagens de faces. entretanto, faces sintéticas podem ser usadas para criar identidades falsas, podendo levar a crimes como fraude de identidade e phishing, onde faces sintéticas são usadas para enganar sistemas de segurança baseados em reconhecimento facial. além disso, também podem ser usadas para criar vídeos e imagens falsos com intenções maliciosas, como difamação, desinformação ou propaganda política. neste trabalho, foi treinada uma rede neural convolucional profunda baseada na arquitetura efficientvit utilizando um conjunto de dados composto por bases de dados disponíveis publicamente e imagens sintéticas geradas pela rede stylegan3. os resultados obtidos indicam uma taxa de acurácia de %, semelhante a outros métodos na literatura, porém as bases de dados utilizadas para treinamento e avaliação diferem além da quantidade de imagens utilizadas na avaliação. ademais, houve uma procura de bases de dados diversificadas a fim de mitigar viés e justiça do modelo em relação à idade/etnia, porém uma análise à parte seria necessária para avaliar o impacto dessa escolha das bases de dados em comparação com outros modelos já treinados na literatura."
83,2022,Heurística online para aquisição de instâncias em cloud pública: um olhar sobre a demanda de e-commerce.,"GOMES, Gabriel Felipe Cardoso.","SILVA, Thiago Emmanuel Pereira da Cunha.","Os gastos que as grandes empresas estão tendo com Infraestrutura como serviço (IaaS) são grandes e estão crescendo cada vez mais. Provedores públicos de clouds disponibilizam diversas formas de compra para seus serviços. Essas opções geralmente são divididas em pagar posteriormente pelo tempo que você utilizou o serviço ou pagar antecipadamente, com um desconto associado, por uma reserva do serviço a ser usada no futuro. Existem muitos estudos que buscam minimizar o custo da alocação de recursos em provedores IaaS, com base na estimativa de demanda futura e nas opções de compra disponibiliza-das pelos provedores. Uma das possíveis soluções é o uso de algoritmos onli-ne que são capazes de decidir quando reservar durante a chegada da demanda, esse estudo busca avaliar o desempenho de uma heurística online levando em consideração a demanda de uma grande companhia de e-commerce.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37885,"os gastos que as grandes empresas estão tendo com infraestrutura como serviço (iaas) são grandes e estão crescendo cada vez mais. provedores públicos de clouds disponibilizam diversas formas de compra para seus serviços. essas opções geralmente são divididas em pagar posteriormente pelo tempo que você utilizou o serviço ou pagar antecipadamente, com um desconto associado, por uma reserva do serviço a ser usada no futuro. existem muitos estudos que buscam minimizar o custo da alocação de recursos em provedores iaas, com base na estimativa de demanda futura e nas opções de compra disponibiliza-das pelos provedores. uma das possíveis soluções é o uso de algoritmos onli-ne que são capazes de decidir quando reservar durante a chegada da demanda, esse estudo busca avaliar o desempenho de uma heurística online levando em consideração a demanda de uma grande companhia de e-commerce."
84,2024,Desafios na colaboração entre engenheiros de software e cientistas de dados em projetos de machine learning.,"ALVES, Arthur Almeida.","RAMALHO, Franklin de Souza.","Recentes avanços em Machine Learning (ML) têm despertado considerável interesse na integração de capacidades de IA em software e serviços, tornando a colaboração entre cientistas de dados e engenheiros de software crucial, porém desafiadora. Este estudo investiga os desafios encontrados nessa colaboração em projetos de ML. Através de entrevistas com profissionais do campo, identificamos questões cruciais, como lacunas de conhecimento entre disciplinas, adaptações de práticas de Engenharia de Software (ES) para ML e dificuldades na avaliação de modelos. Destacamos a importância do envolvimento precoce de cientistas de dados na definição de requisitos do software, contribuindo para o desenvolvimento bem-sucedido de sistemas de ML. Este estudo oferece valiosos insights para equipes que enfrentam desafios similares na implementação de ML.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37878,"recentes avanços em machine learning (ml) têm despertado considerável interesse na integração de capacidades de ia em software e serviços, tornando a colaboração entre cientistas de dados e engenheiros de software crucial, porém desafiadora. este estudo investiga os desafios encontrados nessa colaboração em projetos de ml. através de entrevistas com profissionais do campo, identificamos questões cruciais, como lacunas de conhecimento entre disciplinas, adaptações de práticas de engenharia de software (es) para ml e dificuldades na avaliação de modelos. destacamos a importância do envolvimento precoce de cientistas de dados na definição de requisitos do software, contribuindo para o desenvolvimento bem-sucedido de sistemas de ml. este estudo oferece valiosos insights para equipes que enfrentam desafios similares na implementação de ml."
85,2022,Utilizando técnicas de aprendizagem de máquina e NLP para o problema de Product Matching.,"SANTANA, Matheus Alcantara de.","BAPTISTA, Cláudio de Souza.","O comércio eletrônico é um mercado que aumenta a cada ano, impulsionado pelos avanços tecnológicos que tornam mais cômodo e eficiente o processo de compra. Por consequência, o número de vendas cresce, aumentando também a oferta de produtos sendo comercializados na internet. Devido ao grande volume de ofertas, a dificuldade do consumidor de encontrar determinado produto cresce, bem como a sua capacidade de identificar e agrupar produtos iguais, com a finalidade de encontrar as melhores ofertas. Isso ocorre, pois, dados dois produtos iguais, ou seja, que possuem o mesmo código de barras, são descritos de formas diferentes. Para isso, existe uma técnica cujo objetivo é determinar se dois produtos são equivalentes, ou seja, correspondem à mesma entidade no mundo real, utilizando técnicas de aprendizagem de máquina, chamada product matching. No presente trabalho, foram analisados diversos modelos de aprendizagem de máquina, incluindo o BERT, com a finalidade de escolher o melhor modelo que será utilizado para identificar produtos os quais sua descrição não corresponde ao seu código de barras. A base de dados utilizada será a base de produtos de notas fiscais emitidas no Estado do Acre, disponibilizadas pelo Tribunal de Contas do Acre, TCE-AC. Ao final da implementação, o modelo foi capaz de classificar de maneira satisfatória os produtos inválidos.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37850,"o comércio eletrônico é um mercado que aumenta a cada ano, impulsionado pelos avanços tecnológicos que tornam mais cômodo e eficiente o processo de compra. por consequência, o número de vendas cresce, aumentando também a oferta de produtos sendo comercializados na internet. devido ao grande volume de ofertas, a dificuldade do consumidor de encontrar determinado produto cresce, bem como a sua capacidade de identificar e agrupar produtos iguais, com a finalidade de encontrar as melhores ofertas. isso ocorre, pois, dados dois produtos iguais, ou seja, que possuem o mesmo código de barras, são descritos de formas diferentes. para isso, existe uma técnica cujo objetivo é determinar se dois produtos são equivalentes, ou seja, correspondem à mesma entidade no mundo real, utilizando técnicas de aprendizagem de máquina, chamada product matching. no presente trabalho, foram analisados diversos modelos de aprendizagem de máquina, incluindo o bert, com a finalidade de escolher o melhor modelo que será utilizado para identificar produtos os quais sua descrição não corresponde ao seu código de barras. a base de dados utilizada será a base de produtos de notas fiscais emitidas no estado do acre, disponibilizadas pelo tribunal de contas do acre, tce-ac. ao final da implementação, o modelo foi capaz de classificar de maneira satisfatória os produtos inválidos."
86,2021,Construção e validação de manual para aplicação da metodologia MDV de verificação funcional.,"SILVA, Anne Gabriele Arcanjo da.","MELCHER, Elmar Uwe Kurt.","Este trabalho tem como objetivo descrever o processo de construção, validação de conteúdo e validação semântica de um manual para aplicação da metodologia Metric-Driven Verification (MDV) de verificação de hardware. Trata-se de uma pesquisa descritiva e metodológica, realizada entre os anos de 2021 e 2022, seguindo as etapas: levantamento bibliográfico; construção do manual em paralela validação de conteúdo pelos juízes e adequação; validação se-mântica por engenheiros de verificação primeiros interessados no produto final através de formulários com 18 itens compostos por níveis de variação da escala Likert: discordo totalmente, discordo, não concordo e nem discordo, concordo e concordo totalmente. Participaram da validação de conteúdo, 2 juízes e na validação semântica 19 peritos, sendo todos engenheiros de verificação da empresa Idea Electronic Systems. O manual foi considerado válido pelos juízes e, entre os peritos, houve concordância total média de 67% na avaliação semântica. Um possível obstáculo no uso do manual é a necessidade de adotar a estrutura do plano de verificação nele oferecida. Espera-se que apesar dos possíveis obstáculos na sua aplicação, este seja utilizado pelos profissionais de verificação de hardware como ferramenta auxiliar para conhecer e adotar as metodologias dirigidas por métricas, assim como possibilitá-los usufruir dos benefícios por elas ofertados.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37849,"este trabalho tem como objetivo descrever o processo de construção, validação de conteúdo e validação semântica de um manual para aplicação da metodologia metric-driven verification (mdv) de verificação de hardware. trata-se de uma pesquisa descritiva e metodológica, realizada entre os anos de e , seguindo as etapas: levantamento bibliográfico; construção do manual em paralela validação de conteúdo pelos juízes e adequação; validação se-mântica por engenheiros de verificação primeiros interessados no produto final através de formulários com itens compostos por níveis de variação da escala likert: discordo totalmente, discordo, não concordo e nem discordo, concordo e concordo totalmente. participaram da validação de conteúdo, juízes e na validação semântica peritos, sendo todos engenheiros de verificação da empresa idea electronic systems. o manual foi considerado válido pelos juízes e, entre os peritos, houve concordância total média de % na avaliação semântica. um possível obstáculo no uso do manual é a necessidade de adotar a estrutura do plano de verificação nele oferecida. espera-se que apesar dos possíveis obstáculos na sua aplicação, este seja utilizado pelos profissionais de verificação de hardware como ferramenta auxiliar para conhecer e adotar as metodologias dirigidas por métricas, assim como possibilitá-los usufruir dos benefícios por elas ofertados."
87,2024,Utilizando extração de relação entre entidades para detecção de informações pessoais sensíveis em português.,"LUCENA, Andrielly de Lima.","MORAIS, Fábio Jorge Almeida.","Atualmente, a grande gama de plataformas, aplicativos e operações online disponíveis para a resolução de diferentes problemas resulta em um tráfego de grande volume de dados de usuários, inclusive dados sensíveis e de identificação. Para proteger a privacidade dos usuários, um direito assegurado por leis em todo o mundo (Leis de Proteção de Dados), é necessária uma atenção maior a esses dados para não serem publicados. No entanto, identificar as informações sensíveis entre tantos outros tipos de dados, pode não ser uma tarefa trivial. Estudos já existentes propõem a aplicação de técnicas de Processamento de Linguagem Natural (PLN) para identificação automática de Informações Pessoais Identificáveis (Personal Identifiable Information, PII) em documentos em português. O objetivo deste trabalho é propor, através de uma prova de conceito, uma abordagem complementar às utilizadas nos estudos relacionados, através da tarefa de Extração de Relação de PLN. Para tal, foi criado um componente que combina um modelo de linguagem especializado na língua portuguesa e camadas adicionais de extração de relação. Para o treinamento e avaliação do componente, foi gerada uma base de dados sensíveis sintéticos com o auxílio de um Large Language Model (LLM). Os resultados foram satisfatórios, com métricas de precisão, recall e f1-score acima de 95%, indicando que a abordagem pode ser uma boa proposta para detecção automática de informações sensíveis pessoais.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37848,"atualmente, a grande gama de plataformas, aplicativos e operações online disponíveis para a resolução de diferentes problemas resulta em um tráfego de grande volume de dados de usuários, inclusive dados sensíveis e de identificação. para proteger a privacidade dos usuários, um direito assegurado por leis em todo o mundo (leis de proteção de dados), é necessária uma atenção maior a esses dados para não serem publicados. no entanto, identificar as informações sensíveis entre tantos outros tipos de dados, pode não ser uma tarefa trivial. estudos já existentes propõem a aplicação de técnicas de processamento de linguagem natural (pln) para identificação automática de informações pessoais identificáveis (personal identifiable information, pii) em documentos em português. o objetivo deste trabalho é propor, através de uma prova de conceito, uma abordagem complementar às utilizadas nos estudos relacionados, através da tarefa de extração de relação de pln. para tal, foi criado um componente que combina um modelo de linguagem especializado na língua portuguesa e camadas adicionais de extração de relação. para o treinamento e avaliação do componente, foi gerada uma base de dados sensíveis sintéticos com o auxílio de um large language model (llm). os resultados foram satisfatórios, com métricas de precisão, recall e f1-score acima de %, indicando que a abordagem pode ser uma boa proposta para detecção automática de informações sensíveis pessoais."
88,2022,A new take of Java 11 GC performance: the heapothesys case.,"TAVARES, Gabriel Alves.","SILVA, Thiago Emmanuel Pereira da Cunha.","Os benchmarks são essenciais à investigação científica, uma vez que proporcionam uma forma fiável de comparar abordagens inovadoras com o padrão académico. Especificamente, benchmarks são amplamente utilizados em Java para avaliar novas versões da JVM e dos Coletores de Lixo (CL). À medida que novas cargas de teste e CLs chegam à indústria, é fundamental expandir a nossa compreensão da gestão dinâmica de memória, estudando como funcionam essas novas estratégias. Este trabalho estuda o desempenho dos coletores de lixo modernos e estabelecidos na indústria utilizando HyperAlloc, uma carga de trabalho do Heapothesys Benchmark da Amazon que prevê com precisão o comportamento de alocação de memória e facilita as comparações entre algoritmos de CL. A análise fornecida neste documento serve como guia sobre a adequação da Heapothesys para avaliar os CLs modernos e fornece informações sobre os seus trade-offs de desempenho.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37847,"os benchmarks são essenciais à investigação científica, uma vez que proporcionam uma forma fiável de comparar abordagens inovadoras com o padrão académico. especificamente, benchmarks são amplamente utilizados em java para avaliar novas versões da jvm e dos coletores de lixo (cl). à medida que novas cargas de teste e cls chegam à indústria, é fundamental expandir a nossa compreensão da gestão dinâmica de memória, estudando como funcionam essas novas estratégias. este trabalho estuda o desempenho dos coletores de lixo modernos e estabelecidos na indústria utilizando hyperalloc, uma carga de trabalho do heapothesys benchmark da amazon que prevê com precisão o comportamento de alocação de memória e facilita as comparações entre algoritmos de cl. a análise fornecida neste documento serve como guia sobre a adequação da heapothesys para avaliar os cls modernos e fornece informações sobre os seus trade-offs de desempenho."
89,2022,Eficiência energética: atuação sobre condicionador de ar em sala de servidores no Campus UFCG.,"FERNANDES, Lucas de Medeiros Nunes.","CAMPOS, Lívia Maria Rodrigues Sampaio.","Em ambientes de processamento de dados, como data centers ou salas de servidores dedicados, é necessário que haja uma refrigeração constante, por causa de equipamentos sensíveis a temperaturas elevadas. Porém, dispositivos como condicionadores de ar elevam os gastos com energia elétrica, devido à grande demanda de carga energética para seu funcionamento. A aplicação de estratégias de monitoramento e automação é capaz de proporcionar ganhos significativos em relação à eficiência energética. No contexto da UFCG, uma infraestrutura inteligente capaz de gerar dados úteis para estudos nessa direção tem sido provida pelo projeto Smart Campus. Porém, as ações tomadas até hoje são mais direcionadas para visualização de dados de consumo do que atuação que identifique oportunidades de redução de gastos com energia elétrica, assim como possíveis automações no gerenciamento, especialmente em salas de servidores. Neste trabalho, será realizado um estudo usando dados provenientes dessa infraestrutura, com o objetivo de avaliar a relevância de atuar sobre a temperatura do condicionador de ar responsável pela refrigeração do Laboratório de Tecnologias de Comunicação (LATEC) a fim de proporcionar economia de energia. Os resultados vão orientar estudos e ações sobre ambientes similares, além de servir como base para futuras automações.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37844,"em ambientes de processamento de dados, como data centers ou salas de servidores dedicados, é necessário que haja uma refrigeração constante, por causa de equipamentos sensíveis a temperaturas elevadas. porém, dispositivos como condicionadores de ar elevam os gastos com energia elétrica, devido à grande demanda de carga energética para seu funcionamento. a aplicação de estratégias de monitoramento e automação é capaz de proporcionar ganhos significativos em relação à eficiência energética. no contexto da ufcg, uma infraestrutura inteligente capaz de gerar dados úteis para estudos nessa direção tem sido provida pelo projeto smart campus. porém, as ações tomadas até hoje são mais direcionadas para visualização de dados de consumo do que atuação que identifique oportunidades de redução de gastos com energia elétrica, assim como possíveis automações no gerenciamento, especialmente em salas de servidores. neste trabalho, será realizado um estudo usando dados provenientes dessa infraestrutura, com o objetivo de avaliar a relevância de atuar sobre a temperatura do condicionador de ar responsável pela refrigeração do laboratório de tecnologias de comunicação (latec) a fim de proporcionar economia de energia. os resultados vão orientar estudos e ações sobre ambientes similares, além de servir como base para futuras automações."
90,2024,Monitoração da sanidade de web scrapers com OpenTelemetry.,"MARTINS, André Lucas Medeiros.","ARAÚJO, Eliane Cristina de.","Web Scrapers são ferramentas para coletar dados de sites web sendo uma estratégia amplamente usada para fornecer diversos tipos de serviços. No entanto, quando se tem um ou mais serviços de extração de dados de sites, como saber a “saúde” desse funcionamento? Não existe um compromisso de compatibilidade entre site e scraper, pois, em geral, são desenvolvidos por equipes diferentes. Dessa forma, o scraper pode inadvertidamente deixar de funcionar devido a mudanças realizadas no site. Neste trabalho foi desenvolvida uma estratégia usando OpenTemeletry, para emissão de métricas e rastreamentos de funcionamento para solucionar esta falta de visão da sanidade do scraper. Espera-se que ao final deste trabalho seja possível aplicar a solução na prática e, assim, ter um único local com as informações de funcionamento dos Web Scrapers.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37843,"web scrapers são ferramentas para coletar dados de sites web sendo uma estratégia amplamente usada para fornecer diversos tipos de serviços. no entanto, quando se tem um ou mais serviços de extração de dados de sites, como saber a “saúde” desse funcionamento? não existe um compromisso de compatibilidade entre site e scraper, pois, em geral, são desenvolvidos por equipes diferentes. dessa forma, o scraper pode inadvertidamente deixar de funcionar devido a mudanças realizadas no site. neste trabalho foi desenvolvida uma estratégia usando opentemeletry, para emissão de métricas e rastreamentos de funcionamento para solucionar esta falta de visão da sanidade do scraper. espera-se que ao final deste trabalho seja possível aplicar a solução na prática e, assim, ter um único local com as informações de funcionamento dos web scrapers."
91,2022,"Cidade Singular: um aplicativo de divulgação de atividades, bens e serviços culturais.","NASCIMENTO, Izaquiel Nunes do.","BARROS, Marcelo Alves de.","Um dos aliados do desenvolvimento sustentável nas cidades é a Economia Criativa, uma forma de unir tecnologia, inovação, cultura, criatividade e sustentabilidade para impulsionar a economia. A UNESCO criou a Rede de Cidades Criativas justamente para incentivar esse tipo de iniciativa. As cidades que aderem à Rede se comprometem a compartilhar suas melhores práticas e desenvolvem parcerias para impulsionar o setor cultural. Uma das responsabilidades é a divulgação e difusão de atividades, bens e serviços culturais. Diante disso, este trabalho se propõe a construir um sistema para divulgação de atrações culturais das cidades criativas. O aplicativo Cidade Singular foi finalizado com as funcionalidades planejadas, como a funcionalidade de mapa interativo para navegar entre os principais pontos turísticos. Além do aplicativo para os visitantes, foi desenvolvido o aplicativo de gestão onde são adicionados curadores especializados e os mesmos cadastram e atualizam a base de dados das atrações turísticas.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37842,"um dos aliados do desenvolvimento sustentável nas cidades é a economia criativa, uma forma de unir tecnologia, inovação, cultura, criatividade e sustentabilidade para impulsionar a economia. a unesco criou a rede de cidades criativas justamente para incentivar esse tipo de iniciativa. as cidades que aderem à rede se comprometem a compartilhar suas melhores práticas e desenvolvem parcerias para impulsionar o setor cultural. uma das responsabilidades é a divulgação e difusão de atividades, bens e serviços culturais. diante disso, este trabalho se propõe a construir um sistema para divulgação de atrações culturais das cidades criativas. o aplicativo cidade singular foi finalizado com as funcionalidades planejadas, como a funcionalidade de mapa interativo para navegar entre os principais pontos turísticos. além do aplicativo para os visitantes, foi desenvolvido o aplicativo de gestão onde são adicionados curadores especializados e os mesmos cadastram e atualizam a base de dados das atrações turísticas."
92,2024,Blockchain e possíveis aplicações.,"DANTAS, Anderson Kleber.","PEREIRA, Thiago Emmanuel da Cunha Silva.","Este artigo explora o potencial transformador e as aplicações no mundo real da tecnologia blockchain. Inicialmente, este documento discute as principais funcionalidades do blockchain, incluindo seu sistema de consenso distribuído e imutável que suporta criptomoedas como o Bitcoin por meio de mecanismos como prova de trabalho. Ele entra em contratos inteligentes, enfatizando as capacidades do Ethereum que ultrapassam simples transações monetárias para permitir aplicações complexas graças à sua linguagem Turing-completa e máquina virtual. Um foco significativo é colocado nas implicações dos tokens não fungíveis (NFTs) para a propriedade de ativos digitais e físicos, destacando como eles suportam representações digitais únicas no blockchain. Outra inovação discutida é o conceito de “Soulbound Tokens” (SBTs), que são projetados para representar atributos intransferíveis como identidade e reputação dentro de uma estrutura descentralizada. Por fim, o artigo mostra o papel crucial dos “oráculos”, que ligam a blockchain aos dados do mundo real, ilustrando o seu impacto nos sistemas financeiros tradicionais através de algoritmos e contratos inteligentes. Portanto, por meio de uma análise abrangente, o artigo articula o vasto potencial da blockchain para inovar múltiplos setores, enfatizando a importância do desenvolvimento colaborativo para garantir a segurança e a conformidade regulatória no aproveitamento eficaz da tecnologia blockchain.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37841,"este artigo explora o potencial transformador e as aplicações no mundo real da tecnologia blockchain. inicialmente, este documento discute as principais funcionalidades do blockchain, incluindo seu sistema de consenso distribuído e imutável que suporta criptomoedas como o bitcoin por meio de mecanismos como prova de trabalho. ele entra em contratos inteligentes, enfatizando as capacidades do ethereum que ultrapassam simples transações monetárias para permitir aplicações complexas graças à sua linguagem turing-completa e máquina virtual. um foco significativo é colocado nas implicações dos tokens não fungíveis (nfts) para a propriedade de ativos digitais e físicos, destacando como eles suportam representações digitais únicas no blockchain. outra inovação discutida é o conceito de “soulbound tokens” (sbts), que são projetados para representar atributos intransferíveis como identidade e reputação dentro de uma estrutura descentralizada. por fim, o artigo mostra o papel crucial dos “oráculos”, que ligam a blockchain aos dados do mundo real, ilustrando o seu impacto nos sistemas financeiros tradicionais através de algoritmos e contratos inteligentes. portanto, por meio de uma análise abrangente, o artigo articula o vasto potencial da blockchain para inovar múltiplos setores, enfatizando a importância do desenvolvimento colaborativo para garantir a segurança e a conformidade regulatória no aproveitamento eficaz da tecnologia blockchain."
93,2021,“Minha Graduação”: uma aplicação para melhorar o acompa-nhamento acadêmico dos alunos.,"ALVES, Gabriel Valentino Botelho.","MOURA, José Antão Beltrão.","Os sistemas de controle acadêmico contém diversas funcionalidades e informações relacionadas à situação acadêmica dos alunos, entretanto há muitas necessidades que não são atendidas. No período de matrícula, por exemplo, é um momento onde grande parte dos alunos recorrem a outros sites e ferramentas para auxiliar em suas decisões e na gestão da sua graduação. Tendo em vista esse cenário, este trabalho busca desenvolver uma aplicação denominada “Minha Graduação”, que irá centralizar informações acadêmicas e disponibilizar funcionalidades focadas nas principais necessidades dos alunos, a fim de melhorar o seu acompanhamento acadêmico.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37840,"os sistemas de controle acadêmico contém diversas funcionalidades e informações relacionadas à situação acadêmica dos alunos, entretanto há muitas necessidades que não são atendidas. no período de matrícula, por exemplo, é um momento onde grande parte dos alunos recorrem a outros sites e ferramentas para auxiliar em suas decisões e na gestão da sua graduação. tendo em vista esse cenário, este trabalho busca desenvolver uma aplicação denominada “minha graduação”, que irá centralizar informações acadêmicas e disponibilizar funcionalidades focadas nas principais necessidades dos alunos, a fim de melhorar o seu acompanhamento acadêmico."
94,2024,Adaptação operacional de uma aplicação arquitetada em microsserviços e os impactos em tempo de resposta.,"HAMAD, Ana Beatriz Souza.","GOMES, Reinaldo Cézar de Morais.","A hospedagem de uma aplicação em um ambiente centralizado pode oferecer vantagens em termos de simplificação de arquitetura, baixo tempo de resposta em condições normais, controle da infraestrutura, mitigação de complexidades operacionais e gerenciamento, porém quando se trata de um ambiente de produção, tal solução pode não ser viável a médio e longo prazo por ser um ambiente limitado, instável, com poucas janelas de otimização e expansão do serviço. Uma das soluções possíveis de evolução em termos de infraestrutura é a distribuição do sistema em cloud pública, no caso desse estudo em nós AWS, com microsserviços orquestrados com Kubernetes, de forma a aproveitar as garantias operacionais de ambas as plataformas para mitigar boa parte do leque de falhas que um ambiente centralizado oferece, a custo de relativa perda de desempenho em relação a tempo de resposta. Esse estudo de caso tem como objetivo elencar os principais problemas que existem hoje na implementação do Sênior Saúde Móvel, uma plataforma de prontuário digital arquitetada em microsserviços e hospedado de forma centralizada no data center do laboratório NUTES-UEPB. Ao final pretende-se adaptar e implementar a mesma aplicação em infraestrutura distribuída, estudar o tradeoff relativo ao tempo de resposta, e por fim sumarizar soluções, melhorias e trabalhos futuros referentes à avaliação dos resultados observados. Podemos concluir que apesar da diferença de desempenho de tempo de resposta, as garantias providas pela solução distribuída, o potencial de expansão, manutenção do sistema, escalabilidade e o nível aceitável de tempo de resposta com prospectos de otimização justificam positivamente a adoção da adaptação para um futuro ambiente de produção.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37839,"a hospedagem de uma aplicação em um ambiente centralizado pode oferecer vantagens em termos de simplificação de arquitetura, baixo tempo de resposta em condições normais, controle da infraestrutura, mitigação de complexidades operacionais e gerenciamento, porém quando se trata de um ambiente de produção, tal solução pode não ser viável a médio e longo prazo por ser um ambiente limitado, instável, com poucas janelas de otimização e expansão do serviço. uma das soluções possíveis de evolução em termos de infraestrutura é a distribuição do sistema em cloud pública, no caso desse estudo em nós aws, com microsserviços orquestrados com kubernetes, de forma a aproveitar as garantias operacionais de ambas as plataformas para mitigar boa parte do leque de falhas que um ambiente centralizado oferece, a custo de relativa perda de desempenho em relação a tempo de resposta. esse estudo de caso tem como objetivo elencar os principais problemas que existem hoje na implementação do sênior saúde móvel, uma plataforma de prontuário digital arquitetada em microsserviços e hospedado de forma centralizada no data center do laboratório nutes-uepb. ao final pretende-se adaptar e implementar a mesma aplicação em infraestrutura distribuída, estudar o tradeoff relativo ao tempo de resposta, e por fim sumarizar soluções, melhorias e trabalhos futuros referentes à avaliação dos resultados observados. podemos concluir que apesar da diferença de desempenho de tempo de resposta, as garantias providas pela solução distribuída, o potencial de expansão, manutenção do sistema, escalabilidade e o nível aceitável de tempo de resposta com prospectos de otimização justificam positivamente a adoção da adaptação para um futuro ambiente de produção."
95,2024,Centralizando informações de pessoas desaparecidas com uma aplicação web.,"GARCIA, Afrânio Alves.","GUERRERO, Dalton Dario Serey.","O desafio de encontrar pessoas desaparecidas e reunir parentes separados é uma preocupação social significativa. Este trabalho propõe o desenvolvimento de um aplicativo web para facilitar a busca e promover a reunificação, fornecendo um ambiente seguro para a troca de informações. A relevância do projeto está na necessidade crescente de auxílio na localização de desaparecidos e no valor emocional da reunião de famílias. A ferramenta usará tecnologia e colaboração da comunidade técnica para criar um espaço de contribuição aberta, integrando desenvolvedores e atendendo a diferentes necessidades culturais. As próximas seções detalham as tecnologias escolhidas, funcionalidades e escopo do aplicativo.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37838,"o desafio de encontrar pessoas desaparecidas e reunir parentes separados é uma preocupação social significativa. este trabalho propõe o desenvolvimento de um aplicativo web para facilitar a busca e promover a reunificação, fornecendo um ambiente seguro para a troca de informações. a relevância do projeto está na necessidade crescente de auxílio na localização de desaparecidos e no valor emocional da reunião de famílias. a ferramenta usará tecnologia e colaboração da comunidade técnica para criar um espaço de contribuição aberta, integrando desenvolvedores e atendendo a diferentes necessidades culturais. as próximas seções detalham as tecnologias escolhidas, funcionalidades e escopo do aplicativo."
96,2022,Uma abordagem para suporte à análise de riscos no Mantis Bug Tracker.,"GALDINO, Yally de Lima.","ALMEIDA, Hyggo Oliveira de.","Mantis Bug Tracker é uma ferramenta web cujo foco é gerenciar defeitos (bugs) no software durante o seu processo de desenvolvimento e evolução. Com ele, tem-se um banco de dados dos defeitos relatados pelos usuários, equipes de desenvolvimento e de qualidade. A motivação para o uso de uma ferramenta como a Mantis é que a alta quantidade de bugs em um software gera desgaste para o cliente, desvaloriza o produto, traz custos com retrabalho e riscos de prejuízos financeiros e de negócio. Em 2009, por exemplo, um programador da Google adicionou uma barra invertida nas URLs e o site foi sinalizado como malware por cerca de uma hora, gerando um prejuízo total de quase US$ 3 milhões. Neste trabalho, tem-se como objetivo apresentar uma abordagem para suporte à análise de riscos no Mantis Bug Tracker, levantando os pontos críticos de um sistema através da análise dos bugs relatados pelos clientes. Com base no estudo desses bugs entender a sua causa e assim criar ações para eliminá-los ou ter uma resposta mais rápida caso eles apareçam. Isso trará benefícios para a empresa que o desenvolve em relação a tempo, custo, curva de aprendizado e maior satisfação do cliente.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37821,"mantis bug tracker é uma ferramenta web cujo foco é gerenciar defeitos (bugs) no software durante o seu processo de desenvolvimento e evolução. com ele, tem-se um banco de dados dos defeitos relatados pelos usuários, equipes de desenvolvimento e de qualidade. a motivação para o uso de uma ferramenta como a mantis é que a alta quantidade de bugs em um software gera desgaste para o cliente, desvaloriza o produto, traz custos com retrabalho e riscos de prejuízos financeiros e de negócio. em , por exemplo, um programador da google adicionou uma barra invertida nas urls e o site foi sinalizado como malware por cerca de uma hora, gerando um prejuízo total de quase us$ milhões. neste trabalho, tem-se como objetivo apresentar uma abordagem para suporte à análise de riscos no mantis bug tracker, levantando os pontos críticos de um sistema através da análise dos bugs relatados pelos clientes. com base no estudo desses bugs entender a sua causa e assim criar ações para eliminá-los ou ter uma resposta mais rápida caso eles apareçam. isso trará benefícios para a empresa que o desenvolve em relação a tempo, custo, curva de aprendizado e maior satisfação do cliente."
97,2022,Análise de plataformas de apoio ao ensino à distância no ensino superior: tratamento dos dados dos usuários.,"COSTA, Larissa Gabriela Amorim da.","GARCIA, Francilene Procópio.","Todas as áreas de atividades precisaram se adaptar por causa do distanciamento social provocado pelo novo coronavírus. O ensino à distância (EaD) foi a principal alternativa para estudantes e professores durante a quarentena. Para que o ensino não presencial ocorresse de forma estruturada e eficiente, o uso de plataformas digitais de apoio ao ensino não presencial e EaD foi essencial. EAD e ensino não presencial são modalidades distintas, com características em comum. O ensino não presencial diz respeito às atividades de ensino mediadas por tecnologias e orientadas pelos princípios da educação presencial, enquanto o EaD, que também utiliza as plataformas digitais, tem seu formato próprio de ensino-aprendizagem. Diante da pandemia, houve um aumento dos usuários nas plataformas digitais, e, consequentemente, a coleta de dados pelas mesmas foi intensificada. É importante ressaltar que o fornecimento, tratamento e armazenamento dos dados pessoais dos usuários precisam estar alinhados com a legislação a fim de coibir o uso indiscriminado dos dados coletados. Nesse sentido, o presente artigo aborda a temática do uso dos dados pelas plataformas digitais utilizadas no ensino superior durante a pandemia. A pesquisa tem como objetivo analisar as plataformas Google Classroom, Zoom Cloud Meeting, Microsoft Teams e Slack para saber como as mesmas tratam os dados dos usuários. A conhecida Lei Geral de Proteção de Dados (Brasil, 2018), cuja sigla é LGPD, estabelece regras sobre coleta, armazenamento, tratamento e compartilhamento de dados. A metodologia parte da pesquisa das políticas de privacidade das plataformas. Desta forma, os resultados esperados atendem a dois propósitos: por um lado, contribuir para que o usuário saiba como são usados e armazenados os seus dados; por outro lado sinalizar recomendações para os usuários das plataformas.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37820,"todas as áreas de atividades precisaram se adaptar por causa do distanciamento social provocado pelo novo coronavírus. o ensino à distância (ead) foi a principal alternativa para estudantes e professores durante a quarentena. para que o ensino não presencial ocorresse de forma estruturada e eficiente, o uso de plataformas digitais de apoio ao ensino não presencial e ead foi essencial. ead e ensino não presencial são modalidades distintas, com características em comum. o ensino não presencial diz respeito às atividades de ensino mediadas por tecnologias e orientadas pelos princípios da educação presencial, enquanto o ead, que também utiliza as plataformas digitais, tem seu formato próprio de ensino-aprendizagem. diante da pandemia, houve um aumento dos usuários nas plataformas digitais, e, consequentemente, a coleta de dados pelas mesmas foi intensificada. é importante ressaltar que o fornecimento, tratamento e armazenamento dos dados pessoais dos usuários precisam estar alinhados com a legislação a fim de coibir o uso indiscriminado dos dados coletados. nesse sentido, o presente artigo aborda a temática do uso dos dados pelas plataformas digitais utilizadas no ensino superior durante a pandemia. a pesquisa tem como objetivo analisar as plataformas google classroom, zoom cloud meeting, microsoft teams e slack para saber como as mesmas tratam os dados dos usuários. a conhecida lei geral de proteção de dados (brasil, ), cuja sigla é lgpd, estabelece regras sobre coleta, armazenamento, tratamento e compartilhamento de dados. a metodologia parte da pesquisa das políticas de privacidade das plataformas. desta forma, os resultados esperados atendem a dois propósitos: por um lado, contribuir para que o usuário saiba como são usados e armazenados os seus dados; por outro lado sinalizar recomendações para os usuários das plataformas."
98,2022,DBS: ferramenta para auxiliar na evolução do modelo de dados com integração contínua.,"DANTAS, Higor Santos de Brito.","FARIAS, Adalberto Cajueiro de.","A utilização de metodologias ágeis no desenvolvimento de softwares traz diversos benefícios, como quando se deseja realizar a evolução do mesmo. Entretanto, a evolução de um sistema, em muitos casos, necessita de mudanças na base de dados dificultando o gerenciamento. Embora esse tipo de evolução seja auxiliada por ferramentas, as mudanças necessárias são criadas e analisadas manualmente. Portanto, uma negligência do desenvolvedor ou a necessidade de realizar operações mais complexas acabam tornando essa atividade passível a erros de execução, e até de integridade do banco de dados. Logo, ao longo deste trabalho será feito o desenvolvimento de uma ferramenta que permita o gerenciamento de modificações no banco de dados de maneira semiautomática. Onde o produto desse projeto irá gerar scripts para a realização das mudanças desejadas no estado do banco de dados. Sendo assim, é esperado que a evolução dos softwares se tornem mais simples e eficientes, com uma redução nos erros relacionados às alterações necessárias nos bancos de dados.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37818,"a utilização de metodologias ágeis no desenvolvimento de softwares traz diversos benefícios, como quando se deseja realizar a evolução do mesmo. entretanto, a evolução de um sistema, em muitos casos, necessita de mudanças na base de dados dificultando o gerenciamento. embora esse tipo de evolução seja auxiliada por ferramentas, as mudanças necessárias são criadas e analisadas manualmente. portanto, uma negligência do desenvolvedor ou a necessidade de realizar operações mais complexas acabam tornando essa atividade passível a erros de execução, e até de integridade do banco de dados. logo, ao longo deste trabalho será feito o desenvolvimento de uma ferramenta que permita o gerenciamento de modificações no banco de dados de maneira semiautomática. onde o produto desse projeto irá gerar scripts para a realização das mudanças desejadas no estado do banco de dados. sendo assim, é esperado que a evolução dos softwares se tornem mais simples e eficientes, com uma redução nos erros relacionados às alterações necessárias nos bancos de dados."
99,2022,Estudo comparativo entre ferramentas de automação para implantação de infraestrutura em TI.,"SILVA JÚNIOR, Paulo Mendes da.","GOMES, Reinaldo Cézar de Morais.","A especificação e avaliação da qualidade de software e dos sistemas de computador com uso intensivo de software é um fator chave para garantir valor às partes interessadas. Para isso, é importante que as características de qualidade sejam especificadas, medidas e avaliadas, sempre que possível, usando medidas e métodos validados e amplamente aceitos. Em relação ao tema Infrastructure as Code (IaC), não existem estudos que fazem um comparativo entre as ferramentas para gerenciamento de configuração de automação em software, em termos de métricas bem definidas, que são usadas como requisitos para a avaliação de uma boa qualidade de software, como por exemplo, as métricas definidas e documentadas pela ISO/IEC 25010:2011 [1]. Ao analisar todas as métricas definidas na especificação, um subconjunto foi escolhido para analisar algumas ferramentas de automação de infraestrutura. As métricas escolhidas foram: manutenibilidade, portabilidade e usabilidade. Foi observado que todas as ferramentas desempenham bem o papel de configuração de infraestrutura como código, porém algumas se destacam pela simplicidade e fácil aprendizado, como é o caso do Ansible e do Terraform. Além de que o Terraform é capaz de não somente configurar máquinas virtuais, mas também provisioná-las. Por outro lado, o Puppet é um pouco mais complexo do que as demais ferramentas pelo fato de sua configuração de agentes ser mais complexa e a curva de aprendizado não ser acentuada, porém também funciona muito bem para a configuração de infraestrutura.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37815,"a especificação e avaliação da qualidade de software e dos sistemas de computador com uso intensivo de software é um fator chave para garantir valor às partes interessadas. para isso, é importante que as características de qualidade sejam especificadas, medidas e avaliadas, sempre que possível, usando medidas e métodos validados e amplamente aceitos. em relação ao tema infrastructure as code (iac), não existem estudos que fazem um comparativo entre as ferramentas para gerenciamento de configuração de automação em software, em termos de métricas bem definidas, que são usadas como requisitos para a avaliação de uma boa qualidade de software, como por exemplo, as métricas definidas e documentadas pela iso/iec : [ ]. ao analisar todas as métricas definidas na especificação, um subconjunto foi escolhido para analisar algumas ferramentas de automação de infraestrutura. as métricas escolhidas foram: manutenibilidade, portabilidade e usabilidade. foi observado que todas as ferramentas desempenham bem o papel de configuração de infraestrutura como código, porém algumas se destacam pela simplicidade e fácil aprendizado, como é o caso do ansible e do terraform. além de que o terraform é capaz de não somente configurar máquinas virtuais, mas também provisioná-las. por outro lado, o puppet é um pouco mais complexo do que as demais ferramentas pelo fato de sua configuração de agentes ser mais complexa e a curva de aprendizado não ser acentuada, porém também funciona muito bem para a configuração de infraestrutura."
100,2022,Desenvolvimento de novas funcionalidades e melhorias de UI/UX no Aplicativo Feridômetro.,"COUTINHO, Matheus de Souza.","ALMEIDA, Hyggo Oliveira de.","O acrônimo TIMERS é utilizado por profissionais da saúde para direcionar e avaliar a conduta adequada em cada situação de tratamento e avaliação de feridas de acordo com o estado da enfermidade. Seu objetivo é auxiliar na ava-liação inicial e proporcionar meios de tratamentos corretos e eficazes, de acordo com os parâmetros avaliados. O aplicativo Feridômetro é um aplicativo portátil desenvolvido inicialmente pela professora Lidiany Galdino e pelo aluno Adiel Andrade Rocha, o projeto está em código aberto e tem como finalidade ser uma ferramenta de auxílio aos profissionais e alunos que buscam aprimorar seus conhecimentos sobre o acrônimo. Neste trabalho, serão desenvolvidas novas funcionalidades para o aplicativo, com o intuito de melhorar a experiência do usuário, criar novas ferramentas de aprendizado e canal de comunicação entre os usuários, assim como, complementar o conteúdo vinculado ao aplicativo referente ao acrônimo. A partir dessas integrações, os usuários terão mais facilidade no aprendizado, comunicação entre outros usuários e terão todo o conteúdo explicativo sobre o acrônimo.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37810,"o acrônimo timers é utilizado por profissionais da saúde para direcionar e avaliar a conduta adequada em cada situação de tratamento e avaliação de feridas de acordo com o estado da enfermidade. seu objetivo é auxiliar na ava-liação inicial e proporcionar meios de tratamentos corretos e eficazes, de acordo com os parâmetros avaliados. o aplicativo feridômetro é um aplicativo portátil desenvolvido inicialmente pela professora lidiany galdino e pelo aluno adiel andrade rocha, o projeto está em código aberto e tem como finalidade ser uma ferramenta de auxílio aos profissionais e alunos que buscam aprimorar seus conhecimentos sobre o acrônimo. neste trabalho, serão desenvolvidas novas funcionalidades para o aplicativo, com o intuito de melhorar a experiência do usuário, criar novas ferramentas de aprendizado e canal de comunicação entre os usuários, assim como, complementar o conteúdo vinculado ao aplicativo referente ao acrônimo. a partir dessas integrações, os usuários terão mais facilidade no aprendizado, comunicação entre outros usuários e terão todo o conteúdo explicativo sobre o acrônimo."
101,2023,Evaluation of cache usage on ecommerce catalogs of multitenant platforms.,"CARVALHO, Thúlio Ícaro Castro.","BRUNET, João Arthur Monteiro.","Um requisito comum para plataformas de comércio eletrônico é o gerenciamento de catálogos de produtos. Em catálogos grandes e multilocatários, o gerenciamento de latências é um desafio, e o cache geralmente é empregado para melhorar o desempenho. Ao observar uma solução de catálogo de uma grande empresa de comércio eletrônico, identificamos o que os engenheiros consideravam um sistema de cache abaixo do ideal. Com base na experiência anterior, os engenheiros da empresa acreditam que as características da carga de trabalho impactam o desempenho do cache. Este trabalho tem como objetivo verificar essa crença. Usamos rastreamentos coletados de solicitações recebidas de produção para analisar e compreender as características da carga de trabalho, bem como relacioná-las com o comportamento do cache.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37804,"um requisito comum para plataformas de comércio eletrônico é o gerenciamento de catálogos de produtos. em catálogos grandes e multilocatários, o gerenciamento de latências é um desafio, e o cache geralmente é empregado para melhorar o desempenho. ao observar uma solução de catálogo de uma grande empresa de comércio eletrônico, identificamos o que os engenheiros consideravam um sistema de cache abaixo do ideal. com base na experiência anterior, os engenheiros da empresa acreditam que as características da carga de trabalho impactam o desempenho do cache. este trabalho tem como objetivo verificar essa crença. usamos rastreamentos coletados de solicitações recebidas de produção para analisar e compreender as características da carga de trabalho, bem como relacioná-las com o comportamento do cache."
102,2023,Monitoramento contínuo de integridade para contêineres em ambientes LINUX.,"SARMENTO, Ramon Sousa.","GOMES, Reinaldo Cézar de Morais.","Neste trabalho será discutido o uso crescente de containers na virtualização de ambientes e implantação de aplicações, enfatizando a importância de garantir a integridade e segurança destes containers. O trabalho apresenta uma solução que usa a arquitetura de medição de integridade do kernel do Linux e o chip Trusted Platform Module para avaliar a integridade de aplicativos e bibliotecas. O ímpeto desta pesquisa está na necessidade de proteger as aplicações em ambientes virtualizados e conteinerizados, garantindo sua confiabilidade e segurança. A solução proposta neste estudo envolve um modelo cliente-servidor, no qual os containers são executados no cliente. Uma aplicação foi desenvolvida para monitorar continuamente a integridade desses contêineres. Quando um erro de integridade no contêiner é identificado, o servidor é notificado imediatamente. O servidor, munido dessas informações, decide a ação apropriada a ser tomada em resposta ao erro identificado. Este processo permite uma resposta rápida e eficaz a possíveis violações de integridade, aumentando assim a segurança geral do sistema.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37803,"neste trabalho será discutido o uso crescente de containers na virtualização de ambientes e implantação de aplicações, enfatizando a importância de garantir a integridade e segurança destes containers. o trabalho apresenta uma solução que usa a arquitetura de medição de integridade do kernel do linux e o chip trusted platform module para avaliar a integridade de aplicativos e bibliotecas. o ímpeto desta pesquisa está na necessidade de proteger as aplicações em ambientes virtualizados e conteinerizados, garantindo sua confiabilidade e segurança. a solução proposta neste estudo envolve um modelo cliente-servidor, no qual os containers são executados no cliente. uma aplicação foi desenvolvida para monitorar continuamente a integridade desses contêineres. quando um erro de integridade no contêiner é identificado, o servidor é notificado imediatamente. o servidor, munido dessas informações, decide a ação apropriada a ser tomada em resposta ao erro identificado. este processo permite uma resposta rápida e eficaz a possíveis violações de integridade, aumentando assim a segurança geral do sistema."
103,2022,Um estudo sobre âncoras de carreira entre desenvolvedores de software que abandonaram a profissão.,"MANGUEIRA, Mateus Pinto.","MASSONI, Tiago Lima.","Fenômenos como abandono (turnaway) e transição de carreira (turnover) estão cada vez mais frequentes em empresas de desenvolvimento de software, um dos principais motivos pode estar relacionado com a falta de identificação com a área. Investigar esses fenômenos no âmbito comportamental por meio das âncoras de carreira do indivíduo pode ser primordial para que as empresas melhorem seus planos de carreira, política empresarial e política de retenção. Este estudo visa investigar a relação entre o abandono de carreira (turnaway) com as âncoras de carreira de ex-desenvolvedores. Para isso foi aplicado o teste Âncora de Carreira entre 15 ex-desenvolvedores de diferentes regiões do Brasil por meio de Survey a fim de identificar dados sobre o processo de desenvolvimento de software a partir de entrevistas semi-estruturadas realizadas, transcritas e codificadas por outros pesquisadores da área. Com base nos dados obtidos, esperamos que esses resultados contribuam para conceber estratégias eficazes para as empresas reterem seus colaboradores, além disso, minimizar o custo social de abandono de carreira daqueles desenvolvedores e incentivar pesquisas futuras.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37779,"fenômenos como abandono (turnaway) e transição de carreira (turnover) estão cada vez mais frequentes em empresas de desenvolvimento de software, um dos principais motivos pode estar relacionado com a falta de identificação com a área. investigar esses fenômenos no âmbito comportamental por meio das âncoras de carreira do indivíduo pode ser primordial para que as empresas melhorem seus planos de carreira, política empresarial e política de retenção. este estudo visa investigar a relação entre o abandono de carreira (turnaway) com as âncoras de carreira de ex-desenvolvedores. para isso foi aplicado o teste âncora de carreira entre ex-desenvolvedores de diferentes regiões do brasil por meio de survey a fim de identificar dados sobre o processo de desenvolvimento de software a partir de entrevistas semi-estruturadas realizadas, transcritas e codificadas por outros pesquisadores da área. com base nos dados obtidos, esperamos que esses resultados contribuam para conceber estratégias eficazes para as empresas reterem seus colaboradores, além disso, minimizar o custo social de abandono de carreira daqueles desenvolvedores e incentivar pesquisas futuras."
104,2022,Programming Courses: plataforma de apoio ao ensino de programação.,"CANUTO, Kleberson Matheus Cunha Silva.","ARAÚJO, Eliane Cristina de.","Aprender lógica e programação pode ser essencial para começar bem um curso de graduação em computação. Atual-mente, o aprendizado de programação tem incentivado pessoas com distintos interesses, seja na área tecnológica profissionalmente, ou apenas por curiosidade e vontade de adquirir novos conhecimentos. Já existem plataformas que buscam apoiar o ensino de programação, porém em sua maioria com pouco material de estudo, disponibilidade limitada, sem testes práticos, entre outros problemas. Tendo em vista estas lacunas, propusemos a plataforma Programming Courses, que busca auxiliar e incentivar, de forma interativa, o aprendizado de programação introdutória. Ele permite que sejam criados cursos de programação em Python [1], utilizando diferentes recursos. Dentre eles, podemos citar: módulos de materiais didáticos, questões de múltipla escolha, recomendações de materiais complementares e testes automáticos, que também conta com o auxílio de um oráculo para validar entradas e saídas propostas pelo aluno. Além destas, há funcionalidades de gamificação, já disponíveis na maioria das plataformas, como pontuação, recompensas e dicas.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37777,"aprender lógica e programação pode ser essencial para começar bem um curso de graduação em computação. atual-mente, o aprendizado de programação tem incentivado pessoas com distintos interesses, seja na área tecnológica profissionalmente, ou apenas por curiosidade e vontade de adquirir novos conhecimentos. já existem plataformas que buscam apoiar o ensino de programação, porém em sua maioria com pouco material de estudo, disponibilidade limitada, sem testes práticos, entre outros problemas. tendo em vista estas lacunas, propusemos a plataforma programming courses, que busca auxiliar e incentivar, de forma interativa, o aprendizado de programação introdutória. ele permite que sejam criados cursos de programação em python [ ], utilizando diferentes recursos. dentre eles, podemos citar: módulos de materiais didáticos, questões de múltipla escolha, recomendações de materiais complementares e testes automáticos, que também conta com o auxílio de um oráculo para validar entradas e saídas propostas pelo aluno. além destas, há funcionalidades de gamificação, já disponíveis na maioria das plataformas, como pontuação, recompensas e dicas."
105,2022,Inteligência artificial aplicada no auxílio à detecção de patologias vocais.,"PEREIRA, Matheus Oliveira.","ARAÚJO, Joseana Macêdo Fechine Régis de.","A escuta da voz é uma forma de avaliação da saúde vocal, em que um profissional julga a voz do paciente como patológica ou não após ouvi-la. O problema desse método é o seu caráter subjetivo, devido à possibilidade do resultado variar conforme examinador. Para uma análise mais precisa, técnicas laboratoriais podem ser aplicadas; contudo, são frequentemente evitadas pelos pacientes devido ao caráter invasivo e oneroso. Assim, pesquisadores têm desenvolvido técnicas para auxiliar na discriminação de vozes patológicas usando análise acústica, por ser uma forma de processamento digital de sinais não invasiva e automática. Esse método consiste em utilizar técnicas de processamento digital de sinais e reconhecimento de padrões, para determinar se o sinal de voz é patológico ou não. Diante disso, este artigo objetiva analisar o uso de uma rede neural artificial (RNA) como classificador e características obtidas por meio de Coeficientes Mel Cepstrais (MFCC), que auxiliarão na detecção de patologias da voz. Para o treinamento e validação da RNA, foi utilizada a base de dados alemã Saarbruecken Voice Database (SVD). Os resultados demonstraram, com validação cruzada k-fold para treinamento e teste, que a solução atingiu níveis de acurácia acima de 85% na distinção entre vozes saudáveis e patológicas.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37775,"a escuta da voz é uma forma de avaliação da saúde vocal, em que um profissional julga a voz do paciente como patológica ou não após ouvi-la. o problema desse método é o seu caráter subjetivo, devido à possibilidade do resultado variar conforme examinador. para uma análise mais precisa, técnicas laboratoriais podem ser aplicadas; contudo, são frequentemente evitadas pelos pacientes devido ao caráter invasivo e oneroso. assim, pesquisadores têm desenvolvido técnicas para auxiliar na discriminação de vozes patológicas usando análise acústica, por ser uma forma de processamento digital de sinais não invasiva e automática. esse método consiste em utilizar técnicas de processamento digital de sinais e reconhecimento de padrões, para determinar se o sinal de voz é patológico ou não. diante disso, este artigo objetiva analisar o uso de uma rede neural artificial (rna) como classificador e características obtidas por meio de coeficientes mel cepstrais (mfcc), que auxiliarão na detecção de patologias da voz. para o treinamento e validação da rna, foi utilizada a base de dados alemã saarbruecken voice database (svd). os resultados demonstraram, com validação cruzada k-fold para treinamento e teste, que a solução atingiu níveis de acurácia acima de % na distinção entre vozes saudáveis e patológicas."
106,2022,A trajetória do evadido no Curso de Ciência da Computação da UFCG.,"SANTOS, Eduardo Pereira dos.","BRASILEIRO, Francisco Vilar.","A evasão é um dos maiores problemas do ensino superior público brasileiro, representando um grande desperdício de recursos, como também uma grande perda social. Há muitos estudos sobre causas e soluções para este problema, porém sabe-se pouco sobre as trajetórias seguidas por esses alunos após a evasão, para entender melhor a extensão dessas perdas. Em particular, para profissões ligadas à área de Tecnologia da Informação, que não possuem regulamentação no Brasil, não é necessário uma formação superior para ingressar no mercado, possibilitando que pessoas que não finalizaram seus cursos sejam absorvidas. Nesse contexto, este trabalho pretendeu mapear as trajetórias seguidas pelos evadidos do curso de Ciência da Computação da Universidade Federal de Campina Grande, a fim de verificar em que medida os recursos investidos foram realmente desperdiçados. Foi apresentada uma análise preliminar, quantitativa, utilizando a base de dados da instituição, identificando grupos e suas características. Posteriormente, dados profissionais e acadêmicos foram coletados da rede social Linkedin, agregando informações aos grupos encontrados. A partir da análise qualitativa dessas informações, a pesquisa mostrou que parte dos alunos utilizam os conhecimentos adquiridos no curso, seja assumindo cargos na área de tecnologia da informação, seja em outros cursos de graduação similares. Esses resultados, de certa forma, desmistificam a ideia de que os recursos alocados para alunos que evadem de um curso de graduação em Ciência da Computação são integralmente perdidos.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37774,"a evasão é um dos maiores problemas do ensino superior público brasileiro, representando um grande desperdício de recursos, como também uma grande perda social. há muitos estudos sobre causas e soluções para este problema, porém sabe-se pouco sobre as trajetórias seguidas por esses alunos após a evasão, para entender melhor a extensão dessas perdas. em particular, para profissões ligadas à área de tecnologia da informação, que não possuem regulamentação no brasil, não é necessário uma formação superior para ingressar no mercado, possibilitando que pessoas que não finalizaram seus cursos sejam absorvidas. nesse contexto, este trabalho pretendeu mapear as trajetórias seguidas pelos evadidos do curso de ciência da computação da universidade federal de campina grande, a fim de verificar em que medida os recursos investidos foram realmente desperdiçados. foi apresentada uma análise preliminar, quantitativa, utilizando a base de dados da instituição, identificando grupos e suas características. posteriormente, dados profissionais e acadêmicos foram coletados da rede social linkedin, agregando informações aos grupos encontrados. a partir da análise qualitativa dessas informações, a pesquisa mostrou que parte dos alunos utilizam os conhecimentos adquiridos no curso, seja assumindo cargos na área de tecnologia da informação, seja em outros cursos de graduação similares. esses resultados, de certa forma, desmistificam a ideia de que os recursos alocados para alunos que evadem de um curso de graduação em ciência da computação são integralmente perdidos."
107,2021,Análise comparativa entre ferramentas de CRM.,"MATOS, André Rosa.","MOURA, José Antão Beltrão.","Customer Relationship Management (CRM), que em português significa “gestão de relacionamento com o cliente”, é uma estratégia de gestão de relacionamento voltada ao entendimento e antecipação das suas necessidades. Seu principal objetivo é atrair e fidelizar clientes. A falta de uma boa comparação entre plataformas de CRM pode levar a uma má escolha de plataforma. O uso de uma plataforma inadequada trará custos e prejuízos para as empresas, pois em vez de ajudar com a relação com o cliente pode causar estresse para o mesmo e uma má reputação para a empresa. Visando ajudar empresas a escolher qual ferramenta melhor se adequa ao seu negócio, este trabalho fará uma comparação entre as seguintes plataformas de CRM: Salesforce, RD Station e Agendor. Serão avaliadas a facilidade de uso, as funcionalidades disponíveis, a integração com outras ferramentas, o custo dos planos ofertados, interface e as limitações que cada plataforma poderá ter. A partir da análise e estruturação do uso de cada plataforma, é intuito deste projeto apresentar um comparativo entre elas através do relato da experiência do autor para que pessoas e empresas tenham um relato de uso real para avaliarem os pontos positivos e negativos de maneira mais prática.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37766,"customer relationship management (crm), que em português significa “gestão de relacionamento com o cliente”, é uma estratégia de gestão de relacionamento voltada ao entendimento e antecipação das suas necessidades. seu principal objetivo é atrair e fidelizar clientes. a falta de uma boa comparação entre plataformas de crm pode levar a uma má escolha de plataforma. o uso de uma plataforma inadequada trará custos e prejuízos para as empresas, pois em vez de ajudar com a relação com o cliente pode causar estresse para o mesmo e uma má reputação para a empresa. visando ajudar empresas a escolher qual ferramenta melhor se adequa ao seu negócio, este trabalho fará uma comparação entre as seguintes plataformas de crm: salesforce, rd station e agendor. serão avaliadas a facilidade de uso, as funcionalidades disponíveis, a integração com outras ferramentas, o custo dos planos ofertados, interface e as limitações que cada plataforma poderá ter. a partir da análise e estruturação do uso de cada plataforma, é intuito deste projeto apresentar um comparativo entre elas através do relato da experiência do autor para que pessoas e empresas tenham um relato de uso real para avaliarem os pontos positivos e negativos de maneira mais prática."
108,2023,Voice Pathology Detector: desenvolvimento de uma aplicação móvel para detecção de patologias de voz.,"AIRES, Mateus Cavalcante de Almeida Farias.","GOMES, Herman Martins.","Na última década, diversas pesquisas vêm sendo desenvolvidas com o objetivo de classificar e identificar patologias de voz. Nesse contexto, a existência de uma ferramenta, de amplo acesso a usuários, que provesse um pré-diagnóstico não invasivo para a detecção de doenças de voz seria de grande relevância no sentido de motivar usuários a buscarem assistência médica. Propõe-se, neste trabalho, o desenvolvimento de uma aplicação móvel que classifica, de forma binária, vozes saudáveis e não saudáveis. Para isso, são utilizadas técnicas de aprendizagem de máquina supervisionada, além de uma base de dados de vozes com quantidade suficiente de amostras para viabilizar o treinamento satisfatório e permitir a generalização da ferramenta para amostras não treinadas. Dessa forma, buscou-se desenvolver uma aplicação pontual, simples, de uso intuitivo e de alto impacto social, que encurtará a distância entre médicos e pessoas com alguma patologia de voz.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37765,"na última década, diversas pesquisas vêm sendo desenvolvidas com o objetivo de classificar e identificar patologias de voz. nesse contexto, a existência de uma ferramenta, de amplo acesso a usuários, que provesse um pré-diagnóstico não invasivo para a detecção de doenças de voz seria de grande relevância no sentido de motivar usuários a buscarem assistência médica. propõe-se, neste trabalho, o desenvolvimento de uma aplicação móvel que classifica, de forma binária, vozes saudáveis e não saudáveis. para isso, são utilizadas técnicas de aprendizagem de máquina supervisionada, além de uma base de dados de vozes com quantidade suficiente de amostras para viabilizar o treinamento satisfatório e permitir a generalização da ferramenta para amostras não treinadas. dessa forma, buscou-se desenvolver uma aplicação pontual, simples, de uso intuitivo e de alto impacto social, que encurtará a distância entre médicos e pessoas com alguma patologia de voz."
109,2022,Levantamento sobre o uso de modelos gráficos no processo do desenvolvimento de software.,"AGUIAR, Jonas Gomes.","MONTEIRO, João Arthur Brunet.","Os modelos gráficos das decisões arquitetônicas, de processo e de código na indústria do desenvolvimento de software se tornaram ferramentas relevantes ao longo do tempo. Ultimamente é sentida uma queda na utilização desses modelos tradicionais como UML ou Modelo C4. Neste artigo queremos entender como se dá a utilização de tais modelos gráficos, quem são as pessoas que realmente utilizam os modelos, a motivação por trás da utilização, além de mostrar os benefícios, desvantagem, e relevância. Iremos avaliar dados coletados com pessoas da comunidade do desenvolvimento de software para entender como se dá todo esse fenômeno envolto dos modelos gráficos. Espera-se que ao final deste artigo sejamos capazes de ter um pequeno panorama atual do uso desses modelos na indústria, e avaliar se realmente esses modelos tradicionais estão declinando.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37764,"os modelos gráficos das decisões arquitetônicas, de processo e de código na indústria do desenvolvimento de software se tornaram ferramentas relevantes ao longo do tempo. ultimamente é sentida uma queda na utilização desses modelos tradicionais como uml ou modelo c4. neste artigo queremos entender como se dá a utilização de tais modelos gráficos, quem são as pessoas que realmente utilizam os modelos, a motivação por trás da utilização, além de mostrar os benefícios, desvantagem, e relevância. iremos avaliar dados coletados com pessoas da comunidade do desenvolvimento de software para entender como se dá todo esse fenômeno envolto dos modelos gráficos. espera-se que ao final deste artigo sejamos capazes de ter um pequeno panorama atual do uso desses modelos na indústria, e avaliar se realmente esses modelos tradicionais estão declinando."
110,2023,Investigação do uso de padrões arquiteturais em projetos que utilizam React e Angular.,"SILVA, Lucas Abrantes Furtado.","BRUNET, João Arthur Monteiro.","No desenvolvimento de software, a forma como o frontend é desenvolvido tem passado por uma evolução significativa, impulsionada pela introdução de novos frameworks e pela padronização de componentes, visando aprimorar a manutenibilidade, escalabilidade e a experiência do usuário. Considerando esse cenário, existem diversas opções de estratégias, formas de implementação e outras características a serem consideradas. Portanto, adotar um padrão permite fácil adaptação e modificações no sistema, melhorando a comunicação e colaboração entre as equipes e reduzindo a probabilidade de falhas. No entanto, não há estudos conhecidos que identifiquem os padrões arquiteturais mais utilizados, a forma como são implementados pelos desenvolvedores, seus desafios, em quais tipos de projeto um determinado padrão se encaixa melhor e quais os custos para implementá-los. O propósito deste trabalho é investigar a aplicação de padrões arquiteturais no frontend de múltiplos projetos, a fim de caracterizar os padrões arquiteturais prevalentes, bem como identificar e caracterizar suas possíveis variações. O objetivo final é contribuir para a identificação e propagação dos padrões arquiteturais mais aplicados no desenvolvimento do frontend utilizando React e Angular como frameworks.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37752,"no desenvolvimento de software, a forma como o frontend é desenvolvido tem passado por uma evolução significativa, impulsionada pela introdução de novos frameworks e pela padronização de componentes, visando aprimorar a manutenibilidade, escalabilidade e a experiência do usuário. considerando esse cenário, existem diversas opções de estratégias, formas de implementação e outras características a serem consideradas. portanto, adotar um padrão permite fácil adaptação e modificações no sistema, melhorando a comunicação e colaboração entre as equipes e reduzindo a probabilidade de falhas. no entanto, não há estudos conhecidos que identifiquem os padrões arquiteturais mais utilizados, a forma como são implementados pelos desenvolvedores, seus desafios, em quais tipos de projeto um determinado padrão se encaixa melhor e quais os custos para implementá-los. o propósito deste trabalho é investigar a aplicação de padrões arquiteturais no frontend de múltiplos projetos, a fim de caracterizar os padrões arquiteturais prevalentes, bem como identificar e caracterizar suas possíveis variações. o objetivo final é contribuir para a identificação e propagação dos padrões arquiteturais mais aplicados no desenvolvimento do frontend utilizando react e angular como frameworks."
111,2023,UFCG acessível: extensão para o Sistema Web do Controle Acadêmico da Universidade Federal de Campina Grande voltada a estudantes com deficiências visuais.,"ROMÃO, João Vitor Patricio.","FECHINE, Joseana Macêdo.","O sistema web do controle acadêmico da Universidade Federal de Campina Grande (UFCG) se faz presente no dia a dia de todos os alunos da instituição, pois nele são centralizadas todas as informações necessárias para que o aluno consiga acompanhar seu desenvolvimento acadêmico na graduação. O fluxo de uso do “Controle Acadêmico Online” se faz, normalmente, de maneira adequada para a maioria dos estudantes. Entretanto, quando se trata de estudantes com deficiências visuais este fluxo de uso apresenta falhas na sua interface assistiva. Com o objetivo de minimizar esse problema, propõe-se o desenvolvimento de uma extensão de navegador que torne a interface do controle acadêmico mais acessível para estudantes cegos ou com baixa visão. Essa extensão foi projetada para facilitar o uso diário do sistema, oferecendo funcionalidades extras e adaptando a interface às necessidades desse público. Ao final do trabalho, a extensão foi capaz de tornar o controle acadêmico da UFCG mais simples e acessível a estudantes com deficiência visual.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37746,"o sistema web do controle acadêmico da universidade federal de campina grande (ufcg) se faz presente no dia a dia de todos os alunos da instituição, pois nele são centralizadas todas as informações necessárias para que o aluno consiga acompanhar seu desenvolvimento acadêmico na graduação. o fluxo de uso do “controle acadêmico online” se faz, normalmente, de maneira adequada para a maioria dos estudantes. entretanto, quando se trata de estudantes com deficiências visuais este fluxo de uso apresenta falhas na sua interface assistiva. com o objetivo de minimizar esse problema, propõe-se o desenvolvimento de uma extensão de navegador que torne a interface do controle acadêmico mais acessível para estudantes cegos ou com baixa visão. essa extensão foi projetada para facilitar o uso diário do sistema, oferecendo funcionalidades extras e adaptando a interface às necessidades desse público. ao final do trabalho, a extensão foi capaz de tornar o controle acadêmico da ufcg mais simples e acessível a estudantes com deficiência visual."
112,2023,Nível de acessibilidade dos sites da UFCG: recomendação de boas práticas e análise com o Google Lighthouse.,"AMORIN, Gabrielly Trajano.","FECHINE, Joseana Macêdo.","Existem diversas barreiras a serem encontradas e resolvidas em sites eletrônicos que atingem principalmente as pessoas com deficiência. Ao utilizar a Web e seus recursos, as pessoas com deficiência ou limitações deparam-se com obstáculos que dificultam e, muitas vezes, impossibilitam o acesso a páginas. O conceito de Acessibilidade Digital pressupõe que os sites e portais sejam projetados de modo que todas as pessoas possam perceber, entender e interagir de maneira efetiva nos sítios eletrônicos. O Governo Federal do Brasil tem investido em serviços e distribuição de informação pela internet e, atualmente, existe um número considerável de sites oficiais do Governo Federal com serviços e informações que podem ser extraídas através de ferramentas e documentos que auxiliam e orientam profissionais na construção, adequação, avaliação e correção de páginas, sites e serviços, garantindo assim o controle da navegação e o pleno acesso, independentemente das suas capacidades físico-motoras e perceptivas, culturais e sociais. Partindo dessa proposta, surgiu a necessidade de verificar a acessibilidade dos sites oficiais da Universidade Federal de Campina Grande. Para isso, será realizado um estudo sobre os conceitos de acessibilidade, para que possa ser fornecido sugestões de boas práticas na inclusão de ferramentas de acessibilidade, assim como recomendações para que esses sites se tornem acessíveis. As análises serão feitas a partir do levantamento de uma ferramentas existente para medição de acessibilidade, o Google Lighthouse - ferramenta automatizada de código aberto para medir a qualidade das páginas da web, que audita o desempenho, a acessibilidade e a otimização do mecanismo de pesquisa de páginas da web.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37742,"existem diversas barreiras a serem encontradas e resolvidas em sites eletrônicos que atingem principalmente as pessoas com deficiência. ao utilizar a web e seus recursos, as pessoas com deficiência ou limitações deparam-se com obstáculos que dificultam e, muitas vezes, impossibilitam o acesso a páginas. o conceito de acessibilidade digital pressupõe que os sites e portais sejam projetados de modo que todas as pessoas possam perceber, entender e interagir de maneira efetiva nos sítios eletrônicos. o governo federal do brasil tem investido em serviços e distribuição de informação pela internet e, atualmente, existe um número considerável de sites oficiais do governo federal com serviços e informações que podem ser extraídas através de ferramentas e documentos que auxiliam e orientam profissionais na construção, adequação, avaliação e correção de páginas, sites e serviços, garantindo assim o controle da navegação e o pleno acesso, independentemente das suas capacidades físico-motoras e perceptivas, culturais e sociais. partindo dessa proposta, surgiu a necessidade de verificar a acessibilidade dos sites oficiais da universidade federal de campina grande. para isso, será realizado um estudo sobre os conceitos de acessibilidade, para que possa ser fornecido sugestões de boas práticas na inclusão de ferramentas de acessibilidade, assim como recomendações para que esses sites se tornem acessíveis. as análises serão feitas a partir do levantamento de uma ferramentas existente para medição de acessibilidade, o google lighthouse - ferramenta automatizada de código aberto para medir a qualidade das páginas da web, que audita o desempenho, a acessibilidade e a otimização do mecanismo de pesquisa de páginas da web."
113,2022,Predição do preço do leite utilizando dados de cooperativas.,"BEZERRA NETO, José Augusto.","PEREIRA, Eanes Torres.","Na atualidade, o volume de dados gerados vem aumentando cada vez mais, tornando possível a utilização de técnicas que detectam padrões, gerando informação relevante para aquele que necessita. Uma dessas técnicas é a aprendizagem supervisionada, que é uma das técnicas de aprendizado de máquina que lida com o reconhecimento de padrões. Essa técnica explora a construção de algoritmos, capazes de aprender e realizar predições a partir de um conjunto de dados. Assim, um modelo treinado com dados de leite seria capaz de sugerir preços a serem pagos ao produtor de leite. Geralmente, o produtor não sabe ao certo o quanto receberá por litro de leite produzido, pois, a entrega do leite é feita durante um mês e ele só saberá do valor ao certo no próximo mês, ocasionando uma incerteza. Para amenizar esse problema, este trabalho treinou um modelo de regressão capaz de predizer o preço do leite, obtendo métricas R² = 0,98 e RMSE = 0,014.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37739,"na atualidade, o volume de dados gerados vem aumentando cada vez mais, tornando possível a utilização de técnicas que detectam padrões, gerando informação relevante para aquele que necessita. uma dessas técnicas é a aprendizagem supervisionada, que é uma das técnicas de aprendizado de máquina que lida com o reconhecimento de padrões. essa técnica explora a construção de algoritmos, capazes de aprender e realizar predições a partir de um conjunto de dados. assim, um modelo treinado com dados de leite seria capaz de sugerir preços a serem pagos ao produtor de leite. geralmente, o produtor não sabe ao certo o quanto receberá por litro de leite produzido, pois, a entrega do leite é feita durante um mês e ele só saberá do valor ao certo no próximo mês, ocasionando uma incerteza. para amenizar esse problema, este trabalho treinou um modelo de regressão capaz de predizer o preço do leite, obtendo métricas r² = , e rmse = , ."
114,2022,Uso de execução de código para detectar problemas de design em atividades de Programação OO.,"SOARES, João Henrique dos Santos.","RÊGO, Matheus Gaudencio do.","Na Universidade Federal de Campina Grande, a disciplina Laboratório de Programação 2 é usada para os alunos aprenderem a programar e entenderem sobre a estruturação do código. As avaliações práticas são aplicadas através de laboratórios, onde a correção é feita por testes e uma análise manual da estrutura do código. Neste processo, o feedback é essencial para a formação do aluno, porém, o excesso de laboratórios impossibilita um feedback rápido. Testes automáticos e análise automática de métricas de código são alternativas para a geração rápida de informação útil para o aluno, entretanto muitas das ferramentas existentes são limitadas na sua capacidade de avaliar uma estrutura de código. Com a execução da ferramenta TraceAgent, uma análise será feita para conseguir identificar problemas relacionados ao design de código. Neste contexto, desejamos observar se métricas extraídas da execução de códigocomo X, Y, Z podem ser informações úteis para avaliação rápida do aluno.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37738,"na universidade federal de campina grande, a disciplina laboratório de programação é usada para os alunos aprenderem a programar e entenderem sobre a estruturação do código. as avaliações práticas são aplicadas através de laboratórios, onde a correção é feita por testes e uma análise manual da estrutura do código. neste processo, o feedback é essencial para a formação do aluno, porém, o excesso de laboratórios impossibilita um feedback rápido. testes automáticos e análise automática de métricas de código são alternativas para a geração rápida de informação útil para o aluno, entretanto muitas das ferramentas existentes são limitadas na sua capacidade de avaliar uma estrutura de código. com a execução da ferramenta traceagent, uma análise será feita para conseguir identificar problemas relacionados ao design de código. neste contexto, desejamos observar se métricas extraídas da execução de códigocomo x, y, z podem ser informações úteis para avaliação rápida do aluno."
115,2022,Mutualistically integrating service mesh with external confidential applications.,"SANTOS, José Amândio Ferreira dos.","BRITO, Andrey Elisio Monteiro.","As malhas de serviço se tornaram populares, pois ajudam a monitorar e gerenciar aplicações baseadas em microserviços: armazenando e processando aplicações que frequentemente incluem conteúdo sensível em seus dados, e permitindo a adição transparente de funcionalidades através de um proxy, sem incluí-las no próprio código. Em paralelo, houve um crescimento na demanda por aplicações sensíveis que isolam dados sensíveis em um enclave de CPU protegido durante o processamento. O uso de aplicações confidenciais em malhas de serviço é uma união incompatível em seu estado atual. Um simples proxy acaba expondo dados que, até então, eram protegidos pela aplicação confidencial. Embora as malhas de serviços atuais não suportem bem, as malhas de serviços e as aplicações confidenciais podem ser combinadas de fato. Testamos vários proxy’s que poderiam atender a esta demanda e avaliamos duas opções que podem ajudar a atingir este objetivo: um GHOSTUNNEL confidencial e o SCONE Network Shield.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37737,"as malhas de serviço se tornaram populares, pois ajudam a monitorar e gerenciar aplicações baseadas em microserviços: armazenando e processando aplicações que frequentemente incluem conteúdo sensível em seus dados, e permitindo a adição transparente de funcionalidades através de um proxy, sem incluí-las no próprio código. em paralelo, houve um crescimento na demanda por aplicações sensíveis que isolam dados sensíveis em um enclave de cpu protegido durante o processamento. o uso de aplicações confidenciais em malhas de serviço é uma união incompatível em seu estado atual. um simples proxy acaba expondo dados que, até então, eram protegidos pela aplicação confidencial. embora as malhas de serviços atuais não suportem bem, as malhas de serviços e as aplicações confidenciais podem ser combinadas de fato. testamos vários proxy’s que poderiam atender a esta demanda e avaliamos duas opções que podem ajudar a atingir este objetivo: um ghostunnel confidencial e o scone network shield."
116,2022,Aplicação de L-Diversidade na anonimização de dados públicos da campanha de vacinação contra COVID-19.,"VIDAL, Anderson Fellipe de Vasconcelos.","PIRES, Carlos Eduardo Santos.","A divulgação de dados é um processo que ocorre com o objetivo de trazer mais transparência e possibilitar análises de dados em geral. Visando garantir a privacidade dos dados, muitas divulgações são feitas anonimizando os registros (de banco de dados) a partir da remoção de informações que identifiquem os indivíduos envolvidos, como é o caso das divulgações dos dados públicos de vacinação contra a COVID-19. Porém, existem ataques que podem ser facilmente realizados em dados anonimizados apenas associando registros, através de atributos comuns com outras divulgações de dados com identificadores que não possuem informações sensíveis. Em razão disso, diversas técnicas de anonimização foram desenvolvidos como, por exemplo, a L-Diversidade. Este artigo tem como objetivo evidenciar o ganho de privacidade aplicando essa técnica sobre os dados de vacinação, em que foram realizados ataques de associação utilizando o perfil de beneficiários do PROUNI e dados públicos de agendamentos divulgados pela prefeitura municipal de Fortaleza. Como resultado, foi possível observar um aumento substancial na proteção de informações sensíveis.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37723,"a divulgação de dados é um processo que ocorre com o objetivo de trazer mais transparência e possibilitar análises de dados em geral. visando garantir a privacidade dos dados, muitas divulgações são feitas anonimizando os registros (de banco de dados) a partir da remoção de informações que identifiquem os indivíduos envolvidos, como é o caso das divulgações dos dados públicos de vacinação contra a covid- . porém, existem ataques que podem ser facilmente realizados em dados anonimizados apenas associando registros, através de atributos comuns com outras divulgações de dados com identificadores que não possuem informações sensíveis. em razão disso, diversas técnicas de anonimização foram desenvolvidos como, por exemplo, a l-diversidade. este artigo tem como objetivo evidenciar o ganho de privacidade aplicando essa técnica sobre os dados de vacinação, em que foram realizados ataques de associação utilizando o perfil de beneficiários do prouni e dados públicos de agendamentos divulgados pela prefeitura municipal de fortaleza. como resultado, foi possível observar um aumento substancial na proteção de informações sensíveis."
117,2022,Investigando abordagens para melhorias nas Escrita de relatórios de bugs.,"MEDEIROS, Áxel Crispim e.","RAMALHO, Franklin de Souza.","No desenvolvimento de software, os relatórios de bugs variam em qualidade, completude e precisão nas suas descri-ções. Normalmente, os relatos mal redigidos são elaborados por usuários sem qualquer instrução técnica, o que requer mais tempo para compressão do bug, por meio de discussões entre os desenvolvedores e relatores. Entretanto, apesar de existirem plataformas com ferramentas para auxiliar a publicação dos relatórios, como o Bugzilla, ainda é frequente a necessidade de discussões, o que faz necessário mais estudos para entender a raiz deste problema. Portanto, este trabalho propõe uma investigação nos campos de descrição e nas interações dos usuários em relatórios de bugs, feitos na plataforma Bugzilla, com objetivo de identificar padrões nos posts que influenciam no período de tempo para solução ou descarte destes. Nesse contexto, a pesquisa será conduzida por estudo quantitativo com Machine Learning (ML) que busca relacionar o tempo de resolução, abertura até o fechamento, com uma estruturação dos campos pertencentes aos relatórios, como: descrições, comentários, prioridade, se foi confirmado ou não, número de comentários, etc. Como resultado, encontrou o intervalo de 8 à 25 comentários como ideal para resolução dos relatórios e houve uma limitação com o trabalho com o processo de estruturação, assim, para os trabalhos futuros espera-se refazer o estudo usando uma abordagem qualitativa ou utilizar uma ferramenta externa para a estruturação.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37721,"no desenvolvimento de software, os relatórios de bugs variam em qualidade, completude e precisão nas suas descri-ções. normalmente, os relatos mal redigidos são elaborados por usuários sem qualquer instrução técnica, o que requer mais tempo para compressão do bug, por meio de discussões entre os desenvolvedores e relatores. entretanto, apesar de existirem plataformas com ferramentas para auxiliar a publicação dos relatórios, como o bugzilla, ainda é frequente a necessidade de discussões, o que faz necessário mais estudos para entender a raiz deste problema. portanto, este trabalho propõe uma investigação nos campos de descrição e nas interações dos usuários em relatórios de bugs, feitos na plataforma bugzilla, com objetivo de identificar padrões nos posts que influenciam no período de tempo para solução ou descarte destes. nesse contexto, a pesquisa será conduzida por estudo quantitativo com machine learning (ml) que busca relacionar o tempo de resolução, abertura até o fechamento, com uma estruturação dos campos pertencentes aos relatórios, como: descrições, comentários, prioridade, se foi confirmado ou não, número de comentários, etc. como resultado, encontrou o intervalo de à comentários como ideal para resolução dos relatórios e houve uma limitação com o trabalho com o processo de estruturação, assim, para os trabalhos futuros espera-se refazer o estudo usando uma abordagem qualitativa ou utilizar uma ferramenta externa para a estruturação."
118,2022,Avistamentos de UFOS e suas possíveis origens.,"SANTOS, Maria Cecília Kemiac.","MORAIS, Fábio Jorge Almeida.","Avistamentos de extraterrestres e UFOs sempre foi um assunto que causou bastante curiosidade e questionamento entre as pessoas. Muitos se perguntam se eles indicam indícios reais ou podem ser influenciados por alguns aspectos externos, como o clima, lançamentos de filmes sci-fi de sucesso ou de alguma forma relacionados com o tema, lan-çamentos de satélites, meteoros, entre outras coisas. O UFO Stalker [1] é um site que permite o cadastro de avista-mentos de extraterrestres e também a visualização dos locais com maiores ocorrências dos mesmos. Através da análise dos dados fornecidos por esse site, este projeto visa fazer um estudo das principais ocorrências dos avistamentos e obter algumas informações sobre eles, a exemplo de localização, horários, formas avistadas, etc. e fazer uma comparação com os dados externos, informações de temperatura e clima e datas de lançamentos de filmes sci-fi de grande sucesso, para analisar se eles possuem alguma influência ou não sobre os avistamentos.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37720,"avistamentos de extraterrestres e ufos sempre foi um assunto que causou bastante curiosidade e questionamento entre as pessoas. muitos se perguntam se eles indicam indícios reais ou podem ser influenciados por alguns aspectos externos, como o clima, lançamentos de filmes sci-fi de sucesso ou de alguma forma relacionados com o tema, lan-çamentos de satélites, meteoros, entre outras coisas. o ufo stalker [ ] é um site que permite o cadastro de avista-mentos de extraterrestres e também a visualização dos locais com maiores ocorrências dos mesmos. através da análise dos dados fornecidos por esse site, este projeto visa fazer um estudo das principais ocorrências dos avistamentos e obter algumas informações sobre eles, a exemplo de localização, horários, formas avistadas, etc. e fazer uma comparação com os dados externos, informações de temperatura e clima e datas de lançamentos de filmes sci-fi de grande sucesso, para analisar se eles possuem alguma influência ou não sobre os avistamentos."
119,2021,Avaliação da técnica do Prebaking para redução do cold start em serviços FaaS para a runtime de Python.,"LEITÃO, Paulo José Bastos.","SILVA, Thiago Emmanuel Pereira da Cunha.","Plataformas serverless são um modelo de negócio bastante atrativo por abstrair do desenvolvedor a infraestrutura do servidor e permití-lo focar na lógica da sua aplicação. Adotamos aqui o FaaS (funções como serviço), que é uma modalidade de plataformas serverless em que o cliente implementa funções que são executadas na nuvem de forma stateless. Porém, devido ao modelo de cobrança dessas plataformas, em que se paga apenas pelo tempo em que a função de fato está sendo executada, não é vantajoso para o provedor que funções permaneçam ociosas ocupando os recursos da nuvem. Esse modelo traz consigo o problema do cold start: muitas vezes, o tempo de instanciação de uma função pode ser muito lento, o que acaba por afastar os clientes do FaaS. Previamente, a técnica do Prebaking, baseada em criar snapshots de funções em execução e restaurá-los posteriormente, de forma a reduzir o cold start, mostrou-se bastante eficaz para a runtime de Java. Neste trabalho, verificamos que para a runtime de Python a melhora também é significativa: conseguimos reduzir o tempo de instanciação de uma função em até 1000%.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/37719,"plataformas serverless são um modelo de negócio bastante atrativo por abstrair do desenvolvedor a infraestrutura do servidor e permití-lo focar na lógica da sua aplicação. adotamos aqui o faas (funções como serviço), que é uma modalidade de plataformas serverless em que o cliente implementa funções que são executadas na nuvem de forma stateless. porém, devido ao modelo de cobrança dessas plataformas, em que se paga apenas pelo tempo em que a função de fato está sendo executada, não é vantajoso para o provedor que funções permaneçam ociosas ocupando os recursos da nuvem. esse modelo traz consigo o problema do cold start: muitas vezes, o tempo de instanciação de uma função pode ser muito lento, o que acaba por afastar os clientes do faas. previamente, a técnica do prebaking, baseada em criar snapshots de funções em execução e restaurá-los posteriormente, de forma a reduzir o cold start, mostrou-se bastante eficaz para a runtime de java. neste trabalho, verificamos que para a runtime de python a melhora também é significativa: conseguimos reduzir o tempo de instanciação de uma função em até %."
120,2023,HelpPet: aplicativo de primeiros socorros para animais de estimação.,"BARROS, Willy Guimarães Morais.","ANDRADE, Wilkerson de Lucena.","Segundo o IBGE, o Brasil detém a terceira maior população de animais de estimação do mundo. Assim como os humanos, os pets estão sujeitos a acidentes domésticos, que sem o devido cuidado podem ser fatais. Com isso, o conhecimento de primeiros socorros para estes animais é um fator decisivo na manutenção da vida em casos de risco à saúde. Com o propósito de resolver esse problema, foi desenvolvido o Helppet: um aplicativo voltado a primeiros socorros para pets, com objetivo de auxiliar a população em situações de emergência.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/36832,"segundo o ibge, o brasil detém a terceira maior população de animais de estimação do mundo. assim como os humanos, os pets estão sujeitos a acidentes domésticos, que sem o devido cuidado podem ser fatais. com isso, o conhecimento de primeiros socorros para estes animais é um fator decisivo na manutenção da vida em casos de risco à saúde. com o propósito de resolver esse problema, foi desenvolvido o helppet: um aplicativo voltado a primeiros socorros para pets, com objetivo de auxiliar a população em situações de emergência."
121,2023,Efeito do estresse no desempenho acadêmico de concluintes em Ciência da Computação @ UFCG.,"CACHO, Wellisson Gomes Pereira Bezerra.","MASSONI, Tiago Lima.","O estresse é uma resposta normal do corpo a situações desafiadoras ou exigentes, mas quando os níveis de estresse são muito altos ou duram por um longo período, podem levar a problemas de saúde mental, como ansiedade e depressão. Estudos mostram que estudantes universitários experimentam altos níveis de estresse relacionados a pressão acadêmica e mudanças na vida social e financeira, entre outros fatores. Neste trabalho, conduzimos uma pesquisa com os concluintes do curso de Ciência da Computação na Universidade Federal de Campina Grande (UFCG) durante o semestre 2022.2. A pesquisa buscou entender a relação entre fatores de estresse (saúde, social e acadêmico), o nível de estresse percebido em diferentes momentos do semestre (início, meio e fim) e seu impacto no desempenho acadêmico. Os resultados mostram que os estudantes apresentam altos níveis de estresse ao longo de todo o semestre, e o principal fator de estresse que afeta o desempenho acadêmico é a pressão da família para conseguir um bom emprego. Além disso, uma correlação negativa significativa foi identificada entre o estresse percebido no final do semestre e o desempenho acadêmico. Contudo, o estresse no início e meio do período não mostrou relação estatisticamente significativa com o desempenho dos alunos.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/36831,"o estresse é uma resposta normal do corpo a situações desafiadoras ou exigentes, mas quando os níveis de estresse são muito altos ou duram por um longo período, podem levar a problemas de saúde mental, como ansiedade e depressão. estudos mostram que estudantes universitários experimentam altos níveis de estresse relacionados a pressão acadêmica e mudanças na vida social e financeira, entre outros fatores. neste trabalho, conduzimos uma pesquisa com os concluintes do curso de ciência da computação na universidade federal de campina grande (ufcg) durante o semestre . . a pesquisa buscou entender a relação entre fatores de estresse (saúde, social e acadêmico), o nível de estresse percebido em diferentes momentos do semestre (início, meio e fim) e seu impacto no desempenho acadêmico. os resultados mostram que os estudantes apresentam altos níveis de estresse ao longo de todo o semestre, e o principal fator de estresse que afeta o desempenho acadêmico é a pressão da família para conseguir um bom emprego. além disso, uma correlação negativa significativa foi identificada entre o estresse percebido no final do semestre e o desempenho acadêmico. contudo, o estresse no início e meio do período não mostrou relação estatisticamente significativa com o desempenho dos alunos."
122,2023,PetCare: uma plataforma para o acompanhamento médico de animais domésticos.,"NUNES, Sammara Beserra.","BRUNET, João Arthur Monteiro.","Com o aumento de animais domésticos nos lares e ONGs de proteção aos animais, sobretudo durante a pandemia, também aumentou a busca por médicos veterinários e, consequentemente, exames clínicos para o cuidado deles. Porém, tais resultados laboratoriais são mantidos pelas clínicas e/ou profissionais que os realizam, causando enorme problema quando o tutor ou profissionais veterinários precisam do histórico médico do pet, embora devessem ser realizados orientados ao paciente, ou seja, o animal. Neste trabalho, buscamos desenvolver uma aplicação mobile que permite unificar o lugar em que estes dados são armazenados e facilitar a busca e a consulta de dados médicos de um pet. Nesse projeto foi produzido como resultado uma aplicação com NodeJS para Backend e React Native para Frontend, além de diagramas detalhados que foram usados para a construção da aplicação. Ao final do desenvolvimento foi realizada uma avaliação com 10 voluntários acerca da utilidade de suas funcionalidades, onde obteve-se resultados positivos da experiência do usuário, destacando-se a facilidade de uso do sistema e utilidade das funcionalidades implementadas. Também foi obtido feedback a respeito de melhorias no sistema que foram sugeridas ao final da avaliação, como refatorar as funcionalidades de registro de exame e cirurgias para facilitar seu uso e novas funcionalidades para o sistema.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/36830,"com o aumento de animais domésticos nos lares e ongs de proteção aos animais, sobretudo durante a pandemia, também aumentou a busca por médicos veterinários e, consequentemente, exames clínicos para o cuidado deles. porém, tais resultados laboratoriais são mantidos pelas clínicas e/ou profissionais que os realizam, causando enorme problema quando o tutor ou profissionais veterinários precisam do histórico médico do pet, embora devessem ser realizados orientados ao paciente, ou seja, o animal. neste trabalho, buscamos desenvolver uma aplicação mobile que permite unificar o lugar em que estes dados são armazenados e facilitar a busca e a consulta de dados médicos de um pet. nesse projeto foi produzido como resultado uma aplicação com nodejs para backend e react native para frontend, além de diagramas detalhados que foram usados para a construção da aplicação. ao final do desenvolvimento foi realizada uma avaliação com voluntários acerca da utilidade de suas funcionalidades, onde obteve-se resultados positivos da experiência do usuário, destacando-se a facilidade de uso do sistema e utilidade das funcionalidades implementadas. também foi obtido feedback a respeito de melhorias no sistema que foram sugeridas ao final da avaliação, como refatorar as funcionalidades de registro de exame e cirurgias para facilitar seu uso e novas funcionalidades para o sistema."
123,2023,Avaliação comparativa em termos de memória e tempo de execução do algoritmo WFC aplicado à geração de mapas de jogos.,"MEIRA, Rodrigo Torres.","GOMES, Herman Martins.","O algoritmo Wave Function Collapse (WFC) desempenha um papel de destaque na indústria de jogos, sendo comumente utilizado para a geração automática de texturas e mapas. Tal utilização faz parte da área de geração procedural de conteúdo (Procedural Content Generation - PCG), a qual tem como motivações aprimorar a rejogabilidade e aliviar a carga de trabalho dos desenvolvedores na criação manual de conteúdo. O uso de PCG tem experimentado um notável aumento nos últimos anos, impulsionado pelo constante crescimento no tamanho e na complexidade dos jogos produzidos. Embora diversas técnicas de PCG já tenham sido amplamente documentadas e testadas, o WFC é uma abordagem relativamente recente que carece de avaliações abrangentes quanto à sua eficácia em comparação com outras técnicas. Este trabalho de conclusão de curso tem como objetivo preencher essa lacuna, realizando uma análise da complexidade do algoritmo WFC em termos de tempo e recursos de hardware, comparando-o com alternativas no contexto da geração de mapas de jogos. Foram executados algoritmos de PCG em mapas de diversos tamanhos, variando de 100px a 1000px. Durante as execuções, foram registrados os dados de consumo de memória e tempo de execução. Os resultados demonstraram que, entre os algoritmos avaliados, o WFC se destaca no quesito consumo de memória, superando os demais algoritmos nesse aspecto. Já o Binary Space Partitioning Room Placement (BSPRP) demonstrou ser o mais eficiente em termos de tempo, superando significativamente o desempenho do WFC. Por fim, o Random Room Placement (RRP) se mostrou o menos eficiente, tanto em consumo de memória quanto em tempo de execução.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/36829,"o algoritmo wave function collapse (wfc) desempenha um papel de destaque na indústria de jogos, sendo comumente utilizado para a geração automática de texturas e mapas. tal utilização faz parte da área de geração procedural de conteúdo (procedural content generation - pcg), a qual tem como motivações aprimorar a rejogabilidade e aliviar a carga de trabalho dos desenvolvedores na criação manual de conteúdo. o uso de pcg tem experimentado um notável aumento nos últimos anos, impulsionado pelo constante crescimento no tamanho e na complexidade dos jogos produzidos. embora diversas técnicas de pcg já tenham sido amplamente documentadas e testadas, o wfc é uma abordagem relativamente recente que carece de avaliações abrangentes quanto à sua eficácia em comparação com outras técnicas. este trabalho de conclusão de curso tem como objetivo preencher essa lacuna, realizando uma análise da complexidade do algoritmo wfc em termos de tempo e recursos de hardware, comparando-o com alternativas no contexto da geração de mapas de jogos. foram executados algoritmos de pcg em mapas de diversos tamanhos, variando de 100px a 1000px. durante as execuções, foram registrados os dados de consumo de memória e tempo de execução. os resultados demonstraram que, entre os algoritmos avaliados, o wfc se destaca no quesito consumo de memória, superando os demais algoritmos nesse aspecto. já o binary space partitioning room placement (bsprp) demonstrou ser o mais eficiente em termos de tempo, superando significativamente o desempenho do wfc. por fim, o random room placement (rrp) se mostrou o menos eficiente, tanto em consumo de memória quanto em tempo de execução."
124,2023,EurecaDash: um dashboard completo para gestão e acompanhamento de matrículas acadêmicas.,"ARAÚJO, Renan Carneiro Barbosa de.","BRASILEIRO, Francisco Vilar.","Ao longo de todo o regime acadêmico é necessário que os discentes façam diversas matrículas, a fim de efetuar a inscrição em disciplinas do período acadêmico vigente. Nesse contexto, principalmente com o grande volume de matrículas realizadas, se faz necessário o melhoramento da organização, do gerenciamento, do controle e do acompanhamento das matrículas acadêmicas. Atualmente, mesmo diante de uma crescente modernização sistemática, o sistema de matrículas universitárias da Universidade Federal de Campina Grande é muito dependente do coordenador acadêmico, que deve manualmente: inscrever turmas, modificar quantidades de vagas e efetuar todo o planejamento de turmas manualmente. Além disso, o sistema não avisa aos estudantes sobre turmas ideais para suas matrículas e nem sobre o horário inicial da abertura do período de inscrição das disciplinas. Nesse viés, o Eureca Dashboard, surge como uma ferramenta facilitadora, na qual o coordenador acadêmico pode visualizar a oferta de vagas ideal para as disciplinas, modificar a disponibilização das disciplinas e acompanhar a inscrição dos discentes, tudo isso de forma unificada e centralizada, com um acesso facilitado e seguro. Com isso, o trabalho desses gerenciadores será facilitado, e através de uma entrevista, com um usuário alvo, será possível medir o real impacto da plataforma e se ela foi fundamental no gerenciamento de tempo desses profissionais.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/36828,"ao longo de todo o regime acadêmico é necessário que os discentes façam diversas matrículas, a fim de efetuar a inscrição em disciplinas do período acadêmico vigente. nesse contexto, principalmente com o grande volume de matrículas realizadas, se faz necessário o melhoramento da organização, do gerenciamento, do controle e do acompanhamento das matrículas acadêmicas. atualmente, mesmo diante de uma crescente modernização sistemática, o sistema de matrículas universitárias da universidade federal de campina grande é muito dependente do coordenador acadêmico, que deve manualmente: inscrever turmas, modificar quantidades de vagas e efetuar todo o planejamento de turmas manualmente. além disso, o sistema não avisa aos estudantes sobre turmas ideais para suas matrículas e nem sobre o horário inicial da abertura do período de inscrição das disciplinas. nesse viés, o eureca dashboard, surge como uma ferramenta facilitadora, na qual o coordenador acadêmico pode visualizar a oferta de vagas ideal para as disciplinas, modificar a disponibilização das disciplinas e acompanhar a inscrição dos discentes, tudo isso de forma unificada e centralizada, com um acesso facilitado e seguro. com isso, o trabalho desses gerenciadores será facilitado, e através de uma entrevista, com um usuário alvo, será possível medir o real impacto da plataforma e se ela foi fundamental no gerenciamento de tempo desses profissionais."
125,2023,ExpoMap: uma aplicação de divulgação de eventos agropecuários na Região Nordeste.,"SILVA, Matheus Eduardo Rodrigues da.","PIRES, Carlos Eduardo Santos.","O turismo é uma atividade de extrema importância para a movimentação econômica, divulgação cultural e de desenvolvimento. Portanto, impulsionar essa atividade pode trazer inúmeros benefícios para a sociedade. Paralelamente, a agropecuária é uma atividade que possui uma grande participação no PIB brasileiro. No entanto, percebe-se que a divulgação dos eventos agropecuários ainda está bastante interligada a meios de comunicação tradicionais, e há uma carência na utilização de meios mais atualizados como, por exemplo, redes sociais, websites e aplicativos. Este trabalho teve como objetivo a criação de um sistema de mapeamento unificado de eventos agropecuários, e de auxílio na interação entre expositores e administradores de eventos. Permitindo uma forma fácil e prática de acesso a informações detalhadas dos eventos agropecuários.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/36827,"o turismo é uma atividade de extrema importância para a movimentação econômica, divulgação cultural e de desenvolvimento. portanto, impulsionar essa atividade pode trazer inúmeros benefícios para a sociedade. paralelamente, a agropecuária é uma atividade que possui uma grande participação no pib brasileiro. no entanto, percebe-se que a divulgação dos eventos agropecuários ainda está bastante interligada a meios de comunicação tradicionais, e há uma carência na utilização de meios mais atualizados como, por exemplo, redes sociais, websites e aplicativos. este trabalho teve como objetivo a criação de um sistema de mapeamento unificado de eventos agropecuários, e de auxílio na interação entre expositores e administradores de eventos. permitindo uma forma fácil e prática de acesso a informações detalhadas dos eventos agropecuários."
126,2023,Análise de sentimentos e emoções de tweets sobre a guerra da Ucrânia.,"COIMBRA, Mariana Victória Souza.","CAMPELO, Claudio Elízio Calazans.","O presente artigo trata-se de uma análise de sentimentos e emoções expressos em Tweets relacionados à Guerra da Ucrânia, mediante análise dos tópicos discutidos pelos usuários da plataforma Twitter. Este estudo visa compreender como os usuários reagem ao evento em curso, quais aspectos da guerra as pessoas estão discutindo na plataforma, e como se sentem a respeito deste acontecimento. Além disso, visa identificar correlações entre as variáveis presentes nos Tweets, como localização, informações de perfil do usuário autor da postagem, e a natureza de suas opiniões. Tais análises foram conduzidas através de tarefas de processamento de linguagem natural como análises exploratórias dos dados e a aplicação de classificadores de sentimentos de Tweets utilizando modelos de dados pré-treinados. Os dados analisados contém Tweets coletados desde o início do conflito, que se deu em fevereiro de 2022 até outubro de 2023, e foram coletados a partir de hashtags relacionadas à Guerra. Para a realização das análises de sentimento e emoção foram utilizados a variante RoBERTa. Os Tweets foram classificados em sentimentos como positivos, negativos ou neutros, e em emoções como alegria, raiva, medo, nojo, otimismo, pessimismo, surpresa e amor. Os resultados mostraram que a maioria dos tweets em inglês expressam raiva e antecipação como emoções predominantes, e sentimentos negativos e neutros com maior predominância, atingindo mais de 50% do da amostragem analisada. Algumas das frases mais recorrentes na análise fazem alusão ao apoio à Ucrânia e pedindo o fim da guerra. Da mesma forma, frases de preocupação com a crise, armas e fatalidades são recorrentes. Na maioria das postagens, pessoas demonstram preocupação com o conflito armado e apoio à Ucrânia. Trabalhos futuros poderiam utilizar mais tweets para abranger a análise e visualizar a correlação de mais atributos relacionados às postagens como os engajamentos e curtidas.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/36826,"o presente artigo trata-se de uma análise de sentimentos e emoções expressos em tweets relacionados à guerra da ucrânia, mediante análise dos tópicos discutidos pelos usuários da plataforma twitter. este estudo visa compreender como os usuários reagem ao evento em curso, quais aspectos da guerra as pessoas estão discutindo na plataforma, e como se sentem a respeito deste acontecimento. além disso, visa identificar correlações entre as variáveis presentes nos tweets, como localização, informações de perfil do usuário autor da postagem, e a natureza de suas opiniões. tais análises foram conduzidas através de tarefas de processamento de linguagem natural como análises exploratórias dos dados e a aplicação de classificadores de sentimentos de tweets utilizando modelos de dados pré-treinados. os dados analisados contém tweets coletados desde o início do conflito, que se deu em fevereiro de até outubro de , e foram coletados a partir de hashtags relacionadas à guerra. para a realização das análises de sentimento e emoção foram utilizados a variante roberta. os tweets foram classificados em sentimentos como positivos, negativos ou neutros, e em emoções como alegria, raiva, medo, nojo, otimismo, pessimismo, surpresa e amor. os resultados mostraram que a maioria dos tweets em inglês expressam raiva e antecipação como emoções predominantes, e sentimentos negativos e neutros com maior predominância, atingindo mais de % do da amostragem analisada. algumas das frases mais recorrentes na análise fazem alusão ao apoio à ucrânia e pedindo o fim da guerra. da mesma forma, frases de preocupação com a crise, armas e fatalidades são recorrentes. na maioria das postagens, pessoas demonstram preocupação com o conflito armado e apoio à ucrânia. trabalhos futuros poderiam utilizar mais tweets para abranger a análise e visualizar a correlação de mais atributos relacionados às postagens como os engajamentos e curtidas."
127,2023,Vulnvisor: um plugin para geração de dashboards de vulnerabilidades para a ferramenta Trivy.,"FIGUEIREDO FILHO, Luciano Erick Sousa.","BRUNET, João Arthur Monteiro.","O crescente uso de componentes de terceiros em projetos de software impulsionou a eficiência do desenvolvimento, mas também introduziu preocupações significativas relacionadas à segurança. A falta de visibilidade e rastreabilidade efetiva das dependências utilizadas pode resultar em vulnerabilidades desconhecidas, destacando a necessidade de gerenciar e avaliar esses componentes. Em resposta a estes desafios, o Trivy, uma ferramenta open source de escaneamento de vulnerabilidades, tornou-se fundamental na identificação e mitigação de ameaças em componentes de software. No entanto, um dos principais obstáculos enfrentados pelos usuários é a complexidade na interpretação dos dados gerados pela ferramenta. Desta forma, este trabalho se propõe a desenvolver um plugin para o Trivy, com o objeto de aprimorar a experiência dos usuários através da geração de um dashboard interativo. Além disso, este documento busca avaliar a ferramenta desenvolvida através de feedbacks de potenciais usuários, medindo o grau de satisfação e eficácia para mitigação de vulnerabilidades.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/36821,"o crescente uso de componentes de terceiros em projetos de software impulsionou a eficiência do desenvolvimento, mas também introduziu preocupações significativas relacionadas à segurança. a falta de visibilidade e rastreabilidade efetiva das dependências utilizadas pode resultar em vulnerabilidades desconhecidas, destacando a necessidade de gerenciar e avaliar esses componentes. em resposta a estes desafios, o trivy, uma ferramenta open source de escaneamento de vulnerabilidades, tornou-se fundamental na identificação e mitigação de ameaças em componentes de software. no entanto, um dos principais obstáculos enfrentados pelos usuários é a complexidade na interpretação dos dados gerados pela ferramenta. desta forma, este trabalho se propõe a desenvolver um plugin para o trivy, com o objeto de aprimorar a experiência dos usuários através da geração de um dashboard interativo. além disso, este documento busca avaliar a ferramenta desenvolvida através de feedbacks de potenciais usuários, medindo o grau de satisfação e eficácia para mitigação de vulnerabilidades."
128,2023,Avaliação das percepções das equipes de desenvolvimento de software no Brasil sobre o retorno ao trabalho presencial no pós-pandemia do COVID-19.,"LIMA, Lucas Araújo de.","ALVES, Everton Leandro Galdino.","Com o fim da pandemia do COVID-19, muitas organizações estão considerando a possibilidade de retornar ao trabalho presencial. Nesse contexto, é importante avaliar as percepções das equipes de desenvolvimento de software no Brasil sobre esse retorno. Este estudo investigou como as equipes brasileiras de desenvolvimento de software lidaram com o retorno ao trabalho presencial/híbrido após a pandemia e como essa mudança de trabalho repercutiu no processo de desenvolvimento de software. Aplicamos uma pesquisa com 46 participantes de equipes de desenvolvimento de software e investigamos aspectos, como: rotina de trabalho, colaboração, comunicação, produtividade, bem-estar, auxílio oferecido pelas empresas e processo de desenvolvimento de software. Realizamos uma análise quantitativa e qualitativa dos resultados da pesquisa e os comparamos com estudos anteriores. Nossas principais conclusões sobre os participantes que retornaram ao trabalho presencial/híbrido são: (i) 85% dos participantes afirmaram que mantém uma rotina de trabalho estável relacionado ao horário padrão da empresa; (ii) 81,50% dos participantes consideram sua equipe colaborativa; (iii) 66,60% estão satisfeitos com a comunicação no regime de trabalho presencial/híbrido em comparação ao Work From Home (WFH) durante a pandemia de COVID-19; (iv) 67% estão satisfeitos com o seu bem-estar; (v) 67% estão satisfeitos com sua produtividade; (vi) 66,67% estão satisfeitos com as medidas de segurança adotadas pela empresa no pós pandemia e (vii) 70,37% afirmaram ter mudado no processo de desenvolvimento de software devido ao retorno ao trabalho presencial/híbrido. As principais mudanças positivas no processo estão relacionadas às práticas de: divisão de tarefas, segurança e eficiência.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/36820,"com o fim da pandemia do covid- , muitas organizações estão considerando a possibilidade de retornar ao trabalho presencial. nesse contexto, é importante avaliar as percepções das equipes de desenvolvimento de software no brasil sobre esse retorno. este estudo investigou como as equipes brasileiras de desenvolvimento de software lidaram com o retorno ao trabalho presencial/híbrido após a pandemia e como essa mudança de trabalho repercutiu no processo de desenvolvimento de software. aplicamos uma pesquisa com participantes de equipes de desenvolvimento de software e investigamos aspectos, como: rotina de trabalho, colaboração, comunicação, produtividade, bem-estar, auxílio oferecido pelas empresas e processo de desenvolvimento de software. realizamos uma análise quantitativa e qualitativa dos resultados da pesquisa e os comparamos com estudos anteriores. nossas principais conclusões sobre os participantes que retornaram ao trabalho presencial/híbrido são: (i) % dos participantes afirmaram que mantém uma rotina de trabalho estável relacionado ao horário padrão da empresa; (ii) , % dos participantes consideram sua equipe colaborativa; (iii) , % estão satisfeitos com a comunicação no regime de trabalho presencial/híbrido em comparação ao work from home (wfh) durante a pandemia de covid- ; (iv) % estão satisfeitos com o seu bem-estar; (v) % estão satisfeitos com sua produtividade; (vi) , % estão satisfeitos com as medidas de segurança adotadas pela empresa no pós pandemia e (vii) , % afirmaram ter mudado no processo de desenvolvimento de software devido ao retorno ao trabalho presencial/híbrido. as principais mudanças positivas no processo estão relacionadas às práticas de: divisão de tarefas, segurança e eficiência."
129,2023,Análise do impacto da pandemia no desempenho e nível de aprendizado dos alunos do Curso de Ciência da Computação da UFCG.,"VIGOLVINO, Lucas Alves.","GOMES, Herman Martins.","Durante o período da pandemia promovida pelo COVID-19, a Universidade Federal de Campina Grande (UFCG) realizou quatro períodos letivos de forma remota para continuar as atividades de ensino. Este trabalho analisa o impacto dessa modalidade de ensino e sua influência no desempenho e no nível de aprendizado dos alunos do curso de Ciência da Computação. A pesquisa utilizou dados anonimizados de registro de matrículas de 2013 a 2022, concentrando-se nas disciplinas obrigatórias do curso. Inicialmente, o estudo analisa a evolução das médias das notas dos alunos ao longo dos períodos acadêmicos, destacando um aumento nas médias durante os períodos remotos. Além disso, a análise mostra uma diminuição no número de reprovações durante a pandemia em comparação com os períodos presenciais. O estudo também investiga, no regime remoto, as relações entre as disciplinas e o aproveitamento do aprendizado dos alunos. Utilizando métodos estatísticos, foram identificadas as disciplinas mais afetadas pelo ensino remoto, tanto positivamente quanto negativamente. Disciplinas como Teoria da Computação e Estatística Aplicada mostraram uma queda no desempenho, enquanto Teoria dos Grafos apresentou uma melhoria. Em conclusão, o estudo aponta para um impacto negativo no desempenho dos alunos após o período de ensino remoto, sugerindo que fatores como eventuais irregularidades nas avaliações remotas podem ter contribuído para esse resultado.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/36819,"durante o período da pandemia promovida pelo covid- , a universidade federal de campina grande (ufcg) realizou quatro períodos letivos de forma remota para continuar as atividades de ensino. este trabalho analisa o impacto dessa modalidade de ensino e sua influência no desempenho e no nível de aprendizado dos alunos do curso de ciência da computação. a pesquisa utilizou dados anonimizados de registro de matrículas de a , concentrando-se nas disciplinas obrigatórias do curso. inicialmente, o estudo analisa a evolução das médias das notas dos alunos ao longo dos períodos acadêmicos, destacando um aumento nas médias durante os períodos remotos. além disso, a análise mostra uma diminuição no número de reprovações durante a pandemia em comparação com os períodos presenciais. o estudo também investiga, no regime remoto, as relações entre as disciplinas e o aproveitamento do aprendizado dos alunos. utilizando métodos estatísticos, foram identificadas as disciplinas mais afetadas pelo ensino remoto, tanto positivamente quanto negativamente. disciplinas como teoria da computação e estatística aplicada mostraram uma queda no desempenho, enquanto teoria dos grafos apresentou uma melhoria. em conclusão, o estudo aponta para um impacto negativo no desempenho dos alunos após o período de ensino remoto, sugerindo que fatores como eventuais irregularidades nas avaliações remotas podem ter contribuído para esse resultado."
130,2023,Tenho que concluir o curso: sistema de gestão de temas de TCC.,"PORFÍRIO, Leonardo Veiga de Medeiros.","MORAIS, Fábio Jorge Almeida.","O Trabalho de Conclusão de Curso (TCC) é um trabalho acadêmico de caráter obrigatório e atualmente instrumento de avaliação final do curso de Ciência da Computação na Universidade Federal de Campina Grande. A escolha do tema é algo que muitas vezes intimida o aluno, pois não sabe ao certo sobre o que vai fazer, o que gosta e qual professor irá aceitar ser orientador do mesmo. Não obstante os professores também podem propor algum tema e procurar alunos que se interessem em realizar esse trabalho. Dessa forma é importante que haja uma solução que facilite esse processo, tanto para o aluno quanto para o professor. Este trabalho tem como objetivo o desenvolvimento de uma aplicação web para expor temas ou ideias de TCC e conectar alunos e professores com interesses mútuos, visando melhorar a experiência do aluno na escolha do tema e do professor orientador. Os resultados obtidos demonstram que os usuários ficaram satisfeitos com a usabilidade do sistema, mas ainda há pontos de melhoria.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/36815,"o trabalho de conclusão de curso (tcc) é um trabalho acadêmico de caráter obrigatório e atualmente instrumento de avaliação final do curso de ciência da computação na universidade federal de campina grande. a escolha do tema é algo que muitas vezes intimida o aluno, pois não sabe ao certo sobre o que vai fazer, o que gosta e qual professor irá aceitar ser orientador do mesmo. não obstante os professores também podem propor algum tema e procurar alunos que se interessem em realizar esse trabalho. dessa forma é importante que haja uma solução que facilite esse processo, tanto para o aluno quanto para o professor. este trabalho tem como objetivo o desenvolvimento de uma aplicação web para expor temas ou ideias de tcc e conectar alunos e professores com interesses mútuos, visando melhorar a experiência do aluno na escolha do tema e do professor orientador. os resultados obtidos demonstram que os usuários ficaram satisfeitos com a usabilidade do sistema, mas ainda há pontos de melhoria."
131,2023,ViVagas UFCG: uma plataforma de gestão e centralização de projetos PD&I.,"SILVA, Leandra de Oliveira.","BRUNET, João Arthur Monteiro.","A Unidade Acadêmica de Sistemas e Computação (UASC) possui 11 (onze) laboratórios focados em diversas áreas da tecnologia e estes adotam processos seletivos para alocação de discentes em seus projetos. A maioria das ofertas de vagas feitas pelos docentes para esses projetos é realizada via e-mail acadêmico, onde estas podem passar despercebidas por diferentes motivos e, além disso, não estão centralizadas em uma plataforma que contenha todas as chamadas para projetos. Portanto, há uma lacuna a ser resolvida principalmente no que diz respeito à gestão destas seleções, tanto pelos professores, quanto pelos alunos. Este trabalho tem a proposta de desenvolver o ViVagas, uma plataforma que tem como objetivo principal facilitar a gestão de todo o processo seletivo mencionado anteriormente. O ViVagas oferece funcionalidades tanto para professores quanto para alunos. Professores publicam vagas, buscam e filtram alunos com base em seus perfis e conhecimentos, e realizam o processo seletivo de forma eficiente. Já os alunos têm acesso à visualização de vagas disponíveis, podem filtrá-las com base em critérios como área de atuação e candidatar-se nas vagas disponíveis. A avaliação da plataforma foi realizada utilizando o Think Aloud Protocol, que consiste em um teste de pensamento em voz alta no qual o usuário faz uso do
sistema. Além disso, testes foram realizados através da versão adaptada do questionário CSUQ com objetivo de recolher métricas de usabilidade de um dado sistema. Também foi utilizado a ferramenta Lighthouse que realiza auditorias automatizadas em páginas da web. Os resultados do Lighthouse indicaram áreas de otimização, mas destacaram a ótima acessibilidade, práticas de desenvolvimento e otimização. O CSUQ refletiu uma avaliação bastante positiva. Da mesma forma, o Think Aloud Protocol forneceu insights valiosos e clareza do fluxo de usabilidade. Em suma, a avaliação geral apontou para bons resultados e uma excelente usabilidade do ViVagas.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/36814,"a unidade acadêmica de sistemas e computação (uasc) possui (onze) laboratórios focados em diversas áreas da tecnologia e estes adotam processos seletivos para alocação de discentes em seus projetos. a maioria das ofertas de vagas feitas pelos docentes para esses projetos é realizada via e-mail acadêmico, onde estas podem passar despercebidas por diferentes motivos e, além disso, não estão centralizadas em uma plataforma que contenha todas as chamadas para projetos. portanto, há uma lacuna a ser resolvida principalmente no que diz respeito à gestão destas seleções, tanto pelos professores, quanto pelos alunos. este trabalho tem a proposta de desenvolver o vivagas, uma plataforma que tem como objetivo principal facilitar a gestão de todo o processo seletivo mencionado anteriormente. o vivagas oferece funcionalidades tanto para professores quanto para alunos. professores publicam vagas, buscam e filtram alunos com base em seus perfis e conhecimentos, e realizam o processo seletivo de forma eficiente. já os alunos têm acesso à visualização de vagas disponíveis, podem filtrá-las com base em critérios como área de atuação e candidatar-se nas vagas disponíveis. a avaliação da plataforma foi realizada utilizando o think aloud protocol, que consiste em um teste de pensamento em voz alta no qual o usuário faz uso do sistema. além disso, testes foram realizados através da versão adaptada do questionário csuq com objetivo de recolher métricas de usabilidade de um dado sistema. também foi utilizado a ferramenta lighthouse que realiza auditorias automatizadas em páginas da web. os resultados do lighthouse indicaram áreas de otimização, mas destacaram a ótima acessibilidade, práticas de desenvolvimento e otimização. o csuq refletiu uma avaliação bastante positiva. da mesma forma, o think aloud protocol forneceu insights valiosos e clareza do fluxo de usabilidade. em suma, a avaliação geral apontou para bons resultados e uma excelente usabilidade do vivagas."
132,2023,Um sistema para monitoramento da evolução de pacientes de clinicas de fisioterapia.,"ARRUDA, José Vinícius Lacerda de.","PIRES, Carlos Eduardo Santos.","À medida que a inovação tecnológica se consolidou como uma força dominante na área de Saúde, por exemplo, com a adoção da telemedicina e dos sistemas eletrônicos de saúde, a fisioterapia tornou-se um campo em busca de soluções otimizadas. Diante disso, o presente trabalho se propõe a desenvolver um sistema (em nível de protótipo) destinado a auxiliar fisioterapeutas a documentar e monitorar a progressão do seu trabalho em clínicas e garantir uma abordagem mais eficaz no acompanhamento das evoluções de seus pacientes. O sistema deve oferecer uma interface fácil e simples de uso, como também promover a utilização de meios tecnológicos em suas clínicas.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/36813,"à medida que a inovação tecnológica se consolidou como uma força dominante na área de saúde, por exemplo, com a adoção da telemedicina e dos sistemas eletrônicos de saúde, a fisioterapia tornou-se um campo em busca de soluções otimizadas. diante disso, o presente trabalho se propõe a desenvolver um sistema (em nível de protótipo) destinado a auxiliar fisioterapeutas a documentar e monitorar a progressão do seu trabalho em clínicas e garantir uma abordagem mais eficaz no acompanhamento das evoluções de seus pacientes. o sistema deve oferecer uma interface fácil e simples de uso, como também promover a utilização de meios tecnológicos em suas clínicas."
133,2023,Estado da arte sobre benchmarks para sistemas de bancos de dados NOSQL.,"MORAIS FILHO, José de Arimateia.","PIRES, Carlos Eduardo Santos.","Com a crescente utilização dos sistemas de bancos de dados NoSQL, se tornou relevante estabelecer um comparativo de desempenho entre eles. Entretanto, dadas as diferenças que esses sistemas possuem em relação aos modelos de dados, torna-se difícil fazer comparações entre tecnologias de diferentes famílias de banco de dados. Portanto, é importante encontrar ferramentas que possam fazer essa análise e trazer resultados relevantes. Esse artigo apresenta um levantamento dos principais benchmarks existentes para avaliar sistemas de bancos de dados NoSQL. Percebe-se que há vários benchmarks específicos para uma determinada categoria, mas os benchmarks que comparam tecnologias de diferentes tipos são mais escassos e se limitam a avaliar operações básicas sobre as bases de dados.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/36784,"com a crescente utilização dos sistemas de bancos de dados nosql, se tornou relevante estabelecer um comparativo de desempenho entre eles. entretanto, dadas as diferenças que esses sistemas possuem em relação aos modelos de dados, torna-se difícil fazer comparações entre tecnologias de diferentes famílias de banco de dados. portanto, é importante encontrar ferramentas que possam fazer essa análise e trazer resultados relevantes. esse artigo apresenta um levantamento dos principais benchmarks existentes para avaliar sistemas de bancos de dados nosql. percebe-se que há vários benchmarks específicos para uma determinada categoria, mas os benchmarks que comparam tecnologias de diferentes tipos são mais escassos e se limitam a avaliar operações básicas sobre as bases de dados."
134,2023,Orientações para educação digital baseada em metodologias ativas com impacto no entorno de Campina Grande.,"SILVA, Izabella Ribeiro de Souza.","CAMPOS, Lívia Maria Rodrigues Sampaio.","A cidadania digital envolve o desenvolvimento de competências eficazes e éticas no uso das tecnologias, sempre respeitando princípios fundamentais, como privacidade, segurança e responsabilidade. A educação digital desempenha um papel crucial como parte integrante da cidadania digital, indo além do mero uso das tecnologias e sendo a base para a formação de cidadãos digitalmente conscientes. A educação digital é a chave para preparar as gerações presentes e futuras, capacitando-as a navegar com sucesso no mundo digital, compreender e aplicar as tecnologias de forma ética e eficaz. A crescente demanda no mercado de trabalho por profissionais com habilidades digitais destaca a importância da educação digital em todos os níveis, desde programas técnicos até a educação superior. A essência de uma aprendizagem eficaz reside na concepção de programas de capacitação envolventes, que não apenas desenvolvam habilidades técnicas, mas também promovam uma cidadania digital consciente. Dentro desse contexto, este trabalho tem como objetivo contribuir para a promoção da educação digital, fornecendo um guia prático repleto de orientações para o desenvolvimento de cursos, com metodologias ativas e no contexto de extensão, que gerem um impacto significativo na comunidade da cidade de Campina Grande.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/36781,"a cidadania digital envolve o desenvolvimento de competências eficazes e éticas no uso das tecnologias, sempre respeitando princípios fundamentais, como privacidade, segurança e responsabilidade. a educação digital desempenha um papel crucial como parte integrante da cidadania digital, indo além do mero uso das tecnologias e sendo a base para a formação de cidadãos digitalmente conscientes. a educação digital é a chave para preparar as gerações presentes e futuras, capacitando-as a navegar com sucesso no mundo digital, compreender e aplicar as tecnologias de forma ética e eficaz. a crescente demanda no mercado de trabalho por profissionais com habilidades digitais destaca a importância da educação digital em todos os níveis, desde programas técnicos até a educação superior. a essência de uma aprendizagem eficaz reside na concepção de programas de capacitação envolventes, que não apenas desenvolvam habilidades técnicas, mas também promovam uma cidadania digital consciente. dentro desse contexto, este trabalho tem como objetivo contribuir para a promoção da educação digital, fornecendo um guia prático repleto de orientações para o desenvolvimento de cursos, com metodologias ativas e no contexto de extensão, que gerem um impacto significativo na comunidade da cidade de campina grande."
135,2023,Recomendações para compra e venda de ativos em day trading utilizando redes neurais artificiais.,"PINHEIRO, Ítalo Miguel Castor Diniz.","GOMES, Herman Martins.","É notório o crescimento do ingresso de investidores individuais no mercado financeiro. Muitos desses investidores não conseguem discernir corretamente onde devem investir o seu dinheiro para obter uma maior rentabilidade. Neste contexto, este trabalho teve como objetivo desenvolver uma aplicação para auxiliar nas decisões de compra e venda de ativos por meio de uma rede neural treinada de forma supervisionada sobre dados extraídos das cotações dos ativos. A aplicação desenvolvida busca apresentar uma forma intuitiva para guiar as decisões diárias de investimento (day trading) no tocante às ações que devem permanecer, entrar ou sair da carteira de cada usuário. O princípio é prever a cotação do dia seguinte da ação, com recomendação de venda se o preço previsto for diminuir e de compra se o preço for aumentar. A aplicação informa também uma estimativa sobre quanto cada operação de compra ou venda produzirá de lucro. Para isso, foram feitos experimentos com três ativos diferentes que atendiam as principais movimentações do mercado e foi possível notar um acréscimo no valor inicial investido pelo usuário de aproximadamente 23% a 43% no montante final. A ferramenta desenvolvida poderá auxiliar tanto usuários iniciantes no mercado de ações quanto usuários mais experientes.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/36778,"é notório o crescimento do ingresso de investidores individuais no mercado financeiro. muitos desses investidores não conseguem discernir corretamente onde devem investir o seu dinheiro para obter uma maior rentabilidade. neste contexto, este trabalho teve como objetivo desenvolver uma aplicação para auxiliar nas decisões de compra e venda de ativos por meio de uma rede neural treinada de forma supervisionada sobre dados extraídos das cotações dos ativos. a aplicação desenvolvida busca apresentar uma forma intuitiva para guiar as decisões diárias de investimento (day trading) no tocante às ações que devem permanecer, entrar ou sair da carteira de cada usuário. o princípio é prever a cotação do dia seguinte da ação, com recomendação de venda se o preço previsto for diminuir e de compra se o preço for aumentar. a aplicação informa também uma estimativa sobre quanto cada operação de compra ou venda produzirá de lucro. para isso, foram feitos experimentos com três ativos diferentes que atendiam as principais movimentações do mercado e foi possível notar um acréscimo no valor inicial investido pelo usuário de aproximadamente % a % no montante final. a ferramenta desenvolvida poderá auxiliar tanto usuários iniciantes no mercado de ações quanto usuários mais experientes."
136,2023,Um estudo sobre metodologias ágeis e sua correlação com o êxito em projetos de software.,"ALENCAR, Gaspar Soares de.","PEREIRA, Thiago Emmanuel.","""Um estudo sobre Metodologias Ágeis e sua Correlação com o Êxito em Projetos de Software"" investiga a eficácia das metodologias ágeis em projetos de desenvolvimento de software e sua relação com o sucesso. O estudo aprofunda a compreensão das práticas e princípios fundamentais das metodologias ágeis, como o Manifesto Ágil e os 12 Princípios Ágeis. Além disso, a pesquisa analisa como diversos fatores, como o apoio executivo, a maturidade emocional das equipes, o envolvimento dos usuários, a otimização de recursos, a qualificação dos membros da equipe e outros elementos, impactam a taxa de sucesso de projetos ágeis. Também são investigados os obstáculos e desafios comuns que as organizações enfrentam ao implementar essas metodologias, incluindo a resistência à mudança e conflitos culturais. O trabalho enfatiza a relevância das metodologias ágeis na melhoria do desempenho em projetos de software e fornece diretrizes valiosas para organizações que buscam adotar ou aprimorar suas práticas ágeis. O estudo oferece uma visão abrangente do universo ágil, abordando suas vantagens e desafios, e apresenta recomendações práticas para aprimorar a implementação de abordagens ágeis nas empresas de desenvolvimento de software.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/36776,"""um estudo sobre metodologias ágeis e sua correlação com o êxito em projetos de software"" investiga a eficácia das metodologias ágeis em projetos de desenvolvimento de software e sua relação com o sucesso. o estudo aprofunda a compreensão das práticas e princípios fundamentais das metodologias ágeis, como o manifesto ágil e os princípios ágeis. além disso, a pesquisa analisa como diversos fatores, como o apoio executivo, a maturidade emocional das equipes, o envolvimento dos usuários, a otimização de recursos, a qualificação dos membros da equipe e outros elementos, impactam a taxa de sucesso de projetos ágeis. também são investigados os obstáculos e desafios comuns que as organizações enfrentam ao implementar essas metodologias, incluindo a resistência à mudança e conflitos culturais. o trabalho enfatiza a relevância das metodologias ágeis na melhoria do desempenho em projetos de software e fornece diretrizes valiosas para organizações que buscam adotar ou aprimorar suas práticas ágeis. o estudo oferece uma visão abrangente do universo ágil, abordando suas vantagens e desafios, e apresenta recomendações práticas para aprimorar a implementação de abordagens ágeis nas empresas de desenvolvimento de software."
137,2023,Suporte à inclusão e à gestão empresarial: versão evolutiva de aplicação web para a CodeX Júnior.,"MATOS, Gabriel Max Vieira","MOURA, José Antão Beltrão.","Este Trabalho de Conclusão de Curso visa aprimorar o Projexa, o aplicativo de gerenciamento de projetos da empresa CodeX Júnior. O foco está na expansão do acesso, permitindo que todos os membros utilizem a plataforma de acordo com suas funções hierárquicas, e na implementação de um sistema de registro de atualizações de projetos em formato de notas. A pesquisa avaliou a utilidade percebida, usabilidade, comportamento, experiência de interface, desempenho e satisfação geral com o aplicativo aprimorado, usando uma escala Likert. Participantes incluíram líderes e assessores da CodeX Júnior, com permissão para criar atualizações de projetos limitada aos líderes e membros envolvidos em projetos específicos. A coleta de dados ocorreu por meio de um formulário online, onde a pesquisa contribui para melhorar a gestão de projetos na CodeX Júnior, promovendo inclusão e transparência. Baseia-se no trabalho anterior de Lucas Anthony Ferreira de Oliveira e foi conduzida com consentimento e colaboração voluntária dos participantes. Este estudo oferece insights valiosos para orientar futuras melhorias no sistema e beneficiar a CodeX Júnior em sua busca por uma gestão de projetos mais eficaz e transparente.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/36772,"este trabalho de conclusão de curso visa aprimorar o projexa, o aplicativo de gerenciamento de projetos da empresa codex júnior. o foco está na expansão do acesso, permitindo que todos os membros utilizem a plataforma de acordo com suas funções hierárquicas, e na implementação de um sistema de registro de atualizações de projetos em formato de notas. a pesquisa avaliou a utilidade percebida, usabilidade, comportamento, experiência de interface, desempenho e satisfação geral com o aplicativo aprimorado, usando uma escala likert. participantes incluíram líderes e assessores da codex júnior, com permissão para criar atualizações de projetos limitada aos líderes e membros envolvidos em projetos específicos. a coleta de dados ocorreu por meio de um formulário online, onde a pesquisa contribui para melhorar a gestão de projetos na codex júnior, promovendo inclusão e transparência. baseia-se no trabalho anterior de lucas anthony ferreira de oliveira e foi conduzida com consentimento e colaboração voluntária dos participantes. este estudo oferece insights valiosos para orientar futuras melhorias no sistema e beneficiar a codex júnior em sua busca por uma gestão de projetos mais eficaz e transparente."
138,2023,Hive: uma rede interligada de contratação.,"FONSECA, Gabriel de Carvalho.","BRUNET, João Arthur Monteiro.","Com a pandemia houve um crescimento de 671% na procura por profissionais na área de TI, criando-se um grande número de oportunidades para candidatos. Porém é possível no entanto perceber que há também a dificuldade de encontrar a vaga adequada para o profissional em questão, podendo muitas vezes não se identificar com as oportunidades que lhe são oferecidas em diversas plataformas de divulgação de vagas. Este trabalho propõe a criação de uma plataforma web, que irá se utilizar de conhecimentos de algoritmos de relevância por documento para que haja um ranqueamento das oportunidades de emprego, e assim sejam sugeridas as melhores oportunidades para o usuário. Ao final deste projeto foi desenvolvido como resultado uma plataforma web para busca e cadastro de oportunidades com a ênfase na transparência de informações para seus usuários, com a sua validação sendo realizada através de um formulário disponibilizado para os usuários, coletando informações a respeito da usabilidade do sistema e recebendo um feedback por parte deles de pontos a serem melhorados futuramente. Em geral os resultados apontam para boas avaliações na usabilidade e facilidade do sistema, com algumas sugestões de melhorias nos pontos de responsividade da plataforma e integração de algumas funcionalidades no sistema.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/36771,"com a pandemia houve um crescimento de % na procura por profissionais na área de ti, criando-se um grande número de oportunidades para candidatos. porém é possível no entanto perceber que há também a dificuldade de encontrar a vaga adequada para o profissional em questão, podendo muitas vezes não se identificar com as oportunidades que lhe são oferecidas em diversas plataformas de divulgação de vagas. este trabalho propõe a criação de uma plataforma web, que irá se utilizar de conhecimentos de algoritmos de relevância por documento para que haja um ranqueamento das oportunidades de emprego, e assim sejam sugeridas as melhores oportunidades para o usuário. ao final deste projeto foi desenvolvido como resultado uma plataforma web para busca e cadastro de oportunidades com a ênfase na transparência de informações para seus usuários, com a sua validação sendo realizada através de um formulário disponibilizado para os usuários, coletando informações a respeito da usabilidade do sistema e recebendo um feedback por parte deles de pontos a serem melhorados futuramente. em geral os resultados apontam para boas avaliações na usabilidade e facilidade do sistema, com algumas sugestões de melhorias nos pontos de responsividade da plataforma e integração de algumas funcionalidades no sistema."
139,2023,DevSpaces: ferramenta para criação de ambientes na nuvem usando instâncias preemptivas.,"MARINHO, Felipe Vasconcelos.","BRUNET, João Arthur Monteiro.","No processo de desenvolvimento de software, a aquisição e manutenção de hardware adequado para as necessidades de programação podem resultar em altos custos de investimento de capital. A alternativa de uso de recursos em nuvem oferece flexibilidade, porém o gerenciamento desses recursos pode ser complexo e oneroso, requerendo conhecimentos especializados em operações em nuvem. O problema consiste em gerenciar um ambiente de desenvolvimento na nuvem de forma eficiente, evitando altos custos de aquisição e manutenção de hardware próprio, além de simplificar o gerenciamento de recursos ao alugar máquinas na nuvem, buscando minimizar despesas e eliminar a necessidade de expertise complexa em operações em nuvem. Propomos o desenvolvimento de uma ferramenta de linha de comando, destinada a simplificar o gerenciamento do ambiente de desenvolvimento de software. Essa ferramenta terá a capacidade de criar, configurar e gerenciar recursos na nuvem de forma automatizada e eficiente. Uma característica diferencial é a utilização de instâncias preemptivas oferecidas por provedores de nuvem, permitindo aproveitar recursos ociosos a custos ainda mais baixos, sem comprometer a qualidade do ambiente de desenvolvimento. Espera-se que o usuário seja capaz de criar ambientes de desenvolvimento utilizando a ferramenta proposta integrando-a com outras soluções já existentes para desenvolvimento de código. Ao oferecer uma solução intuitiva, nossa abordagem visa otimizar o ambiente de desenvolvimento, maximizando a economia e eliminando a necessidade de conhecimentos avançados em operações em nuvem por parte da equipe de desenvolvimento. Ao final deste trabalho, a usabilidade da ferramenta foi validada e demonstrou ser eficaz na simplificação do gerenciamento dos ambientes. A maioria dos participantes conseguiu gerenciar ambientes com sucesso, destacando a facilidade de uso e a utilidade da documentação fornecida.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/36736,"no processo de desenvolvimento de software, a aquisição e manutenção de hardware adequado para as necessidades de programação podem resultar em altos custos de investimento de capital. a alternativa de uso de recursos em nuvem oferece flexibilidade, porém o gerenciamento desses recursos pode ser complexo e oneroso, requerendo conhecimentos especializados em operações em nuvem. o problema consiste em gerenciar um ambiente de desenvolvimento na nuvem de forma eficiente, evitando altos custos de aquisição e manutenção de hardware próprio, além de simplificar o gerenciamento de recursos ao alugar máquinas na nuvem, buscando minimizar despesas e eliminar a necessidade de expertise complexa em operações em nuvem. propomos o desenvolvimento de uma ferramenta de linha de comando, destinada a simplificar o gerenciamento do ambiente de desenvolvimento de software. essa ferramenta terá a capacidade de criar, configurar e gerenciar recursos na nuvem de forma automatizada e eficiente. uma característica diferencial é a utilização de instâncias preemptivas oferecidas por provedores de nuvem, permitindo aproveitar recursos ociosos a custos ainda mais baixos, sem comprometer a qualidade do ambiente de desenvolvimento. espera-se que o usuário seja capaz de criar ambientes de desenvolvimento utilizando a ferramenta proposta integrando-a com outras soluções já existentes para desenvolvimento de código. ao oferecer uma solução intuitiva, nossa abordagem visa otimizar o ambiente de desenvolvimento, maximizando a economia e eliminando a necessidade de conhecimentos avançados em operações em nuvem por parte da equipe de desenvolvimento. ao final deste trabalho, a usabilidade da ferramenta foi validada e demonstrou ser eficaz na simplificação do gerenciamento dos ambientes. a maioria dos participantes conseguiu gerenciar ambientes com sucesso, destacando a facilidade de uso e a utilidade da documentação fornecida."
140,2023,Busca em catálogo de produtos: uma comparação entre banco de dados relacional e motor de busca.,"SILVA JÚNIOR, Eniedson Fabiano Pereira da.","BAPTISTA, Cláudio de Souza.","O objetivo do TCE-AC é fiscalizar as despesas e receitas dos municípios e do estado do Acre. Para tanto, nos últimos anos tem modernizado a sua forma de trabalho. Em particular, o acesso rápido aos preços praticados é fundamental para a fiscalização e também para a população em geral. Para isso, o Banco de Preços é utilizado, sendo alimentado por uma base de dados em constante crescimento e que, atualmente, conta com dezenas de milhões de registros de notas fiscais. Diante desse cenário, por utilizar de banco de dados relacionais para a realização das consultas e devido a grande massa de dados existente, o sistema em questão acaba demorando para produzir resultados em diversas situações, além de retornar resultados pouco relevantes em algumas situações. Para solucionar o problema, propõe-se a implantação do Elasticsearch como o motor de busca do sistema. O Elasticsearch utiliza técnicas de indexação e possui ferramentas que otimizam a execução e resultados das queries realizadas. Além disso, serão implementadas estratégias para a carga contínua dos dados, além da documentação dos desafios enfrentados durante a implementação. Para avaliar a solução proposta, foram realizadas medições de estatísticas referentes ao tempo de resposta e qualidade das consultas antes e depois da implantação do Elasticsearch. A qualidade dos resultados foi verificada por meio de técnicas como NDCG (Normalized Discounted Cumulative Gain) e f1-score, a partir da definição dos documentos relevantes ou não para cada consulta. Como resultado, foi possível notar uma diminuição em 10 vezes do tempo de respostas das consultas realizadas no Elasticsearch quando comparado com os resultados envolvendo o Sql Server. Além disso, também foi possível observar uma melhora na relevância dos resultados retornados de cerca de 2%, chegando a um NDCG de 95,3% em média, para consultas com 10 resultados, utilizadas por padrão no sistema.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/36735,"o objetivo do tce-ac é fiscalizar as despesas e receitas dos municípios e do estado do acre. para tanto, nos últimos anos tem modernizado a sua forma de trabalho. em particular, o acesso rápido aos preços praticados é fundamental para a fiscalização e também para a população em geral. para isso, o banco de preços é utilizado, sendo alimentado por uma base de dados em constante crescimento e que, atualmente, conta com dezenas de milhões de registros de notas fiscais. diante desse cenário, por utilizar de banco de dados relacionais para a realização das consultas e devido a grande massa de dados existente, o sistema em questão acaba demorando para produzir resultados em diversas situações, além de retornar resultados pouco relevantes em algumas situações. para solucionar o problema, propõe-se a implantação do elasticsearch como o motor de busca do sistema. o elasticsearch utiliza técnicas de indexação e possui ferramentas que otimizam a execução e resultados das queries realizadas. além disso, serão implementadas estratégias para a carga contínua dos dados, além da documentação dos desafios enfrentados durante a implementação. para avaliar a solução proposta, foram realizadas medições de estatísticas referentes ao tempo de resposta e qualidade das consultas antes e depois da implantação do elasticsearch. a qualidade dos resultados foi verificada por meio de técnicas como ndcg (normalized discounted cumulative gain) e f1-score, a partir da definição dos documentos relevantes ou não para cada consulta. como resultado, foi possível notar uma diminuição em vezes do tempo de respostas das consultas realizadas no elasticsearch quando comparado com os resultados envolvendo o sql server. além disso, também foi possível observar uma melhora na relevância dos resultados retornados de cerca de %, chegando a um ndcg de , % em média, para consultas com resultados, utilizadas por padrão no sistema."
141,2023,Aprimoramento de mecanismos de tratamento de logs não enviados em uma plataforma de comércio eletrônico.,"LEANDRO, Caroliny Regina Valença.","MASSONI, Tiago Lima.","A observabilidade desempenha um papel importante no desenvolvimento e na manutenção de software. Podemos dizer que um sistema é observável quando pode-se entender e explicar qualquer estado em que o mesmo possa entrar, podendo ele ser corriqueiro ou algo totalmente novo. Juntamente com métricas e traces, os logs representam um dos pilares da observabilidade, desempenhando um papel vital na depuração dos estados de um sistema. Isso ressalta sua importância como fonte de dados e a necessidade de seu tratamento e armazenamento. Nesse contexto, o OpenTelemetry emerge como um framework e conjunto de ferramentas que se propõe a facilitar a coleta e a gestão de dados de observabilidade em sistemas. Sendo independente de fornecedores e ferramentas, e adotando um modelo de código aberto, o OpenTelemetry se revela um software altamente versátil, adaptável às necessidades individuais de seus usuários, tornando-se uma escolha ideal na implementação de observabilidade em sistemas. O foco deste trabalho está no aprimoramento de um módulo utilizado em um coletor OpenTelemetry, cuja função principal é receber logs em uma plataforma de comércio eletrônico. Esse módulo compreende dois componentes: o WAL, responsável por detectar falhas no envio de logs ao OpenSearch e armazenar logs não enviados em um serviço de armazenamento de objetos; e um Replayer de logs, que tenta reenviar os logs armazenados posteriormente ao OpenSearch. Entretanto, o Replayer de logs enfrenta desafios relacionados a disponibilidade de recursos de hardware, instabilidade em ambientes variáveis e limitações na configuração, o que impacta negativamente em sua eficácia no envio de logs ao OpenSearch. Além disso, a ausência de dados sobre a saúde e o desempenho do WAL pode dificultar a manutenção e depuração deste componente, devido à falta de informações relevantes. Diante desse cenário, este trabalho tem como objetivo aprimorar o Replayer de logs, visando melhorar a disponibilidade e a utilização dos recursos de hardware, aumentar sua confiabilidade no envio de logs ao OpenSearch e torná-lo mais flexível em termos de configuração. Também, pretende-se adicionar capacidades de observabilidade ao mecanismo WAL com o objetivo de garantir maior visibilidade do funcionamento do mecanismo e facilitar a depuração do mesmo.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/36733,"a observabilidade desempenha um papel importante no desenvolvimento e na manutenção de software. podemos dizer que um sistema é observável quando pode-se entender e explicar qualquer estado em que o mesmo possa entrar, podendo ele ser corriqueiro ou algo totalmente novo. juntamente com métricas e traces, os logs representam um dos pilares da observabilidade, desempenhando um papel vital na depuração dos estados de um sistema. isso ressalta sua importância como fonte de dados e a necessidade de seu tratamento e armazenamento. nesse contexto, o opentelemetry emerge como um framework e conjunto de ferramentas que se propõe a facilitar a coleta e a gestão de dados de observabilidade em sistemas. sendo independente de fornecedores e ferramentas, e adotando um modelo de código aberto, o opentelemetry se revela um software altamente versátil, adaptável às necessidades individuais de seus usuários, tornando-se uma escolha ideal na implementação de observabilidade em sistemas. o foco deste trabalho está no aprimoramento de um módulo utilizado em um coletor opentelemetry, cuja função principal é receber logs em uma plataforma de comércio eletrônico. esse módulo compreende dois componentes: o wal, responsável por detectar falhas no envio de logs ao opensearch e armazenar logs não enviados em um serviço de armazenamento de objetos; e um replayer de logs, que tenta reenviar os logs armazenados posteriormente ao opensearch. entretanto, o replayer de logs enfrenta desafios relacionados a disponibilidade de recursos de hardware, instabilidade em ambientes variáveis e limitações na configuração, o que impacta negativamente em sua eficácia no envio de logs ao opensearch. além disso, a ausência de dados sobre a saúde e o desempenho do wal pode dificultar a manutenção e depuração deste componente, devido à falta de informações relevantes. diante desse cenário, este trabalho tem como objetivo aprimorar o replayer de logs, visando melhorar a disponibilidade e a utilização dos recursos de hardware, aumentar sua confiabilidade no envio de logs ao opensearch e torná-lo mais flexível em termos de configuração. também, pretende-se adicionar capacidades de observabilidade ao mecanismo wal com o objetivo de garantir maior visibilidade do funcionamento do mecanismo e facilitar a depuração do mesmo."
142,2023,Termobake: aplicativo para digitalizar indicadores de temperaturas de fornos contínuos na indústria local de biscoitos.,"SILVA, Eduardo Afonso Nunes da.","ANDRADE, Wilkerson de Lucena.","O controle de temperatura de fornos industriais para uma empresa de biscoitos é essencial para a qualidade do produto. Porém, nem toda empresa possui uma forma digital para gerenciar as informações coletadas durante a fabricação dos produtos e, por isso, seus registros são realizados em papéis e posteriormente repassado para planilhas digitais. Nesse sentido, software com objetivos parecidos estão escassos. Portanto, o propósito deste trabalho é entregar uma aplicação android a fim de modernizar a indústria local de biscoitos, a qual utiliza fornos contendo oito zonas, requerendo atenção para suas temperaturas. Com o uso do aplicativo, o processo de apontamento de temperaturas será agilizado e o fabricante poderá ter um acompanhamento controlado mais intuitivo. Além disso, não haverá a necessidade do uso de papel.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/36712,"o controle de temperatura de fornos industriais para uma empresa de biscoitos é essencial para a qualidade do produto. porém, nem toda empresa possui uma forma digital para gerenciar as informações coletadas durante a fabricação dos produtos e, por isso, seus registros são realizados em papéis e posteriormente repassado para planilhas digitais. nesse sentido, software com objetivos parecidos estão escassos. portanto, o propósito deste trabalho é entregar uma aplicação android a fim de modernizar a indústria local de biscoitos, a qual utiliza fornos contendo oito zonas, requerendo atenção para suas temperaturas. com o uso do aplicativo, o processo de apontamento de temperaturas será agilizado e o fabricante poderá ter um acompanhamento controlado mais intuitivo. além disso, não haverá a necessidade do uso de papel."
143,2023,Geração de clientes para comunicação assíncrona com base na especificação AsyncAPI.,"SOUSA, Davi Barbosa Silva.","FARIAS, Adalberto Cajueiro de.","O desenvolvimento de aplicações que interagem entre si através de microsserviços pode ser feito de forma síncrona e assíncrona. Este trabalho explora a arquitetura orientada a eventos (Event-Driven Architecture) que possui uma especificação para documentação de rotas chamada AsyncAPI, com ela é possível gerar APIs assíncronas partindo de templates de geração de código. No entanto, os geradores de código existentes são construídos com a finalidade de produzir código publicador-consumidor para determinados conjuntos de tecnologias e ainda há uma lacuna de ferramental para dispositivos embarcados e aplicações Web. O objetivo deste trabalho é construir uma ferramenta para as linguagens C++ e Typescript que auxilia os usuários a integrar APIs assíncronas em suas aplicações a partir de uma especificação AsyncAPI. Desta forma, a solução desenvolvida baseia-se em
desenvolvimento dirigido por modelos através de uma ferramenta que gera código para publicação e consumo de mensagens gerenciadas por um Message Broker de forma mais dinâmica e parametrizável. Nesse sentido, o desenvolvimento de sistemas assíncrono tem foco principal na especificação (modelo) e na injeção de aspectos de negócio no código gerado pela tradução automática. Isso promove a redução do esforço e tempo no desenvolvimento de sistemas assíncronos.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/36711,"o desenvolvimento de aplicações que interagem entre si através de microsserviços pode ser feito de forma síncrona e assíncrona. este trabalho explora a arquitetura orientada a eventos (event-driven architecture) que possui uma especificação para documentação de rotas chamada asyncapi, com ela é possível gerar apis assíncronas partindo de templates de geração de código. no entanto, os geradores de código existentes são construídos com a finalidade de produzir código publicador-consumidor para determinados conjuntos de tecnologias e ainda há uma lacuna de ferramental para dispositivos embarcados e aplicações web. o objetivo deste trabalho é construir uma ferramenta para as linguagens c++ e typescript que auxilia os usuários a integrar apis assíncronas em suas aplicações a partir de uma especificação asyncapi. desta forma, a solução desenvolvida baseia-se em desenvolvimento dirigido por modelos através de uma ferramenta que gera código para publicação e consumo de mensagens gerenciadas por um message broker de forma mais dinâmica e parametrizável. nesse sentido, o desenvolvimento de sistemas assíncrono tem foco principal na especificação (modelo) e na injeção de aspectos de negócio no código gerado pela tradução automática. isso promove a redução do esforço e tempo no desenvolvimento de sistemas assíncronos."
144,2023,Analisando LLMS na resolução de problemas de competições de programação: um estudo com ChatGPT e Bard.,"MELO, Daniel Carlos Alves de.","GHEYI, Rohit Gheyi.","Com a recente adoção de Inteligências Artificiais Generativas no campo da Ciência da Computação, surge o questionamento dos limites dessas ferramentas na geração de código e no desempenho desse código na resolução de problemas de programação de alta complexidade, como desafios envolvendo programação dinâmica. Neste estudo, analisaremos o desempenho de dois modelos de IA(Inteligência Artificial), o Bard e o ChatGPT, ao submetê-los a 83 problemas de programação de diversos níveis de complexidade. Utilizaremos os prompts de ambas as ferramentas em um estudo de caso comparativo que aplicará o código gerado por esses modelos em problemas de programação obtidos de juízes online, incluindo Codeforces, Atcoder, CodeChef e LeetCode. Compararemos os resultados desses modelos em competições online realizadas regularmente pelas plataformas citadas, os textos das questões serão submetidos para as ferramentas enquanto as competições estiverem acontecendo, garantindo que os problemas sejam inéditos e desconhecidos pelas IAs. Este estudo visa obter dados consistentes para avaliar a capacidade do Bard e do ChatGPT 3.5 na resolução de problemas de programação com enunciados desconhecidos por ambas as ferramentas. Os resultados contribuirão para um entendimento mais aprofundado do desempenho dessas IAs em competições de programação e para pesquisas futuras relacionadas ao uso de IA na resolução de desafios computacionais complexos.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/36710,"com a recente adoção de inteligências artificiais generativas no campo da ciência da computação, surge o questionamento dos limites dessas ferramentas na geração de código e no desempenho desse código na resolução de problemas de programação de alta complexidade, como desafios envolvendo programação dinâmica. neste estudo, analisaremos o desempenho de dois modelos de ia(inteligência artificial), o bard e o chatgpt, ao submetê-los a problemas de programação de diversos níveis de complexidade. utilizaremos os prompts de ambas as ferramentas em um estudo de caso comparativo que aplicará o código gerado por esses modelos em problemas de programação obtidos de juízes online, incluindo codeforces, atcoder, codechef e leetcode. compararemos os resultados desses modelos em competições online realizadas regularmente pelas plataformas citadas, os textos das questões serão submetidos para as ferramentas enquanto as competições estiverem acontecendo, garantindo que os problemas sejam inéditos e desconhecidos pelas ias. este estudo visa obter dados consistentes para avaliar a capacidade do bard e do chatgpt . na resolução de problemas de programação com enunciados desconhecidos por ambas as ferramentas. os resultados contribuirão para um entendimento mais aprofundado do desempenho dessas ias em competições de programação e para pesquisas futuras relacionadas ao uso de ia na resolução de desafios computacionais complexos."
145,2023,Ingestão e processamento de dados textuais do Reddit: uma solução de qualidade e disponibilidade.,"NASCIMENTO, André Jordão do.","MORAIS, Fábio Jorge Almeida.","Um dos maiores problemas encontrados em aplicações que estão envolvidas no ecossistema de Big Data está relacionado à disponibilidade e qualidade de dados para modelos de IA e outras análises direcionadas. Aplicações com esse foco necessitam de dados que disponham de alta qualidade, já que o resultado de seus serviços depende da integridade da informação usada no processo. Quando pensamos em dados textuais, devemos saber que a informação fornecida para aplicações que envolvem processamento de texto, devem ser as melhores possíveis. Desta forma, foi desenvolvido uma aplicação que trata da gerência da coleta e tratamento contínuo de dados textuais. O contexto da aplicação está fixo na coleta de dados textuais da rede social Reddit. Através da API fornecida pela rede, é feita a ingestão de dados de uma comunidade específica. Com base nos dados coletados, a ferramenta trata de fazer todo o orquestramento de tarefas que gerenciam a coleta, tratamento e disponibilização desses dados. Para teste da ferramenta, os dados disponíveis são passados para um modelo de PLN, que usa LDA para mapear tópicos com base nos textos extraídos do site. A aplicação se baseia nos conceitos de streaming de dados e processamento de texto, de forma contínua e automática, a fim de manter uma base de dados sólida e de qualidade para análises de texto.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/36709,"um dos maiores problemas encontrados em aplicações que estão envolvidas no ecossistema de big data está relacionado à disponibilidade e qualidade de dados para modelos de ia e outras análises direcionadas. aplicações com esse foco necessitam de dados que disponham de alta qualidade, já que o resultado de seus serviços depende da integridade da informação usada no processo. quando pensamos em dados textuais, devemos saber que a informação fornecida para aplicações que envolvem processamento de texto, devem ser as melhores possíveis. desta forma, foi desenvolvido uma aplicação que trata da gerência da coleta e tratamento contínuo de dados textuais. o contexto da aplicação está fixo na coleta de dados textuais da rede social reddit. através da api fornecida pela rede, é feita a ingestão de dados de uma comunidade específica. com base nos dados coletados, a ferramenta trata de fazer todo o orquestramento de tarefas que gerenciam a coleta, tratamento e disponibilização desses dados. para teste da ferramenta, os dados disponíveis são passados para um modelo de pln, que usa lda para mapear tópicos com base nos textos extraídos do site. a aplicação se baseia nos conceitos de streaming de dados e processamento de texto, de forma contínua e automática, a fim de manter uma base de dados sólida e de qualidade para análises de texto."
146,2023,Sem conflito no cache: observações de uma plataforma de comércio eletrônico multi-tenant.,"LIRA, Anna Beatriz Lucena.","PEREIRA, Thiago Emmanuel.","O armazenamento em cache é uma técnica clássica para aumentar o desempenho do sistema, reduzindo a latência percebida pelo cliente e a carga do servidor. No entanto, projetar e configurar cuidadosamente o cache é uma tarefa desafiaforal. Inclui a escolha do tamanho da capacidade, da política de remoção de itens, entre outros aspectos. Esta tarefa é ainda mais complexa em sistemas multi-inquilinos, nos quais cada inquilino opera de forma independente e apresenta demandas diferentes ao longo do tempo. Por essa razão, a configuração eficaz e a gestão do cache requerem uma compreensão das características da carga de trabalho, incluindo níveis de carga, padrões de acesso e localidade temporal. Este artigo concentra-se na caracterização da carga de trabalho de um cache multi-inquilino em uma grande plataforma de comércio eletrônico. Encontramos uma diversidade significativa entre inquilinos em relação a padrões de carga, utilidade do cache e localidade temporal. Com base nisso, destacamos estratégias para otimizar a gestão de sistemas de cache multi-inquilino, adotando políticas de admissão e ajuste dinâmico de capacidade (escalonamento). A implementação dessas estratégias em um ambiente de produção constituirá uma fase subsequente desta investigação.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/36708,"o armazenamento em cache é uma técnica clássica para aumentar o desempenho do sistema, reduzindo a latência percebida pelo cliente e a carga do servidor. no entanto, projetar e configurar cuidadosamente o cache é uma tarefa desafiaforal. inclui a escolha do tamanho da capacidade, da política de remoção de itens, entre outros aspectos. esta tarefa é ainda mais complexa em sistemas multi-inquilinos, nos quais cada inquilino opera de forma independente e apresenta demandas diferentes ao longo do tempo. por essa razão, a configuração eficaz e a gestão do cache requerem uma compreensão das características da carga de trabalho, incluindo níveis de carga, padrões de acesso e localidade temporal. este artigo concentra-se na caracterização da carga de trabalho de um cache multi-inquilino em uma grande plataforma de comércio eletrônico. encontramos uma diversidade significativa entre inquilinos em relação a padrões de carga, utilidade do cache e localidade temporal. com base nisso, destacamos estratégias para otimizar a gestão de sistemas de cache multi-inquilino, adotando políticas de admissão e ajuste dinâmico de capacidade (escalonamento). a implementação dessas estratégias em um ambiente de produção constituirá uma fase subsequente desta investigação."
147,2023,ChatGPT aplicado a programação: possibilidades e desafios no processo de ensino e aprendizagem no ensino superior.,"VASCONCELOS, Ana Carolina Chaves de.","CAMPOS, Lívia Maria Rodrigues Sampaio","Estamos vivendo uma fase de inserção tecnológica de um novo sistema de recuperação de informação de forma fácil e bastante eficiente: o ChatGPT. Diante do surgimento dessa promissora ferramenta, há diversos casos em que o ensino/aprendizagem vem se moldando considerando as possibilidades que ela nos oferece. No ensino superior especificamente, durante os primeiros semestres, o processo de adaptação ao ensino na graduação se torna um grande desafio para muitos e é possível que o uso dessa tecnologia possa deixar esse processo cada vez mais ameno. Como exemplo, temos os sistemas de tutoria inteligentes que usam algoritmos de IA para avaliar o desempenho dos alunos e fornecer feedback personalizado e adaptado em tempo real. Nesta perspectiva, este trabalho tem por objetivo realizar uma revisão narrativa da literatura para identificar possibilidades e desafios no uso do ChatGPT no processo de ensino e aprendizagem de áreas e disciplinas diversas durante o curso de Ciência da Computação e temas voltados para a programação, no geral. Para isso serão definidas palavras chaves relacionadas tanto em português quanto inglês, perguntas de pesquisa que permitam catalogar os trabalhos encontrados de forma sistemática e a realização de busca por trabalhos em bases de dados bem conhecidos como Google Acadêmico e ACM. O foco do estudo é a programação, mas, resultados mais gerais também serão considerados e relacionados para o contexto desejado. Por fim, espera-se que em primeiro âmbito essa pesquisa contribua positivamente no ensino e na aprendizagem na área de programação, promovendo o uso responsável e ético da ferramenta.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/36596,"estamos vivendo uma fase de inserção tecnológica de um novo sistema de recuperação de informação de forma fácil e bastante eficiente: o chatgpt. diante do surgimento dessa promissora ferramenta, há diversos casos em que o ensino/aprendizagem vem se moldando considerando as possibilidades que ela nos oferece. no ensino superior especificamente, durante os primeiros semestres, o processo de adaptação ao ensino na graduação se torna um grande desafio para muitos e é possível que o uso dessa tecnologia possa deixar esse processo cada vez mais ameno. como exemplo, temos os sistemas de tutoria inteligentes que usam algoritmos de ia para avaliar o desempenho dos alunos e fornecer feedback personalizado e adaptado em tempo real. nesta perspectiva, este trabalho tem por objetivo realizar uma revisão narrativa da literatura para identificar possibilidades e desafios no uso do chatgpt no processo de ensino e aprendizagem de áreas e disciplinas diversas durante o curso de ciência da computação e temas voltados para a programação, no geral. para isso serão definidas palavras chaves relacionadas tanto em português quanto inglês, perguntas de pesquisa que permitam catalogar os trabalhos encontrados de forma sistemática e a realização de busca por trabalhos em bases de dados bem conhecidos como google acadêmico e acm. o foco do estudo é a programação, mas, resultados mais gerais também serão considerados e relacionados para o contexto desejado. por fim, espera-se que em primeiro âmbito essa pesquisa contribua positivamente no ensino e na aprendizagem na área de programação, promovendo o uso responsável e ético da ferramenta."
148,2023,ForHealth: desenvolvimento de aplicação para o estudo e combate à propagação de doenças.,"GADÊLHA FILHO, Igor Franca.","MONTEIRO, João Arthur Brunet.","Com o recente caso pandêmico vimos o quanto nosso
país estava despreparado para receber uma demanda tão alta de
pacientes em hospitais, muitos desses casos poderiam ter sido
evitados caso medidas de prevenção fossem adotadas mais
rapidamente. Nesse contexto, com dados médicos gerados e
tratados de uma forma mais inteligente, o aumento rápido de
casos de uma determinada doença poderia ser combatido de
maneira mais eficaz, uma vez que a população poderia ser
alertada sobre as doenças em crescimento, das zonas com maior
incidência e os meios de se prevenir. Com isso, o objetivo do
trabalho foi desenvolver uma aplicação para o atendimento
médico, supervisionada por uma profissional, que poderia ser
adotada por clínicas e postos de saúde, com a finalidade de
demonstrar que a propagação das doenças pode ser diminuída
caso façamos melhor uso desses dados, mostrando as autoridades
potenciais focos de propagação, remédios, sintomas e doenças em
alta. A aplicação foi validada durante seu desenvolvimento por
profissionais de saúde e acadêmicos de saúde. A avaliação da
aplicação foi realizada em um formulário respondido por 54
pessoas, os resultados comprovaram que a aplicação pode ser bem
útil à sociedade.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/35962,"com o recente caso pandêmico vimos o quanto nosso país estava despreparado para receber uma demanda tão alta de pacientes em hospitais, muitos desses casos poderiam ter sido evitados caso medidas de prevenção fossem adotadas mais rapidamente. nesse contexto, com dados médicos gerados e tratados de uma forma mais inteligente, o aumento rápido de casos de uma determinada doença poderia ser combatido de maneira mais eficaz, uma vez que a população poderia ser alertada sobre as doenças em crescimento, das zonas com maior incidência e os meios de se prevenir. com isso, o objetivo do trabalho foi desenvolver uma aplicação para o atendimento médico, supervisionada por uma profissional, que poderia ser adotada por clínicas e postos de saúde, com a finalidade de demonstrar que a propagação das doenças pode ser diminuída caso façamos melhor uso desses dados, mostrando as autoridades potenciais focos de propagação, remédios, sintomas e doenças em alta. a aplicação foi validada durante seu desenvolvimento por profissionais de saúde e acadêmicos de saúde. a avaliação da aplicação foi realizada em um formulário respondido por pessoas, os resultados comprovaram que a aplicação pode ser bem útil à sociedade."
149,2023,Aperfeiçoando o reconhecimento óptico de caracteres em imagens de documentos pessoais.,"FARIAS, Walisson Nascimento de.","GOMES, Herman Martins.","O reconhecimento óptico de caracteres (OCR) desempenha um papel fundamental na digitalização e processamento de documentos pessoais, no entanto, enfrenta desafios significativos de precisão e eficiência, visto que as ferramentas que realizam OCR ainda dependem muito da qualidade da entrada de dados e das condições em que os documentos são escaneados ou fotografados. Para aperfeiçoar o reconhecimento óptico de caracteres (OCR), propõe-se a utilização da combinação de técnicas de pré-processamento e pós-processamento a fim de melhorar a qualidade do OCR. O processo inicia-se através da coleta de um conjunto de dados representativo de imagens de documentos pessoais. Após a coleta, realiza-se o pré-processamento e pós-processamento das imagens, seguindo então do OCR e a utilização de uma métrica que avalia o OCR obtido. As técnicas de pré-processamento incluíram modificação do DPI das imagens, suavização da imagem e conversão para escala de cinza, seguida pela aplicação do OCR. Além disso, houve um pós-processamento para remover a acentuação do texto extraído e convertê-lo em letras maiúsculas. Os resultados indicaram que o pré-processamento melhorou significativamente a precisão do OCR para documentos de identidade (RG), aumentando o F1-Score de 0.33 (sem pré-processamento) para 0.53 (com pré-processamento). Para imagens de CPF, o pré-processamento resultou em uma precisão de 73.48% e uma taxa de erro de 26.52%, enquanto o OCR sem pré-processamento teve uma precisão de 36.46% e uma taxa de erro de 63.54%. Este estudo visa investigar técnicas com o propósito de melhorar o reconhecimento óptico de caracteres em documentos pessoais, contribuindo para maior precisão do OCR, com potenciais benefícios para aplicações que realizam a extração de conteúdo de imagens de documentos pessoais.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/34848,"o reconhecimento óptico de caracteres (ocr) desempenha um papel fundamental na digitalização e processamento de documentos pessoais, no entanto, enfrenta desafios significativos de precisão e eficiência, visto que as ferramentas que realizam ocr ainda dependem muito da qualidade da entrada de dados e das condições em que os documentos são escaneados ou fotografados. para aperfeiçoar o reconhecimento óptico de caracteres (ocr), propõe-se a utilização da combinação de técnicas de pré-processamento e pós-processamento a fim de melhorar a qualidade do ocr. o processo inicia-se através da coleta de um conjunto de dados representativo de imagens de documentos pessoais. após a coleta, realiza-se o pré-processamento e pós-processamento das imagens, seguindo então do ocr e a utilização de uma métrica que avalia o ocr obtido. as técnicas de pré-processamento incluíram modificação do dpi das imagens, suavização da imagem e conversão para escala de cinza, seguida pela aplicação do ocr. além disso, houve um pós-processamento para remover a acentuação do texto extraído e convertê-lo em letras maiúsculas. os resultados indicaram que o pré-processamento melhorou significativamente a precisão do ocr para documentos de identidade (rg), aumentando o f1-score de . (sem pré-processamento) para . (com pré-processamento). para imagens de cpf, o pré-processamento resultou em uma precisão de . % e uma taxa de erro de . %, enquanto o ocr sem pré-processamento teve uma precisão de . % e uma taxa de erro de . %. este estudo visa investigar técnicas com o propósito de melhorar o reconhecimento óptico de caracteres em documentos pessoais, contribuindo para maior precisão do ocr, com potenciais benefícios para aplicações que realizam a extração de conteúdo de imagens de documentos pessoais."
150,2023,Análise do desempenho das equipes do NBB nas últimas três temporadas da liga.,"NUNES, Felipe Emanuel de Farias.","CAMPELO, Claudio Elízio Calazans.","Este artigo oferece um estudo sobre a evolução do basquete brasileiro, empregando Índices Estatísticos de Desempenho (IED) como métrica para avaliar o desempenho das equipes no contexto das três temporadas mais recentes do Novo Basquete Brasil (NBB), que abrangem o período de 2021 a 2023. O objetivo central desta pesquisa é explorar e analisar o desempenho das equipes de maior destaque no cenário do basquete brasileiro. Os dados utilizados nesta análise foram coletados a partir da plataforma da Liga Nacional de Basquete (LNB), a entidade responsável pela organização e gestão do NBB. Foram analisados 883 jogos ao longo dessas três temporadas, abrangendo diversos índices estatísticos, que incluem a média e o desvio padrão de diversos parâmetros, tais como pontuação, arremessos (tentados e convertidos), aproveitamento de arremessos de dois pontos, três pontos e lances livres, assistências, rebotes, roubadas de bola, erros, bloqueios (tocos), eficiência e outros índices avançados associados ao esporte do basquete. Os dados foram comparados utilizando a análise de variância (ANOVA) e os valores de referência foram calculados a partir de percentis, permitindo uma análise comparativa e a identificação de tendências. Nesse contexto, a temporada de 2022 emergiu como aquela que registrou os índices mais baixos,
especialmente em termos de aproveitamento de arremessos, eficiência, média de pontos e assistências. Por outro lado, as outras duas temporadas analisadas apresentaram números similares na maioria dos índices estudados, o que pode sugerir uma certa estabilidade nesses aspectos ao longo desse período. Outro ponto observado no estudo é que as equipes que competem no NBB precisam atingir um alto nível de desempenho, conforme evidenciado pelos percentis utilizados como referência. Além disso, o estudo revela uma clara tendência ao aumento do uso de arremessos de três pontos nos últimos anos do NBB, alinhando-se com as mudanças observadas no basquete em nível global, onde a bola de três pontos se tornou um elemento fundamental nas estratégias ofensivas.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/34847,"este artigo oferece um estudo sobre a evolução do basquete brasileiro, empregando índices estatísticos de desempenho (ied) como métrica para avaliar o desempenho das equipes no contexto das três temporadas mais recentes do novo basquete brasil (nbb), que abrangem o período de a . o objetivo central desta pesquisa é explorar e analisar o desempenho das equipes de maior destaque no cenário do basquete brasileiro. os dados utilizados nesta análise foram coletados a partir da plataforma da liga nacional de basquete (lnb), a entidade responsável pela organização e gestão do nbb. foram analisados jogos ao longo dessas três temporadas, abrangendo diversos índices estatísticos, que incluem a média e o desvio padrão de diversos parâmetros, tais como pontuação, arremessos (tentados e convertidos), aproveitamento de arremessos de dois pontos, três pontos e lances livres, assistências, rebotes, roubadas de bola, erros, bloqueios (tocos), eficiência e outros índices avançados associados ao esporte do basquete. os dados foram comparados utilizando a análise de variância (anova) e os valores de referência foram calculados a partir de percentis, permitindo uma análise comparativa e a identificação de tendências. nesse contexto, a temporada de emergiu como aquela que registrou os índices mais baixos, especialmente em termos de aproveitamento de arremessos, eficiência, média de pontos e assistências. por outro lado, as outras duas temporadas analisadas apresentaram números similares na maioria dos índices estudados, o que pode sugerir uma certa estabilidade nesses aspectos ao longo desse período. outro ponto observado no estudo é que as equipes que competem no nbb precisam atingir um alto nível de desempenho, conforme evidenciado pelos percentis utilizados como referência. além disso, o estudo revela uma clara tendência ao aumento do uso de arremessos de três pontos nos últimos anos do nbb, alinhando-se com as mudanças observadas no basquete em nível global, onde a bola de três pontos se tornou um elemento fundamental nas estratégias ofensivas."
151,2023,Viés na IA: como o viés algoritmo influencia na perpetuação de estereótipos e desigualdades existentes.,"SENA, Erick Morais de.","GARCIA, Francilene Procópio.","O avanço da Inteligência Artificial (IA) tem revolucionado diversos setores da sociedade, como a saúde, indústria, educação, justiça, entre outros. Entretanto, essa crescente incorporação da IA em nossas vidas também representa desafios significativos relacionados a sua aceitação generalizada. Um dos problemas mais cruciais é o viés algorítmico presente em sistemas de IA, que pode levar a decisões discriminatórias e injustas, perpetuando preconceitos e afastando as minorias das áreas essenciais, como emprego, saúde, educação, justiça e outros setores fundamentais da sociedade. Este trabalho tem como objetivo relacionar o tópico do viés algoritmo com os impactos das decisões automatizadas sobre as minorias.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/34844,"o avanço da inteligência artificial (ia) tem revolucionado diversos setores da sociedade, como a saúde, indústria, educação, justiça, entre outros. entretanto, essa crescente incorporação da ia em nossas vidas também representa desafios significativos relacionados a sua aceitação generalizada. um dos problemas mais cruciais é o viés algorítmico presente em sistemas de ia, que pode levar a decisões discriminatórias e injustas, perpetuando preconceitos e afastando as minorias das áreas essenciais, como emprego, saúde, educação, justiça e outros setores fundamentais da sociedade. este trabalho tem como objetivo relacionar o tópico do viés algoritmo com os impactos das decisões automatizadas sobre as minorias."
152,2023,Análise de emoções em transcrições de Adventure Time.,"LOPES, Deilton Vasconcelos Figueiredo.","MARINHO, Leandro Balby.","Desenhos animados estão entre as mídias de entretenimento mais consumidas no mundo. Um dos principais motivos é o fato desse formato não ter tantas limitações físicas quanto o cinema tradicional, o que permite uma maior liberdade nos temas abordados e na construção das cenas. Uma das animações mais populares dos últimos tempos, Adventure Time (exibido originalmente pelo canal Cartoon Network), é um exemplo perfeito disso. Ao longo de seus quase trezentos episódios, o desenho infantil aborda uma variedade de temas e adota vários estilos narrativos. No entanto, ao se analisar o enredo como um todo, essa quantidade grande de episódios pode tornar árdua a tarefa de acompanhar a complexidade emocional dos numerosos personagens, o que pode ser um empecilho ao se tentar compreender a profundidade da trama. Com o auxílio de modelos Transformers e da plataforma Hugging Face, este trabalho investiga uma abordagem de detecção de emoções nas transcrições de falas de personagens da obra. Os resultados demonstram que a abordagem é viável para este tipo de análise e identificam a vasta gama emocional neste desenho animado.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/34842,"desenhos animados estão entre as mídias de entretenimento mais consumidas no mundo. um dos principais motivos é o fato desse formato não ter tantas limitações físicas quanto o cinema tradicional, o que permite uma maior liberdade nos temas abordados e na construção das cenas. uma das animações mais populares dos últimos tempos, adventure time (exibido originalmente pelo canal cartoon network), é um exemplo perfeito disso. ao longo de seus quase trezentos episódios, o desenho infantil aborda uma variedade de temas e adota vários estilos narrativos. no entanto, ao se analisar o enredo como um todo, essa quantidade grande de episódios pode tornar árdua a tarefa de acompanhar a complexidade emocional dos numerosos personagens, o que pode ser um empecilho ao se tentar compreender a profundidade da trama. com o auxílio de modelos transformers e da plataforma hugging face, este trabalho investiga uma abordagem de detecção de emoções nas transcrições de falas de personagens da obra. os resultados demonstram que a abordagem é viável para este tipo de análise e identificam a vasta gama emocional neste desenho animado."
153,2023,MeuHábito: uma ferramenta para o auxílio da criação e transformação de hábitos.,"BORGES, Áthila Matheus Barros.","ANDRADE, Wilkerson de Lucena.","A maior parte das decisões cotidianas é influenciada pelos nossos hábitos. Muitas pessoas almejam iniciar atividades como leitura ou exercícios físicos, por exemplo, mas deixam de fazê-lo devido à falta de organização e incentivo. O MeuHábito foi desenvolvido com o intuito de fornecer suporte para a melhoria e desenvolvimento de hábitos, oferecendo funcionalidades ausentes em ferramentas similares, com um design simples e intuitivo que possibilita sua utilização por diversos públicos. A versão inicial do MeuHábito foi submetida à avaliação por parte de usuários comuns, os quais compartilharam suas impressões sobre o sistema. Com base no feedback recebido, ficou evidente que os usuários tiveram uma visão positiva, indicando que o aplicativo é funcional e está pronto para ser aprimorado visando atingir um público mais amplo.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/34840,"a maior parte das decisões cotidianas é influenciada pelos nossos hábitos. muitas pessoas almejam iniciar atividades como leitura ou exercícios físicos, por exemplo, mas deixam de fazê-lo devido à falta de organização e incentivo. o meuhábito foi desenvolvido com o intuito de fornecer suporte para a melhoria e desenvolvimento de hábitos, oferecendo funcionalidades ausentes em ferramentas similares, com um design simples e intuitivo que possibilita sua utilização por diversos públicos. a versão inicial do meuhábito foi submetida à avaliação por parte de usuários comuns, os quais compartilharam suas impressões sobre o sistema. com base no feedback recebido, ficou evidente que os usuários tiveram uma visão positiva, indicando que o aplicativo é funcional e está pronto para ser aprimorado visando atingir um público mais amplo."
154,2023,Smart wallet: aplicativo para controle financeiro inteligente com comandos de voz.,"PORTO, Arthur Dantas.","FECHINE, Joseana Macêdo.","A gestão eficaz das finanças pessoais é fundamental para a saúde financeira e, consequentemente, para a qualidade de vida. Para melhorar a gestão financeira, muitas pessoas recorrem a aplicativos de controle financeiro para smartphones. Pesquisas demonstraram que esses aplicativos têm um impacto positivo na administração financeira dos usuários. No entanto, alguns usuários enfrentam dificuldades na utilização desses aplicativos visto que a maioria exige atualizações manuais dos dados. Além disso, aplicativos com automatização muitas vezes carecem de detalhes sobre os gastos, deixando os usuários questionando como gastaram seu dinheiro. Tendo isso em vista, o propósito do trabalho ora descrito é desenvolver um aplicativo Android, a fim de facilitar o controle financeiro dos seus usuários com o registro de finanças, por meio de comando de voz. O uso da voz tornará mais fácil e prático o registro em qualquer momento do dia, incluindo o exato momento em que uma alteração em suas finanças é feita, desde o recebimento de um salário até um gasto com um alimento comprado no caminho para o trabalho.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/34838,"a gestão eficaz das finanças pessoais é fundamental para a saúde financeira e, consequentemente, para a qualidade de vida. para melhorar a gestão financeira, muitas pessoas recorrem a aplicativos de controle financeiro para smartphones. pesquisas demonstraram que esses aplicativos têm um impacto positivo na administração financeira dos usuários. no entanto, alguns usuários enfrentam dificuldades na utilização desses aplicativos visto que a maioria exige atualizações manuais dos dados. além disso, aplicativos com automatização muitas vezes carecem de detalhes sobre os gastos, deixando os usuários questionando como gastaram seu dinheiro. tendo isso em vista, o propósito do trabalho ora descrito é desenvolver um aplicativo android, a fim de facilitar o controle financeiro dos seus usuários com o registro de finanças, por meio de comando de voz. o uso da voz tornará mais fácil e prático o registro em qualquer momento do dia, incluindo o exato momento em que uma alteração em suas finanças é feita, desde o recebimento de um salário até um gasto com um alimento comprado no caminho para o trabalho."
155,2023,O excesso de tempo frente as telas e os resultados sobre os possíveis impactos no desenvolvimento infantil.,"Brito Junior, Wander Medeiros de","BARROS, Marcelo Alves de.","Nos últimos anos houve uma expansão dos recursos tecnológicos utilizados por todas as faixas etárias e que foram intensificados em seus tempos de uso durante a pandemia. A decorrência desse uso se intensificou entre o público infantil e adolescentes através de acessos aos equipamentos tecnológicos. O alerta é sobre o excesso de tempo de exposição às telas, pois a fase da infância é marcada pelas descobertas de si mesmo e o desenvolvimento social. Assim, a dependência dos recursos digitais pode oferecer riscos para a saúde física, mental e comportamental das crianças, além de comprometer a interação social com outras crianças e adultos. O presente estudo busca identificar quais são os impactos ocorridos pelo excesso de tempo em frente às telas através de uma revisão de literatura com análise sistemática, investigando, por meio análises de dados baseados em pesquisas acadêmicas, acerca dos impactos no uso das telas no desenvolvimento infantil; demonstrando a importância das atividades lúdicas para o desenvolvimento infantil; e apresentando sugestões corretas para uso apropriado das telas e recursos tecnológicos na fase infantil. Quanto à metodologia, trata-se de uma pesquisa de abordagem qualitativa, do tipo exploratória e de natureza de revisão bibliográfica. Como resultados encontramos três pesquisas acadêmicas que se dedicam ao tema. Conclui-se que a exposição às telas é um fator que interfere no desenvolvimento das crianças, mas que uma solução viável é a incorporação do aparato tecnológico às brincadeiras lúdicas das mesmas.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/34827,"nos últimos anos houve uma expansão dos recursos tecnológicos utilizados por todas as faixas etárias e que foram intensificados em seus tempos de uso durante a pandemia. a decorrência desse uso se intensificou entre o público infantil e adolescentes através de acessos aos equipamentos tecnológicos. o alerta é sobre o excesso de tempo de exposição às telas, pois a fase da infância é marcada pelas descobertas de si mesmo e o desenvolvimento social. assim, a dependência dos recursos digitais pode oferecer riscos para a saúde física, mental e comportamental das crianças, além de comprometer a interação social com outras crianças e adultos. o presente estudo busca identificar quais são os impactos ocorridos pelo excesso de tempo em frente às telas através de uma revisão de literatura com análise sistemática, investigando, por meio análises de dados baseados em pesquisas acadêmicas, acerca dos impactos no uso das telas no desenvolvimento infantil; demonstrando a importância das atividades lúdicas para o desenvolvimento infantil; e apresentando sugestões corretas para uso apropriado das telas e recursos tecnológicos na fase infantil. quanto à metodologia, trata-se de uma pesquisa de abordagem qualitativa, do tipo exploratória e de natureza de revisão bibliográfica. como resultados encontramos três pesquisas acadêmicas que se dedicam ao tema. conclui-se que a exposição às telas é um fator que interfere no desenvolvimento das crianças, mas que uma solução viável é a incorporação do aparato tecnológico às brincadeiras lúdicas das mesmas."
156,2023,Beez: aplicativo que une pessoas à formas de entretenimento.,"REGIS, Franklin Oliveira.","ALVES, Everton Leandro Galdino.","O entretenimento sempre fez parte do dia a dia do ser humano. Contudo, mesmo com o avanço tecnológico, ainda é um desafio buscar formas de entretenimento de forma rápida e organizada na internet. A partir dessa necessidade surgiu o Beez, uma aplicação que mostra e divulga possibilidades de lazer e entretenimento nas proximidades com base nos gostos e interesses de cada usuário. A aplicação foi desenvolvida para dispositivos Android usando o serviço do Firebase. Ao final do projeto o sistema foi posto à prova e avaliado como satisfatório por potenciais usuários, demonstrando a viabilidade do Beez como solução neste contexto pouco explorado.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/34823,"o entretenimento sempre fez parte do dia a dia do ser humano. contudo, mesmo com o avanço tecnológico, ainda é um desafio buscar formas de entretenimento de forma rápida e organizada na internet. a partir dessa necessidade surgiu o beez, uma aplicação que mostra e divulga possibilidades de lazer e entretenimento nas proximidades com base nos gostos e interesses de cada usuário. a aplicação foi desenvolvida para dispositivos android usando o serviço do firebase. ao final do projeto o sistema foi posto à prova e avaliado como satisfatório por potenciais usuários, demonstrando a viabilidade do beez como solução neste contexto pouco explorado."
157,2023,Um guia para educação em cidadania digital voltado ao ensino fundamental.,"CRUZ, Jaciane de Oliveira.","SAMPAIO, Lívia Maria Rodrigues Sampaio.","O mundo se aproxima a quase 5 bilhões de usuários na internet, tornando-se a sua utilização um hábito imperceptível. Estamos conectados e precisamos seguir um conjunto de regras para um relacionamento virtual agradável, para isso, surge a cidadania digital. Cidadania digital pode ser entendido como um conjunto de normas que devemos seguir para utilizarmos o mundo digital, e as diferentes tecnologias que o constituem, com consciência, responsabilidade, ética e segurança. A temática abrange pessoas de todas as idades e gera especial atenção para as crianças e adolescentes. Considerando esse público, existem iniciativas relevantes de grandes empresas como a Google™, através da plataforma Interland[4], e de ONGs especializadas no uso seguro da internet, tais como SaferNet[9], nic.br e cetic.br[2]. Apesar dessas ações, ainda é um desafio a introdução de trilhas de conhecimento em cidadania digital para crianças e adolescentes na escola. O objetivo dessa pesquisa é desenvolver uma trilha de conhecimento para educação em cidadania digital voltada para o público do Ensino Fundamental (anos iniciais) que seja lúdica e participativa, com produção de material didático para alunos e professores, desenvolverem conhecimento e prática em cidadania digital.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/34750,"o mundo se aproxima a quase bilhões de usuários na internet, tornando-se a sua utilização um hábito imperceptível. estamos conectados e precisamos seguir um conjunto de regras para um relacionamento virtual agradável, para isso, surge a cidadania digital. cidadania digital pode ser entendido como um conjunto de normas que devemos seguir para utilizarmos o mundo digital, e as diferentes tecnologias que o constituem, com consciência, responsabilidade, ética e segurança. a temática abrange pessoas de todas as idades e gera especial atenção para as crianças e adolescentes. considerando esse público, existem iniciativas relevantes de grandes empresas como a google™, através da plataforma interland[ ], e de ongs especializadas no uso seguro da internet, tais como safernet[ ], nic.br e cetic.br[ ]. apesar dessas ações, ainda é um desafio a introdução de trilhas de conhecimento em cidadania digital para crianças e adolescentes na escola. o objetivo dessa pesquisa é desenvolver uma trilha de conhecimento para educação em cidadania digital voltada para o público do ensino fundamental (anos iniciais) que seja lúdica e participativa, com produção de material didático para alunos e professores, desenvolverem conhecimento e prática em cidadania digital."
158,2023,Poda estruturada de redes neurais profundas: um estudo sobre a utilização de métodos de explicabilidade como critério de poda.,"FREITAS, Eduardo Macedo Cavalcanti.","GOMES, Herman Martins.","O avanço dos modelos de Deep Learning tem proporcionado resultados excepcionais em tarefas de visão computacional e processamento de linguagem natural. No entanto, o aumento do tamanho e complexidade desses modelos traz desafios significativos em termos de infraestrutura e custos operacionais. Nesse contexto, a técnica de poda em redes neurais profundas surge como uma solução para reduzir o tamanho dos modelos, mantendo níveis similares de acurácia. Este estudo investiga o impacto da utilização de métricas de explicabilidade (Conductance e Layer-wise Relevance Propagation) como critério de poda, comparando-as com a poda por magnitude de pesos e a poda aleatória. Diferentes percentuais de poda são avaliados, considerando tanto a poda de oneshot quanto a poda iterativa. Os resultados mostram uma correlação positiva entre o uso de métricas de explicabilidade e a melhoria na qualidade dos modelos podados, incluindo maior acurácia, menor variância e a capacidade de realizar podas mais agressivas sem perda significativa de acurácia. Esses métodos promissores têm o potencial de melhorar a operacionalização e reduzir os custos associados aos modelos de Deep Learning em larga escala.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/34744,"o avanço dos modelos de deep learning tem proporcionado resultados excepcionais em tarefas de visão computacional e processamento de linguagem natural. no entanto, o aumento do tamanho e complexidade desses modelos traz desafios significativos em termos de infraestrutura e custos operacionais. nesse contexto, a técnica de poda em redes neurais profundas surge como uma solução para reduzir o tamanho dos modelos, mantendo níveis similares de acurácia. este estudo investiga o impacto da utilização de métricas de explicabilidade (conductance e layer-wise relevance propagation) como critério de poda, comparando-as com a poda por magnitude de pesos e a poda aleatória. diferentes percentuais de poda são avaliados, considerando tanto a poda de oneshot quanto a poda iterativa. os resultados mostram uma correlação positiva entre o uso de métricas de explicabilidade e a melhoria na qualidade dos modelos podados, incluindo maior acurácia, menor variância e a capacidade de realizar podas mais agressivas sem perda significativa de acurácia. esses métodos promissores têm o potencial de melhorar a operacionalização e reduzir os custos associados aos modelos de deep learning em larga escala."
159,2023,Explorando modelos preditivos para prever características e comportamentos de aplicações.,"PAIVA, Sheila Maria Mendes.","MORAIS, Fábio Jorge Almeida.","Em um mercado globalizado e competitivo as empresas necessitam de processos que estejam focados no uso eficiente de seus recursos. Em relação a custos computacionais, elas vêm se beneficiando nas últimas décadas com a adoção de computação em nuvem, o que promoveu economias significativas para empresas. No entanto, esse cenário se estabilizou e novos desafios surgem na gestão destes recursos. Para gerir o uso eficiente de recursos computacionais, afloram softwares e algoritmos que se utilizam de modelos preditivos para prever comportamentos e reagir para adequar sua infraestrutura à demanda de uso em tempo real. O presente trabalho tem como objetivo explorar técnicas preditivas de aprendizagem de máquina para prever comportamentos de aplicações baseados no histórico de consumo de memória, requisição e latência, a fim de determinar como gerenciar melhor esses recursos. A análise foi dividida em pré-processamento e limpeza dos dados, em seguida os dados foram submetidos ao processamento de algoritmos que detectam comportamentos embutidos nos dados e foi gerada uma predição que foi utilizada para estimar comportamentos futuros da aplicação. Para ajudar na detecção de comportamentos de aplicações a partir de dados históricos de consumo e estimar seu comportamento, no artigo foram abordadas diferentes técnicas relacionadas a predição de séries temporais. Essas estimativas podem ser utilizadas para realizar aumento ou redução da infraestrutura, baseado em comportamentos de inatividade ou uso excessivo de recursos.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/34616,"em um mercado globalizado e competitivo as empresas necessitam de processos que estejam focados no uso eficiente de seus recursos. em relação a custos computacionais, elas vêm se beneficiando nas últimas décadas com a adoção de computação em nuvem, o que promoveu economias significativas para empresas. no entanto, esse cenário se estabilizou e novos desafios surgem na gestão destes recursos. para gerir o uso eficiente de recursos computacionais, afloram softwares e algoritmos que se utilizam de modelos preditivos para prever comportamentos e reagir para adequar sua infraestrutura à demanda de uso em tempo real. o presente trabalho tem como objetivo explorar técnicas preditivas de aprendizagem de máquina para prever comportamentos de aplicações baseados no histórico de consumo de memória, requisição e latência, a fim de determinar como gerenciar melhor esses recursos. a análise foi dividida em pré-processamento e limpeza dos dados, em seguida os dados foram submetidos ao processamento de algoritmos que detectam comportamentos embutidos nos dados e foi gerada uma predição que foi utilizada para estimar comportamentos futuros da aplicação. para ajudar na detecção de comportamentos de aplicações a partir de dados históricos de consumo e estimar seu comportamento, no artigo foram abordadas diferentes técnicas relacionadas a predição de séries temporais. essas estimativas podem ser utilizadas para realizar aumento ou redução da infraestrutura, baseado em comportamentos de inatividade ou uso excessivo de recursos."
160,2023,Avaliação da acessibilidade de aplicações web populares conforme a norma técnica NBR 17060.,"SOUZA, Nayara Silva Pereira de.","OLIVEIRA, Maxwell Guimarães de.","A tecnologia, com o passar dos anos, trouxe mudanças significativas para a sociedade, em que a utilização da web para viabilização de serviços e informações tem se tornado cada vez mais intensa. Assim, é imprescindível garantir que todos os cidadãos, independente de qualquer deficiência ou outro tipo de impedimento, possam acessar conteúdos e serviços disponibilizados na web. No Brasil, a Associação Brasileira de Normas Técnicas (ABNT), lançou em 2022, a Norma Técnica Brasileira (NBR) 17060, uma norma técnica de acessibilidade que visa eliminar barreiras encontradas na utilização de páginas web e aplicativos em dispositivos móveis, facilitando o acesso de pessoas com deficiência a esses ambientes virtuais. O objetivo desta pesquisa é verificar o impacto dessa regulamentação em aplicações popularmente utilizadas pelos usuários web. Para isso, foi observada uma amostra composta pelos webApps Amazon (e-commerce) e YouTube (vídeo), com a análise dos seus padrões de acessibilidade e a avaliação do seu nível de conformidade com a norma, utilizadas para isso as ferramentas de análise: axe DevTools e WAVE Evaluation Tool, de modo a apresentar um relatório descrevendo os problemas comuns identificados durante a investigação, assim como sugestões de adequação às normas para os sites.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/34615,"a tecnologia, com o passar dos anos, trouxe mudanças significativas para a sociedade, em que a utilização da web para viabilização de serviços e informações tem se tornado cada vez mais intensa. assim, é imprescindível garantir que todos os cidadãos, independente de qualquer deficiência ou outro tipo de impedimento, possam acessar conteúdos e serviços disponibilizados na web. no brasil, a associação brasileira de normas técnicas (abnt), lançou em , a norma técnica brasileira (nbr) , uma norma técnica de acessibilidade que visa eliminar barreiras encontradas na utilização de páginas web e aplicativos em dispositivos móveis, facilitando o acesso de pessoas com deficiência a esses ambientes virtuais. o objetivo desta pesquisa é verificar o impacto dessa regulamentação em aplicações popularmente utilizadas pelos usuários web. para isso, foi observada uma amostra composta pelos webapps amazon (e-commerce) e youtube (vídeo), com a análise dos seus padrões de acessibilidade e a avaliação do seu nível de conformidade com a norma, utilizadas para isso as ferramentas de análise: axe devtools e wave evaluation tool, de modo a apresentar um relatório descrevendo os problemas comuns identificados durante a investigação, assim como sugestões de adequação às normas para os sites."
161,2023,POMOSYNC: uma aplicação para Pomodoro em grupo.,"MATIAS, Lucio Nathan Trigueiro.","ALVES, Everton Leandro Galdino.","Em ambientes de trabalho e estudo cada vez mais digitais e colaborativos, manter a produtividade individual e de equipe pode ser um desafio significativo. A técnica Pomodoro, desenvolvida nos anos 80, é uma metodologia de gerenciamento de tempo amplamente usada para aumentar a produtividade, mas sua implementação em um contexto colaborativo pode ser difícil. Portanto, a necessidade de uma solução digital eficaz para facilitar a implementação colaborativa da técnica Pomodoro se torna clara. O PomoSync surge como uma aplicação web que visa abordar esse problema, permitindo aos usuários organizar e participar de sessões Pomodoro de forma colaborativa. O objetivo deste trabalho é detalhar o processo de desenvolvimento desta aplicação, analisando seus aspectos técnicos, metodológicos e seu impacto no aumento da produtividade em ambientes colaborativos. Os resultados obtidos sugerem um bom grau de satisfação do usuário com a usabilidade e eficácia do PomoSync, validando a necessidade de tal solução e, a partir das críticas feitas ao sistema, são sugeridas futuras melhorias para a aplicação.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/34614,"em ambientes de trabalho e estudo cada vez mais digitais e colaborativos, manter a produtividade individual e de equipe pode ser um desafio significativo. a técnica pomodoro, desenvolvida nos anos , é uma metodologia de gerenciamento de tempo amplamente usada para aumentar a produtividade, mas sua implementação em um contexto colaborativo pode ser difícil. portanto, a necessidade de uma solução digital eficaz para facilitar a implementação colaborativa da técnica pomodoro se torna clara. o pomosync surge como uma aplicação web que visa abordar esse problema, permitindo aos usuários organizar e participar de sessões pomodoro de forma colaborativa. o objetivo deste trabalho é detalhar o processo de desenvolvimento desta aplicação, analisando seus aspectos técnicos, metodológicos e seu impacto no aumento da produtividade em ambientes colaborativos. os resultados obtidos sugerem um bom grau de satisfação do usuário com a usabilidade e eficácia do pomosync, validando a necessidade de tal solução e, a partir das críticas feitas ao sistema, são sugeridas futuras melhorias para a aplicação."
162,2023,Blockchain-enabled compliance for trustworthy Kubernetes cluster scanning.,"SILVA, Héricles Emanuel Gomes da.","BRITO, Andrey Elísio Monteiro.","Este artigo apresenta um sistema de certificação de conformidade que utiliza a tecnologia blockchaine um Ambiente de Execução Confiável (TEE) para escaneamento seguro e confiável de clusters Kubernetes. O objetivo é ajudar as organizações a superarem os desafios de manter padrões da indústria e requisitos regulatórios em ambientes Kubernetes dinâmicos e distribuídos. O design do sistema incorpora um TEE para garantir processos de escaneamento seguros e aproveita a tecnologia blockchain para fornecer transparência e confiança no processo de certificação. O artigo fornece perspectivas sobre o fluxo de execução do processo de certificação de conformidade e apresenta a avaliação e resultados da implementação do conceito. Os resultados demonstram que o sistema aborda efetivamente preocupações relacionadas à confiabilidade, transparência e responsabilidade na certificação de clusters Kubernetes. No entanto, são necessários esforços adicionais de pesquisa e desenvolvimento para refinar e otimizar o sistema para implantação pronta para produção.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/34598,"este artigo apresenta um sistema de certificação de conformidade que utiliza a tecnologia blockchaine um ambiente de execução confiável (tee) para escaneamento seguro e confiável de clusters kubernetes. o objetivo é ajudar as organizações a superarem os desafios de manter padrões da indústria e requisitos regulatórios em ambientes kubernetes dinâmicos e distribuídos. o design do sistema incorpora um tee para garantir processos de escaneamento seguros e aproveita a tecnologia blockchain para fornecer transparência e confiança no processo de certificação. o artigo fornece perspectivas sobre o fluxo de execução do processo de certificação de conformidade e apresenta a avaliação e resultados da implementação do conceito. os resultados demonstram que o sistema aborda efetivamente preocupações relacionadas à confiabilidade, transparência e responsabilidade na certificação de clusters kubernetes. no entanto, são necessários esforços adicionais de pesquisa e desenvolvimento para refinar e otimizar o sistema para implantação pronta para produção."
163,2023,Estudo comparativo entre ferramentas de inicialização de projetos web.,"SANTOS, Gabriel Nascimento.","GUERRERO, Dalton Dario Serey.","Com o crescente avanço do ecossistema web nos últimos anos, tem havido um surgimento constante de novos frameworks e bibliotecas. Entre eles, o ReactJS, lançado em 2013 pela Meta, destacou-se como uma poderosa ferramenta para a criação de interfaces interativas, complexas e eficientes, baseadas em componentes. Atualmente, o ReactJS possui uma comunidade ativa de desenvolvedores e conta com uma sólida documentação, consolidando-se como uma das principais tecnologias utilizadas no desenvolvimento web. Devido à sua ampla adoção em grandes empresas de diversos setores ao redor do mundo e ao crescente uso em novas aplicações web, a Meta e outras empresas estão constantemente buscando maneiras de facilitar e agilizar o início de projetos em React. Como resultado, surgiram ferramentas como o create-react-app (desenvolvido pela própria Meta), Vite e Parcel. O objetivo deste trabalho é analisar e comparar essas bibliotecas, considerando diferentes parâmetros, como o tempo de instalação utilizando os gerenciadores de pacotes mais comuns, npm e yarn, facilidade de configuração do projeto, estrutura de pastas e arquivos criados, bem como a qualidade e legibilidade do código necessário para sua utilização. Como contribuição, serão apresentadas sugestões para o aprimoramento dessas aplicações, levando em consideração os aspectos avaliados. O estudo visa oferecer insights valiosos para desenvolvedores que desejam iniciar projetos em React, auxiliando na escolha da melhor ferramenta e fornecendo recomendações para uma experiência mais eficiente e eficaz.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/34590,"com o crescente avanço do ecossistema web nos últimos anos, tem havido um surgimento constante de novos frameworks e bibliotecas. entre eles, o reactjs, lançado em pela meta, destacou-se como uma poderosa ferramenta para a criação de interfaces interativas, complexas e eficientes, baseadas em componentes. atualmente, o reactjs possui uma comunidade ativa de desenvolvedores e conta com uma sólida documentação, consolidando-se como uma das principais tecnologias utilizadas no desenvolvimento web. devido à sua ampla adoção em grandes empresas de diversos setores ao redor do mundo e ao crescente uso em novas aplicações web, a meta e outras empresas estão constantemente buscando maneiras de facilitar e agilizar o início de projetos em react. como resultado, surgiram ferramentas como o create-react-app (desenvolvido pela própria meta), vite e parcel. o objetivo deste trabalho é analisar e comparar essas bibliotecas, considerando diferentes parâmetros, como o tempo de instalação utilizando os gerenciadores de pacotes mais comuns, npm e yarn, facilidade de configuração do projeto, estrutura de pastas e arquivos criados, bem como a qualidade e legibilidade do código necessário para sua utilização. como contribuição, serão apresentadas sugestões para o aprimoramento dessas aplicações, levando em consideração os aspectos avaliados. o estudo visa oferecer insights valiosos para desenvolvedores que desejam iniciar projetos em react, auxiliando na escolha da melhor ferramenta e fornecendo recomendações para uma experiência mais eficiente e eficaz."
164,2023,PlaneJáUFCG: uma ferramenta para o planejamento de matrículas.,"CAVALCANTI, Rodrigo Eloy.","MASSONI, Tiago Lima.","O período de matrículas pode ser fonte de estresse e ansiedade para muitos graduandos da Universidade Federal de Campina Grande (UFCG). É comum estudantes ficarem confusos quanto a quais matérias serão cursadas no próximo semestre, isso devido a choques de horários, pré-requisitos e/ou preferências pessoais. Este trabalho tem o objetivo de desenvolver o PlaneJáUFCG, um sistema online para o planejamento de matrículas dos graduandos. Com o sistema, é possível que o estudante envie seu histórico acadêmico e, a partir dos pré-requisitos entre as disciplinas, dos horários destas e também das informações extraídas do histórico enviado, selecione quais disciplinas ele pode cursar no período vindouro. A aplicação permite, dessa forma, que os alunos montem de forma mais visual e consciente as suas matrículas. Os resultados obtidos indicam uma alta satisfação dos usuários com a simplicidade e usabilidade do PlaneJáUFCG. Para a evolução do sistema, alguns usuários sugeriram melhorias em questões relacionadas à acessibilidade na usabilidade da aplicação e também novas funcionalidades para o sistema.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/34529,"o período de matrículas pode ser fonte de estresse e ansiedade para muitos graduandos da universidade federal de campina grande (ufcg). é comum estudantes ficarem confusos quanto a quais matérias serão cursadas no próximo semestre, isso devido a choques de horários, pré-requisitos e/ou preferências pessoais. este trabalho tem o objetivo de desenvolver o planejáufcg, um sistema online para o planejamento de matrículas dos graduandos. com o sistema, é possível que o estudante envie seu histórico acadêmico e, a partir dos pré-requisitos entre as disciplinas, dos horários destas e também das informações extraídas do histórico enviado, selecione quais disciplinas ele pode cursar no período vindouro. a aplicação permite, dessa forma, que os alunos montem de forma mais visual e consciente as suas matrículas. os resultados obtidos indicam uma alta satisfação dos usuários com a simplicidade e usabilidade do planejáufcg. para a evolução do sistema, alguns usuários sugeriram melhorias em questões relacionadas à acessibilidade na usabilidade da aplicação e também novas funcionalidades para o sistema."
165,2023,Better Together: aplicação web para conectar programadores.,"LIMA, Matheus Vinicius Benevides.","CAMPELO, Cláudio Elízio Calazans.","Criar projetos de programação que necessitam de mais de um programador é uma prática comum na comunidade de desenvolvimento de software. Isso ocorre porque muitos projetos exigem uma equipe de programadores com diferentes habilidades e conhecimentos para serem concluídos de maneira eficiente e eficaz. É comum ver programadores buscando outros profissionais para colaborar em seus projetos e, assim, alcançar um resultado de alta qualidade e escalabilidade. Infelizmente, muitas vezes esse projeto não é levado adiante devido à falta de pessoas capacitadas e dispostas a trabalhar neles. O problema é a dificuldade em encontrar programadores qualificados e interessados em trabalhar em um projeto específico, o que pode levar a uma perda de tempo e recursos para aqueles que estão procurando por colaboradores. Nesse contexto, o presente projeto propõe uma solução: uma aplicação web que organiza e conecta programadores para realizar projetos em conjunto. O usuário que se cadastrar no site irá disponibilizar informações sobre suas habilidades e conhecimentos na área de programação, permitindo que seja conectado a projetos disponíveis de acordo com seu perfil. Além disso, o usuário também poderá criar seu próprio projeto, informando as tecnologias que serão utilizadas. Dessa forma, espera-se que, ao final deste projeto, os programadores que desejam criar algum projeto ou empreender consigam encontrar facilmente outros programadores capacitados e dispostos a trabalhar com eles, superando a dificuldade encontrada atualmente na procura por colaboradores.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/34527,"criar projetos de programação que necessitam de mais de um programador é uma prática comum na comunidade de desenvolvimento de software. isso ocorre porque muitos projetos exigem uma equipe de programadores com diferentes habilidades e conhecimentos para serem concluídos de maneira eficiente e eficaz. é comum ver programadores buscando outros profissionais para colaborar em seus projetos e, assim, alcançar um resultado de alta qualidade e escalabilidade. infelizmente, muitas vezes esse projeto não é levado adiante devido à falta de pessoas capacitadas e dispostas a trabalhar neles. o problema é a dificuldade em encontrar programadores qualificados e interessados em trabalhar em um projeto específico, o que pode levar a uma perda de tempo e recursos para aqueles que estão procurando por colaboradores. nesse contexto, o presente projeto propõe uma solução: uma aplicação web que organiza e conecta programadores para realizar projetos em conjunto. o usuário que se cadastrar no site irá disponibilizar informações sobre suas habilidades e conhecimentos na área de programação, permitindo que seja conectado a projetos disponíveis de acordo com seu perfil. além disso, o usuário também poderá criar seu próprio projeto, informando as tecnologias que serão utilizadas. dessa forma, espera-se que, ao final deste projeto, os programadores que desejam criar algum projeto ou empreender consigam encontrar facilmente outros programadores capacitados e dispostos a trabalhar com eles, superando a dificuldade encontrada atualmente na procura por colaboradores."
166,2023,Cidade inteligente: implementação de um sistema de software para gestão urbana.,"SANTOS, Gustavo Luiz Bispo dos.","MONTEIRO,  João Arthur Brunet.","Softwares de gestão são meios altamente eficazes de administrar
um ambiente. Na sociedade moderna, em que as coisas ocorrem
em alta velocidade e frequência, não é incomum deixar de anotar
algo importante por falta de conhecimento da situação e, se
tratando de cidades, mão de obra fiscalizadora. Em uma de suas
falas ao público, o prefeito de Campina Grande, Bruno Cunha
Lima, mencionou não haver registro na prefeitura sobre ruas
calçadas, asfaltadas ou qualquer registro relacionado a isso. Este
trabalho de conclusão de curso propõe um software para web que
irá facilitar a gestão pública, registrando, de forma colaborativa,
problemas encontrados na cidade. Ao final deste trabalho,
esperamos possuir um ecossistema composto pela sociedade,
sistema e poder público, capaz de garantir melhores condições de
administração para o governo local e tornar-se replicável para
outras municipalidades, beneficiando a sociedade através da
transparência e agilidade aplicada aos governantes com o
software.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/33534,"softwares de gestão são meios altamente eficazes de administrar um ambiente. na sociedade moderna, em que as coisas ocorrem em alta velocidade e frequência, não é incomum deixar de anotar algo importante por falta de conhecimento da situação e, se tratando de cidades, mão de obra fiscalizadora. em uma de suas falas ao público, o prefeito de campina grande, bruno cunha lima, mencionou não haver registro na prefeitura sobre ruas calçadas, asfaltadas ou qualquer registro relacionado a isso. este trabalho de conclusão de curso propõe um software para web que irá facilitar a gestão pública, registrando, de forma colaborativa, problemas encontrados na cidade. ao final deste trabalho, esperamos possuir um ecossistema composto pela sociedade, sistema e poder público, capaz de garantir melhores condições de administração para o governo local e tornar-se replicável para outras municipalidades, beneficiando a sociedade através da transparência e agilidade aplicada aos governantes com o software."
167,2023,Detecção automática de fake news em tweets sobre as eleições brasileiras de 2022.,"SILVA, Rafaela de Amorim Barbosa.","PEREIRA, Eanes Torres.","Fake News, ou notícias falsas, são informações deliberadamente falsas ou enganosas criadas e
disseminadas com o intuito de enganar o público. Esses artigos de notícia são feitos para se
parecerem com notícias legítimas. Seu objetivo é manipular a opinião pública, espalhar
desinformação, influenciar eleições, gerar controvérsia ou usados para ganhos financeiros. Com o
advento das redes sociais, as pessoas começaram a consumir suas notícias online, pois é
extremamente simples, rápido e facilmente acessível. No entanto, essa facilidade também levou a um
aumento na disseminação das notícias falsas. Nos últimos anos, temos visto que as eleições e a
opinião pública sobre causas sociais importantes têm sido influenciadas pelo espalhamento das fake
news. Elas são criadas e proliferam-se rapidamente, ressaltando a urgência da necessidade para que
sua detecção seja rápida. Neste trabalho, é proposta uma metodologia para detecção de fake news
usando redes neurais profundas, com um conjunto de dados com mais de 2 milhões de tweets sobre
as eleições presidenciais Brasileiras de 2022, rotuladas automaticamente por um modelo de
supervisão fraca, obtivemos F1-score de 98% em tweets que não contém fake news, e F1-score de
47% em tweets contendo fake news.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/33365,"fake news, ou notícias falsas, são informações deliberadamente falsas ou enganosas criadas e disseminadas com o intuito de enganar o público. esses artigos de notícia são feitos para se parecerem com notícias legítimas. seu objetivo é manipular a opinião pública, espalhar desinformação, influenciar eleições, gerar controvérsia ou usados para ganhos financeiros. com o advento das redes sociais, as pessoas começaram a consumir suas notícias online, pois é extremamente simples, rápido e facilmente acessível. no entanto, essa facilidade também levou a um aumento na disseminação das notícias falsas. nos últimos anos, temos visto que as eleições e a opinião pública sobre causas sociais importantes têm sido influenciadas pelo espalhamento das fake news. elas são criadas e proliferam-se rapidamente, ressaltando a urgência da necessidade para que sua detecção seja rápida. neste trabalho, é proposta uma metodologia para detecção de fake news usando redes neurais profundas, com um conjunto de dados com mais de milhões de tweets sobre as eleições presidenciais brasileiras de , rotuladas automaticamente por um modelo de supervisão fraca, obtivemos f1-score de % em tweets que não contém fake news, e f1-score de % em tweets contendo fake news."
168,2023,Avaliação de grandes modelos de linguagem quantizados na resolução de questões do ENEM.,"SANTOS, Matheus Lisboa Oliveira dos.","CAMPELO, Cláudio Elízio Calazans.","Embora os grandes modelos de linguagem (LLMs) representem uma revolução na forma como
interagimos com computadores, permitindo a construção de perguntas complexas e a capacidade de
raciocinar sobre uma sequência de declarações, seu uso é restrito devido à necessidade de hardware
dedicado para a execução. Neste estudo, avaliamos o desempenho de LLMs baseados nos modelos
LLaMA de 7 e 13 bilhões, submetidos a um processo de quantização e executados em hardware
doméstico. Os modelos considerados foram alpaca, koala e vicuna. Para avaliar a eficácia desses
modelos, desenvolvemos um banco de dados contendo 1006 perguntas do ENEM (Exame Nacional
do Ensino Médio). Nossa análise revelou que o modelo de melhor desempenho alcançou uma
acurácia de aproximadamente 40% tanto para os textos originais das perguntas em português quanto
para suas traduções em inglês. Além disso, avaliamos a eficiência computacional dos modelos
medindo o tempo necessário para a execução. Em média, os LLMs de 7 e 13 bilhões levaram
aproximadamente 20 e 50 segundos, respectivamente, para processar as consultas em uma máquina
equipada com um processador AMD Ryzen 5 3600x.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/33359,"embora os grandes modelos de linguagem (llms) representem uma revolução na forma como interagimos com computadores, permitindo a construção de perguntas complexas e a capacidade de raciocinar sobre uma sequência de declarações, seu uso é restrito devido à necessidade de hardware dedicado para a execução. neste estudo, avaliamos o desempenho de llms baseados nos modelos llama de e bilhões, submetidos a um processo de quantização e executados em hardware doméstico. os modelos considerados foram alpaca, koala e vicuna. para avaliar a eficácia desses modelos, desenvolvemos um banco de dados contendo perguntas do enem (exame nacional do ensino médio). nossa análise revelou que o modelo de melhor desempenho alcançou uma acurácia de aproximadamente % tanto para os textos originais das perguntas em português quanto para suas traduções em inglês. além disso, avaliamos a eficiência computacional dos modelos medindo o tempo necessário para a execução. em média, os llms de e bilhões levaram aproximadamente e segundos, respectivamente, para processar as consultas em uma máquina equipada com um processador amd ryzen 3600x."
169,2023,Localização de fraturas na coluna cervical em CT utilizando redes neurais convolucionais.,"SILVA, Pedro Henrique de Oliveira.","GOMES, Herman Martins.","A cada 5 segundos uma vértebra da coluna é fraturada no mundo e com o envelhecimento natural da
população esse tempo tende a diminuir. O principal método para analisar tais fraturas é a tomografia
computadorizada (também conhecida como CT) e o tempo dispendido para a sua análise pode ser
determinante para minimizar a ocorrência de sequelas nos pacientes. Sendo assim, o emprego de
técnicas como redes neurais convolucionais pode auxiliar o profissional de saúde a tomar uma
decisão com maior agilidade. Neste contexto, este artigo visa investigar uma abordagem
fundamentada em uma rede neural convolucional para localizar fraturas em fatias de CT. A base de
dados de detecção de fraturas da coluna cervical da RSNA (Sociedade Radiológica da América do
Norte) 2022, disponibilizada em uma competição da plataforma Kaggle, foi utilizada para fins de
treinamento e validação experimental de uma rede neural proposta. Espera-se que a investigação
realizada neste trabalho e o modelo obtido possam ajudar profissionais de saúde na tarefa de
detecção e localização de fraturas na coluna cervical.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/33358,"a cada segundos uma vértebra da coluna é fraturada no mundo e com o envelhecimento natural da população esse tempo tende a diminuir. o principal método para analisar tais fraturas é a tomografia computadorizada (também conhecida como ct) e o tempo dispendido para a sua análise pode ser determinante para minimizar a ocorrência de sequelas nos pacientes. sendo assim, o emprego de técnicas como redes neurais convolucionais pode auxiliar o profissional de saúde a tomar uma decisão com maior agilidade. neste contexto, este artigo visa investigar uma abordagem fundamentada em uma rede neural convolucional para localizar fraturas em fatias de ct. a base de dados de detecção de fraturas da coluna cervical da rsna (sociedade radiológica da américa do norte) , disponibilizada em uma competição da plataforma kaggle, foi utilizada para fins de treinamento e validação experimental de uma rede neural proposta. espera-se que a investigação realizada neste trabalho e o modelo obtido possam ajudar profissionais de saúde na tarefa de detecção e localização de fraturas na coluna cervical."
170,2023,RecipeMaster: um sistema de gerenciamento de receitas para chefes de cozinha.,"NASCIMENTO, Matheus Augusto Silva do.","CAMPELO, Claudio Elízio Calazans.","RecipeMaster é um sistema de gerenciamento voltado para chefs de cozinha, facilitando o controle de
receitas, ingredientes e cardápios. Ele permite aos usuários manter um registro digital detalhado de
suas receitas, bem como dos ingredientes utilizados. Além disso, possui uma funcionalidade especial
de criação de cardápios, onde cada item e custo adicional podem ser especificados, gerando uma
estimativa de custo baseada nos ingredientes. Desenvolvido usando o framework Django para o
back-end e Angular para o front-end, o RecipeMaster combina a segurança e facilidade de uso do
Django com a capacidade do Angular de criar interfaces de usuário interativas. A principal
contribuição deste trabalho é oferecer uma solução eficiente para o gerenciamento de receitas,
otimizando a organização na cozinha, reduzindo o desperdício e melhorando a qualidade dos pratos.
Futuros aprimoramentos podem incluir recursos de aprendizado de máquina para previsão de demanda
e sugestão de receitas.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/33357,"recipemaster é um sistema de gerenciamento voltado para chefs de cozinha, facilitando o controle de receitas, ingredientes e cardápios. ele permite aos usuários manter um registro digital detalhado de suas receitas, bem como dos ingredientes utilizados. além disso, possui uma funcionalidade especial de criação de cardápios, onde cada item e custo adicional podem ser especificados, gerando uma estimativa de custo baseada nos ingredientes. desenvolvido usando o framework django para o back-end e angular para o front-end, o recipemaster combina a segurança e facilidade de uso do django com a capacidade do angular de criar interfaces de usuário interativas. a principal contribuição deste trabalho é oferecer uma solução eficiente para o gerenciamento de receitas, otimizando a organização na cozinha, reduzindo o desperdício e melhorando a qualidade dos pratos. futuros aprimoramentos podem incluir recursos de aprendizado de máquina para previsão de demanda e sugestão de receitas."
171,2023,Metodologia para análise preditiva de resultados de jogos esportivos: um estudo de caso por jogos da NBA.,"PRATA NETTO, Lourival Gonçalves.","GOMES, Herman Martins.","Este artigo apresenta uma metodologia para análise preditiva de resultados de jogos esportivos,
utilizando jogos da National Basketball Association (NBA) como estudo de caso. Especificamente, a
NBA tem notoriedade no uso de análises de dados e estatísticas avançadas para melhorar o
desempenho da equipe e do jogador. Os objetivos deste trabalho são analisar a disponibilidade e
qualidade dos dados da NBA, selecionar variáveis para análise preditiva, aplicar técnicas de
aprendizado de máquina para prever resultados de jogos da NBA e avaliar a eficácia da metodologia
proposta. A metodologia inclui coleta de dados obtidos através da técnica de raspagem de dados
utilizados no site oficial da NBA, pré-processamento dos dados, seleção de variáveis mais relevantes
através da técnica PCA, modelagem e avaliação. Os resultados obtidos demonstram uma metodologia
eficaz para análise preditiva de resultados de jogos esportivos, no tocante à identificação das
variáveis mais importantes para prever resultados de jogos da NBA e estatísticas de acerto de
predição. O presente trabalho, portanto, contribui para o avanço da análise preditiva em esportes e
outros campos de aplicação.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/33354,"este artigo apresenta uma metodologia para análise preditiva de resultados de jogos esportivos, utilizando jogos da national basketball association (nba) como estudo de caso. especificamente, a nba tem notoriedade no uso de análises de dados e estatísticas avançadas para melhorar o desempenho da equipe e do jogador. os objetivos deste trabalho são analisar a disponibilidade e qualidade dos dados da nba, selecionar variáveis para análise preditiva, aplicar técnicas de aprendizado de máquina para prever resultados de jogos da nba e avaliar a eficácia da metodologia proposta. a metodologia inclui coleta de dados obtidos através da técnica de raspagem de dados utilizados no site oficial da nba, pré-processamento dos dados, seleção de variáveis mais relevantes através da técnica pca, modelagem e avaliação. os resultados obtidos demonstram uma metodologia eficaz para análise preditiva de resultados de jogos esportivos, no tocante à identificação das variáveis mais importantes para prever resultados de jogos da nba e estatísticas de acerto de predição. o presente trabalho, portanto, contribui para o avanço da análise preditiva em esportes e outros campos de aplicação."
172,2023,Analisando vulnerabilidade de segurança em um projeto de software.,"ARAÚJO, Jerônimo Jairo Silva de.","ALVES, Everton Leandro Galdino.","Vulnerabilidades de segurança em sistemas computacionais são
problemas geralmente complexos de tratar e que mesmo com a
melhora no processo de desenvolvimento tendem a persistir. A
falta de interesse na remoção dessas vulnerabilidades durante o
desenvolvimento pode se tornar um contratempo no futuro (débito
técnico), resultar em acessos indevidos, expor dados dos usuários
e reverter em custos financeiros para a empresa. Desta forma,
faz-se necessário que preocupações com a identificação e remoção
dessas vulnerabilidades existam durante todo o processo de
desenvolvimento do software. Neste trabalho, serão utilizadas
ferramentas de análise estática (Check Marx, Black Duck e Jfrog
Xray) para analisar a evolução, distribuição por classe de risco e
tempo de vida de vulnerabilidades de segurança em um projeto
desenvolvido por uma empresa de grande porte em parceria com o
Laboratório de Sistemas Distribuídos. O projeto em questão
consiste de um serviço que oferece gerenciamento para recursos
de observabilidade. A partir dos resultados obtidos foi constatado
que vulnerabilidades que afetam componentes open-source
encontradas pelas ferramentas Black Duck e Jfrog Xray estavam
sendo tratadas. No entanto, as vulnerabilidades de segurança que
afetam pontos de código do projeto encontrados na ferramenta
Check Marx, não estavam sendo abordadas.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/33351,"vulnerabilidades de segurança em sistemas computacionais são problemas geralmente complexos de tratar e que mesmo com a melhora no processo de desenvolvimento tendem a persistir. a falta de interesse na remoção dessas vulnerabilidades durante o desenvolvimento pode se tornar um contratempo no futuro (débito técnico), resultar em acessos indevidos, expor dados dos usuários e reverter em custos financeiros para a empresa. desta forma, faz-se necessário que preocupações com a identificação e remoção dessas vulnerabilidades existam durante todo o processo de desenvolvimento do software. neste trabalho, serão utilizadas ferramentas de análise estática (check marx, black duck e jfrog xray) para analisar a evolução, distribuição por classe de risco e tempo de vida de vulnerabilidades de segurança em um projeto desenvolvido por uma empresa de grande porte em parceria com o laboratório de sistemas distribuídos. o projeto em questão consiste de um serviço que oferece gerenciamento para recursos de observabilidade. a partir dos resultados obtidos foi constatado que vulnerabilidades que afetam componentes open-source encontradas pelas ferramentas black duck e jfrog xray estavam sendo tratadas. no entanto, as vulnerabilidades de segurança que afetam pontos de código do projeto encontrados na ferramenta check marx, não estavam sendo abordadas."
173,2023,Uma ferramenta para otimizar a relação instrutor-aluno em academias.,"MARTINS, João Antônio Bandeira de Oliveira.","FARIAS, Adalberto Cajueiro de.","Nos últimos anos, houve um aumento significativo no interesse em exercícios físicos e frequência em academias em todo o
Brasil[1], por diversos públicos. No entanto, a comunicação entre instrutores e alunos tem sido apontada como um problema
por ambas as partes, com orientação inadequada e dificuldades na entrega de exercícios, resultando em sobrecarga de
trabalho para os instrutores e estudantes desmotivados e estagnados. Portanto, propomos uma aplicação web que possa
otimizar e aprimorar essa relação, fornecendo resultados positivos tanto para instrutores quanto para alunos. Após consultar
usuários potenciais e identificar os problemas experimentados por instrutores e alunos, desenvolvemos uma solução:
GrowTogether. Esta aplicação gratuita permite que os instrutores cadastrem alunos, forneçam programas de treinamento
personalizados, e acompanhem os resultados. Com esta solução, acreditamos que os instrutores serão capazes de gerenciar
sua carga de trabalho de forma mais eficaz, enquanto melhoram a aprendizagem e o engajamento dos alunos, impactando
positivamente a vida daqueles que frequentam esses ambientes.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/33349,"nos últimos anos, houve um aumento significativo no interesse em exercícios físicos e frequência em academias em todo o brasil[ ], por diversos públicos. no entanto, a comunicação entre instrutores e alunos tem sido apontada como um problema por ambas as partes, com orientação inadequada e dificuldades na entrega de exercícios, resultando em sobrecarga de trabalho para os instrutores e estudantes desmotivados e estagnados. portanto, propomos uma aplicação web que possa otimizar e aprimorar essa relação, fornecendo resultados positivos tanto para instrutores quanto para alunos. após consultar usuários potenciais e identificar os problemas experimentados por instrutores e alunos, desenvolvemos uma solução: growtogether. esta aplicação gratuita permite que os instrutores cadastrem alunos, forneçam programas de treinamento personalizados, e acompanhem os resultados. com esta solução, acreditamos que os instrutores serão capazes de gerenciar sua carga de trabalho de forma mais eficaz, enquanto melhoram a aprendizagem e o engajamento dos alunos, impactando positivamente a vida daqueles que frequentam esses ambientes."
174,2023,Uma abordagem com busca semântica e modelo de linguagem para responder a perguntas do contexto @CCC.,"SILVA, Caio Davi Pereira da.","MARINHO, Leandro Balby.","A ciência de extrair dados a partir de informações textuais avança consideravelmente. Com a rápida
evolução tecnológica da área de Processamento de Linguagem Natural (PLN), os modelos de
linguagem são capazes de fornecer resultados completos e concisos a partir de entradas textuais.
Atualmente, informações sobre a graduação em Ciência da Computação na UFCG se apresentam
diluídas em diversos documentos, planilhas eletrônicas e links da web, podendo resultar em
obstáculos para o aluno obter informações precisas referentes ao curso e seus respectivos aspectos,
gerando assim uma potencial dificuldade para a resolução de dúvidas. Diante disso, este trabalho se
propõe a utilizar técnicas da área de PLN e Machine Learning a fim de construir uma ferramenta
capaz de gerar respostas automáticas para questionamentos no contexto da graduação em Ciência da
Computação na Universidade Federal de Campina Grande.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/33340,"a ciência de extrair dados a partir de informações textuais avança consideravelmente. com a rápida evolução tecnológica da área de processamento de linguagem natural (pln), os modelos de linguagem são capazes de fornecer resultados completos e concisos a partir de entradas textuais. atualmente, informações sobre a graduação em ciência da computação na ufcg se apresentam diluídas em diversos documentos, planilhas eletrônicas e links da web, podendo resultar em obstáculos para o aluno obter informações precisas referentes ao curso e seus respectivos aspectos, gerando assim uma potencial dificuldade para a resolução de dúvidas. diante disso, este trabalho se propõe a utilizar técnicas da área de pln e machine learning a fim de construir uma ferramenta capaz de gerar respostas automáticas para questionamentos no contexto da graduação em ciência da computação na universidade federal de campina grande."
175,2023,Escalonador oportunístico na nuvem com qualidade de serviço.,"ALBUQUERQUE, Caetano Bezerra Cavalcanti.","BRITO, Andrey Elísio Monteiro.","O uso de computação oportunista na nuvem é amplamente adotado devido a sua capacidade de
hospedar aplicações de processamento em lote a um custo reduzido. No entanto, esse modelo
apresenta a desvantagem de não garantir disponibilidade, o que pode afetar a qualidade de serviço
das aplicações. Além disso, devido à alta oscilação de preço, alcançar uma disponibilidade ideal com
esse tipo de serviço requer despriorizar o potencial econômico oferecido. Este trabalho propõe uma
solução na forma de um escalonador oportunista modular para Kubernetes, que busca equilibrar os
custos dos nós oportunistas e os atrasos no processamento, garantindo assim a qualidade de serviço.
Com base nos preços de 2021 da AWS, a solução demonstrou uma economia significativa, de até 50%
em determinados dias, quando comparado aos custos com instâncias sob demanda, possibilitando o
processamento em tempo quase real.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/33339,"o uso de computação oportunista na nuvem é amplamente adotado devido a sua capacidade de hospedar aplicações de processamento em lote a um custo reduzido. no entanto, esse modelo apresenta a desvantagem de não garantir disponibilidade, o que pode afetar a qualidade de serviço das aplicações. além disso, devido à alta oscilação de preço, alcançar uma disponibilidade ideal com esse tipo de serviço requer despriorizar o potencial econômico oferecido. este trabalho propõe uma solução na forma de um escalonador oportunista modular para kubernetes, que busca equilibrar os custos dos nós oportunistas e os atrasos no processamento, garantindo assim a qualidade de serviço. com base nos preços de da aws, a solução demonstrou uma economia significativa, de até % em determinados dias, quando comparado aos custos com instâncias sob demanda, possibilitando o processamento em tempo quase real."
176,2023,Reformulação de interface para o projeto SAPS.,"FERREIRA, Felipe de Amorim.","SILVA, Thiago Emmanuel Pereira da Cunha.","O Serviço de Automação do Processamento de Imagens de
Satélite (SAPS) é uma ferramenta usada para o monitoramento e
previsão de fenômenos climáticos e ambientais. Este artigo aborda
uma reformulação de sua interface de usuário. Esta reformulação
teve o objetivo de melhorar a experiência do usuário e a eficiência
da ferramenta, focando em cinco áreas-chave: acessibilidade,
responsividade, consistência do design, manutenibilidade e
testabilidade. Para isso, o projeto emprega o framework Next.js,
trazendo uma série de vantagens, como uma experiência de
usuário aprimorada, facilidade de manutenção e uma integração
mais eficiente para novos colaboradores. O artigo detalha o
processo de implementação, descrevendo a estrutura do projeto, a
seleção de dependências e a estratégia de testes. Essas melhorias
estão voltadas não só para otimizar a funcionalidade atual da
ferramenta, mas também para garantir sua sustentabilidade a
longo prazo, preparando o SAPS para futuras inovações e
demandas.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/33313,"o serviço de automação do processamento de imagens de satélite (saps) é uma ferramenta usada para o monitoramento e previsão de fenômenos climáticos e ambientais. este artigo aborda uma reformulação de sua interface de usuário. esta reformulação teve o objetivo de melhorar a experiência do usuário e a eficiência da ferramenta, focando em cinco áreas-chave: acessibilidade, responsividade, consistência do design, manutenibilidade e testabilidade. para isso, o projeto emprega o framework next.js, trazendo uma série de vantagens, como uma experiência de usuário aprimorada, facilidade de manutenção e uma integração mais eficiente para novos colaboradores. o artigo detalha o processo de implementação, descrevendo a estrutura do projeto, a seleção de dependências e a estratégia de testes. essas melhorias estão voltadas não só para otimizar a funcionalidade atual da ferramenta, mas também para garantir sua sustentabilidade a longo prazo, preparando o saps para futuras inovações e demandas."
177,2023,Evolução do sistema de agendamento de horários do complexo esportivo da UFCG - SAHCE - UFCG.,"LUCENA, Igor Dantas.","LIRA, Melina Mongiovi Brito.","O complexo esportivo da Universidade Federal de Campina Grande (UFCG) atualmente oferece
opções de agendamento consideradas mais tradicionais. Os usuários têm a possibilidade de fazer
reservas pessoalmente na secretaria do complexo localizada no campus, ou por meio de um
aplicativo de mensagens. No entanto, esses métodos são considerados pouco eficientes. Para
aprimorar o processo tanto para as comunidades envolvidas quanto para os administradores dos
espaços, torna-se necessário o desenvolvimento de uma aplicação online. Uma versão inicial dessa
aplicação foi criada no início deste ano, porém ainda não estava disponível para uso e já se fez
necessário adicionar novas funcionalidades. Este trabalho documenta o desenvolvimento de uma
Progressive Web App (PWA), com ênfase nas funcionalidades essenciais que serão implementadas,
destacando-se: recuperação de senha do usuário, controle de reserva, atualização dos perfis,
notificações por e-mail e bloqueio de usuários. Essas funcionalidades são consideradas prioritárias e
fundamentais para o pleno funcionamento e experiência do usuário no sistema.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/32386,"o complexo esportivo da universidade federal de campina grande (ufcg) atualmente oferece opções de agendamento consideradas mais tradicionais. os usuários têm a possibilidade de fazer reservas pessoalmente na secretaria do complexo localizada no campus, ou por meio de um aplicativo de mensagens. no entanto, esses métodos são considerados pouco eficientes. para aprimorar o processo tanto para as comunidades envolvidas quanto para os administradores dos espaços, torna-se necessário o desenvolvimento de uma aplicação online. uma versão inicial dessa aplicação foi criada no início deste ano, porém ainda não estava disponível para uso e já se fez necessário adicionar novas funcionalidades. este trabalho documenta o desenvolvimento de uma progressive web app (pwa), com ênfase nas funcionalidades essenciais que serão implementadas, destacando-se: recuperação de senha do usuário, controle de reserva, atualização dos perfis, notificações por e-mail e bloqueio de usuários. essas funcionalidades são consideradas prioritárias e fundamentais para o pleno funcionamento e experiência do usuário no sistema."
178,2023,"Explorando técnicas de redução de dimensionalidade na análise de DNA de grupos judaicos e de outros grupos étnicos: uma comparação entre PCA, t-SNE e UMAP.","RODRIGUES, Matheus Andrade.","MASSONI, Tiago Lima.","Aplicamos PCA, t-SNE e UMAP nos datasets de calculadoras de interpretação genética com dados de grupos
étnicos judaicos, de vários vizinhos não-judeus e de etnias correlacionadas, utilizando o software R. Realizamos
uma comparação visual entre os resultados gerados e utilizamos o microbenchmark para verificar o tempo de
execução dos métodos. O t-SNE e o UMAP são eficientes para trabalharmos com âmbitos locais da visualização,
enquanto o PCA é adequado quando o número de amostras é reduzido. t-SNE e UMAP são capazes de formar
agrupamentos que não veríamos somente utilizando o PCA. Apesar disso, são mais lentos que o PCA, e as
visualizações geradas por eles mudam ao executar o algoritmo novamente.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/30521,"aplicamos pca, t-sne e umap nos datasets de calculadoras de interpretação genética com dados de grupos étnicos judaicos, de vários vizinhos não-judeus e de etnias correlacionadas, utilizando o software r. realizamos uma comparação visual entre os resultados gerados e utilizamos o microbenchmark para verificar o tempo de execução dos métodos. o t-sne e o umap são eficientes para trabalharmos com âmbitos locais da visualização, enquanto o pca é adequado quando o número de amostras é reduzido. t-sne e umap são capazes de formar agrupamentos que não veríamos somente utilizando o pca. apesar disso, são mais lentos que o pca, e as visualizações geradas por eles mudam ao executar o algoritmo novamente."
179,2023,Redash: uma solução de monitoramento e análise de dados para gerenciamento de recursos em tempo real em nuvens privadas.,"MONTE, Wesley Henrique Araújo.","SILVA, Thiago Emmanuel Pereira da Cunha.","O Laboratório de Sistemas Distribuídos (LSD) é responsável por gerenciar
a nuvem privada do UASC/UFCG. Para manter essa nuvem
privada, o LSD enfrentou desaios no gerenciamento dos recursos
da nuvem, especialmente na visualização de dados e na geração
de novos relatórios para os responsáveis pelos projetos que usam
esses recursos.
Anteriormente, a ferramenta utilizada era o Shylock, mas ela
apresentava diiculdades na geração de relatórios sobre a quantidade
e o consumo de recursos da nuvem, pois gerava apenas um
relatório por dia. Além disso, a criação de relatórios era um processo
complexo que exigia a criação de um novo modelo Jinja e a
codiicação de variáveis.
Dado os déicits encontrados no sistema atual, o Redash foi a
plataforma selecionada para supri-los. O Redash resolve a diiculdade
de visualização dos dados analisados através da criação de
dashboards para a visualização e monitoramento dos recursos da
nuvem em tempo real.
Ao incluir as informações dos dashboards criados no Redash no
luxo de trabalho de gerenciamento e monitoramento da nuvem, a
facilidade de tomar decisões com base em dados reais e atualizados
permitiu uma melhor tomada de decisões sobre o gerenciamento
dos recursos da nuvem.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/30517,"o laboratório de sistemas distribuídos (lsd) é responsável por gerenciar a nuvem privada do uasc/ufcg. para manter essa nuvem privada, o lsd enfrentou desaios no gerenciamento dos recursos da nuvem, especialmente na visualização de dados e na geração de novos relatórios para os responsáveis pelos projetos que usam esses recursos. anteriormente, a ferramenta utilizada era o shylock, mas ela apresentava diiculdades na geração de relatórios sobre a quantidade e o consumo de recursos da nuvem, pois gerava apenas um relatório por dia. além disso, a criação de relatórios era um processo complexo que exigia a criação de um novo modelo jinja e a codiicação de variáveis. dado os déicits encontrados no sistema atual, o redash foi a plataforma selecionada para supri-los. o redash resolve a diiculdade de visualização dos dados analisados através da criação de dashboards para a visualização e monitoramento dos recursos da nuvem em tempo real. ao incluir as informações dos dashboards criados no redash no luxo de trabalho de gerenciamento e monitoramento da nuvem, a facilidade de tomar decisões com base em dados reais e atualizados permitiu uma melhor tomada de decisões sobre o gerenciamento dos recursos da nuvem."
180,2023,O crescimento do uso dos jogos digitais durante a pandemia e seus efeitos nos universitários.,"DINIZ, Vitor Mota Leite.","BARROS, Marcelo Alves de.","Durante a pandemia de COVID-19, foi necessário que as pessoas se isolassem, devido aos altos índices de
contágio e eventuais mortes. De acordo com o ministério da saúde, apenas no Brasil já foram mais de 35
milhões de casos confirmados e 695 mil mortes, até o início do ano de 2023. Com isso, a população
precisou abrir mão de suas formas usuais de entretenimento presencial e socialização, o que levou as
formas de passatempo digital a aparecerem como forma alternativa de diversão e socialização. Entre
elas, uma das que mais viu crescimento neste período foi o uso dos jogos digitais, sendo apreciados até
por quem nunca tinha tido contato anterior ao período de isolamento. Por isso, neste trabalho,
pretendemos analisar como o crescimento do uso dos jogos digitais durante a pandemia gerou impactos
positivos e negativos na vida de alunos universitários brasileiros após a pandemia. Para isso, foi
encaminhado para tais estudantes formulários do Google forms, permitindo assim a geração de gráficos
comparativos a partir da coleta e análise de dados. Assim, conseguimos comprovar um relacionamento
entre este crescimento aos efeitos observados após o fim da mesma, tanto para quem já tinha contato
com jogos como para quem teve sua primeira experiência. Ao final da pesquisa, conseguimos obter
respostas de 115 estudantes universitários de graduação e pós, conseguindo obter uma boa perspectiva
desta conexão e esperando com isso incentivar trabalhos futuros.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/30516,"durante a pandemia de covid- , foi necessário que as pessoas se isolassem, devido aos altos índices de contágio e eventuais mortes. de acordo com o ministério da saúde, apenas no brasil já foram mais de milhões de casos confirmados e mil mortes, até o início do ano de . com isso, a população precisou abrir mão de suas formas usuais de entretenimento presencial e socialização, o que levou as formas de passatempo digital a aparecerem como forma alternativa de diversão e socialização. entre elas, uma das que mais viu crescimento neste período foi o uso dos jogos digitais, sendo apreciados até por quem nunca tinha tido contato anterior ao período de isolamento. por isso, neste trabalho, pretendemos analisar como o crescimento do uso dos jogos digitais durante a pandemia gerou impactos positivos e negativos na vida de alunos universitários brasileiros após a pandemia. para isso, foi encaminhado para tais estudantes formulários do google forms, permitindo assim a geração de gráficos comparativos a partir da coleta e análise de dados. assim, conseguimos comprovar um relacionamento entre este crescimento aos efeitos observados após o fim da mesma, tanto para quem já tinha contato com jogos como para quem teve sua primeira experiência. ao final da pesquisa, conseguimos obter respostas de estudantes universitários de graduação e pós, conseguindo obter uma boa perspectiva desta conexão e esperando com isso incentivar trabalhos futuros."
181,2023,Verificação de autoria em mensagens de texto utilizando grafos e aprendizagem de máquina.,"SOARES, Caio Maxximus Pereira.","GOMES, Herman Martins.","A busca por extração de características em textos é uma área de interesse em aprendizagem de máquina
devido às inúmeras possibilidades relacionadas, dentre elas a verificação de autoria é um tema relevante
por suas aplicações e elevada complexidade. Neste contexto, o presente artigo faz uso de dados
provenientes de mensagens de chat de servidores Discord com o propósito de verificar automaticamente
a autoria das mensagens mediante um treinamento supervisionado. O processo inicia-se com um
pré-processamento que busca reduzir ruído e viés nos dados, para então explorar a capacidade do
modelo de aprendizagem em generalizar ao encontrar textos desconhecidos e defini-los como de sua
autoria ou não. Desta forma são utilizados grafos como extratores de características em mensagens de
texto, utilizando de redes neurais artificiais como modelos de aprendizagem de máquina para
classificá-las . Palavras se tornam nós, e suas arestas capturam a intensidade referente à distância dos
termos na frase, resultando na construção de um grafo que representa o vocabulário de um indivíduo e
que tem como objetivo captar características relevantes no texto.Obtidas boas acurácias para o
verdadeiros positivos e para os verdadeiros negativos ao se ajustar o limiar de ativação, os modelos
conseguem alcançar resultados satisfatórios com reduzido custo de treinamento, permitindo uma
facilidade maior para exploração de novos parâmetros.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/30514,"a busca por extração de características em textos é uma área de interesse em aprendizagem de máquina devido às inúmeras possibilidades relacionadas, dentre elas a verificação de autoria é um tema relevante por suas aplicações e elevada complexidade. neste contexto, o presente artigo faz uso de dados provenientes de mensagens de chat de servidores discord com o propósito de verificar automaticamente a autoria das mensagens mediante um treinamento supervisionado. o processo inicia-se com um pré-processamento que busca reduzir ruído e viés nos dados, para então explorar a capacidade do modelo de aprendizagem em generalizar ao encontrar textos desconhecidos e defini-los como de sua autoria ou não. desta forma são utilizados grafos como extratores de características em mensagens de texto, utilizando de redes neurais artificiais como modelos de aprendizagem de máquina para classificá-las . palavras se tornam nós, e suas arestas capturam a intensidade referente à distância dos termos na frase, resultando na construção de um grafo que representa o vocabulário de um indivíduo e que tem como objetivo captar características relevantes no texto.obtidas boas acurácias para o verdadeiros positivos e para os verdadeiros negativos ao se ajustar o limiar de ativação, os modelos conseguem alcançar resultados satisfatórios com reduzido custo de treinamento, permitindo uma facilidade maior para exploração de novos parâmetros."
182,2023,Guia para estilização de componentes reutilizáveis em aplicações angular.,"SOUZA, José Davi de Araújo.","FARIAS, Adalberto Cajueiro de.","Dentro da carreira de desenvolvedor web, especializar-se em front-end é comum. Nessa área é frequente
encontrar problemas semelhantes que exigem soluções similares, como interfaces de navegação, áreas
de busca e formulários. Para lidar com essas situações existem diversos recursos prontos que possibilitam
a reutilização de soluções, estabelecendo um padrão. No entanto, ao utilizar componentes reutilizáveis
no desenvolvimento front-end com o framework Angular, surgem desafios na personalização dessas
soluções para se adequarem a diferentes design. Este trabalho aborda os diversos tipos de componentes
reutilizáveis da biblioteca Angular Material, além de explorar diferentes abordagens para estilizá-los no
contexto do framework Angular. Foi criado um guia com exemplos práticos e dicas para auxiliar os
desenvolvedores front-end na personalização dos componentes já existentes no Angular, superando as
dificuldades encontradas. Com essa abordagem aprimorada, os desenvolvedores front-end poderão
personalizar os componentes reutilizáveis no Angular de forma mais eficiente, atendendo aos requisitos
de design de maneira mais flexível e intuitiva.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/30513,"dentro da carreira de desenvolvedor web, especializar-se em front-end é comum. nessa área é frequente encontrar problemas semelhantes que exigem soluções similares, como interfaces de navegação, áreas de busca e formulários. para lidar com essas situações existem diversos recursos prontos que possibilitam a reutilização de soluções, estabelecendo um padrão. no entanto, ao utilizar componentes reutilizáveis no desenvolvimento front-end com o framework angular, surgem desafios na personalização dessas soluções para se adequarem a diferentes design. este trabalho aborda os diversos tipos de componentes reutilizáveis da biblioteca angular material, além de explorar diferentes abordagens para estilizá-los no contexto do framework angular. foi criado um guia com exemplos práticos e dicas para auxiliar os desenvolvedores front-end na personalização dos componentes já existentes no angular, superando as dificuldades encontradas. com essa abordagem aprimorada, os desenvolvedores front-end poderão personalizar os componentes reutilizáveis no angular de forma mais eficiente, atendendo aos requisitos de design de maneira mais flexível e intuitiva."
183,2023,FAVA: Aplicação de simulação e validação de autômatos finitos para auxílio de ensino e aprendizagem.,"BARBOSA, João Pedro de Barros.","BRITO, Andrey Elísio Monteiro.","Os cursos que apresentam a teoria dos autômatos trazem consigo
uma natureza matemática e formal necessária. Porém, quando o
estudo desse tema não é planejado de forma conjunta à realização
de exercícios práticos, geralmente se torna fator que compromete
a compreensão por parte do aluno. Ainda assim, a resolução e
correção de tais exercícios, quando feitas de forma confusa, sem a
devida instrução, podem ser longas, tediosas e propensas a erros.
Para mitigar essa dificuldade e apoiar o ensino e aprendizagem,
este trabalho propõe uma plataforma web online visual e interativa
para construção de autômatos finitos, determinísticos ou não, sua
testagem, validação e aplicação de determinados algoritmos sob
eles; além de contar com um ambiente focado na realização de
exercícios criados por professores para os alunos, fornecendo-os
feedbacks rápidos e constantes.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/30511,"os cursos que apresentam a teoria dos autômatos trazem consigo uma natureza matemática e formal necessária. porém, quando o estudo desse tema não é planejado de forma conjunta à realização de exercícios práticos, geralmente se torna fator que compromete a compreensão por parte do aluno. ainda assim, a resolução e correção de tais exercícios, quando feitas de forma confusa, sem a devida instrução, podem ser longas, tediosas e propensas a erros. para mitigar essa dificuldade e apoiar o ensino e aprendizagem, este trabalho propõe uma plataforma web online visual e interativa para construção de autômatos finitos, determinísticos ou não, sua testagem, validação e aplicação de determinados algoritmos sob eles; além de contar com um ambiente focado na realização de exercícios criados por professores para os alunos, fornecendo-os feedbacks rápidos e constantes."
184,2023,Annotation Tool: anotações de dados por meio de áudios.,"MACENA, Arthur de Amorim.","CAMPELO, Cláudio Elízio Calazans.","Este trabalho de conclusão de curso aborda o desenvolvimento de uma ferramenta web para o
projeto de anotação de dados do Laboratório de Computação Inteligente Aplicada(LACINA). Essa
ferramenta tem como foco anotações de áudio baseadas em diálogos, com o objetivo de facilitar a
criação de conjuntos de dados obtidos para o treinamento de sistemas de diálogo baseados em
machine learning. A ferramenta foi projetada para fornecer uma plataforma eficiente e intuitiva,
permitindo a identificação de falantes e a marcação de intenções e entidades nos diálogos em áudio.
O projeto destaca a importância das anotações de áudio baseadas em diálogos para o avanço dos
sistemas de diálogo, e discute as vantagens de se ter conjuntos de dados anotados, bem como as
considerações éticas e de privacidade associadas a esse processo. A sessão de desenvolvimento
abordou os aspectos técnicos da ferramenta, incluindo a escolha das tecnologias e frameworks
utilizados, os desafios enfrentados durante o andamento e as soluções adotadas para superá-los.
Foram destacadas as funcionalidades desejáveis, como uma interface de usuário amigável, recursos
avançados de reprodução e visualização sincronizada de áudio e texto anotados. Em seguida, foram
discutidas as aplicações práticas da ferramenta no contexto de projetos de machine learning e
processamento de linguagem natural. Os conjuntos de dados anotados criados com a ferramenta
podem ser usados para treinar modelos de reconhecimento de fala e compreensão de linguagem,
contribuindo para o desenvolvimento de sistemas de diálogo conversacional. Este trabalho visa
fornecer uma visão abrangente desta área em constante evolução, destacando seu impacto e seu
potencial para impulsionar a pesquisa e o desenvolvimento de aplicações de machine learning
baseadas em áudio. A ferramenta web de anotações de áudio baseadas em diálogos representa uma
contribuição significativa para o campo do processamento de linguagem natural e sistemas de
diálogo, facilitando a criação de conjuntos de dados anotados de alta qualidade e impulsionando o
avanço e o desenvolvimento de sistemas de diálogo mais eficientes, naturais e precisos.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/30510,"este trabalho de conclusão de curso aborda o desenvolvimento de uma ferramenta web para o projeto de anotação de dados do laboratório de computação inteligente aplicada(lacina). essa ferramenta tem como foco anotações de áudio baseadas em diálogos, com o objetivo de facilitar a criação de conjuntos de dados obtidos para o treinamento de sistemas de diálogo baseados em machine learning. a ferramenta foi projetada para fornecer uma plataforma eficiente e intuitiva, permitindo a identificação de falantes e a marcação de intenções e entidades nos diálogos em áudio. o projeto destaca a importância das anotações de áudio baseadas em diálogos para o avanço dos sistemas de diálogo, e discute as vantagens de se ter conjuntos de dados anotados, bem como as considerações éticas e de privacidade associadas a esse processo. a sessão de desenvolvimento abordou os aspectos técnicos da ferramenta, incluindo a escolha das tecnologias e frameworks utilizados, os desafios enfrentados durante o andamento e as soluções adotadas para superá-los. foram destacadas as funcionalidades desejáveis, como uma interface de usuário amigável, recursos avançados de reprodução e visualização sincronizada de áudio e texto anotados. em seguida, foram discutidas as aplicações práticas da ferramenta no contexto de projetos de machine learning e processamento de linguagem natural. os conjuntos de dados anotados criados com a ferramenta podem ser usados para treinar modelos de reconhecimento de fala e compreensão de linguagem, contribuindo para o desenvolvimento de sistemas de diálogo conversacional. este trabalho visa fornecer uma visão abrangente desta área em constante evolução, destacando seu impacto e seu potencial para impulsionar a pesquisa e o desenvolvimento de aplicações de machine learning baseadas em áudio. a ferramenta web de anotações de áudio baseadas em diálogos representa uma contribuição significativa para o campo do processamento de linguagem natural e sistemas de diálogo, facilitando a criação de conjuntos de dados anotados de alta qualidade e impulsionando o avanço e o desenvolvimento de sistemas de diálogo mais eficientes, naturais e precisos."
185,2023,RegBot: chatbot para o regulamento de ensino de graduação da Universidade Federal de Campina Grande.,"MELO, Luana Barbosa de.","ARAÚJO, Joseana Macêdo Fechine Régis de.","O Regulamento de Ensino de Graduação é um dispositivo legal da Universidade Federal de Campina
Grande que congrega as principais regras que devem ser observadas pela comunidade universitária,
no âmbito da graduação. Esse regulamento dispõe sobre temas como: a organização de cursos de
graduação e seus componentes curriculares; estágio; formas de ingresso e seleção de estudantes; os
procedimentos acadêmicos referentes ao vínculo dos discentes; a mobilidade acadêmica; o
aproveitamento de estudos; o quadro de horários; as avaliações de aprendizagem; os documentos
acadêmicos, etc. No entanto, nem todos os alunos conhecem esse regulamento, ou alguns apresentam
dificuldade para encontrar um tópico específico, por se tratar de um documento extenso. Além disso,
alunos portadores de deficiência, a exemplo de deficiência visual, também encontram dificuldades no
uso do regulamento. Pensando nessa problemática, o trabalho consistiu em desenvolver um chatbot,
denominado RegBot, que possibilitará ao estudante o acesso às informações sobre o Regulamento de
Ensino de Graduação da UFCG, de forma mais fácil, ágil e dinâmica, a partir do uso de uma linguagem
mais acessível. Em seguida, o chatbot foi avaliado por uma amostra da comunidade acadêmica, a partir
de um questionário de avaliação, de forma a concretizar o objetivo do trabalho.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/30491,"o regulamento de ensino de graduação é um dispositivo legal da universidade federal de campina grande que congrega as principais regras que devem ser observadas pela comunidade universitária, no âmbito da graduação. esse regulamento dispõe sobre temas como: a organização de cursos de graduação e seus componentes curriculares; estágio; formas de ingresso e seleção de estudantes; os procedimentos acadêmicos referentes ao vínculo dos discentes; a mobilidade acadêmica; o aproveitamento de estudos; o quadro de horários; as avaliações de aprendizagem; os documentos acadêmicos, etc. no entanto, nem todos os alunos conhecem esse regulamento, ou alguns apresentam dificuldade para encontrar um tópico específico, por se tratar de um documento extenso. além disso, alunos portadores de deficiência, a exemplo de deficiência visual, também encontram dificuldades no uso do regulamento. pensando nessa problemática, o trabalho consistiu em desenvolver um chatbot, denominado regbot, que possibilitará ao estudante o acesso às informações sobre o regulamento de ensino de graduação da ufcg, de forma mais fácil, ágil e dinâmica, a partir do uso de uma linguagem mais acessível. em seguida, o chatbot foi avaliado por uma amostra da comunidade acadêmica, a partir de um questionário de avaliação, de forma a concretizar o objetivo do trabalho."
186,2023,Análise de Tweets em grandes eventos: um estudo de caso da Copa do Mundo no Twiter.,"PEREIRA, Igor de Sousa.","CAMPELO, Claudio Elízio Calazans.","A internet tem possibilitado uma maior interação entre as pessoas ao redor do mundo, e o Twitter
tem desempenhado um papel significativo nisso. Como uma das redes sociais mais utilizadas do
planeta, o Twitter permite que os usuários façam postagens expressando diversos aspectos do seu dia
a dia. Com a aproximação de grandes eventos de reconhecimento mundial(e.g., eventos esportivos),
é natural que os usuários também expressem seus comentários sobre os diversos aspectos dessas
competições. No entanto, devido à enorme quantidade de comentários gerados diariamente, é
possível observar uma variedade de interpretações que refletem diferentes aspectos do evento,
como discussões sobre escolha dos técnicos, desempenho das equipes e até mesmo comentários
pessoais sobre os participantes. Este artigo apresenta uma abordagem para analisar as discussões em
torno de um evento, utilizando a Copa do Mundo como exemplo para validar o método. Para isso,
foram empregados dados coletados do Twitter, os quais foram usados como entrada em técnicas de
agrupamento, a fim de identificar potenciais conjuntos de comentários relacionados à competição.
Como resultado, foram obtidos 13 grupos diversos, cada um com características únicas, abrangendo
desde avaliações individuais, até críticas ao país-sede Qatar, rivalidades entre seleções, entre outros
aspectos. Esses resultados indicam a existência de padrões nos comentários sobre um tema
específico, sugerindo que os usuários buscam comentar temas do momento e com grande
engajamento.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/30490,"a internet tem possibilitado uma maior interação entre as pessoas ao redor do mundo, e o twitter tem desempenhado um papel significativo nisso. como uma das redes sociais mais utilizadas do planeta, o twitter permite que os usuários façam postagens expressando diversos aspectos do seu dia a dia. com a aproximação de grandes eventos de reconhecimento mundial(e.g., eventos esportivos), é natural que os usuários também expressem seus comentários sobre os diversos aspectos dessas competições. no entanto, devido à enorme quantidade de comentários gerados diariamente, é possível observar uma variedade de interpretações que refletem diferentes aspectos do evento, como discussões sobre escolha dos técnicos, desempenho das equipes e até mesmo comentários pessoais sobre os participantes. este artigo apresenta uma abordagem para analisar as discussões em torno de um evento, utilizando a copa do mundo como exemplo para validar o método. para isso, foram empregados dados coletados do twitter, os quais foram usados como entrada em técnicas de agrupamento, a fim de identificar potenciais conjuntos de comentários relacionados à competição. como resultado, foram obtidos grupos diversos, cada um com características únicas, abrangendo desde avaliações individuais, até críticas ao país-sede qatar, rivalidades entre seleções, entre outros aspectos. esses resultados indicam a existência de padrões nos comentários sobre um tema específico, sugerindo que os usuários buscam comentar temas do momento e com grande engajamento."
187,2023,Sistema para gestão de projetos urbanos.,"SILVA, Luan Rocha.","MASSONI, Tiago Lima.","Pequenas prefeituras normalmente fazem uso de empresas privadas para realização de serviços
relacionados ao monitoramento da situação do Imposto Predial e Territorial Urbano (IPTU) de
imóveis, ou seja, terceirizam estes serviços. Uma dessas empresas sentiu a necessidade da criação de
um sistema web que viabilizasse o cadastro e manutenção dos dados que são coletados, permitindo
uma otimização no gerenciamento dessas informações. Utilizando o sistema será possível concentrar
todos os dados em um único local, abolindo assim a utilização e acúmulo de planilhas.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/30489,"pequenas prefeituras normalmente fazem uso de empresas privadas para realização de serviços relacionados ao monitoramento da situação do imposto predial e territorial urbano (iptu) de imóveis, ou seja, terceirizam estes serviços. uma dessas empresas sentiu a necessidade da criação de um sistema web que viabilizasse o cadastro e manutenção dos dados que são coletados, permitindo uma otimização no gerenciamento dessas informações. utilizando o sistema será possível concentrar todos os dados em um único local, abolindo assim a utilização e acúmulo de planilhas."
188,2023,League of Legends: predição de resultados em tempo real.,"SILVA JUNIOR, Jailson Barros da.","CAMPELO, Cláudio Elízio Calazans.","Este artigo apresenta um estudo sobre a predição de resultados em partidas do jogo eletrônico
League of Legends (LoL) utilizando técnicas de aprendizado de máquina. Com o objetivo de explorar a
capacidade de prever resultados em tempo real, considerando diferentes variáveis e estágios da
partida, destacamos o uso de dados inéditos como parte fundamental desse processo. Com o
aumento da popularidade do LoL e a realização de torneios, surgiram também as apostas
relacionadas ao jogo, tornando ainda mais relevante a investigação nessa área. Diversos modelos
foram avaliados e os resultados foram encorajadores. O modelo baseado em Random Forest obteve o
melhor desempenho, alcançando uma acurácia média de 81,57% em estágios intermediários da
partida, quando a porcentagem de tempo decorrido estava entre 60% e 80%. Por outro lado, os
modelos de Regressão Logística e Gradient Boosting mostraram-se mais eficazes em estágios iniciais
do jogo, com resultados promissores. Esse estudo contribui para o campo de aprendizado de
máquina aplicado a jogos eletrônicos, fornecendo insights valiosos sobre a predição em tempo real
no League of Legends. Os resultados obtidos podem ser relevantes tanto para os jogadores que
desejam aprimorar suas estratégias quanto para a indústria de apostas relacionada ao jogo.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/30488,"este artigo apresenta um estudo sobre a predição de resultados em partidas do jogo eletrônico league of legends (lol) utilizando técnicas de aprendizado de máquina. com o objetivo de explorar a capacidade de prever resultados em tempo real, considerando diferentes variáveis e estágios da partida, destacamos o uso de dados inéditos como parte fundamental desse processo. com o aumento da popularidade do lol e a realização de torneios, surgiram também as apostas relacionadas ao jogo, tornando ainda mais relevante a investigação nessa área. diversos modelos foram avaliados e os resultados foram encorajadores. o modelo baseado em random forest obteve o melhor desempenho, alcançando uma acurácia média de , % em estágios intermediários da partida, quando a porcentagem de tempo decorrido estava entre % e %. por outro lado, os modelos de regressão logística e gradient boosting mostraram-se mais eficazes em estágios iniciais do jogo, com resultados promissores. esse estudo contribui para o campo de aprendizado de máquina aplicado a jogos eletrônicos, fornecendo insights valiosos sobre a predição em tempo real no league of legends. os resultados obtidos podem ser relevantes tanto para os jogadores que desejam aprimorar suas estratégias quanto para a indústria de apostas relacionada ao jogo."
189,2023,UrnaLogs: facilitando a análise de logs de urnas eletrônicas para promover transparência no processo eleitoral.,"VIRGOLINO, Victor Arruda Câmara.","OLIVEIRA, Maxwell Guimarães de.","O processo de votação eletrônica no Brasil, utilizando urnas eletrônicas e reconhecimento biométrico,
trouxe facilidades e agilidade para as eleições. No entanto, problemas técnicos e a falta de transparência
têm gerado desconfiança e questionamentos sobre a contabilização correta dos votos. Nesse contexto, os
logs das urnas eletrônicas se tornam uma fonte valiosa de dados, registrando todas as operações
realizadas pelos eleitores e mesários. No entanto, a grande parcela da população desconhece a
existência desses logs e como acessá-los. Este trabalho visa tornar mais acessível a obtenção e análise
dos dados armazenados nos logs das urnas das eleições, disponibilizados no site do Tribunal Superior
Eleitoral (TSE). A ferramenta possui 4 módulos: o primeiro é responsável por realizar a coleta de todos os
logs das urnas da eleição através do uso de Web Scraping; o segundo efetua o processo de Extract,
Transform, Load (ETL) para tornar os dados estruturados; o terceiro é responsável por armazenar os
dados; e, por fim, o quarto disponibiliza um dashboard no qual é possível visualizar e filtrar os dados de
cada seção com o suporte de ferramentas visuais que facilitem a interpretação.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/30487,"o processo de votação eletrônica no brasil, utilizando urnas eletrônicas e reconhecimento biométrico, trouxe facilidades e agilidade para as eleições. no entanto, problemas técnicos e a falta de transparência têm gerado desconfiança e questionamentos sobre a contabilização correta dos votos. nesse contexto, os logs das urnas eletrônicas se tornam uma fonte valiosa de dados, registrando todas as operações realizadas pelos eleitores e mesários. no entanto, a grande parcela da população desconhece a existência desses logs e como acessá-los. este trabalho visa tornar mais acessível a obtenção e análise dos dados armazenados nos logs das urnas das eleições, disponibilizados no site do tribunal superior eleitoral (tse). a ferramenta possui módulos: o primeiro é responsável por realizar a coleta de todos os logs das urnas da eleição através do uso de web scraping; o segundo efetua o processo de extract, transform, load (etl) para tornar os dados estruturados; o terceiro é responsável por armazenar os dados; e, por fim, o quarto disponibiliza um dashboard no qual é possível visualizar e filtrar os dados de cada seção com o suporte de ferramentas visuais que facilitem a interpretação."
190,2023,Internacionalização de websites.,"SILVA, Ronnyldo Rodrigues Eloy da.","PEREIRA, Eanes Torres.","A localização e internacionalização de websites são práticas que visam, entre outros objetivos,
conquistar ou atrair clientes em novos mercados; e/ou conferir maior credibilidade e visibilidade à
instituição, empresa ou produto a que se destina o seu conteúdo. Para atingir esse resultado, é
necessária uma estratégia para determinar como o website será feito, pensando em cada público-alvo e
região. É necessário ser capaz de suportar não apenas idiomas diferentes, mas regiões diferentes com o
mesmo idioma. A interface do usuário precisa responder não apenas ao tamanho da tela, mas também a
diferentes idiomas e modos de escrita. O conteúdo precisa ser estruturado, desde sua interface do
usuário e o formato de suas datas, para ser adaptável a qualquer idioma que você lançar nele. Neste
trabalho será apresentada a importância da internacionalização/localização de websites, explicando as
principais etapas para a localização de um website, desde sua estrutura e design. Assim como funcionam
os principais serviços de hospedagem de websites e seus serviços de tradução para solucionar a
demanda de internacionalização. Por fim, foi desenvolvida uma aplicação web em Django e React, capaz
de traduzir texto a partir de HTML, além de legendar e traduzir vídeos e áudios. A aplicação utiliza APIs
da Google para o processo de tradução e legenda.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/30486,"a localização e internacionalização de websites são práticas que visam, entre outros objetivos, conquistar ou atrair clientes em novos mercados; e/ou conferir maior credibilidade e visibilidade à instituição, empresa ou produto a que se destina o seu conteúdo. para atingir esse resultado, é necessária uma estratégia para determinar como o website será feito, pensando em cada público-alvo e região. é necessário ser capaz de suportar não apenas idiomas diferentes, mas regiões diferentes com o mesmo idioma. a interface do usuário precisa responder não apenas ao tamanho da tela, mas também a diferentes idiomas e modos de escrita. o conteúdo precisa ser estruturado, desde sua interface do usuário e o formato de suas datas, para ser adaptável a qualquer idioma que você lançar nele. neste trabalho será apresentada a importância da internacionalização/localização de websites, explicando as principais etapas para a localização de um website, desde sua estrutura e design. assim como funcionam os principais serviços de hospedagem de websites e seus serviços de tradução para solucionar a demanda de internacionalização. por fim, foi desenvolvida uma aplicação web em django e react, capaz de traduzir texto a partir de html, além de legendar e traduzir vídeos e áudios. a aplicação utiliza apis da google para o processo de tradução e legenda."
191,2023,Aplicativo gerenciador de pedidos de restaurante com conexão para impressora térmica.,"PONTES, Isaías Martins Teixeira.","CAMPELO, Claudio Elízio Calazans.","Este trabalho tem como objetivo promover uma solução para pequenas e médias empresas no
ramo gastronômico de delivery (entregas em domicílio), com ênfase nos estabelecimentos que,
por muitas vezes, contam com uma equipe reduzida e pessoas não familiarizadas com o uso de
computadores. Com a pandemia da COVID-19, o número de entregas de alimentos aumentou
consideravelmente, e a maioria dessas demandas são concentradas em poucos aplicativos
comerciais. No entanto, esses aplicativos apresentam alta complexidade de uso. O que prejudica
os restaurantes de menor porte que não tem familiaridade com uso de computador e nem
condições para compra de equipamentos necessários como impressora térmica serial que tem
um custo elevado. Para solucionar esse problema, foi desenvolvido uma aplicação Android e
backend que gerencia os pedidos, desde o fluxo do cardápio até a entrega. A aplicação possui
funcionalidades essenciais, como a impressão do pedido por meio de impressora térmica
bluetooth de baixo custo. Dessa forma, é possível atingir um público maior que depende de
pedidos impressos para a comunicação entre a cozinha e os entregadores, melhorando a
organização do estabelecimento com redução do tempo de entrega e prevenção de erros
humanos.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/30485,"este trabalho tem como objetivo promover uma solução para pequenas e médias empresas no ramo gastronômico de delivery (entregas em domicílio), com ênfase nos estabelecimentos que, por muitas vezes, contam com uma equipe reduzida e pessoas não familiarizadas com o uso de computadores. com a pandemia da covid- , o número de entregas de alimentos aumentou consideravelmente, e a maioria dessas demandas são concentradas em poucos aplicativos comerciais. no entanto, esses aplicativos apresentam alta complexidade de uso. o que prejudica os restaurantes de menor porte que não tem familiaridade com uso de computador e nem condições para compra de equipamentos necessários como impressora térmica serial que tem um custo elevado. para solucionar esse problema, foi desenvolvido uma aplicação android e backend que gerencia os pedidos, desde o fluxo do cardápio até a entrega. a aplicação possui funcionalidades essenciais, como a impressão do pedido por meio de impressora térmica bluetooth de baixo custo. dessa forma, é possível atingir um público maior que depende de pedidos impressos para a comunicação entre a cozinha e os entregadores, melhorando a organização do estabelecimento com redução do tempo de entrega e prevenção de erros humanos."
192,2023,"Virtualização, Refatoração e Revitalização do Serviço Cursos UFCG: um relato de experiência.","COSTA, Fernando Lisboa.","MORAIS, Fábio Jorge Almeida.","À medida que um software envelhece, muitas das tecnologias que o compõem se tornam obsoletas e difíceis de
evoluir. Além disso, novas abordagens para construir serviços surgem, como a virtualização de ambientes de
execução, que proporciona maior facilidade na integração de novos desenvolvedores e no gerenciamento de
dependências. Neste trabalho, o objetivo é aplicar processos de virtualização, refatoração e revitalização ao
sistema web Cursos UFCG, utilizado pelos alunos da Universidade Federal de Campina Grande para visualizar
grades de cursos, simular composições curriculares e analisar matrículas. O sistema é composto por código
legado e enfrenta desafios relacionados à evolução e gerenciamento de dependências. Para lidar com essas
questões, foi utilizada a plataforma Docker para virtualização, combinada com análise da estrutura do projeto e
suas dependências. O objetivo principal é modernizar o ambiente de execução e aplicar refatorações para se
adequar a um novo conjunto de ferramentas e linguagem de programação. Espera-se que esse trabalho melhore
o ciclo de vida do desenvolvimento de software e atualize as tecnologias empregadas no projeto.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/30484,"à medida que um software envelhece, muitas das tecnologias que o compõem se tornam obsoletas e difíceis de evoluir. além disso, novas abordagens para construir serviços surgem, como a virtualização de ambientes de execução, que proporciona maior facilidade na integração de novos desenvolvedores e no gerenciamento de dependências. neste trabalho, o objetivo é aplicar processos de virtualização, refatoração e revitalização ao sistema web cursos ufcg, utilizado pelos alunos da universidade federal de campina grande para visualizar grades de cursos, simular composições curriculares e analisar matrículas. o sistema é composto por código legado e enfrenta desafios relacionados à evolução e gerenciamento de dependências. para lidar com essas questões, foi utilizada a plataforma docker para virtualização, combinada com análise da estrutura do projeto e suas dependências. o objetivo principal é modernizar o ambiente de execução e aplicar refatorações para se adequar a um novo conjunto de ferramentas e linguagem de programação. espera-se que esse trabalho melhore o ciclo de vida do desenvolvimento de software e atualize as tecnologias empregadas no projeto."
193,2023,MemorizApp: um sistema de aprendizado baseado em repetição espaçada.,"SEABRA, Igor Santa Ritta.","MONTEIRO, João Arthur Brunet.","Considerando a relevância da disponibilidade de ferramentas inovadoras e acessíveis para um
aprendizado eficaz e contínuo, este artigo descreve o MemorizApp, um Sistema de Repetição
Espaçada (SRS) gratuito e de código aberto. Baseado em cartões de memorização digitais
personalizados, seu objetivo é auxiliar os usuários a memorizar conteúdos de maneira eficiente,
utilizando um algoritmo de agendamento de revisões baseado na técnica da repetição espaçada. A
aplicação visa superar as limitações de outras opções disponíveis no mercado, oferecendo uma
variedade de tipos de teste para os cartões e buscando simplificar o uso da ferramenta. Algumas
melhorias e funcionalidades adicionais são sugeridas para versões futuras do sistema.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/30483,"considerando a relevância da disponibilidade de ferramentas inovadoras e acessíveis para um aprendizado eficaz e contínuo, este artigo descreve o memorizapp, um sistema de repetição espaçada (srs) gratuito e de código aberto. baseado em cartões de memorização digitais personalizados, seu objetivo é auxiliar os usuários a memorizar conteúdos de maneira eficiente, utilizando um algoritmo de agendamento de revisões baseado na técnica da repetição espaçada. a aplicação visa superar as limitações de outras opções disponíveis no mercado, oferecendo uma variedade de tipos de teste para os cartões e buscando simplificar o uso da ferramenta. algumas melhorias e funcionalidades adicionais são sugeridas para versões futuras do sistema."
194,2023,Um estudo de caso de implantação de processo de qualidade no desenvolvimento de uma aplicação para dispositivos Android.,"SILVA, Francicláudio Dantas da.","MASSONI, Tiago Lima.","O desenvolvimento de aplicações Android é uma tarefa complexa. A variedade de dispositivos, e suas diferentes
configurações, são um exemplo das razões que dificultam esse desenvolvimento. Por causa disso, um processo de
desenvolvimento bem planejado é importante para garantir a qualidade do software. A falta desse processo pode aumentar a
incidência de bugs e as chances de requisitos do sistema não serem satisfeitos. Esse trabalho tem como objetivo implantar um
processo de qualidade de software no contexto do desenvolvimento de uma aplicação Android. Essa aplicação tem como
propósito ser utilizada por agentes de saúde que a alimentarão com dados que serão processados e modelados a fim de emitir
alertas antecipados sobre a incidência de populações de mosquitos transmissores de doenças. O processo de qualidade será
definido a partir de uma pesquisa na literatura sobre boas práticas em desenvolvimento Android, um estudo sobre o domínio
do problema e sobre regras de negócio da aplicação. A partir dessa pesquisa, será discutida uma estratégia para a criação de
um processo que engloba o desenvolvimento de testes, versionamento de código, escolha dos requisitos não funcionais e
procedimentos para a implantação da aplicação. Ao final do trabalho, será aplicado um questionário aos supervisores para
que eles possam avaliar a eficácia do processo implantado. Espera-se que, depois de adotado o processo de qualidade, exista
uma maior clareza e fluidez nas entregas da aplicação, e que seja minimizada a quantidade de problemas.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/30482,"o desenvolvimento de aplicações android é uma tarefa complexa. a variedade de dispositivos, e suas diferentes configurações, são um exemplo das razões que dificultam esse desenvolvimento. por causa disso, um processo de desenvolvimento bem planejado é importante para garantir a qualidade do software. a falta desse processo pode aumentar a incidência de bugs e as chances de requisitos do sistema não serem satisfeitos. esse trabalho tem como objetivo implantar um processo de qualidade de software no contexto do desenvolvimento de uma aplicação android. essa aplicação tem como propósito ser utilizada por agentes de saúde que a alimentarão com dados que serão processados e modelados a fim de emitir alertas antecipados sobre a incidência de populações de mosquitos transmissores de doenças. o processo de qualidade será definido a partir de uma pesquisa na literatura sobre boas práticas em desenvolvimento android, um estudo sobre o domínio do problema e sobre regras de negócio da aplicação. a partir dessa pesquisa, será discutida uma estratégia para a criação de um processo que engloba o desenvolvimento de testes, versionamento de código, escolha dos requisitos não funcionais e procedimentos para a implantação da aplicação. ao final do trabalho, será aplicado um questionário aos supervisores para que eles possam avaliar a eficácia do processo implantado. espera-se que, depois de adotado o processo de qualidade, exista uma maior clareza e fluidez nas entregas da aplicação, e que seja minimizada a quantidade de problemas."
195,2023,Microsserviços e orquestração de contêineres: uma abordagem prática.,"COSTA, Holliver de Oliveira.","MORAIS, Fábio Jorge Almeida.","Com a evolução dos softwares e comunicação distribuída, os
múltiplos microsserviços estão cada vez mais presentes e
com grande demanda nas macros empresas. Esse formato
arquitetural é amplamente utilizado atualmente, portanto, se
faz necessário profissionais qualificados para a implantação
dessa arquitetura. Assim, o presente trabalho tem como
objetivo apresentar e analisar métodos e estratégias de
sistemas que utilizam microsserviços em uma plataforma
distribuída, analisando os pontos positivos, benefícios e
desvantagens. Isto é feito usando uma arquitetura de
microsserviços e implantação em uma infraestrutura
distribuída baseada em Kubernetes e Docker. Este trabalho
tem como objetivo fornecer base conceitual e técnica para
que o leitor entenda a arquitetura em microsserviços e
consiga implementar e implantar uma aplicação padrão
utilizando microsserviços em um ambiente Kubernetes com
Docker.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/30478,"com a evolução dos softwares e comunicação distribuída, os múltiplos microsserviços estão cada vez mais presentes e com grande demanda nas macros empresas. esse formato arquitetural é amplamente utilizado atualmente, portanto, se faz necessário profissionais qualificados para a implantação dessa arquitetura. assim, o presente trabalho tem como objetivo apresentar e analisar métodos e estratégias de sistemas que utilizam microsserviços em uma plataforma distribuída, analisando os pontos positivos, benefícios e desvantagens. isto é feito usando uma arquitetura de microsserviços e implantação em uma infraestrutura distribuída baseada em kubernetes e docker. este trabalho tem como objetivo fornecer base conceitual e técnica para que o leitor entenda a arquitetura em microsserviços e consiga implementar e implantar uma aplicação padrão utilizando microsserviços em um ambiente kubernetes com docker."
196,2023,Classificação de queixas dermatológicas usando redes neurais convolucionais.,"NÓBREGA, Pedro Henrique de Moraes.","PEREIRA, Eanes Torres.","Queixas dermatológicas estéticas, mesmo não representando
riscos à vida, podem ter um impacto significativo na autoestima
das pessoas e, consequentemente, causar danos à saúde
emocional. Com o intuito de auxiliar profissionais da área de
estética na identificação e tratamento desses problemas, foi
proposta a criação de um aplicativo que possui, entre suas
funcionalidades, a classificação de queixas dermatológicas, tais
como desidratação, acne, oleosidade, comedões, rugas, flacidez,
hiperpigmentação e lesões cutâneas. Com a utilização de técnicas
de aprendizado de máquina, especialmente redes neurais
convolucionais, a classificação de imagens tem se tornado cada
vez mais precisa. Com base nisso, o objetivo deste projeto é
utilizar redes neurais convolucionais para criar um modelo que
possa integrar o aplicativo acima referido, visando a classificação
dessas queixas dermatológicas. Para isso, será realizado o
treinamento de um modelo com um conjunto de dados contendo
imagens de cada tipo de queixa, possibilitando a classificação das
imagens enviadas pelo usuário e a identificação das queixas
presentes nelas.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/30477,"queixas dermatológicas estéticas, mesmo não representando riscos à vida, podem ter um impacto significativo na autoestima das pessoas e, consequentemente, causar danos à saúde emocional. com o intuito de auxiliar profissionais da área de estética na identificação e tratamento desses problemas, foi proposta a criação de um aplicativo que possui, entre suas funcionalidades, a classificação de queixas dermatológicas, tais como desidratação, acne, oleosidade, comedões, rugas, flacidez, hiperpigmentação e lesões cutâneas. com a utilização de técnicas de aprendizado de máquina, especialmente redes neurais convolucionais, a classificação de imagens tem se tornado cada vez mais precisa. com base nisso, o objetivo deste projeto é utilizar redes neurais convolucionais para criar um modelo que possa integrar o aplicativo acima referido, visando a classificação dessas queixas dermatológicas. para isso, será realizado o treinamento de um modelo com um conjunto de dados contendo imagens de cada tipo de queixa, possibilitando a classificação das imagens enviadas pelo usuário e a identificação das queixas presentes nelas."
197,2023,Estudo de caso: uso do ChatGPT para resolução de problemas de programação.,"SOUZA, Débora Lêda de Lucena.","GHEYI, Rohit.","A geração de programas a partir de linguagem natural visa transformar frases ou comandos em
linguagem natural em código de programação. O ChatGPT é um chatbot de propósito geral baseado
no modelo de linguagem GPT-3 desenvolvido para gerar texto como humano, e treinado em uma
forma de conversação usando aprendizagem por reforço com feedback humano. Nesse cenário,
questionamentos a respeito da confiabilidade das respostas geradas pelo ChatGPT 3.5 foram
levantados. Assim, neste estudo, foi realizada uma avaliação do desempenho do modelo na resolução
de 100 problemas de programação selecionados aleatoriamente de plataformas populares como
LeetCode e BeeCrowd. Os problemas selecionados estão distribuídos entre os graus de complexidade
Fácil, Intermediário e Difícil. Do total de 100 problemas submetidos, o modelo de linguagem
conseguiu responder corretamente 71 problemas ao longo de 3 tentativas, sendo 50 deles da
plataforma LeetCode e 21 da plataforma BeeCrowd. Sendo assim, é possível concluir que o ChatGPT
pode ser usado para resolver uma gama de problemas, porém seu uso requer muita atenção, uma
vez que nem sempre o resultado gerado estará correto.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/30461,"a geração de programas a partir de linguagem natural visa transformar frases ou comandos em linguagem natural em código de programação. o chatgpt é um chatbot de propósito geral baseado no modelo de linguagem gpt- desenvolvido para gerar texto como humano, e treinado em uma forma de conversação usando aprendizagem por reforço com feedback humano. nesse cenário, questionamentos a respeito da confiabilidade das respostas geradas pelo chatgpt . foram levantados. assim, neste estudo, foi realizada uma avaliação do desempenho do modelo na resolução de problemas de programação selecionados aleatoriamente de plataformas populares como leetcode e beecrowd. os problemas selecionados estão distribuídos entre os graus de complexidade fácil, intermediário e difícil. do total de problemas submetidos, o modelo de linguagem conseguiu responder corretamente problemas ao longo de tentativas, sendo deles da plataforma leetcode e da plataforma beecrowd. sendo assim, é possível concluir que o chatgpt pode ser usado para resolver uma gama de problemas, porém seu uso requer muita atenção, uma vez que nem sempre o resultado gerado estará correto."
198,2023,Um Dashboard de visualização de estatísticas para usuários do Spotify.,"LIMA, Daniel Gomes de.","MASSONI, Tiago Lima.","O streaming de áudio vem crescendo, em 2021 foram registrados mais de 500 milhões de assinantes
juntando todas as plataformas, e isso tornou o ato de escutar músicas e podcasts algo mais simples e
rápido. Graças a esses aplicativos, é possível ter acesso a um diverso acervo musical, de diferentes
artistas e gêneros, e de podcasts. Atualmente o Spotify é o serviço de streaming de áudio mais
popular no mundo com mais de 400 milhões de usuários mensais ativos. Entretanto, não é possível
para o usuário consultar as estatísticas, como música mais ouvidas e métricas sobre as músicas
(popularidade, duração, positividade e etc), referente ao que vem escutando ao longo dos anos, já
que o Spotify disponibiliza apenas a retrospectiva anual e as músicas e artistas mais ouvidos no mês.
Por isso, esse trabalho tem o intuito de criar um dashboard acessível ao usuário com estatísticas
musicais, a partir de uma investigação da API do Spotify, que é disponibilizada para desenvolvedores.
Uma contribuição adicional é, apresentar e analisar a semântica, contexto e retorno das
funcionalidades da API de forma a definir os requisitos para projetar uma aplicação web com o
dashboard do usuário. Este documento contém os resultados da experimentação e análise da API,
além de tornar possível a utilização do dashboard com as estatísticas do usuário que estiver logado.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/30460,"o streaming de áudio vem crescendo, em foram registrados mais de milhões de assinantes juntando todas as plataformas, e isso tornou o ato de escutar músicas e podcasts algo mais simples e rápido. graças a esses aplicativos, é possível ter acesso a um diverso acervo musical, de diferentes artistas e gêneros, e de podcasts. atualmente o spotify é o serviço de streaming de áudio mais popular no mundo com mais de milhões de usuários mensais ativos. entretanto, não é possível para o usuário consultar as estatísticas, como música mais ouvidas e métricas sobre as músicas (popularidade, duração, positividade e etc), referente ao que vem escutando ao longo dos anos, já que o spotify disponibiliza apenas a retrospectiva anual e as músicas e artistas mais ouvidos no mês. por isso, esse trabalho tem o intuito de criar um dashboard acessível ao usuário com estatísticas musicais, a partir de uma investigação da api do spotify, que é disponibilizada para desenvolvedores. uma contribuição adicional é, apresentar e analisar a semântica, contexto e retorno das funcionalidades da api de forma a definir os requisitos para projetar uma aplicação web com o dashboard do usuário. este documento contém os resultados da experimentação e análise da api, além de tornar possível a utilização do dashboard com as estatísticas do usuário que estiver logado."
199,2023,Vem Jogar: aplicação web para gerenciamento de grupos de práticas esportivas.,"FERREIRA, Higor Roberto Ferreira.","ARAÚJO, Eliane Cristina de.","A prática de esportes coletivos contribui de forma relevante para a manutenção da saúde física e
mental do ser humano. Dependendo do meio social em que o indivíduo está inserido, tal prática pode
ser impedida ou desestimulada por uma série de fatores, dentre eles a falta de interesse comum em
relação a determinado esporte, nível de habilidade discrepante entre os praticantes, horários das
práticas que não se encaixam na rotina do atleta, condições climáticas desfavoráveis, entre outros
fatores. Este trabalho relata o desenvolvimento de uma aplicação web que tem como objetivo
estimular a prática de esportes coletivos através da gestão de grupos com este propósito. Os usuários
poderão gerenciar ou participar de grupos de determinada prática esportiva que atendam ao seu
perfil como atleta.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/30454,"a prática de esportes coletivos contribui de forma relevante para a manutenção da saúde física e mental do ser humano. dependendo do meio social em que o indivíduo está inserido, tal prática pode ser impedida ou desestimulada por uma série de fatores, dentre eles a falta de interesse comum em relação a determinado esporte, nível de habilidade discrepante entre os praticantes, horários das práticas que não se encaixam na rotina do atleta, condições climáticas desfavoráveis, entre outros fatores. este trabalho relata o desenvolvimento de uma aplicação web que tem como objetivo estimular a prática de esportes coletivos através da gestão de grupos com este propósito. os usuários poderão gerenciar ou participar de grupos de determinada prática esportiva que atendam ao seu perfil como atleta."
200,2023,Vitrine popular digital: o começo de uma aplicação para todos.,"MENDES JUNIOR, José Adrião Barbosa.","ARAÚJO, Eliane Cristina de.","O projeto de backend ""Vitrine popular digital"" é uma plataforma
desenvolvida para auxiliar pequenos proprietários de negócios nas
fases iniciais do desenvolvimento de suas aplicações web. Seu
principal objetivo é fornecer recursos e funcionalidades essenciais
para que os comerciantes possam criar, gerenciar e expandir seus
negócios online. Esse backend oferece recursos como
gerenciamento de produtos, processamento de pedidos,
autenticação e segurança, feedback dos clientes, construção de
credibilidade e confiança por meio de avaliações dos clientes,
registro eficiente de produtos em massa e escalabilidade e
extensibilidade para atender às necessidades crescentes do
negócio. O projeto ""Vitrine popular digital"" visa capacitar
pequenos comerciantes e estudantes interessados em ingressar no
mercado online, oferecendo uma solução confiável e
personalizável para suas empreitadas no comércio eletrônico.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/30444,"o projeto de backend ""vitrine popular digital"" é uma plataforma desenvolvida para auxiliar pequenos proprietários de negócios nas fases iniciais do desenvolvimento de suas aplicações web. seu principal objetivo é fornecer recursos e funcionalidades essenciais para que os comerciantes possam criar, gerenciar e expandir seus negócios online. esse backend oferece recursos como gerenciamento de produtos, processamento de pedidos, autenticação e segurança, feedback dos clientes, construção de credibilidade e confiança por meio de avaliações dos clientes, registro eficiente de produtos em massa e escalabilidade e extensibilidade para atender às necessidades crescentes do negócio. o projeto ""vitrine popular digital"" visa capacitar pequenos comerciantes e estudantes interessados em ingressar no mercado online, oferecendo uma solução confiável e personalizável para suas empreitadas no comércio eletrônico."
201,2023,Reconhecimento de instrumentos musicais utilizando machine learning: um estudo de caso.,"ALMEIDA, Gabryelle Soares Herculano de.","MARINHO, Leandro Balby.","A área de Recuperação de Informações Musicais (Music Information Retrieval ou MIR)
engloba uma variedade de tópicos, incluindo a transcrição musical, a separação de fontes sonoras, o
reconhecimento de instrumentos e/ou gêneros musicais. Um exemplo prático de um desses campos é o
Spotify, que utiliza sistemas de recomendação capazes de aprender o padrão de conteúdo reproduzido
e sugere aos usuários músicas similares. No entanto, o reconhecimento de instrumentos ainda pode ser
desafiador de acordo com o conjunto de dados utilizado, dificultando o reconhecimento de padrões.
Nesse contexto, essa pesquisa tem como objetivo treinar um modelo capaz de detectar e identificar
instrumentos, além de avaliá-lo em diferentes conjuntos de dados amplamente conhecidos na área de
MIR. Para isso, foram utilizados áudios do OpenMIC-2018 no treinamento e os modelos foram
avaliados em três conjuntos de dados, sendo estes: MTG-Jamendo, NSynth e áudios de apresentações
ao vivo com instrumentos separados utilizando o Demucs. A acurácia será um dos critérios utilizados
para avaliar o desempenho do modelo. Ao abordar essa problemática, espera-se contribuir para
avanços na área de MIR, permitindo recomendações musicais mais personalizadas por meio do
aprimoramento da precisão em sistemas de recomendação. Além disso, deseja-se fornecer insights
para a comunidade de MIR, auxiliando na análise musical e em campos relacionados, a fim de permitir
aplicações cada vez mais eficientes.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/30435,"a área de recuperação de informações musicais (music information retrieval ou mir) engloba uma variedade de tópicos, incluindo a transcrição musical, a separação de fontes sonoras, o reconhecimento de instrumentos e/ou gêneros musicais. um exemplo prático de um desses campos é o spotify, que utiliza sistemas de recomendação capazes de aprender o padrão de conteúdo reproduzido e sugere aos usuários músicas similares. no entanto, o reconhecimento de instrumentos ainda pode ser desafiador de acordo com o conjunto de dados utilizado, dificultando o reconhecimento de padrões. nesse contexto, essa pesquisa tem como objetivo treinar um modelo capaz de detectar e identificar instrumentos, além de avaliá-lo em diferentes conjuntos de dados amplamente conhecidos na área de mir. para isso, foram utilizados áudios do openmic- no treinamento e os modelos foram avaliados em três conjuntos de dados, sendo estes: mtg-jamendo, nsynth e áudios de apresentações ao vivo com instrumentos separados utilizando o demucs. a acurácia será um dos critérios utilizados para avaliar o desempenho do modelo. ao abordar essa problemática, espera-se contribuir para avanços na área de mir, permitindo recomendações musicais mais personalizadas por meio do aprimoramento da precisão em sistemas de recomendação. além disso, deseja-se fornecer insights para a comunidade de mir, auxiliando na análise musical e em campos relacionados, a fim de permitir aplicações cada vez mais eficientes."
202,2023,Avaliação de modelos de agrupamento para detecção de comportamento de aplicações em termos de demanda e uso de recursos.,"MEDEIROS, Gabriel Paiva.","MORAIS, Fábio Jorge Almeida.","Vem se tornando cada vez mais comum a utilização de técnicas de observação de aplicações.
Observar uma aplicação gera dados importantes sobre o seu funcionamento e da infraestrutura onde
ela está inserida. Analisar o comportamento de aplicações é um elemento chave que permite
entender e provisionar recursos computacionais, otimizando o uso da infraestrutura em que se
executam as aplicações. Embora haja o reconhecimento comportamental das aplicações em relação
ao uso de recursos computacionais a partir de decisões humanas, a detecção de comportamentos de
alto e baixo consumo de memória, por exemplo, através de modelos preditivos ainda não é muito
comum, o que abre oportunidades de estudos nesta área. O presente trabalho se propõe a detectar
comportamentos de uma aplicação a partir de diferentes algoritmos de agrupamento. Os resultados
mostram que é possível detectar cada comportamento para facilitar a compreensão e alocação
eficiente de recursos de computação.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/30434,"vem se tornando cada vez mais comum a utilização de técnicas de observação de aplicações. observar uma aplicação gera dados importantes sobre o seu funcionamento e da infraestrutura onde ela está inserida. analisar o comportamento de aplicações é um elemento chave que permite entender e provisionar recursos computacionais, otimizando o uso da infraestrutura em que se executam as aplicações. embora haja o reconhecimento comportamental das aplicações em relação ao uso de recursos computacionais a partir de decisões humanas, a detecção de comportamentos de alto e baixo consumo de memória, por exemplo, através de modelos preditivos ainda não é muito comum, o que abre oportunidades de estudos nesta área. o presente trabalho se propõe a detectar comportamentos de uma aplicação a partir de diferentes algoritmos de agrupamento. os resultados mostram que é possível detectar cada comportamento para facilitar a compreensão e alocação eficiente de recursos de computação."
203,2023,Understanding the testing culture of machine learning projects on Github.,"SANTOS, Wesley Matteus Araújo dos.","ALVES, Everton Leandro Galdino.","Nos últimos anos, o uso de aprendizado de máquina aumentou em diversas indústrias, mostrando
seu notável potencial para resolver tanto problemas antigos como emergentes em uma escala nunca
antes vista. No entanto, apesar dos esforços na produção de modelos novos e melhorados, bem
como metodologias de treinamento mais confiáveis, pouco se sabe sobre como esses softwares estão
sendo testados. Neste trabalho, investigamos a adoção de bibliotecas Python para, ou relacionadas, a
testes automatizados em mais de 290 repositórios de aprendizado de máquina no Github. Nós
também comparamos repositórios que usam e não usam essas ferramentas, em termos de métricas
de qualidade, e estudamos sua cobertura de código. Como resultado, 28 bibliotecas usadas para fins
de suporte a testes foram identificadas e 65,19% de todos os projetos adotaram pelo menos uma
delas. Nós também encontramos que projetos de aprendizagem por reforço e de análise/visualização
de dados têm as maiores adoções de testes automatizados, e que unittest, pytest e doctest são as
bibliotecas mais utilizadas em nosso corpus. Além disso, descobrimos que metade dos projetos que
usam pelo menos uma biblioteca de testes, tem menos code smells (48,28% em mediana) e, em
média, eles têm menos vulnerabilidades (71,42%).",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29359,"nos últimos anos, o uso de aprendizado de máquina aumentou em diversas indústrias, mostrando seu notável potencial para resolver tanto problemas antigos como emergentes em uma escala nunca antes vista. no entanto, apesar dos esforços na produção de modelos novos e melhorados, bem como metodologias de treinamento mais confiáveis, pouco se sabe sobre como esses softwares estão sendo testados. neste trabalho, investigamos a adoção de bibliotecas python para, ou relacionadas, a testes automatizados em mais de repositórios de aprendizado de máquina no github. nós também comparamos repositórios que usam e não usam essas ferramentas, em termos de métricas de qualidade, e estudamos sua cobertura de código. como resultado, bibliotecas usadas para fins de suporte a testes foram identificadas e , % de todos os projetos adotaram pelo menos uma delas. nós também encontramos que projetos de aprendizagem por reforço e de análise/visualização de dados têm as maiores adoções de testes automatizados, e que unittest, pytest e doctest são as bibliotecas mais utilizadas em nosso corpus. além disso, descobrimos que metade dos projetos que usam pelo menos uma biblioteca de testes, tem menos code smells ( , % em mediana) e, em média, eles têm menos vulnerabilidades ( , %)."
204,2023,"Gamificação em um aplicativo de divulgação de atividades, bens e serviços culturais.","ARAÚJO, Pablwo Mattheus Ribeiro de.","BARROS, Marcelo Alves de.","Estimular a inteligência coletiva e criativa das cidades é o grande
desafio da Rede Mundial de Cidades Criativas da UNESCO.
Nesse contexto, Campina Grande, cidade membro da UCCN na
categoria Artes Midiáticas, desenvolveu, na Unidade Acadêmica
de Sistemas e Computação da UFCG, uma versão inicial do
aplicativo Cidade Singular, com o objetivo de ajudar a população
a divulgar e fomentar as atividades, bens e serviços culturais das
Cidades Criativas. Para além do desafio de ofertar à população um
meio digital de divulgar seus bens culturais, resta o desafio de
engajar esta população na participação coletiva e voluntária de
uma política pública de Economia Criativa. Este trabalho tem o
objetivo de criar uma experiência na qual o usuário se sinta
motivado a participar ativamente no aplicativo, compartilhando e
alimentando o sistema com sua própria vivência. Para isso foi
concebida, desenvolvida e avaliada, uma nova versão do app
Cidade Singular usando técnicas de gamificação para aumentar a
participação e o engajamento do usuário na missão de valorizar as
singularidades de uma Cidade Criativa. Uma análise qualitativa
dos resultados, mostrou que, na percepção dos usuários, o impacto
da gamificação no aumento do engajamento da nova versão do
aplicativo foi positivo.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29358,"estimular a inteligência coletiva e criativa das cidades é o grande desafio da rede mundial de cidades criativas da unesco. nesse contexto, campina grande, cidade membro da uccn na categoria artes midiáticas, desenvolveu, na unidade acadêmica de sistemas e computação da ufcg, uma versão inicial do aplicativo cidade singular, com o objetivo de ajudar a população a divulgar e fomentar as atividades, bens e serviços culturais das cidades criativas. para além do desafio de ofertar à população um meio digital de divulgar seus bens culturais, resta o desafio de engajar esta população na participação coletiva e voluntária de uma política pública de economia criativa. este trabalho tem o objetivo de criar uma experiência na qual o usuário se sinta motivado a participar ativamente no aplicativo, compartilhando e alimentando o sistema com sua própria vivência. para isso foi concebida, desenvolvida e avaliada, uma nova versão do app cidade singular usando técnicas de gamificação para aumentar a participação e o engajamento do usuário na missão de valorizar as singularidades de uma cidade criativa. uma análise qualitativa dos resultados, mostrou que, na percepção dos usuários, o impacto da gamificação no aumento do engajamento da nova versão do aplicativo foi positivo."
205,2023,Diversidade de gênero no planejamento de tarefas em equipes de software: um estudos e caso.,"SOUZA, Natan Ataide de.","MASSONI, Tiago Lima.","Na atualidade, a diversidade de gênero é um assunto recorrente, e,
no contexto de equipes de desenvolvimento de software, esse
tópico vem ganhando cada vez mais espaço, recebendo mais
atenção dos profissionais e pesquisadores. Portanto, este trabalho
tem como objetivo o aprofundamento das discussões sobre a
relação da diversidade de gênero na estimativa de esforço e seus
resultados na produtividade das tarefas realizadas pelas equipes de
software. Tratando-se de um estudo de caso, em cima de dados de
estimativa de tempo e tempo gasto para a realização de tarefas em
uma equipe de software. Nesse contexto, foi realizada uma coleta
de dados e, posteriormente, uma limpeza dos dados, excluindo
dessa forma algumas linhas do conjunto de dados, tendo em vista
que algumas tarefas não possuíam todos os dados referentes aos
atributos existentes ou então não faziam sentido de acordo com o
objetivo do trabalho. Adicionalmente, novos atributos foram
criados para possibilitar análises mais ricas. Como resultado, foi
possível observar que a diversidade de gênero tem sim influência
no planejamento de tarefas em equipes de software,
especificamente em relação à produtividade e estimativa de tempo
das tarefas desempenhadas pela equipe.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29357,"na atualidade, a diversidade de gênero é um assunto recorrente, e, no contexto de equipes de desenvolvimento de software, esse tópico vem ganhando cada vez mais espaço, recebendo mais atenção dos profissionais e pesquisadores. portanto, este trabalho tem como objetivo o aprofundamento das discussões sobre a relação da diversidade de gênero na estimativa de esforço e seus resultados na produtividade das tarefas realizadas pelas equipes de software. tratando-se de um estudo de caso, em cima de dados de estimativa de tempo e tempo gasto para a realização de tarefas em uma equipe de software. nesse contexto, foi realizada uma coleta de dados e, posteriormente, uma limpeza dos dados, excluindo dessa forma algumas linhas do conjunto de dados, tendo em vista que algumas tarefas não possuíam todos os dados referentes aos atributos existentes ou então não faziam sentido de acordo com o objetivo do trabalho. adicionalmente, novos atributos foram criados para possibilitar análises mais ricas. como resultado, foi possível observar que a diversidade de gênero tem sim influência no planejamento de tarefas em equipes de software, especificamente em relação à produtividade e estimativa de tempo das tarefas desempenhadas pela equipe."
206,2023,Investigando as causas de turnover de desenvolvedores de software usando análise de dados de avaliações de funcionários.,"RANGEL, Mateus Brito de Sousa.","MASSONI, Tiago Lima.","Turnover é definido como a intenção de saída de um profissional
de determinada empresa, partindo do funcionário ou da própria
organização. A área de tecnologia da informação é a que mais
sofre com a alta desse índice de rotatividade, e entender as causas
e consequências disso é fundamental. Por isso, o objetivo deste
trabalho é investigar, por meio de avaliações de profissionais e
ex-profissionais, quais são os principais fatores que diminuem a
satisfação do trabalho e acabam levando a uma possível troca de
emprego, além de entender melhor cada um desses fatores. Assim,
foi realizado um estudo quantitativo através das reviews de
profissionais de mais de 20 empresas do ramo de
desenvolvimento de software e, com isso, foi possível observar
que a categoria Promoção é a possui maior destaque, seguida por
Pagamento, Recompensas e Supervisão. Estas são as que mais
influenciam em avaliações negativas, ou seja, influenciam
consideravelmente na intenção de turnover das empresas de
software.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29354,"turnover é definido como a intenção de saída de um profissional de determinada empresa, partindo do funcionário ou da própria organização. a área de tecnologia da informação é a que mais sofre com a alta desse índice de rotatividade, e entender as causas e consequências disso é fundamental. por isso, o objetivo deste trabalho é investigar, por meio de avaliações de profissionais e ex-profissionais, quais são os principais fatores que diminuem a satisfação do trabalho e acabam levando a uma possível troca de emprego, além de entender melhor cada um desses fatores. assim, foi realizado um estudo quantitativo através das reviews de profissionais de mais de empresas do ramo de desenvolvimento de software e, com isso, foi possível observar que a categoria promoção é a possui maior destaque, seguida por pagamento, recompensas e supervisão. estas são as que mais influenciam em avaliações negativas, ou seja, influenciam consideravelmente na intenção de turnover das empresas de software."
207,2023,Análise de desempenho em um ambiente OpenStack hiperconvergente.,"DANTAS, Marta Laís de Macedo.","SILVA, Thiago Emmanuel Pereira da Cunha.","Um middleware de computação na nuvem apresenta arquitetura
hiperconvergente quando seus serviços de computação, virtualização,
armazenamento e rede podem ser implantados, de forma
consolidada, em um mesmo servidor. Diferente de uma arquitetura
clássica, na qual os serviços precisam estar em servidores diferentes,
a arquitetura hiperconvergente permite otimizar o uso dos recursos
de hardware disponíveis ao consolidar vários serviços em um
número menor de recursos. No entanto, esta consolidação pode
apresentar desaios, pois pode criar contenção pelos recursos, e por
consequência reduzir o desempenho do sistema. Neste trabalho,
pretende-se avaliar o desempenho de uma arquitetura hiperconvergente
da nuvem OpenStack. Este teste considerará a carga típica
atendida por uma grande empresa de e-commerce brasileira.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29353,"um middleware de computação na nuvem apresenta arquitetura hiperconvergente quando seus serviços de computação, virtualização, armazenamento e rede podem ser implantados, de forma consolidada, em um mesmo servidor. diferente de uma arquitetura clássica, na qual os serviços precisam estar em servidores diferentes, a arquitetura hiperconvergente permite otimizar o uso dos recursos de hardware disponíveis ao consolidar vários serviços em um número menor de recursos. no entanto, esta consolidação pode apresentar desaios, pois pode criar contenção pelos recursos, e por consequência reduzir o desempenho do sistema. neste trabalho, pretende-se avaliar o desempenho de uma arquitetura hiperconvergente da nuvem openstack. este teste considerará a carga típica atendida por uma grande empresa de e-commerce brasileira."
208,2023,HelpSUS!: plataforma para auxiliar profissionais das Unidades de Pronto Atendimento a  acelerar procedimentos burocráticos dos pacientes.,"GOMES, Tibério Gadelha Mahon.","MONTEIRO, João Arthur Brunet.","Atualmente, as Unidades de Pronto Atendimento (UPA) de
Campina Grande não possuem sistema para persistir os dados e
realizar operações, tudo é preenchido manualmente e armazenado
em papel. Esse tipo de prática demanda tempo, trabalho repetitivo
e tem riscos de perda dos dados. Nesse sentido, o presente
trabalho tem como objetivo desenvolver o HelpSUS!. Trata-se de
um sistema que funciona como prontuário eletrônico para as
UPAs. Através desse sistema os funcionários poderão cadastrar
pacientes, gerenciar atendimentos, adicionar dados vitais do
paciente, solicitar e gerenciar exames e medicamentos, emitir
atestado e visualizar histórico do paciente.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29352,"atualmente, as unidades de pronto atendimento (upa) de campina grande não possuem sistema para persistir os dados e realizar operações, tudo é preenchido manualmente e armazenado em papel. esse tipo de prática demanda tempo, trabalho repetitivo e tem riscos de perda dos dados. nesse sentido, o presente trabalho tem como objetivo desenvolver o helpsus!. trata-se de um sistema que funciona como prontuário eletrônico para as upas. através desse sistema os funcionários poderão cadastrar pacientes, gerenciar atendimentos, adicionar dados vitais do paciente, solicitar e gerenciar exames e medicamentos, emitir atestado e visualizar histórico do paciente."
209,2023,Métodos de estruturação de passos de reprodução em bug reports.,"LIMA, Thiago Nascimento de.","RAMALHO, Franklin de Souza.","A resolução de bugs é uma etapa natural no ciclo de vida de um
software, desde o desenvolvimento até a fase de interação com o
usuário, problemas irão surgir. Os usuários, em geral, relatam estes
problemas através de relatórios, entretanto é comum que as informações
nestes relatórios estejam incompletas ou mal-estruturadas.
Dentre estas informações, os passos para reprodução elucidam a
sequência de ações que reproduzem o erro e são considerados como
uma das informações mais importantes do relatório. Entretanto, é
comum que tal informação não esteja presente ou esteja presente
de forma não-estruturada, dificultando, por exemplo, o trabalho
de encontrar o problema por parte do desenvolvedor e a geração
de testes automáticos. Com isso, uma aplicação se faz necessária
para identificar e estruturar os passos de reprodução de um bug
através da extração de informações do corpo do texto dos relatórios,
a fim de proporcionar dados que possam ser utilizados nas mais
diversas aplicações. Este projeto propõe o desenvolvimento de modelos
de aprendizagem de máquina baseados em Processamento de
Linguagem Natural com capacidade de identificar e estruturar os
passos para reprodução. No qual, ficou evidenciado alta eficiência
na detecção dos passos de reprodução em um relatório (F1 = 0,69),
mas baixa capacidade de promover a estruturação de componentes
dos relatórios, tais como os atores e ações.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29351,"a resolução de bugs é uma etapa natural no ciclo de vida de um software, desde o desenvolvimento até a fase de interação com o usuário, problemas irão surgir. os usuários, em geral, relatam estes problemas através de relatórios, entretanto é comum que as informações nestes relatórios estejam incompletas ou mal-estruturadas. dentre estas informações, os passos para reprodução elucidam a sequência de ações que reproduzem o erro e são considerados como uma das informações mais importantes do relatório. entretanto, é comum que tal informação não esteja presente ou esteja presente de forma não-estruturada, dificultando, por exemplo, o trabalho de encontrar o problema por parte do desenvolvedor e a geração de testes automáticos. com isso, uma aplicação se faz necessária para identificar e estruturar os passos de reprodução de um bug através da extração de informações do corpo do texto dos relatórios, a fim de proporcionar dados que possam ser utilizados nas mais diversas aplicações. este projeto propõe o desenvolvimento de modelos de aprendizagem de máquina baseados em processamento de linguagem natural com capacidade de identificar e estruturar os passos para reprodução. no qual, ficou evidenciado alta eficiência na detecção dos passos de reprodução em um relatório (f1 = , ), mas baixa capacidade de promover a estruturação de componentes dos relatórios, tais como os atores e ações."
210,2023,Avaliação da técnica de snapshotting para mitigar os efeitos do cold start de funções Javascript executados em ambiente FaaS.,"MAFRA, Luis Eduardo Barroso.","SILVA, Thiago Emmanuel Pereira da Cunha.","O modelo de computação serverless permite a criação e execução
de aplicações na nuvem, delegando para a plataforma a responsabilidade
de gerenciamento e escalonamento da infraestrutura.
Com isso, a cobrança pelos serviços considera apenas o tempo
de execução de requisições, havendo naturalmente um uso eiciente
de recursos. Essa estratégia visa reduzir custos de manter os
serviços executando, mas vem com um ônus: iniciar aplicações demandam
um tempo (cold start), e fazer isso sempre que a aplicação
for requisitada pode ser um empecilho para o desempenho delas,
principalmente em um ambiente altamente escalável. A técnica de
Prebaking surge como uma solução para esse problema, utilizando
o método de snapshot do estado de um processo para lidar com o
cold start, obtendo bons resultados para aplicações criadas em Java.
Nessa direção, este trabalho visa avaliar a utilização desse método
para a redução do cold start de aplicações Javascripts que utilizam
a runtime V8.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29350,"o modelo de computação serverless permite a criação e execução de aplicações na nuvem, delegando para a plataforma a responsabilidade de gerenciamento e escalonamento da infraestrutura. com isso, a cobrança pelos serviços considera apenas o tempo de execução de requisições, havendo naturalmente um uso eiciente de recursos. essa estratégia visa reduzir custos de manter os serviços executando, mas vem com um ônus: iniciar aplicações demandam um tempo (cold start), e fazer isso sempre que a aplicação for requisitada pode ser um empecilho para o desempenho delas, principalmente em um ambiente altamente escalável. a técnica de prebaking surge como uma solução para esse problema, utilizando o método de snapshot do estado de um processo para lidar com o cold start, obtendo bons resultados para aplicações criadas em java. nessa direção, este trabalho visa avaliar a utilização desse método para a redução do cold start de aplicações javascripts que utilizam a runtime v8."
211,2023,HealthCheckAPI: monitoramento de APIs gRPC.,"SANTOS SOBRINHA, Vitória Heliane Pereira dos.","MONTEIRO, João Arthur Brunet.","Lançado pelo Google em 2016, gRPC é um framework baseado
em RPC (Remote Procedure Call) para criação de APIs que vem
se tornando cada vez mais popular entre empresas, startups e
projetos open-source. Por ser uma tecnologia nova, ferramentas de
monitoramento, observabilidade e manutenção que deem suporte
gRPC são bastante escassas na comunidade de desenvolvimento
de software. Além disso, as poucas soluções disponíveis
geralmente são difíceis de configurar ou que não produzem
métricas desejadas, como a latência da execução das chamadas.
Diante desse contexto, o propósito deste trabalho é desenvolver o
HealthCheckAPI, uma plataforma de monitoramento de APIs
gRPC. Essa aplicação é capaz de monitorar todos os endpoints
disponíveis pela API através de chamadas periódicas ao serviço,
obtendo informações de disponibilidade e tempo de resposta, além
de permitir ao usuário configurar validações para a mensagem
retornada pela API, assim como feito nas plataformas Assertible e
Checkly que são para monitoramento apenas de APIs REST.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29347,"lançado pelo google em , grpc é um framework baseado em rpc (remote procedure call) para criação de apis que vem se tornando cada vez mais popular entre empresas, startups e projetos open-source. por ser uma tecnologia nova, ferramentas de monitoramento, observabilidade e manutenção que deem suporte grpc são bastante escassas na comunidade de desenvolvimento de software. além disso, as poucas soluções disponíveis geralmente são difíceis de configurar ou que não produzem métricas desejadas, como a latência da execução das chamadas. diante desse contexto, o propósito deste trabalho é desenvolver o healthcheckapi, uma plataforma de monitoramento de apis grpc. essa aplicação é capaz de monitorar todos os endpoints disponíveis pela api através de chamadas periódicas ao serviço, obtendo informações de disponibilidade e tempo de resposta, além de permitir ao usuário configurar validações para a mensagem retornada pela api, assim como feito nas plataformas assertible e checkly que são para monitoramento apenas de apis rest."
212,2023,The correspondence between the medieval trivium and object-oriented programming.,"SOUZA, Vinícius Abner Pereira de.","ARAÚJO, Eliane Cristina de.","Ensinar o paradigma de programação orientada a objetos costuma ser um desafio para os professores. A
principal dificuldade é muitas vezes atribuída à mentalidade que o paradigma exige. Essa mentalidade envolve
raciocinar sobre elementos da realidade em termos de classes, objetos, atributos, polimorfismo etc. Em suma, é
uma mentalidade que requer boas habilidades de abstração. Várias metodologias, abordagens e ferramentas já
foram propostas para ajudar os alunos a alcançar a mentalidade necessária para aplicar esse paradigma, mas o
aprendizado continua difícil. Diante disso, uma ferramenta que até então nunca havia sido considerada para o
ensino de programação é o Trivium medieval. O Trivium consiste nas três artes liberais de Gramática, Lógica e
Retórica. O syllabus e a estrutura das aulas do Trivium podem ser um modelo interessante para ser aplicado em
cursos de programação orientada a objetos, pois abordam de forma bastante didática conceitos fundamentais
idênticos ao do paradigma orientado a objetos. A demonstração da correlação entre os dois assuntos é um dos
objetivos deste trabalho. Além disso, conjecturamos que ensinar os conceitos fundamentais da Gramática antes
ou paralelamente ao ensino do paradigma orientado a objetos parece ser mais eficiente do que começar logo
pela prática de programação, como costuma ser feito em cursos de programação. Este artigo propõe duas
abordagens para o ensino do paradigma orientado a objetos. Eles consistem na estruturação do curso de
Programação Orientada a Objetos com base na filosofia e metodologia educacional clássica, a fim de facilitar a
compreensão do paradigma.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29346,"ensinar o paradigma de programação orientada a objetos costuma ser um desafio para os professores. a principal dificuldade é muitas vezes atribuída à mentalidade que o paradigma exige. essa mentalidade envolve raciocinar sobre elementos da realidade em termos de classes, objetos, atributos, polimorfismo etc. em suma, é uma mentalidade que requer boas habilidades de abstração. várias metodologias, abordagens e ferramentas já foram propostas para ajudar os alunos a alcançar a mentalidade necessária para aplicar esse paradigma, mas o aprendizado continua difícil. diante disso, uma ferramenta que até então nunca havia sido considerada para o ensino de programação é o trivium medieval. o trivium consiste nas três artes liberais de gramática, lógica e retórica. o syllabus e a estrutura das aulas do trivium podem ser um modelo interessante para ser aplicado em cursos de programação orientada a objetos, pois abordam de forma bastante didática conceitos fundamentais idênticos ao do paradigma orientado a objetos. a demonstração da correlação entre os dois assuntos é um dos objetivos deste trabalho. além disso, conjecturamos que ensinar os conceitos fundamentais da gramática antes ou paralelamente ao ensino do paradigma orientado a objetos parece ser mais eficiente do que começar logo pela prática de programação, como costuma ser feito em cursos de programação. este artigo propõe duas abordagens para o ensino do paradigma orientado a objetos. eles consistem na estruturação do curso de programação orientada a objetos com base na filosofia e metodologia educacional clássica, a fim de facilitar a compreensão do paradigma."
213,2023,Sou doador: uma aplicação para melhorar o sistema de doação de sangue na Paraíba.,"AQUINO, Vitor Alves Correia Lima de.","MOURA, José Antão Beltrão.","É preciso criar o hábito de doar sangue em especial. Atualmente, são coletadas no Brasil cerca de 3,6
milhões de bolsas/ano, o que corresponde ao índice de apenas 1,6% da população[1]. Tendo em vista
esse cenário, o “Sou Doador” é um projeto de aplicação para Desktop que tem como objetivo facilitar
e agilizar o processo de doação de sangue tanto para o doador, quanto para o recebedor, no estado
da Paraíba. O propósito central desse projeto é funcionar como uma forma de conexão entre pessoas
que necessitam de um(a) doador(a) de sangue e as que já são doadoras, ou que ao menos possuem
os requisitos e o desejo de doar sangue, mas precisam de ajuda para se tornar um(a) doador(a).
Propõe-se assim, oferecer uma maneira mais fácil, simplificada e informatizada de manejar uma
questão de saúde tão relevante e atual que é a doação de sangue, com a meta de auxiliar
mutuamente os cidadãos que precisam de auxílio nessa situação. Este documento apresenta o “Sou
Doador” em atendimento aos requisitos para o Trabalho de Conclusão de Curso (TCC) no Curso em
Ciência da Computação da UFCG.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29345,"é preciso criar o hábito de doar sangue em especial. atualmente, são coletadas no brasil cerca de , milhões de bolsas/ano, o que corresponde ao índice de apenas , % da população[ ]. tendo em vista esse cenário, o “sou doador” é um projeto de aplicação para desktop que tem como objetivo facilitar e agilizar o processo de doação de sangue tanto para o doador, quanto para o recebedor, no estado da paraíba. o propósito central desse projeto é funcionar como uma forma de conexão entre pessoas que necessitam de um(a) doador(a) de sangue e as que já são doadoras, ou que ao menos possuem os requisitos e o desejo de doar sangue, mas precisam de ajuda para se tornar um(a) doador(a). propõe-se assim, oferecer uma maneira mais fácil, simplificada e informatizada de manejar uma questão de saúde tão relevante e atual que é a doação de sangue, com a meta de auxiliar mutuamente os cidadãos que precisam de auxílio nessa situação. este documento apresenta o “sou doador” em atendimento aos requisitos para o trabalho de conclusão de curso (tcc) no curso em ciência da computação da ufcg."
214,2023,Veresionamento de esquemas relacionais em ambientes multi-módulo.,"VILAS BOAS, Luiz Fernando Soares.","BAPTISTA, Claudio de Souza.","As novas tecnologias estão cada vez mais presentes no cotidiano
da humanidade, consequentemente isso acarreta grande aumento
na produção de dados digitais. Dessa forma, os sistemas de
gerenciamento de bancos de dados estão sendo cada vez mais
demandados. Nesse âmbito, especificamente em ambientes
modularizados, notou-se uma necessidade em analisar os desafios
em lidar com o controle de versão nos esquemas relacionais. A
construção desta pesquisa foi dividida em três etapas: uma análise
de um caso real de uma grande empresa de soluções fiscais; um
estudo sobre as alternativas atualmente disponíveis no mercado; e,
finalmente, a sugestão de soluções iniciais para o versionamento
neste tipo de ambiente. A partir dos estudos realizados, foi visto
que o sistema da empresa é extremamente denso considerando as
questões de práticas, processos e ferramentas utilizadas. Logo,
apesar de existir alternativas no mercado, adaptar uma integração
de uma solução externa ao sistema da companhia acarretaria
mudanças radicais e em alguns casos até inviáveis. Assim, é
recomendado buscar uma solução mesclada, para manter os
processos da companhia e aderir a ferramentas externas que
otimizem a qualidade e a eficiência do controle de versão.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29343,"as novas tecnologias estão cada vez mais presentes no cotidiano da humanidade, consequentemente isso acarreta grande aumento na produção de dados digitais. dessa forma, os sistemas de gerenciamento de bancos de dados estão sendo cada vez mais demandados. nesse âmbito, especificamente em ambientes modularizados, notou-se uma necessidade em analisar os desafios em lidar com o controle de versão nos esquemas relacionais. a construção desta pesquisa foi dividida em três etapas: uma análise de um caso real de uma grande empresa de soluções fiscais; um estudo sobre as alternativas atualmente disponíveis no mercado; e, finalmente, a sugestão de soluções iniciais para o versionamento neste tipo de ambiente. a partir dos estudos realizados, foi visto que o sistema da empresa é extremamente denso considerando as questões de práticas, processos e ferramentas utilizadas. logo, apesar de existir alternativas no mercado, adaptar uma integração de uma solução externa ao sistema da companhia acarretaria mudanças radicais e em alguns casos até inviáveis. assim, é recomendado buscar uma solução mesclada, para manter os processos da companhia e aderir a ferramentas externas que otimizem a qualidade e a eficiência do controle de versão."
215,2023,Análise descritiva de fatores de impactos socioeconômicos em um serviço de streaming.,"SOUZA, Klawert Danilo Ferreira de.","MORAIS, Fábio Jorge Almeida.","Em um mundo cada vez mais conectado, o surgimento de novos
serviços digitais que atendam demandas de usuários tem se tornado
uma grande tendência mundial, algo que é visado e interpretado
como meta para muitas organizações do ramo. Estes usuários, no
que lhe concerne, são cada vez mais exigentes e possuem demandas
especíicas sobre o conteúdo que desejam consumir, bem como
quando e sob quais condições podem consumir tal conteúdo. Um
desses serviços digitais que se tornaram mais populares trata-se do
streaming, que pode ser deinido como a transmissão de conteúdo
multimídia por meio da internet, sem necessidade de download prévio;
essa popularização foi potencializada principalmente durante
o período de isolamento social em escala mundial, que tornou a
utilização desse serviço um dos principais canais de entretenimento
para grande parte da população. Uma das plataformas de streaming,
a Netlix, no entanto, presenciou uma grande queda nas suas ações
de maneira súbita em alguns momentos. Nesse contexto, esta análise
busca estudar e compreender os agravantes para esse cenário.
Para isso, foram utilizados conjunto de dados econômicos e técnicos
da empresa, bem como dados de levantamentos envolvendo
usuários da plataforma, suas experiências e suas preferências.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29342,"em um mundo cada vez mais conectado, o surgimento de novos serviços digitais que atendam demandas de usuários tem se tornado uma grande tendência mundial, algo que é visado e interpretado como meta para muitas organizações do ramo. estes usuários, no que lhe concerne, são cada vez mais exigentes e possuem demandas especíicas sobre o conteúdo que desejam consumir, bem como quando e sob quais condições podem consumir tal conteúdo. um desses serviços digitais que se tornaram mais populares trata-se do streaming, que pode ser deinido como a transmissão de conteúdo multimídia por meio da internet, sem necessidade de download prévio; essa popularização foi potencializada principalmente durante o período de isolamento social em escala mundial, que tornou a utilização desse serviço um dos principais canais de entretenimento para grande parte da população. uma das plataformas de streaming, a netlix, no entanto, presenciou uma grande queda nas suas ações de maneira súbita em alguns momentos. nesse contexto, esta análise busca estudar e compreender os agravantes para esse cenário. para isso, foram utilizados conjunto de dados econômicos e técnicos da empresa, bem como dados de levantamentos envolvendo usuários da plataforma, suas experiências e suas preferências."
216,2023,Avaliando o impacto do controle de concorrência do React 18: um estudo de caso.,"CUNHA, Túlio Araújo.","MASSONI, Tiago Lima.","Com a versão 18 da biblioteca React, foram apresentadas funcionalidades
que usam o conceito de concorrência para criar sistemas
web que proporcionem uma melhor experiência para o usuário.
Dentre as novas ferramentas ofertadas, encontra-se o hook
useDefferedValue1 que permite deinir um valor que será atualizado
com atraso. Nesse trabalho, utilizou-se esse hook para propor
melhorias em um sistema com pontos problemáticos. Para realizar
uma análise comparativa entre um sistema com e sem a utilização
desse hook, criou-se uma simulação de interações que permitiram
coletar linhas temporais de performance. Ao analisar essas linhas,
observou-se que o uso do useDefferedValue implicou em vantagens
como a redução do tempo necessário para realizar ações e a
obtenção de um feedback mais rápido às ações realizadas. Além
disso, economizaram-se recursos do navegador ao evitar o cálculo
de etapas intermediárias não desejadas pelo usuário, otimizando o
desempenho do sistema.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29341,"com a versão da biblioteca react, foram apresentadas funcionalidades que usam o conceito de concorrência para criar sistemas web que proporcionem uma melhor experiência para o usuário. dentre as novas ferramentas ofertadas, encontra-se o hook usedefferedvalue1 que permite deinir um valor que será atualizado com atraso. nesse trabalho, utilizou-se esse hook para propor melhorias em um sistema com pontos problemáticos. para realizar uma análise comparativa entre um sistema com e sem a utilização desse hook, criou-se uma simulação de interações que permitiram coletar linhas temporais de performance. ao analisar essas linhas, observou-se que o uso do usedefferedvalue implicou em vantagens como a redução do tempo necessário para realizar ações e a obtenção de um feedback mais rápido às ações realizadas. além disso, economizaram-se recursos do navegador ao evitar o cálculo de etapas intermediárias não desejadas pelo usuário, otimizando o desempenho do sistema."
217,2023,Checklife: sistema de organização de tarefas e atividades pessoais.,"ANDRADE, Marcelo Fagner da Silva.","ARAÚJO, Eliane Cristina de.","A organização pessoal é um aspecto importante da vida moderna,
podendo se apresentar de diversas formas, como anotações, agendas
e até listas de tarefas. O Checklife foi desenvolvido visando atender
a necessidade de uma lista de tarefas com organização temporal,
apresentando funcionalidades ausentes em sistemas similares, de
forma que os mais diversos públicos possam utilizá-lo de maneira
simples e objetiva. A primeira versão do Checklife foi submetida à avaliação por
usuários típicos e foi realizada a coleta de suas impressões sobre o
sistema. De acordo com o feedback obtido, as opiniões dos usuários
foram positivas, o que aponta que a aplicação é viável e está pronta
para aprimoramentos que permitirão alcançar um público mais
amplo.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29340,"a organização pessoal é um aspecto importante da vida moderna, podendo se apresentar de diversas formas, como anotações, agendas e até listas de tarefas. o checklife foi desenvolvido visando atender a necessidade de uma lista de tarefas com organização temporal, apresentando funcionalidades ausentes em sistemas similares, de forma que os mais diversos públicos possam utilizá-lo de maneira simples e objetiva. a primeira versão do checklife foi submetida à avaliação por usuários típicos e foi realizada a coleta de suas impressões sobre o sistema. de acordo com o feedback obtido, as opiniões dos usuários foram positivas, o que aponta que a aplicação é viável e está pronta para aprimoramentos que permitirão alcançar um público mais amplo."
218,2023,Analisando o senso de pertencimento em uma equipe de Engenharia de Software: um estudo de caso.,"ALBUQUERQUE, Kamila da Silva.","MASSONI, Tiago Lima.","O senso de pertencimento em equipes de engenharia de
software ainda é um conceito pouco estudado quando se trata de
aspectos humanos relacionados à área. Porém, algumas
pesquisas recentes já identificam esse aspecto no que diz
respeito à eficácia do trabalho em equipe, liderança e
produtividade. Nelas, o sentimento de pertencer a uma equipe
ou projeto, e até mesmo à organização em que trabalham, lhes
permitem ter bons resultados em seus produtos ou serviços
desenvolvidos. Diante disso, este trabalho realizou um estudo
de caso com uma equipe de desenvolvimento de software que
trabalha de forma remota, com o objetivo de identificar qual a
perspectiva do líder e dos desenvolvedores (não-líderes) de uma
empresa privada. Por meio de entrevistas e observações, os
dados foram analisados qualitativamente através de análise
temática. Os resultados evidenciam que, para os
desenvolvedores, a liderança tem um papel fundamental na
contribuição desse sentimento. Para o líder, à medida que esse
valoriza e incentiva o trabalho em equipe, e mantém ações de
melhorias, o senso de pertencimento é fortalecido, trazendo
produtividade, engajamento e melhores resultados em seus
serviços.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29338,"o senso de pertencimento em equipes de engenharia de software ainda é um conceito pouco estudado quando se trata de aspectos humanos relacionados à área. porém, algumas pesquisas recentes já identificam esse aspecto no que diz respeito à eficácia do trabalho em equipe, liderança e produtividade. nelas, o sentimento de pertencer a uma equipe ou projeto, e até mesmo à organização em que trabalham, lhes permitem ter bons resultados em seus produtos ou serviços desenvolvidos. diante disso, este trabalho realizou um estudo de caso com uma equipe de desenvolvimento de software que trabalha de forma remota, com o objetivo de identificar qual a perspectiva do líder e dos desenvolvedores (não-líderes) de uma empresa privada. por meio de entrevistas e observações, os dados foram analisados qualitativamente através de análise temática. os resultados evidenciam que, para os desenvolvedores, a liderança tem um papel fundamental na contribuição desse sentimento. para o líder, à medida que esse valoriza e incentiva o trabalho em equipe, e mantém ações de melhorias, o senso de pertencimento é fortalecido, trazendo produtividade, engajamento e melhores resultados em seus serviços."
219,2023,Um estudo comparativo entre ferramentas de monitoramento de Containers Docker.,"SALUSTIANO, Lucas Chaves Salustiano.","GOMES, Reinaldo Cezar de Morais.","A utilização de contêineres tem sido amplamente adotada na
indústria de tecnologia devido à sua flexibilidade e escalabilidade.
No entanto, o monitoramento dos contêineres é uma tarefa crucial
para garantir a disponibilidade e o desempenho do sistema. Por
isso, há uma ampla variedade de ferramentas de monitoramento
disponíveis, para os mais variados casos de uso e escopos. Neste
estudo, serão comparadas duas dessas ferramentas, o Prometheus
e o NetData, ambas sendo apontadas pela Cloud Native
Computing Foundation (CNCF) como sendo dois dos projetos
com mais contribuidores de 2022 [4].
Os critérios de avaliação serão cinco: Monitoramento em tempo
real, indicador base de performance, monitoramento de
perfomance de rede, visualização de dados e alerta. Ao final,
concluiu-se que o NetData obtém leve vantagem sobre o
Prometheus por este ser mais limitado em aspectos como
monitoramento de performance de rede e visualização de dados.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29337,"a utilização de contêineres tem sido amplamente adotada na indústria de tecnologia devido à sua flexibilidade e escalabilidade. no entanto, o monitoramento dos contêineres é uma tarefa crucial para garantir a disponibilidade e o desempenho do sistema. por isso, há uma ampla variedade de ferramentas de monitoramento disponíveis, para os mais variados casos de uso e escopos. neste estudo, serão comparadas duas dessas ferramentas, o prometheus e o netdata, ambas sendo apontadas pela cloud native computing foundation (cncf) como sendo dois dos projetos com mais contribuidores de [ ]. os critérios de avaliação serão cinco: monitoramento em tempo real, indicador base de performance, monitoramento de perfomance de rede, visualização de dados e alerta. ao final, concluiu-se que o netdata obtém leve vantagem sobre o prometheus por este ser mais limitado em aspectos como monitoramento de performance de rede e visualização de dados."
220,2023,Avaliando a qualidade de suítes de teste geradas automaticamente em detectar faltas introduzidas por refatoramentos.,"GOMES, Levi Rios.","LIRA, Melina Mongiovi Brito.","Refatoramentos são a prática em que desenvolvedores alteram seu
código de forma que não altere o comportamento do sistema. Tal
prática costuma vir acompanhada do uso de suítes de regressão
para detectar mudanças de comportamento indesejadas em um
sistema. Porém, tais suítes de teste podem não garantir a detecção
de faltas, criando um falso senso de segurança durante
refatoramentos, visto que a suíte pode não perceber certas
alterações. Neste trabalho, propomos uma abordagem que tem por
objetivo avaliar tais suítes de teste na sua capacidade de detectar
faltas de refatoramento, assim como as comparar com alternativas
de geração de suítes de teste automatizadas. Para isso, foi
realizado um estudo relacionado às faltas do refatoramento
Extract Method, e o desenvolvimento de uma ferramenta que
facilita a avaliação de uma suíte de testes, por meio de um plugin
da IDE Eclipse feito com a linguagem de programação Java. A
partir disso, foram criados mutantes de refatoramento (faltas) e
utilizados em um estudo quantitativo, no qual avaliamos as suítes
de regressão de 3 diferentes projetos open source, assim como
suítes de testes geradas pela ferramenta de geração EvoSuite.
Nossos estudos mostraram que existe uma possível relação entre
cobertura de testes e detecção de mutantes de refatoramento em
um sistema, assim como uma negligência de casos menos comuns
durante o desenvolvimento dessas suítes, visto que cerca de
38,7% das faltas de refatoramento injetadas não foram detectadas
nas suítes manuais, e 45,3% nas suítes automatizadas,
demonstrando que existe espaço para melhoria das suites de teste
focadas neste contexto.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29336,"refatoramentos são a prática em que desenvolvedores alteram seu código de forma que não altere o comportamento do sistema. tal prática costuma vir acompanhada do uso de suítes de regressão para detectar mudanças de comportamento indesejadas em um sistema. porém, tais suítes de teste podem não garantir a detecção de faltas, criando um falso senso de segurança durante refatoramentos, visto que a suíte pode não perceber certas alterações. neste trabalho, propomos uma abordagem que tem por objetivo avaliar tais suítes de teste na sua capacidade de detectar faltas de refatoramento, assim como as comparar com alternativas de geração de suítes de teste automatizadas. para isso, foi realizado um estudo relacionado às faltas do refatoramento extract method, e o desenvolvimento de uma ferramenta que facilita a avaliação de uma suíte de testes, por meio de um plugin da ide eclipse feito com a linguagem de programação java. a partir disso, foram criados mutantes de refatoramento (faltas) e utilizados em um estudo quantitativo, no qual avaliamos as suítes de regressão de diferentes projetos open source, assim como suítes de testes geradas pela ferramenta de geração evosuite. nossos estudos mostraram que existe uma possível relação entre cobertura de testes e detecção de mutantes de refatoramento em um sistema, assim como uma negligência de casos menos comuns durante o desenvolvimento dessas suítes, visto que cerca de , % das faltas de refatoramento injetadas não foram detectadas nas suítes manuais, e , % nas suítes automatizadas, demonstrando que existe espaço para melhoria das suites de teste focadas neste contexto."
221,2023,Sistema mobile de agendamento de horários para uso do complexo esportivo da UFCG.,"PEREIRA, Italo Modesto.","LIRA, Melina Mongiovi Brito.","O agendamento de horários para uso de algum dos espaços do
complexo esportivo da Universidade Federal de Campina Grande
é feito presencialmente, na secretaria do complexo, ou via
whatsapp. As duas estratégias são desconfortáveis para o usuário,
visto que na primeira, o usuário precisa deslocar-se até a secretaria
e na segunda, o usuário precisa aguardar que algum funcionário
da parte administrativa do complexo esteja disponível, para só
então, respondê-lo. Com objetivo de apresentar uma solução que
torne o processo de agendamento de horários mais prático, este
trabalho documenta o desenvolvimento de um aplicativo android,
com versões para usuários e administradores do complexo, que
torna o agendamento muito mais simples, visto que ele pode ser
feito de qualquer local, através do aplicativo e que o usuário não
precisa aguardar a disponibilidade de um funcionário da secretaria
do complexo, para respondê-lo. Como resultado, é apresentado o
aplicativo que permite a realização de agendamentos dos espaços
do complexo esportivo, além da validação do mesmo com
usuários através de questionamentos feitos no formato de
formulário, após a apresentação do aplicativo, e sugestões para
trabalhos futuros.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29333,"o agendamento de horários para uso de algum dos espaços do complexo esportivo da universidade federal de campina grande é feito presencialmente, na secretaria do complexo, ou via whatsapp. as duas estratégias são desconfortáveis para o usuário, visto que na primeira, o usuário precisa deslocar-se até a secretaria e na segunda, o usuário precisa aguardar que algum funcionário da parte administrativa do complexo esteja disponível, para só então, respondê-lo. com objetivo de apresentar uma solução que torne o processo de agendamento de horários mais prático, este trabalho documenta o desenvolvimento de um aplicativo android, com versões para usuários e administradores do complexo, que torna o agendamento muito mais simples, visto que ele pode ser feito de qualquer local, através do aplicativo e que o usuário não precisa aguardar a disponibilidade de um funcionário da secretaria do complexo, para respondê-lo. como resultado, é apresentado o aplicativo que permite a realização de agendamentos dos espaços do complexo esportivo, além da validação do mesmo com usuários através de questionamentos feitos no formato de formulário, após a apresentação do aplicativo, e sugestões para trabalhos futuros."
222,2023,Workload characterization of a large ecommerce platform.,"SILVA, Ítallo de Sousa.","MORAIS, Fabio Jorge Almeida.","Vários trabalhos abordaram a caracterização da carga de trabalho de servidores web. Esses
trabalhos resultaram em uma compilação de padrões chamados invariantes, ou seja,
observações recorrentes vistas em vários servidores. Embora alguns desses trabalhos tenham
se concentrado em sistemas de comércio eletrônico, eles analisaram dados de servidores de
pequenas lojas em um curto espaço de tempo no final dos anos 90 e início dos anos 2000.
Assim, este trabalho propôs uma caracterização da carga de trabalho de um servidor de uma
empresa multinacional de comércio eletrônico e sua comparação com os invariantes anteriores
encontrados na literatura. Descobrimos que alguns padrões, como a presença de picos e vales
na distribuição da taxa de chegada de requisições ao longo do tempo e sua relação com as
horas de trabalho do dia, continuam presentes em servidores de comércio eletrônico
modernos. Enquanto isso, outros diminuíram ou desapareceram, como a correlação entre a
taxa de chegada de requisições e a latência. Também conduzimos análises não encontradas na
literatura, como o impacto da Black Friday na carga de trabalho do servidor e a análise de
duas novas métricas: comprimento da fila de pico (surge queue length) e contagem de
transbordo (spillover count). Encontramos uma taxa de chegada mais alta durante a Black
Friday do que em dias típicos, uma distribuição assimétrica para o comprimento da fila de
pico e uma associação entre a contagem de transbordo e valores elevados de comprimento de
fila e latência.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29332,"vários trabalhos abordaram a caracterização da carga de trabalho de servidores web. esses trabalhos resultaram em uma compilação de padrões chamados invariantes, ou seja, observações recorrentes vistas em vários servidores. embora alguns desses trabalhos tenham se concentrado em sistemas de comércio eletrônico, eles analisaram dados de servidores de pequenas lojas em um curto espaço de tempo no final dos anos e início dos anos . assim, este trabalho propôs uma caracterização da carga de trabalho de um servidor de uma empresa multinacional de comércio eletrônico e sua comparação com os invariantes anteriores encontrados na literatura. descobrimos que alguns padrões, como a presença de picos e vales na distribuição da taxa de chegada de requisições ao longo do tempo e sua relação com as horas de trabalho do dia, continuam presentes em servidores de comércio eletrônico modernos. enquanto isso, outros diminuíram ou desapareceram, como a correlação entre a taxa de chegada de requisições e a latência. também conduzimos análises não encontradas na literatura, como o impacto da black friday na carga de trabalho do servidor e a análise de duas novas métricas: comprimento da fila de pico (surge queue length) e contagem de transbordo (spillover count). encontramos uma taxa de chegada mais alta durante a black friday do que em dias típicos, uma distribuição assimétrica para o comprimento da fila de pico e uma associação entre a contagem de transbordo e valores elevados de comprimento de fila e latência."
223,2023,Sistema de anotação de pedidos para serviços de alimentação.,"SILVA FILHO, Gutemberg.","LIRA, Melina Mongiovi Brito.","O mercado de restaurantes e fast foods tem
experimentado um crescimento constante ao longo dos anos,
representando uma parcela significativa das vendas de alimentos
anuais. Os serviços de distribuição de alimentos têm um impacto
significativo na vida cotidiana da sociedade, proporcionando
acesso rápido e eficiente à comida. Com isso, foi desenvolvido um
aplicativo móvel que ajuda os funcionários dos estabelecimentos a
capturar os pedidos dos clientes de maneira mais atualizada e
segura, gerando uma comanda digital altamente flexível, fácil de
gerenciar e ler. Isso contribui para aumentar a segurança, otimizar
os tempos de atendimento e fornecer um serviço mais atual e
inclusivo tecnologicamente para os funcionários que utilizam a
ferramenta, com uma interface intuitiva e minimalista. Além
disso, essa ferramenta também contribui para a preservação do
meio ambiente ao eliminar a necessidade de usar papel,
substituindo-o por um método completamente digital, evitando o
descarte excessivo de material orgânico.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29331,"o mercado de restaurantes e fast foods tem experimentado um crescimento constante ao longo dos anos, representando uma parcela significativa das vendas de alimentos anuais. os serviços de distribuição de alimentos têm um impacto significativo na vida cotidiana da sociedade, proporcionando acesso rápido e eficiente à comida. com isso, foi desenvolvido um aplicativo móvel que ajuda os funcionários dos estabelecimentos a capturar os pedidos dos clientes de maneira mais atualizada e segura, gerando uma comanda digital altamente flexível, fácil de gerenciar e ler. isso contribui para aumentar a segurança, otimizar os tempos de atendimento e fornecer um serviço mais atual e inclusivo tecnologicamente para os funcionários que utilizam a ferramenta, com uma interface intuitiva e minimalista. além disso, essa ferramenta também contribui para a preservação do meio ambiente ao eliminar a necessidade de usar papel, substituindo-o por um método completamente digital, evitando o descarte excessivo de material orgânico."
224,2023,Análise textual de tweets referenciando nordestinos durante as eleições presidenciais brasileiras de 2022.,"CAMPOS, Gustavo Gurjão Camargo.","PEREIRA, Eanes Torres.","Com o surgimento das redes sociais e sua popularização, elas se
tornaram plataformas de discussão sobre os mais variados assuntos,
incluindo a política. No cenário das eleições presidenciais brasileiras
de 2022, não foi diferente. O Nordeste, tendo destaque durante
as eleições de 2022, também foi assunto de discussões durante esse
período, então esse projeto tem o objetivo analisar as menções a nordestinos
em tweets durante o período de pré eleições e de eleições.
Esse projeto empregou pré-processamento de dados, utilizando métodos
de processamento de linguagem natural e a análise dos dados
foi feita por meio de técnicas e de algoritmos de análise exploratória
textual, como o Word2Vec e a frequência de distância. Foram
encontradas evidências de que no decorrer do período das eleições,
quanto mais se aproximava os dias de votação, mais negativa era a
opinião dos usuários da rede social acerca dos nordestinos.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29330,"com o surgimento das redes sociais e sua popularização, elas se tornaram plataformas de discussão sobre os mais variados assuntos, incluindo a política. no cenário das eleições presidenciais brasileiras de , não foi diferente. o nordeste, tendo destaque durante as eleições de , também foi assunto de discussões durante esse período, então esse projeto tem o objetivo analisar as menções a nordestinos em tweets durante o período de pré eleições e de eleições. esse projeto empregou pré-processamento de dados, utilizando métodos de processamento de linguagem natural e a análise dos dados foi feita por meio de técnicas e de algoritmos de análise exploratória textual, como o word2vec e a frequência de distância. foram encontradas evidências de que no decorrer do período das eleições, quanto mais se aproximava os dias de votação, mais negativa era a opinião dos usuários da rede social acerca dos nordestinos."
225,2023,Customização do cliente http para Biblioteca Clojure cognitect.aws-api.,"SOUSA, Thayanne Luiza Victor Landim.","MORAIS, Fábio Jorge Almeida.","A cognitect.aws-api é uma biblioteca em Clojure que permite o
acesso programático aos serviços da Amazon Web Services
(AWS) e que usa outra biblioteca chamada cognitect.http-client
para realizar as comunicações HTTP. A restrição de
cognitect.http-client ser a única possibilidade de cliente HTTP
impossibilita usuários de flexibilizar o comportamento de
requisições para adequar aos seus casos de uso ou necessidades,
como também, tal cliente possui complicações por utilizar Jetty na
versão 9 para implementar o cliente, versão esta que não possui
mais suporte da comunidade e não é mais recomendada a
utilização, além das diversas vulnerabilidades reportadas por
usuários. Este trabalho possibilita uma completa customização do
cliente HTTP utilizado pela biblioteca, de forma que agora os
usuários podem escolher qualquer cliente HTTP para acoplar
através de uma abstração simples utilizando uma interface pública
disposta na biblioteca. Adicionalmente, através da customização,
é disponibilizada uma alternativa pronta de cliente HTTP
utilizando o cliente do pacote nativo java.net do Java 11,
solucionando assim rapidamente os problemas que alguns
usuários estavam tendo com o cliente HTTP padrão. Nenhuma das
evoluções desenvolvidas causa qualquer quebra de
compatibilidade que possa causar falhas ou erros inesperados para
atuais usuários da biblioteca.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29329,"a cognitect.aws-api é uma biblioteca em clojure que permite o acesso programático aos serviços da amazon web services (aws) e que usa outra biblioteca chamada cognitect.http-client para realizar as comunicações http. a restrição de cognitect.http-client ser a única possibilidade de cliente http impossibilita usuários de flexibilizar o comportamento de requisições para adequar aos seus casos de uso ou necessidades, como também, tal cliente possui complicações por utilizar jetty na versão para implementar o cliente, versão esta que não possui mais suporte da comunidade e não é mais recomendada a utilização, além das diversas vulnerabilidades reportadas por usuários. este trabalho possibilita uma completa customização do cliente http utilizado pela biblioteca, de forma que agora os usuários podem escolher qualquer cliente http para acoplar através de uma abstração simples utilizando uma interface pública disposta na biblioteca. adicionalmente, através da customização, é disponibilizada uma alternativa pronta de cliente http utilizando o cliente do pacote nativo java.net do java , solucionando assim rapidamente os problemas que alguns usuários estavam tendo com o cliente http padrão. nenhuma das evoluções desenvolvidas causa qualquer quebra de compatibilidade que possa causar falhas ou erros inesperados para atuais usuários da biblioteca."
226,2023,Busca escalável de região geográfica similar utilizando BM25.,"MOREIRA, Paulo Mateus Alves.","CAMPELO, Claudio Elízio Calazans.","Aplicações de recuperação de informação estão cada dia mais robustas,
versáteis e atendendo aos mais diversos ins. Na área de
Recuperação de Informação Geográica (GIR), embora muitas abordagens
tenham sido propostas para lidar com diversos problemas,
alguns ainda permanecem insuicientemente explorados, a exemplo
de abordagens que permitam buscar regiões que sejam similares
a uma região de interesse de forma rápida e escalável. Dada uma
região espacial e uma região de consulta, uma pesquisa por região
similar visa encontrar as K regiões mais semelhantes à região de
consulta na região espacial. Neste trabalho é apresentada uma abordagem
de busca por similaridade em mapas utilizando um algoritmo
de similaridade textual com dados armazenados e indexados. Para
isso, desenvolveu-se um algoritmo baseado no uso de índices no
ElasticSearch[1] para armazenamento dos dados geográicos. As
consultas são textuais, utilizando o conceito de índice invertido
junto com o algoritmo de similaridade BM25[14]. Nesse algoritmo,
as informações de Points of Interest (POI) presente nas regiões
dos mapas são convertidas em dados textuais que são a base para
realização de consultas. A abordagem proposta é baseada em um
estudo de caso utilizando dados de grandes cidades obtidos através
OpenStreetMaps1.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29328,"aplicações de recuperação de informação estão cada dia mais robustas, versáteis e atendendo aos mais diversos ins. na área de recuperação de informação geográica (gir), embora muitas abordagens tenham sido propostas para lidar com diversos problemas, alguns ainda permanecem insuicientemente explorados, a exemplo de abordagens que permitam buscar regiões que sejam similares a uma região de interesse de forma rápida e escalável. dada uma região espacial e uma região de consulta, uma pesquisa por região similar visa encontrar as k regiões mais semelhantes à região de consulta na região espacial. neste trabalho é apresentada uma abordagem de busca por similaridade em mapas utilizando um algoritmo de similaridade textual com dados armazenados e indexados. para isso, desenvolveu-se um algoritmo baseado no uso de índices no elasticsearch[ ] para armazenamento dos dados geográicos. as consultas são textuais, utilizando o conceito de índice invertido junto com o algoritmo de similaridade bm25[ ]. nesse algoritmo, as informações de points of interest (poi) presente nas regiões dos mapas são convertidas em dados textuais que são a base para realização de consultas. a abordagem proposta é baseada em um estudo de caso utilizando dados de grandes cidades obtidos através openstreetmaps1."
227,2023,plpPoolWeb: um sistema para suporte à monitoria da Disciplina Paradigmas de Linguagens de Programação.,"SILVA, Luiggy Ferreira Dias.","ALVES, Everton Leandro Galdino.","O tempo de trabalho extraclasse de um professor é
normalmente dedicado a preparação de aulas, correção de provas,
revisão de materiais e pesquisa de estratégias de ensino. Porém,
em muitos momentos o volume destas atividades pode se tornar
muito demandante e afetar negativamente tanto a qualidade do
ensino quanto a vida pessoal do professor. A disciplina de
Paradigmas de Linguagens de Programação trabalha laboratórios
práticos de programação e monitores elaboram questões que
podem ser selecionadas pelo professor. Atualmente, as questões
são submetidas no Github, mas isso não é vantajoso tanto para o
professor, pois dificulta sua seleção de questões, já que não
existem filtros para buscar questões do seu interesse, como
também para os monitores, que não tem uma maneira fácil e
prática de analisar as questões que foram criadas em períodos
anteriores. A partir desses problemas, o trabalho apresentado neste
documento se propôs a desenvolver um sistema para dar suporte
ao professor e monitores da disciplina de Paradigmas de
Linguagens de Programação da Universidade Federal de Campina
Grande (UFCG). Trata-se do desenvolvimento do plpPoolWeb,
uma aplicação que permitirá o gerenciamento de questões,
notificações para monitores e outras atividades de maneira rápida
e ágil.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29327,"o tempo de trabalho extraclasse de um professor é normalmente dedicado a preparação de aulas, correção de provas, revisão de materiais e pesquisa de estratégias de ensino. porém, em muitos momentos o volume destas atividades pode se tornar muito demandante e afetar negativamente tanto a qualidade do ensino quanto a vida pessoal do professor. a disciplina de paradigmas de linguagens de programação trabalha laboratórios práticos de programação e monitores elaboram questões que podem ser selecionadas pelo professor. atualmente, as questões são submetidas no github, mas isso não é vantajoso tanto para o professor, pois dificulta sua seleção de questões, já que não existem filtros para buscar questões do seu interesse, como também para os monitores, que não tem uma maneira fácil e prática de analisar as questões que foram criadas em períodos anteriores. a partir desses problemas, o trabalho apresentado neste documento se propôs a desenvolver um sistema para dar suporte ao professor e monitores da disciplina de paradigmas de linguagens de programação da universidade federal de campina grande (ufcg). trata-se do desenvolvimento do plppoolweb, uma aplicação que permitirá o gerenciamento de questões, notificações para monitores e outras atividades de maneira rápida e ágil."
228,2023,Sistema de failover automatizado com monitoramento sintético para LDAP do Laboratório de Sistemas Distribuídos da UFCG.,"ESPÍNDULA, João Pedro Santino.","SILVA, Thiago Emmanuel Pereira da Cunha.","O Lightweight Directory Access Protocol (LDAP) é um
protocolo direcionado a aplicativos de gerenciamento que
fornecem acesso interativo de leitura e gravação a um
diretório. Esse protocolo é utilizado pelo Laboratório de
Sistemas Distribuídos (LSD) na Universidade Federal de
Campina Grande (UFCG) no armazenamento de dados dos
usuários para sistemas internos em conjunto com sua
autenticação. Em casos de falha desse sistema — sejam falhas
de rede, falta de recursos ou qualquer outro — vários outros
sistemas do laboratório ficam comprometidos, uma vez que o
usuário precisa estar autenticado para a utilização deles. Isso
inclui serviços no próprio data center do laboratório, bem
como serviços em nuvens públicas. Neste trabalho, iremos
projetar e desenvolver uma solução para a implantação de um
failover visando o LDAP do LSD. Esse failover terá como
objetivo garantir o acesso aos dados dos usuários do LSD
mesmo que o sistema do LDAP se torne indisponível. Ele fará
isso através do monitoramento desse sistema, e, em caso de
falha, a implantação automática de uma réplica dele em uma
nuvem pública.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29326,"o lightweight directory access protocol (ldap) é um protocolo direcionado a aplicativos de gerenciamento que fornecem acesso interativo de leitura e gravação a um diretório. esse protocolo é utilizado pelo laboratório de sistemas distribuídos (lsd) na universidade federal de campina grande (ufcg) no armazenamento de dados dos usuários para sistemas internos em conjunto com sua autenticação. em casos de falha desse sistema — sejam falhas de rede, falta de recursos ou qualquer outro — vários outros sistemas do laboratório ficam comprometidos, uma vez que o usuário precisa estar autenticado para a utilização deles. isso inclui serviços no próprio data center do laboratório, bem como serviços em nuvens públicas. neste trabalho, iremos projetar e desenvolver uma solução para a implantação de um failover visando o ldap do lsd. esse failover terá como objetivo garantir o acesso aos dados dos usuários do lsd mesmo que o sistema do ldap se torne indisponível. ele fará isso através do monitoramento desse sistema, e, em caso de falha, a implantação automática de uma réplica dele em uma nuvem pública."
229,2023,SEML: um processo para execução segura de aprendizagem de máquina em nuvem.,"LUZ, Ariel Roque Inácio.","BRITO, Andrey Elísio Monteiro.","Algoritmos de aprendizado de máquina são cruciais para o desenvolvimento
dos softwares utilizados em nosso cotidiano. Frente à
grande quantidade de dados e a necessidade crescente de recursos
computacionais para treinar esses algoritmos, a computação
moderna tem migrado para a nuvem. Por outro lado, existem preocupações
a respeito da segurança dos dados que trafegam nesse
meio. Este trabalho tem como objetivo o desenvolvimento de um
processo que garanta conidencialidade de aplicações de aprendizado
de máquina utilizando tecnologias de execução coniável.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29325,"algoritmos de aprendizado de máquina são cruciais para o desenvolvimento dos softwares utilizados em nosso cotidiano. frente à grande quantidade de dados e a necessidade crescente de recursos computacionais para treinar esses algoritmos, a computação moderna tem migrado para a nuvem. por outro lado, existem preocupações a respeito da segurança dos dados que trafegam nesse meio. este trabalho tem como objetivo o desenvolvimento de um processo que garanta conidencialidade de aplicações de aprendizado de máquina utilizando tecnologias de execução coniável."
230,2023,ConectBug: sistema para gerar e gerenciar bug report de aplicativos mobiles.,"FREITAS, João Felipe da Silva.","RAMALHO, Franklin de Souza.","Por dia, 3739 novos aplicativos são lançados na playstore e com eles
inúmeros bugs, definidos como um erro ou falha em um software
ou sistema, que causa um resultado inesperado ou incorreto, ou se
comporta de maneira não intencional. Para controlar esses bugs
surgiram os bugs reports, relatórios feitos por usuários ou profissionais
contratados para testar uma aplicação. Esses relatórios ajudam
tanto aos desenvolvedores a dar manutenção no sistema como a
organizar a ordem de prioridade e como cada bug será atacado.
Esses relatórios são muitas vezes criados com base em feedbacks e
avaliações, que apontam alguma falha ou problema. Esses feedbacks
são lidos e interpretados por pessoas de cunho mais técnico, para aí
sim se tornarem bug reports, o que gera uma camada a mais entre
o cliente final e o desenvolvedor. Neste trabalho, propomos uma
ferramenta de integração pensada em conectar o aplicativo com
uma ferramenta de bug tracking, aproximando mais a relação entre
o cliente e o desenvolvedor. O objetivo é oferecer autonomia para
o usuário inal do aplicativo criar um bug report, já preenchendo
os dados mais comuns e que não demandam um conhecimento técnico,
e após isso já gerar um relatório, dando facilidade ao luxo de
criação de relatórios de bugs por usuários de uma aplicação e consequentemente
a sua investigação e correção pelos desenvolvedores
responsáveis.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29324,"por dia, novos aplicativos são lançados na playstore e com eles inúmeros bugs, definidos como um erro ou falha em um software ou sistema, que causa um resultado inesperado ou incorreto, ou se comporta de maneira não intencional. para controlar esses bugs surgiram os bugs reports, relatórios feitos por usuários ou profissionais contratados para testar uma aplicação. esses relatórios ajudam tanto aos desenvolvedores a dar manutenção no sistema como a organizar a ordem de prioridade e como cada bug será atacado. esses relatórios são muitas vezes criados com base em feedbacks e avaliações, que apontam alguma falha ou problema. esses feedbacks são lidos e interpretados por pessoas de cunho mais técnico, para aí sim se tornarem bug reports, o que gera uma camada a mais entre o cliente final e o desenvolvedor. neste trabalho, propomos uma ferramenta de integração pensada em conectar o aplicativo com uma ferramenta de bug tracking, aproximando mais a relação entre o cliente e o desenvolvedor. o objetivo é oferecer autonomia para o usuário inal do aplicativo criar um bug report, já preenchendo os dados mais comuns e que não demandam um conhecimento técnico, e após isso já gerar um relatório, dando facilidade ao luxo de criação de relatórios de bugs por usuários de uma aplicação e consequentemente a sua investigação e correção pelos desenvolvedores responsáveis."
231,2023,Quizzify App: uma ferramenta baseada em PLN para o auxílio na memorização e assimilação de conteúdos e conceitos.,"OLIVEIRA, André Gomes Ferreira de.","MORAIS, Fábio Jorge Almeida.","O processo de aprendizagem, dê-se ele por um agente
humano ou artificial, nem sempre é algo fluido e fácil
e costuma levar várias etapas de treinamento. Mesmo
assim, aplicações baseadas em inteligência artificial e
Processamento de Linguagem Natural têm mostrado
resultados surpreendentes e costumam melhorar
através da exposição a novas situações. Buscando
explorar e aplicar os conceitos e avanços desta área ao
aprendizado humano, este trabalho visa propor o
desenvolvimento de uma aplicação, utilizando
técnicas de PLN, onde o usuário, ao inserir um texto
do seu interesse, será apresentado a questões geradas
automaticamente, abrangendo as principais ideias e
pontos chaves contidos nele. Auxiliando no que diz
respeito à fixação e assimilação de conteúdos,
assistindo na rememoração de tópicos, definições e
conceitos. Com isto, visa-se agilizar o processo de
estudo e memorização de temas de interesse do
usuário, facilitando o processo de aquisição e
consolidação de conhecimentos.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29323,"o processo de aprendizagem, dê-se ele por um agente humano ou artificial, nem sempre é algo fluido e fácil e costuma levar várias etapas de treinamento. mesmo assim, aplicações baseadas em inteligência artificial e processamento de linguagem natural têm mostrado resultados surpreendentes e costumam melhorar através da exposição a novas situações. buscando explorar e aplicar os conceitos e avanços desta área ao aprendizado humano, este trabalho visa propor o desenvolvimento de uma aplicação, utilizando técnicas de pln, onde o usuário, ao inserir um texto do seu interesse, será apresentado a questões geradas automaticamente, abrangendo as principais ideias e pontos chaves contidos nele. auxiliando no que diz respeito à fixação e assimilação de conteúdos, assistindo na rememoração de tópicos, definições e conceitos. com isto, visa-se agilizar o processo de estudo e memorização de temas de interesse do usuário, facilitando o processo de aquisição e consolidação de conhecimentos."
232,2023,SAP: um sistema para otimização e automação de procedimentos do PPGCC/UFCG.,"CAVALCANTI NETO, Jessé Souza.","ALVES, Everton Leandro Galdino.","Cada vez mais empresas e órgãos públicos têm estudado
estratégias para adoção de modelos de execução baseados em
procedimentos e indicadores de eficiência automatizados. Dentre
os benefícios desta prática, estão a agilidade na execução,
padronização e previsibilidade de resultados, bem como
diminuição de custos e análise de desempenho. Nesse contexto,
softwares com o objetivo de oferecer suporte a automação de
processos têm ganhado espaço dentro dos meios corporativos,
otimizando processos e proporcionando à organização sistemática
destas organizações.
Assim como essas empresas, o Programa de Pós-Graduação de
Ciências da Computação da Universidade Federal de Campina
Grande (PPGCC/UFCG) é composto de uma série de
procedimentos já virtualizados. Entretanto, muitos destes
compostos de etapas manuais, descentralizadas e que contribuem
para o sobrecarregamento da secretaria e da coordenação do
programa.
O objetivo desse trabalho é a criação de uma ferramenta para
automação de procedimentos do PPGCC/UFCG. Espera-se que a
solução possa melhorar o dia a dia dos discentes e docentes
integrantes da pós-graduação através da simplificação, otimização
e automação dos processos dentro da plataforma.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29322,"cada vez mais empresas e órgãos públicos têm estudado estratégias para adoção de modelos de execução baseados em procedimentos e indicadores de eficiência automatizados. dentre os benefícios desta prática, estão a agilidade na execução, padronização e previsibilidade de resultados, bem como diminuição de custos e análise de desempenho. nesse contexto, softwares com o objetivo de oferecer suporte a automação de processos têm ganhado espaço dentro dos meios corporativos, otimizando processos e proporcionando à organização sistemática destas organizações. assim como essas empresas, o programa de pós-graduação de ciências da computação da universidade federal de campina grande (ppgcc/ufcg) é composto de uma série de procedimentos já virtualizados. entretanto, muitos destes compostos de etapas manuais, descentralizadas e que contribuem para o sobrecarregamento da secretaria e da coordenação do programa. o objetivo desse trabalho é a criação de uma ferramenta para automação de procedimentos do ppgcc/ufcg. espera-se que a solução possa melhorar o dia a dia dos discentes e docentes integrantes da pós-graduação através da simplificação, otimização e automação dos processos dentro da plataforma."
233,2023,Community smells in software teams: a systematic literature mapping.,"SOARES, André Filipe Queiroz de Melo e.","MASSONI, Tiago Lima.","Community smells são sintomas de problemas
organizacionais e sociais em equipes de software que
frequentemente aumentam os custos do projeto e
afetam a qualidade do software. Pesquisas recentes
identificaram vários community smells e os definiram
como padrões abaixo do ideal relacionados à estrutura
social organizacional em equipes de desenvolvimento
de software, como falta de comunicação, coordenação
e colaboração. Por esse motivo, esse estudo tem como
objetivo realizar um mapeamento sistemático a partir
de artigos científicos com a finalidade de
compreender como o tema está sendo tratado. Em
vista disso, foram selecionados 24 artigos que
abordam a temática em diversas bases de dados
existentes e elaborado critérios de classificação com o
objetivo de responder às indagações feitas e avaliando
os resultados, este artigo concluiu que estudar os
community smells no nível estrutural e organizacional
pode ser vital para livrar as equipes de software para
evitar falhas organizacionais críticas que podem no
futuro acarretar em custos adicionais consideráveis.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29321,"community smells são sintomas de problemas organizacionais e sociais em equipes de software que frequentemente aumentam os custos do projeto e afetam a qualidade do software. pesquisas recentes identificaram vários community smells e os definiram como padrões abaixo do ideal relacionados à estrutura social organizacional em equipes de desenvolvimento de software, como falta de comunicação, coordenação e colaboração. por esse motivo, esse estudo tem como objetivo realizar um mapeamento sistemático a partir de artigos científicos com a finalidade de compreender como o tema está sendo tratado. em vista disso, foram selecionados artigos que abordam a temática em diversas bases de dados existentes e elaborado critérios de classificação com o objetivo de responder às indagações feitas e avaliando os resultados, este artigo concluiu que estudar os community smells no nível estrutural e organizacional pode ser vital para livrar as equipes de software para evitar falhas organizacionais críticas que podem no futuro acarretar em custos adicionais consideráveis."
234,2023,Ferramenta para análise de grandes volumes de dados neurofisiológicos.,"CORDEIRO, Izaquiel Luiz de França.","GOMES, Herman Martins.","Tentativas de se compreender o cérebro humano permeiam a
literatura desde antes da Grécia Antiga até os dias de hoje [1].
Desde então, esse órgão tão importante continua sendo um
mistério em que ainda nos debruçamos. Na necessidade de
democratizar o conhecimento em busca de uma cooperação
interdisciplinar para melhor entender-se o cérebro, existe hoje
uma vertente científica denominada Neurociência. E devido a sua
natureza interdisciplinar, esse ramo científico envolve
profissionais de diversas áreas. Entretanto, nem todos os
profissionais que compartilham da necessidade de estudar o
cérebro detém conhecimento técnico o suficiente para, em seus
estudos, fazerem uso de avanços tecnológicos na ciência da
computação e no desenvolvimento de algoritmos. Nesse contexto,
o presente trabalho apresenta uma ferramenta que minimiza
problemas de armazenamento relacionados a grandes conjuntos de
dados e permite que pesquisadores de neurociência analisem
intuitivamente registros de atividades neuronais.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29320,"tentativas de se compreender o cérebro humano permeiam a literatura desde antes da grécia antiga até os dias de hoje [ ]. desde então, esse órgão tão importante continua sendo um mistério em que ainda nos debruçamos. na necessidade de democratizar o conhecimento em busca de uma cooperação interdisciplinar para melhor entender-se o cérebro, existe hoje uma vertente científica denominada neurociência. e devido a sua natureza interdisciplinar, esse ramo científico envolve profissionais de diversas áreas. entretanto, nem todos os profissionais que compartilham da necessidade de estudar o cérebro detém conhecimento técnico o suficiente para, em seus estudos, fazerem uso de avanços tecnológicos na ciência da computação e no desenvolvimento de algoritmos. nesse contexto, o presente trabalho apresenta uma ferramenta que minimiza problemas de armazenamento relacionados a grandes conjuntos de dados e permite que pesquisadores de neurociência analisem intuitivamente registros de atividades neuronais."
235,2023,Sistema de recomendação de bug reports similares utilizando o BERT.,"CARNEIRO, Guilherme de Melo.","RAMALHO, Franklin de Souza.","No contexto de projetos de software de grande porte, há demanda
crescente por correções de erros em sua concepção, que ultrapassam
os iltros de testes e qualidade da equipe de Quality Assurance
e impactam os clientes inais do produto. A im de documentar
estes comportamentos para que sejam posteriormente analisados e
corrigidos, a engenharia de software faz uso de documentos chamados
Bug Reports (BR). Como apontado por Anvik et. al [2], a
frequência de novos BRs sendo abertos em grandes projetos é elevada,
exempliicado pela ferramenta Eclipse, que, ainda em 2005,
já contava com aproximadamente 190 novos BRs sendo abertos
diariamente. Motivado por essa problemática, o presente estudo
propõe e avalia um sistema de recomendação de BRs baseado em
similaridade textual, com o diferencial de utilizar o modelo estadoda-
arte de compreensão textual BERT [3] como um dos fatores
no cálculo de similaridade. Este tem como objetivo aprimorar as
sugestões de BRs de contexto próximo ao fornecido pelo mantenedor,
o que supostamente aumentaria sua produtividade, e por
consequência, a quantidade de BRs resolvidos. Como resultados
obtidos, atestou-se ganhos de aproximadamente 14% na frequência
de BRs relevantes para as 20 primeiras recomendações, quando
comparado à técnica que utilizou apenas TF-IDF como modelo de
vetorização textual. Por im, o modelo BERT agregou melhoras às
métricas avaliadas (precisão, feedback e likelihood) quando utilizado
de maneira complementar ao TF-IDF, não desempenhando
positivamente de maneira isolada.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29319,"no contexto de projetos de software de grande porte, há demanda crescente por correções de erros em sua concepção, que ultrapassam os iltros de testes e qualidade da equipe de quality assurance e impactam os clientes inais do produto. a im de documentar estes comportamentos para que sejam posteriormente analisados e corrigidos, a engenharia de software faz uso de documentos chamados bug reports (br). como apontado por anvik et. al [ ], a frequência de novos brs sendo abertos em grandes projetos é elevada, exempliicado pela ferramenta eclipse, que, ainda em , já contava com aproximadamente novos brs sendo abertos diariamente. motivado por essa problemática, o presente estudo propõe e avalia um sistema de recomendação de brs baseado em similaridade textual, com o diferencial de utilizar o modelo estadoda- arte de compreensão textual bert [ ] como um dos fatores no cálculo de similaridade. este tem como objetivo aprimorar as sugestões de brs de contexto próximo ao fornecido pelo mantenedor, o que supostamente aumentaria sua produtividade, e por consequência, a quantidade de brs resolvidos. como resultados obtidos, atestou-se ganhos de aproximadamente % na frequência de brs relevantes para as primeiras recomendações, quando comparado à técnica que utilizou apenas tf-idf como modelo de vetorização textual. por im, o modelo bert agregou melhoras às métricas avaliadas (precisão, feedback e likelihood) quando utilizado de maneira complementar ao tf-idf, não desempenhando positivamente de maneira isolada."
236,2023,Antecedentes e consequentes em modelos de SD para gestão de projetos de software.,"OLIVEIRA, Giovana Brito.","MOURA, José Antão Beltrão.","Ao tomar decisões, gerentes de projetos de software precisam
considerar diversos fatores, tornando essa uma atividade muito
complexa. Para auxiliar os gerentes com essas decisões,
ferramentas têm sido utilizadas para simular o impacto desses
fatores nos resultados do projeto. Modelos em Dinâmica de
Sistemas (SD) têm se mostrado uma boa opção para tais
simulações por possuírem características dinâmicas e utilizarem
sistemas de ""Feedback"", aspectos próprios do desenvolvimento de
projetos de software. O objetivo deste trabalho é identificar quais
os fatores (antecedentes) que influenciam os projetos de software
e o que eles influenciam (consequentes) nos projetos que já foram
modelados em SD. Para isso foi realizado um mapeamento por
meio da base de indexação Web of Science (WoS). Os artigos
foram avaliados por ordem de publicação partindo do mais
recente e considerando os critérios de inclusão e exclusão
propostos. Alguns dos fatores mapeados foram: influência do
cliente, promoção da equipe, pressão de cronograma, horas extras
(antecedentes); produtividade do time, custo do projeto e duração
do projeto (consequentes). A contribuição esperada é auxiliar
pesquisadores que pretendem construir modelos SD a
encontrarem fatores ainda não modelados ou reaproveitar os
fatores já modelados por outros pesquisadores evitando
re-trabalho.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29318,"ao tomar decisões, gerentes de projetos de software precisam considerar diversos fatores, tornando essa uma atividade muito complexa. para auxiliar os gerentes com essas decisões, ferramentas têm sido utilizadas para simular o impacto desses fatores nos resultados do projeto. modelos em dinâmica de sistemas (sd) têm se mostrado uma boa opção para tais simulações por possuírem características dinâmicas e utilizarem sistemas de ""feedback"", aspectos próprios do desenvolvimento de projetos de software. o objetivo deste trabalho é identificar quais os fatores (antecedentes) que influenciam os projetos de software e o que eles influenciam (consequentes) nos projetos que já foram modelados em sd. para isso foi realizado um mapeamento por meio da base de indexação web of science (wos). os artigos foram avaliados por ordem de publicação partindo do mais recente e considerando os critérios de inclusão e exclusão propostos. alguns dos fatores mapeados foram: influência do cliente, promoção da equipe, pressão de cronograma, horas extras (antecedentes); produtividade do time, custo do projeto e duração do projeto (consequentes). a contribuição esperada é auxiliar pesquisadores que pretendem construir modelos sd a encontrarem fatores ainda não modelados ou reaproveitar os fatores já modelados por outros pesquisadores evitando re-trabalho."
237,2023,CCC inteligente: uma ferramenta web que coleciona arquivos de conhecimento do CCC/UFCG através de repositórios virtuais de aprendizagem.,"FIALHO JÚNIOR, Adísio Pereira.","SABINO, Melina Mongiovi Cunha Lima.","Esta pesquisa aborda a filosofia do Movimento Aberto ao
Conhecimento Científico e o surgimento dos repositórios virtuais
de aprendizagem como recursos capazes de organizar e tornar
acessíveis os conteúdos de universidades e instituições produtoras
de conhecimento científico. Os repositórios virtuais surgiram
como alternativa para aumentar a visibilidade da produção
científica. O objetivo geral deste estudo é analisar a tendência de
uso do sistema CCC-Inteligente por parte dos docentes e discentes
do Curso de Ciência da Computação da UFCG e a disposição para
compartilhamento de materiais didáticos. O sistema
CCC-Inteligente inclui desde uma tela de avisos, acesso a páginas
de perguntas frequentes até o desenvolvimento do aprendizado
dos discentes ao consumir tais conteúdos de forma digital, livre e
gratuita. Neste estudo, são tratados assuntos como acesso aberto,
repositórios virtuais, destaque de repositórios existentes e
comparação com o MVP (Produto Viável Mínimo)
CCC-Inteligente. Para tanto, foi realizado um levantamento
bibliográfico na área da Ciência da Informação sobre os assuntos
em questão, com base na literatura científica nacional e
internacional. Para a coleta de dados, foi utilizado um
questionário eletrônico aplicado pelo Google Docs. Como
principais resultados, tem-se que a grande maioria dos discentes
de computação da amostra mostrou aceitação ao novo sistema e
que este agregaria valor durante o curso.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29317,"esta pesquisa aborda a filosofia do movimento aberto ao conhecimento científico e o surgimento dos repositórios virtuais de aprendizagem como recursos capazes de organizar e tornar acessíveis os conteúdos de universidades e instituições produtoras de conhecimento científico. os repositórios virtuais surgiram como alternativa para aumentar a visibilidade da produção científica. o objetivo geral deste estudo é analisar a tendência de uso do sistema ccc-inteligente por parte dos docentes e discentes do curso de ciência da computação da ufcg e a disposição para compartilhamento de materiais didáticos. o sistema ccc-inteligente inclui desde uma tela de avisos, acesso a páginas de perguntas frequentes até o desenvolvimento do aprendizado dos discentes ao consumir tais conteúdos de forma digital, livre e gratuita. neste estudo, são tratados assuntos como acesso aberto, repositórios virtuais, destaque de repositórios existentes e comparação com o mvp (produto viável mínimo) ccc-inteligente. para tanto, foi realizado um levantamento bibliográfico na área da ciência da informação sobre os assuntos em questão, com base na literatura científica nacional e internacional. para a coleta de dados, foi utilizado um questionário eletrônico aplicado pelo google docs. como principais resultados, tem-se que a grande maioria dos discentes de computação da amostra mostrou aceitação ao novo sistema e que este agregaria valor durante o curso."
238,2023,Desenvolvimento de um simulador de cache para análise de políticas de gerenciamento.,"NASCIMENTO, Gabriela Roberta Alverga do.","SILVA, Thiago Emmanuel Pereira da Cunha.","Caching é uma estratégia tradicional para melhorar o desempenho de sistemas de computação.
Sistemas de cache possuem várias configurações que podem alterar seu funcionamento e por
consequência seu desempenho. É o caso, por exemplo, da parametrização das políticas de remoção
de itens. Quando a escala do sistema de cache se torna muito grande, os experimentos para testes de
alternativas para essas configurações se tornam difíceis. Considerando esse problema,
desenvolvemos um simulador que modela um sistema de cache popular, o NGINX. Validamos esse
simulador usando traces de uma implantação de um cache para um sistema web de alta escala. A
validação do nosso simulador indica que ele apresenta baixo erro, cerca de 1% das requisições.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29313,"caching é uma estratégia tradicional para melhorar o desempenho de sistemas de computação. sistemas de cache possuem várias configurações que podem alterar seu funcionamento e por consequência seu desempenho. é o caso, por exemplo, da parametrização das políticas de remoção de itens. quando a escala do sistema de cache se torna muito grande, os experimentos para testes de alternativas para essas configurações se tornam difíceis. considerando esse problema, desenvolvemos um simulador que modela um sistema de cache popular, o nginx. validamos esse simulador usando traces de uma implantação de um cache para um sistema web de alta escala. a validação do nosso simulador indica que ele apresenta baixo erro, cerca de % das requisições."
239,2023,Aprendizado profundo aplicado à classificação de peças de xadrez.,"ARAÚJO, Gabriel Schubert Silva.","GOMES, Herman Martins.","Esta pesquisa apresenta uma solução fundamentada em redes
neurais de aprendizado profundo para a classificação de peças
de xadrez. O objetivo é avaliar a aplicabilidade destes
algoritmos em contextos como na robótica, por exemplo.
Pensando nisso, foram treinados diferentes modelos de redes
neurais, com arquitetura e hiperparâmetros diferentes.
Posteriormente, calculou-se as métricas acurácia, precisão,
revocação e f1-score para cada modelo treinado e
comparou-se estas métricas para se definir o modelo com
melhor desempenho. O objetivo de cada modelo foi classificar
corretamente a imagem de entrada em uma de treze classes,
sendo estas classes 12 peças de xadrez e uma classe que
representa o espaço do tabuleiro vazio. Desta forma,
chegou-se a um modelo com 99.15% de acurácia no
reconhecimento de peças de xadrez, este modelo foi
fundamentado na arquitetura MobileNet e teve como melhores
parâmetros encontrados: learning rate de 0.00019, 256
neurônios na camada densa e 43 das primeiras camadas
congeladas. Além disso, utilizou-se os pesos pré-treinados da
ImageNet neste modelo. Estes resultados mostram a eficácia
das redes neurais profundas na classificação de imagens de
peças de xadrez",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29312,"esta pesquisa apresenta uma solução fundamentada em redes neurais de aprendizado profundo para a classificação de peças de xadrez. o objetivo é avaliar a aplicabilidade destes algoritmos em contextos como na robótica, por exemplo. pensando nisso, foram treinados diferentes modelos de redes neurais, com arquitetura e hiperparâmetros diferentes. posteriormente, calculou-se as métricas acurácia, precisão, revocação e f1-score para cada modelo treinado e comparou-se estas métricas para se definir o modelo com melhor desempenho. o objetivo de cada modelo foi classificar corretamente a imagem de entrada em uma de treze classes, sendo estas classes peças de xadrez e uma classe que representa o espaço do tabuleiro vazio. desta forma, chegou-se a um modelo com . % de acurácia no reconhecimento de peças de xadrez, este modelo foi fundamentado na arquitetura mobilenet e teve como melhores parâmetros encontrados: learning rate de . , neurônios na camada densa e das primeiras camadas congeladas. além disso, utilizou-se os pesos pré-treinados da imagenet neste modelo. estes resultados mostram a eficácia das redes neurais profundas na classificação de imagens de peças de xadrez"
240,2023,Análise de dados socioeconômicos do FIES.,"SOUZA, Artur Brito.","MORAIS, Fábio Jorge Almeida.","A análise de dados é uma das formas que os governos e a sociedade de diversos países diferentes
encontraram para melhorar seu funcionamento, por meio da análise de indicadores e dados abertos do
governo, que oferecem um melhor direcionamento a políticos, funcionários públicos e agentes da
sociedade para tomarem melhores ações para o benefício da população. Diante do exposto, utilizando
dados obtidos pelo Governo Federal, esse trabalho busca fazer um estudo do impacto do
financiamento do ensino superior privado por meio do Fundo de Financiamento Estudantil (FIES) a
partir da análise e visualização de dados. O objetivo é observar, a partir da análise dos dados, as
características dos cursos e dos alunos participantes do FIES ao longo dos anos 2011-2019, ajudando
a entender e demonstrar o impacto que esse programa causa na sociedade civil.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29311,"a análise de dados é uma das formas que os governos e a sociedade de diversos países diferentes encontraram para melhorar seu funcionamento, por meio da análise de indicadores e dados abertos do governo, que oferecem um melhor direcionamento a políticos, funcionários públicos e agentes da sociedade para tomarem melhores ações para o benefício da população. diante do exposto, utilizando dados obtidos pelo governo federal, esse trabalho busca fazer um estudo do impacto do financiamento do ensino superior privado por meio do fundo de financiamento estudantil (fies) a partir da análise e visualização de dados. o objetivo é observar, a partir da análise dos dados, as características dos cursos e dos alunos participantes do fies ao longo dos anos - , ajudando a entender e demonstrar o impacto que esse programa causa na sociedade civil."
241,2023,Um estudo de caso para avaliar o impacto do uso de code review em aspectos de qualidade de um sistema real.,"GUEDES, Arthur Silva Lima.","ALVES, Everton Leandro Galdino.","O desenvolvimento de software normalmente é guiado por um
conjunto de atividades/fases para que o produto atinja o objetivo
esperado. Durante essas fases, boas práticas voltadas para a
manutenção e garantia da qualidade, como o code review, são
imprescindíveis, ainda mais em cenários de rápido crescimento e
aprovação do produto, que requerem um desenvolvimento ágil.
Este trabalho consiste na realização de um estudo de caso para
avaliar o impacto em aspectos de qualidade do código de um
sistema real do Hospital Israelita Albert Einstein, após a equipe
introduzir atividades de code review no seu processo de
desenvolvimento. Para tal, foram usadas métricas quantitativas
(e.g., número de bugs) e qualitativas (e.g., confiabilidade),
comparando dois momentos do projeto, pré e pós o uso de code
review. De modo geral, encontramos uma tendência à redução de
bugs e melhoria na qualidade do código. As características
majoritárias das discussões entre autor e revisor mudaram e, de
maneira unânime, os desenvolvedores acreditam no impacto
positivo do code review no projeto.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29310,"o desenvolvimento de software normalmente é guiado por um conjunto de atividades/fases para que o produto atinja o objetivo esperado. durante essas fases, boas práticas voltadas para a manutenção e garantia da qualidade, como o code review, são imprescindíveis, ainda mais em cenários de rápido crescimento e aprovação do produto, que requerem um desenvolvimento ágil. este trabalho consiste na realização de um estudo de caso para avaliar o impacto em aspectos de qualidade do código de um sistema real do hospital israelita albert einstein, após a equipe introduzir atividades de code review no seu processo de desenvolvimento. para tal, foram usadas métricas quantitativas (e.g., número de bugs) e qualitativas (e.g., confiabilidade), comparando dois momentos do projeto, pré e pós o uso de code review. de modo geral, encontramos uma tendência à redução de bugs e melhoria na qualidade do código. as características majoritárias das discussões entre autor e revisor mudaram e, de maneira unânime, os desenvolvedores acreditam no impacto positivo do code review no projeto."
242,2023,Um estudo comparativo de mecanismos de privacidade diferencial aplicado à resolução de entidades com garantias de privacidade.,"ANDRADE, Arthur Fernandes de.","PIRES, Carlos Eduardo Santos.","O progresso da tecnologia tem gerado uma evolução da
popularidade de serviços que utilizam a troca de dados,
consentindo que computadores desconhecidos ou que não sejam
confiáveis mantenham uma grande quantidade de informações dos
indivíduos a partir de seus dados fornecidos. Como resultado,
manter a privacidade dos usuários e ao mesmo tempo garantir a
qualidade dos serviços é um dilema complexo que tem recebido
atenção nos últimos anos. A integração dessas diversas bases de
dados pode ocorrer por meio da Resolução de Entidades (RE),
entretanto em muitas situações esses dados são de caráter privado,
algo não suportado pela RE. Surge então a Resolução de Entidade
com Garantia de Privacidade (REGP) com o mesmo propósito da
RE, mas com a adição de suporte à privacidade dos dados. Uma
das técnicas de proteção de dados utilizadas na REGP é conhecida
como a Privacidade Diferencial (PD) que consiste em usar
mecanismos para adicionar ruído aos registros. Este trabalho
propõe avaliar a privacidade de dados através de mecanismos de
PD aplicados à REGP.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29309,"o progresso da tecnologia tem gerado uma evolução da popularidade de serviços que utilizam a troca de dados, consentindo que computadores desconhecidos ou que não sejam confiáveis mantenham uma grande quantidade de informações dos indivíduos a partir de seus dados fornecidos. como resultado, manter a privacidade dos usuários e ao mesmo tempo garantir a qualidade dos serviços é um dilema complexo que tem recebido atenção nos últimos anos. a integração dessas diversas bases de dados pode ocorrer por meio da resolução de entidades (re), entretanto em muitas situações esses dados são de caráter privado, algo não suportado pela re. surge então a resolução de entidade com garantia de privacidade (regp) com o mesmo propósito da re, mas com a adição de suporte à privacidade dos dados. uma das técnicas de proteção de dados utilizadas na regp é conhecida como a privacidade diferencial (pd) que consiste em usar mecanismos para adicionar ruído aos registros. este trabalho propõe avaliar a privacidade de dados através de mecanismos de pd aplicados à regp."
243,2023,HoráriosUFCG: ferramenta para auxílio no planejamento de horários e escolha de disciplinas para a matrícula.,"FERRÃO, Arthur de Lima.","MASSONI, Tiago Lima.","Os dias que antecedem a semana de matrículas da Universidade
Federal de Campina Grande é o período em que os alunos
dedicam parte do seu tempo organizando seus horários e
planejando quais disciplinas pretendem cursar no próximo
semestre. Nesse período, as coordenações disponibilizam listas,
através do sistema de “Controle Acadêmico” da universidade,
com os dados de professores e horários para as disciplinas daquele
semestre. Esse trabalho tem o intuito de auxiliar o planejamento
dos horários para o período de matrículas dos cursos de graduação
na Universidade Federal de Campina Grande, com o
desenvolvimento de um sistema web que permite o aluno
organizar e planejar suas disciplinas através de uma interface
agradável e que proporcione uma melhor experiência para a
matrícula. Para verificar a satisfação dos usuários quanto a
usabilidade do sistema foi realizado um levantamento, utilizando
o Computer System Usability Questionnaire, que analisando as
médias das respostas, foi obtido, na maioria dos itens, valores
entre 5 e 7, sendo 7 o valor máximo, que apontam bons
indicadores e alto nível de satisfação.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29308,"os dias que antecedem a semana de matrículas da universidade federal de campina grande é o período em que os alunos dedicam parte do seu tempo organizando seus horários e planejando quais disciplinas pretendem cursar no próximo semestre. nesse período, as coordenações disponibilizam listas, através do sistema de “controle acadêmico” da universidade, com os dados de professores e horários para as disciplinas daquele semestre. esse trabalho tem o intuito de auxiliar o planejamento dos horários para o período de matrículas dos cursos de graduação na universidade federal de campina grande, com o desenvolvimento de um sistema web que permite o aluno organizar e planejar suas disciplinas através de uma interface agradável e que proporcione uma melhor experiência para a matrícula. para verificar a satisfação dos usuários quanto a usabilidade do sistema foi realizado um levantamento, utilizando o computer system usability questionnaire, que analisando as médias das respostas, foi obtido, na maioria dos itens, valores entre e , sendo o valor máximo, que apontam bons indicadores e alto nível de satisfação."
244,2023,Perfis de uso de recursos em cloud.,"NÓBREGA, Gabriel de Oliveira Meira.","MORAIS, Fábio Jorge Almeida.","Com o advento da cloud nunca foi tão rápido o provisionamento
de recursos computacionais, isso se dá pela vasta quantidade
desses recursos que esses provedores possuem. O custo
operacional de aplicações em cloud pode se tornar bastante
elevado, tornando o uso inteligente desses recursos
computacionais um ponto vital da indústria atualmente. Fazer isso
pode permitir um barateamento dos recursos em geral e permitir
negócios passem a ser viáveis, a proposta desse artigo é fazer uma
análise exploratória de dados open source providos pela Azure e
procurar investigar os diferentes perfis de uso nessa cloud e retirar
insights do mesmo.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29306,"com o advento da cloud nunca foi tão rápido o provisionamento de recursos computacionais, isso se dá pela vasta quantidade desses recursos que esses provedores possuem. o custo operacional de aplicações em cloud pode se tornar bastante elevado, tornando o uso inteligente desses recursos computacionais um ponto vital da indústria atualmente. fazer isso pode permitir um barateamento dos recursos em geral e permitir negócios passem a ser viáveis, a proposta desse artigo é fazer uma análise exploratória de dados open source providos pela azure e procurar investigar os diferentes perfis de uso nessa cloud e retirar insights do mesmo."
245,2023,Desenvolvimento de versão web para aplicativo Feridômetro.,"BRANDÃO, Gabriel de Lacerda.","CAMPOS, Lívia Maria Rodrigues Sampaio.","O acrônimo TIMERS é utilizado por profissionais da saúde para
avaliar pacientes e encaminhar para o tratamento mais adequado.
Cada letra do acrônimo representa uma categoria que visa o
tratamento e cuidado de feridas. Através do aplicativo
Feridômetro é possível realizar a checagem de feridas,
enfermidades e possíveis prevenções baseados no que foi
avaliado. O aplicativo Feridômetro foi idealizado inicialmente
pela professora Lidiany Galdino (CCBS/UFCG) e os graduandos
Adiel Andrade Rocha e Matheus de Souza Coutinho
(UASC/UFCG), seu objetivo é auxiliar os professores e alunos
com conhecimentos sobre o acrônimo. O presente trabalho tem
por objetivo desenvolver uma aplicação web, com o intuito de
disponibilizar o Feridômetro para usuários de outros sistemas
além do Android™. A partir dessa construção, a disponibilidade
do aplicativo será ampliada e mais pessoas terão acesso ao
conteúdo do acrônimo.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29305,"o acrônimo timers é utilizado por profissionais da saúde para avaliar pacientes e encaminhar para o tratamento mais adequado. cada letra do acrônimo representa uma categoria que visa o tratamento e cuidado de feridas. através do aplicativo feridômetro é possível realizar a checagem de feridas, enfermidades e possíveis prevenções baseados no que foi avaliado. o aplicativo feridômetro foi idealizado inicialmente pela professora lidiany galdino (ccbs/ufcg) e os graduandos adiel andrade rocha e matheus de souza coutinho (uasc/ufcg), seu objetivo é auxiliar os professores e alunos com conhecimentos sobre o acrônimo. o presente trabalho tem por objetivo desenvolver uma aplicação web, com o intuito de disponibilizar o feridômetro para usuários de outros sistemas além do android™. a partir dessa construção, a disponibilidade do aplicativo será ampliada e mais pessoas terão acesso ao conteúdo do acrônimo."
246,2023,Segurança e privacidade em assistentes pessoais.,"CANDIDO, Enzo Raian Teixeira.","MOURA, José Antão Beltrão.","Nos últimos anos, a automação do trabalho e de atividades
domésticas se tornou algo indispensável para os seres
humanos, que buscam formas de otimizar tempo e se livrar
de tarefas repetitivas e indesejadas. As assistentes pessoais
chegaram para facilitar a vida desses usuários, sendo
dirigidas por comandos de voz, elas podem juntamente com
outros dispositivos, transformar uma casa comum em uma
casa inteligente. Entretanto, as assistentes virtuais ainda
possuem falhas de segurança e privacidade que podem
tornar o seu uso perigoso, colocando em risco os dados dos
consumidores. Este trabalho explora as principais
vulnerabilidades presentes nas assistentes virtuais e como
os dados dos usuários que utilizam essa tecnologia podem
ser expostos, assim como investiga qual a percepção das
pessoas quanto ao vazamento de suas informações.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29302,"nos últimos anos, a automação do trabalho e de atividades domésticas se tornou algo indispensável para os seres humanos, que buscam formas de otimizar tempo e se livrar de tarefas repetitivas e indesejadas. as assistentes pessoais chegaram para facilitar a vida desses usuários, sendo dirigidas por comandos de voz, elas podem juntamente com outros dispositivos, transformar uma casa comum em uma casa inteligente. entretanto, as assistentes virtuais ainda possuem falhas de segurança e privacidade que podem tornar o seu uso perigoso, colocando em risco os dados dos consumidores. este trabalho explora as principais vulnerabilidades presentes nas assistentes virtuais e como os dados dos usuários que utilizam essa tecnologia podem ser expostos, assim como investiga qual a percepção das pessoas quanto ao vazamento de suas informações."
247,2023,Smart Geo-comparative Maps: ferramenta para visualização e comparação de similaridades entre pontos de interesse e regiões a partir de vetores de características.,"FARIAS, Flávio Roberto Pires Quirino.","CAMPELO, Claudio Elízio Calazans.","Mapeamento digital é o processo de compilar um conjunto de dados
em formato digital. O principal objetivo desse mapeamento é
permitir a criação de mapas com representações precisas das áreas
mapeadas. Localização, planejamento de rotas, busca, recomendação,
entre outros, são algumas das principais funcionalidades que
serviços que utilizam mapas digitais podem oferecer. Contudo, as
funcionalidades citadas geralmente não envolvem, quando possível,
características geográficas em seus parâmetros. Dessa forma, a
ferramenta descrita nesse trabalho é um mapa digital que promove
integração de características geográficas às características básicas
de Pontos de Interesse e de elementos geográficos na realização de
atividades de busca, comparação e análise entre locais e regiões.
Para isso, os pontos e os elementos geográficos serão representados
por vetores de características e os valores de similaridade de
cada local serão obtidos por modelos de aprendizagem de máquina
pré-treinados.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29301,"mapeamento digital é o processo de compilar um conjunto de dados em formato digital. o principal objetivo desse mapeamento é permitir a criação de mapas com representações precisas das áreas mapeadas. localização, planejamento de rotas, busca, recomendação, entre outros, são algumas das principais funcionalidades que serviços que utilizam mapas digitais podem oferecer. contudo, as funcionalidades citadas geralmente não envolvem, quando possível, características geográficas em seus parâmetros. dessa forma, a ferramenta descrita nesse trabalho é um mapa digital que promove integração de características geográficas às características básicas de pontos de interesse e de elementos geográficos na realização de atividades de busca, comparação e análise entre locais e regiões. para isso, os pontos e os elementos geográficos serão representados por vetores de características e os valores de similaridade de cada local serão obtidos por modelos de aprendizagem de máquina pré-treinados."
248,2023,RomaneioApp: um sistema para controle de pedidos no atacado.,"SILVA, Eduardo Henrique Pontes.","ANDRADE, Wilkerson de Lucena.","O crescimento do setor hortifrutigranjeiro foi um fator decisivo
para a implementação de sistemas para armazenamento e gerenciamento
de informações. Contudo, ainda faltam sistemas acessíveis
aos usuários de tal setor, tendo em vista que grande parte são analfabetos
totais ou funcionais. Com o intuito de suprir as necessidades
usuais (baixo custo, fácil usabilidade e compreensão), propomos
o RomaneioApp. Com esta ferramenta, será possível garantir a
eiciência na gestão dos pedidos de forma simples e clara.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29300,"o crescimento do setor hortifrutigranjeiro foi um fator decisivo para a implementação de sistemas para armazenamento e gerenciamento de informações. contudo, ainda faltam sistemas acessíveis aos usuários de tal setor, tendo em vista que grande parte são analfabetos totais ou funcionais. com o intuito de suprir as necessidades usuais (baixo custo, fácil usabilidade e compreensão), propomos o romaneioapp. com esta ferramenta, será possível garantir a eiciência na gestão dos pedidos de forma simples e clara."
249,2023,Estudo e análise de técnicas para melhorar desempenho de sistemas front-end com react.,"ROCHA, Ezequias de Oliveira.","BAPTISTA, Cláudio de Souza.","Os sistemas de aplicação web são de extrema importância para as
grandes empresas atualmente. Esses sistemas podem ter um nível
de complexidade elevado, precisando, desta forma, de mais
desempenho para ter sucesso no mercado competitivo e entregar
uma experiência de interação melhor para os usuários. Neste
trabalho, são descritas e analisadas algumas técnicas que podem
ser utilizadas para aumentar o desempenho de uma aplicação web
que utiliza React, uma das bibliotecas mais recorrentes na
atualidade. Para tal fim, foi realizada uma pesquisa na literatura e
em comunidades de desenvolvimento para obter técnicas, como a
de code-splitting, lazy load e de minificação de código. Em
seguida, essas técnicas avaliadas em um sistema real já existente,
no qual foram coletados dados seguindo algumas métricas, como
a de primeira renderização de conteúdo e a de tempo até
interatividade, para ser possível observar a eficiência dessas
práticas, iniciando, desta forma, uma catalogação das boas e más
práticas para o desempenho dos sistemas front-end.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29299,"os sistemas de aplicação web são de extrema importância para as grandes empresas atualmente. esses sistemas podem ter um nível de complexidade elevado, precisando, desta forma, de mais desempenho para ter sucesso no mercado competitivo e entregar uma experiência de interação melhor para os usuários. neste trabalho, são descritas e analisadas algumas técnicas que podem ser utilizadas para aumentar o desempenho de uma aplicação web que utiliza react, uma das bibliotecas mais recorrentes na atualidade. para tal fim, foi realizada uma pesquisa na literatura e em comunidades de desenvolvimento para obter técnicas, como a de code-splitting, lazy load e de minificação de código. em seguida, essas técnicas avaliadas em um sistema real já existente, no qual foram coletados dados seguindo algumas métricas, como a de primeira renderização de conteúdo e a de tempo até interatividade, para ser possível observar a eficiência dessas práticas, iniciando, desta forma, uma catalogação das boas e más práticas para o desempenho dos sistemas front-end."
250,2023,ESCOMath: desenvolvimento de uma ferramenta para o Moodle no domínio de questões de matemática.,"NASCIMENTO, Edson Weslley Almeida do.","OLIVEIRA, Maxwell Guimarães de.","Este trabalho relata o desenvolvimento de uma aplicação e a
criação de um pacote SCORM base para gerar questões
matemáticas e corrigir os passos de maneira automática. A
aplicação foi desenvolvida com sucesso e atingiu as expectativas
iniciais. Foi testada com sucesso no Moodle. Durante o
desenvolvimento, foram encontradas dificuldades como falta de
documentação atualizada e complexidade do fluxo da aplicação.
A ideia inicial de desenvolver um plugin para o Moodle não foi
viável devido ao tempo e dificuldades encontradas, assim,
optou-se pelo uso do SCORM.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29298,"este trabalho relata o desenvolvimento de uma aplicação e a criação de um pacote scorm base para gerar questões matemáticas e corrigir os passos de maneira automática. a aplicação foi desenvolvida com sucesso e atingiu as expectativas iniciais. foi testada com sucesso no moodle. durante o desenvolvimento, foram encontradas dificuldades como falta de documentação atualizada e complexidade do fluxo da aplicação. a ideia inicial de desenvolver um plugin para o moodle não foi viável devido ao tempo e dificuldades encontradas, assim, optou-se pelo uso do scorm."
251,2023,GESTO: uma abordagem de formação complementar e colaborativa de alunos veteranos e ingressantes para redução da evasão dos estudantes ingressantes no Curso de Computação da UFCG.,"SILVA, Dayvid Daniel da.","BARROS, Marcelo Alves de.","A evasão nas Instituições de Ensino Superior no Brasil é
um problema que gera impactos de cunhos financeiro e social,
para toda a população. No Curso de Computação da Universidade
Federal de Campina Grande (UFCG) a evasão é motivo de
preocupação de professores e gestores, sobretudo em relação aos
alunos ingressantes do curso. O Programa de Educação Tutorial
(PET) em Computação da UFCG desenvolveu uma abordagem
complementar e colaborativa de formação de alunos veteranos e
ingressantes, denominada Gesto, com o intuito de diminuir os
índices de evasão dos estudantes ingressantes nesta fase
desafiadora de início da experiência universitária. A abordagem é
baseada na prática do voluntariado e na construção social de
sentidos do estudo de computação, através de atividades de
desenvolvimento de habilidades técnicas (hardskills) e
não-técnicas (softskills) escolhidas pelos alunos em um portfólio
que lhes é oferecido semestralmente. Este trabalho apresenta uma
análise dos impactos desta abordagem a partir do estudo de três
atividades escolhidas pelos ingressantes dentre aquelas
disponíveis no portfólio oferecido no semestre letivo de 2022.1.
Resultados das avaliações feitas pelos alunos participantes,
ingressantes e veteranos, indicam que tal abordagem pode,
juntamente com outras ações, diminuir a evasão no Curso de
Ciência da Computação na UFCG.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29297,"a evasão nas instituições de ensino superior no brasil é um problema que gera impactos de cunhos financeiro e social, para toda a população. no curso de computação da universidade federal de campina grande (ufcg) a evasão é motivo de preocupação de professores e gestores, sobretudo em relação aos alunos ingressantes do curso. o programa de educação tutorial (pet) em computação da ufcg desenvolveu uma abordagem complementar e colaborativa de formação de alunos veteranos e ingressantes, denominada gesto, com o intuito de diminuir os índices de evasão dos estudantes ingressantes nesta fase desafiadora de início da experiência universitária. a abordagem é baseada na prática do voluntariado e na construção social de sentidos do estudo de computação, através de atividades de desenvolvimento de habilidades técnicas (hardskills) e não-técnicas (softskills) escolhidas pelos alunos em um portfólio que lhes é oferecido semestralmente. este trabalho apresenta uma análise dos impactos desta abordagem a partir do estudo de três atividades escolhidas pelos ingressantes dentre aquelas disponíveis no portfólio oferecido no semestre letivo de . . resultados das avaliações feitas pelos alunos participantes, ingressantes e veteranos, indicam que tal abordagem pode, juntamente com outras ações, diminuir a evasão no curso de ciência da computação na ufcg."
252,2023,Aplicação de redes neurais convolucionais na detecção de assentamentos precários em João Pessoa.,"BARROS, Débora Ferreira de.","PEREIRA, Eanes Torres.","Devido ao crescimento populacional e a expansão dos
assentamentos informais faz-se necessário o monitoramento e
mapeamento desses locais para que possam ser desenvolvidas
políticas públicas visando a solução da precariedade
característica presente nesses espaços. Algumas das soluções
atuais envolvem classificação de imagem baseada em
algoritmos de aprendizagem de máquina, entretanto, as
presentes no estado da arte necessitam da extração de muitas
características, o que demanda muito tempo e gera uma grande
quantidade de parâmetros que precisam ser processados pelos
algoritmos. Este trabalho apresenta o uso de uma rede neural
convolucional, a U-Net com Inception ResNet-V2, como
solução para a automação de extração de características e
redução de parâmetros em imagens de satélite, com foco na
cidade de João Pessoa, na Paraíba, junto com a segmentação
das imagens visando a detecção e classificação de
assentamentos precários nos espaços urbanos. O modelo foi
avaliado utilizando os coeficientes Jaccard e Dice, que
apresentaram respectivamente 53% e 69%, nos dados de teste.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29296,"devido ao crescimento populacional e a expansão dos assentamentos informais faz-se necessário o monitoramento e mapeamento desses locais para que possam ser desenvolvidas políticas públicas visando a solução da precariedade característica presente nesses espaços. algumas das soluções atuais envolvem classificação de imagem baseada em algoritmos de aprendizagem de máquina, entretanto, as presentes no estado da arte necessitam da extração de muitas características, o que demanda muito tempo e gera uma grande quantidade de parâmetros que precisam ser processados pelos algoritmos. este trabalho apresenta o uso de uma rede neural convolucional, a u-net com inception resnet-v2, como solução para a automação de extração de características e redução de parâmetros em imagens de satélite, com foco na cidade de joão pessoa, na paraíba, junto com a segmentação das imagens visando a detecção e classificação de assentamentos precários nos espaços urbanos. o modelo foi avaliado utilizando os coeficientes jaccard e dice, que apresentaram respectivamente % e %, nos dados de teste."
253,2023,Desenvolvimento de um website para auxiliar na busca de lar temporário para animais abandonados.,"VIEIRA, Danielle de Lima.","FARIA, Roberto Medeiros de.","O resgate e tratamento de animais abandonados é uma questão de
suma importância do ponto de vista social, do bem estar animal e
da saúde pública. Em muitas situações o intervalo entre o resgate
do animal e sua adoção pode ser bastante longo, o que dificulta o
resgate devido a superlotação ou falta de espaço físico para
abrigar os animais. Uma alternativa nessas situações é buscar um
lar temporário que possa cuidar do animal até que um lar
permanente e responsável seja encontrado. Para auxiliar nessa
tarefa foi desenvolvido um website com o objetivo de facilitar a
busca por lares temporários, utilizando o framework React para o
frontend (a interface gráfica de usuário) e o BaaS (Backend as a
Service) Firebase. Os usuários deste website são os
projetos/pessoas comuns que prestam apoio a animais
abandonados e voluntários que estão dispostos a oferecer um lar.
Ao final do desenvolvimento foi feita uma pesquisa de satisfação
com potenciais usuários. No geral, o site foi bem aceito e a
pesquisa também apontou áreas em que o site deve melhorar.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29295,"o resgate e tratamento de animais abandonados é uma questão de suma importância do ponto de vista social, do bem estar animal e da saúde pública. em muitas situações o intervalo entre o resgate do animal e sua adoção pode ser bastante longo, o que dificulta o resgate devido a superlotação ou falta de espaço físico para abrigar os animais. uma alternativa nessas situações é buscar um lar temporário que possa cuidar do animal até que um lar permanente e responsável seja encontrado. para auxiliar nessa tarefa foi desenvolvido um website com o objetivo de facilitar a busca por lares temporários, utilizando o framework react para o frontend (a interface gráfica de usuário) e o baas (backend as a service) firebase. os usuários deste website são os projetos/pessoas comuns que prestam apoio a animais abandonados e voluntários que estão dispostos a oferecer um lar. ao final do desenvolvimento foi feita uma pesquisa de satisfação com potenciais usuários. no geral, o site foi bem aceito e a pesquisa também apontou áreas em que o site deve melhorar."
254,2023,Aplicações para modelos de inteligência artificial que realizam geração automática de questões a partir de textos.,"MOREIRA, Caio Fernandes.","CAMPELO, Cláudio Elízio Calazans.","Nos últimos anos, avanços na área de Inteligência Artiicial permitiram
desenvolvimento de modelos de processamento de linguagem
natural em prol de aplicações em diversos contextos, como a automatização
do processo de elaboração de questões sobre temas especíicos.
Atualmente, existem modelos capazes de formular questões
sobre um tópico qualquer após receber como entrada um texto relevante.
Tais projetos possuem grande potencial auxiliar no contexto
educacional, entretanto, ainda existe carência de um sistema que
forneça a seus usuários uma maneira fácil e intuitiva de utilizar
esses modelos. Esse trabalho tem como objetivo o desenvolvimento
de uma aplicação web que supra essa necessidade, incorporando
modelos de processamento de linguagem natural que recebem como
entrada um texto e geram para o usuário uma lista de perguntas
relevantes ao tema. A utilização da aplicação web também traz a
oportunidade de obter feedback dos usuários sobre a qualidade das
perguntas geradas, informação que pode ser utilizada para retroalimentação
e aprimoramento dos modelos utilizados.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29294,"nos últimos anos, avanços na área de inteligência artiicial permitiram desenvolvimento de modelos de processamento de linguagem natural em prol de aplicações em diversos contextos, como a automatização do processo de elaboração de questões sobre temas especíicos. atualmente, existem modelos capazes de formular questões sobre um tópico qualquer após receber como entrada um texto relevante. tais projetos possuem grande potencial auxiliar no contexto educacional, entretanto, ainda existe carência de um sistema que forneça a seus usuários uma maneira fácil e intuitiva de utilizar esses modelos. esse trabalho tem como objetivo o desenvolvimento de uma aplicação web que supra essa necessidade, incorporando modelos de processamento de linguagem natural que recebem como entrada um texto e geram para o usuário uma lista de perguntas relevantes ao tema. a utilização da aplicação web também traz a oportunidade de obter feedback dos usuários sobre a qualidade das perguntas geradas, informação que pode ser utilizada para retroalimentação e aprimoramento dos modelos utilizados."
255,2023,COMPUTACAO@UFCG: um CRM para a Coordenação do Curso de Graduação em Ciência da Computação da UFCG.,"MARQUES, Cilas Medeiros de Farias.","BRASILEIRO, Francisco Vilar.","O Customer Relationship Management ´e uma estrat´egia
de neg´ocios amplamente adotada, com o objetivo de melhorar
a intera¸c˜ao entre uma empresa e seus clientes. Sua
implementa¸c˜ao utiliza ferramentas de software para compilar,
armazenar e analisar informa¸c˜oes sobre os clientes,
permitindo que a empresa compreenda melhor quem s˜ao,
como interagem com a marca e quais servi¸cos desejam.
Nos ´ultimos anos, algumas Institui¸c˜oes de Ensino Superior
tˆem estudado o uso dessa pr´atica, devido ao seu
grande potencial de influenciar a gest˜ao acadˆemica e a
experiˆencia dos estudantes. Diante disso, o sistema COMPUTACAO@
UFCG foi concebido, a fim de melhorar a
comunica¸c˜ao, o envolvimento e as conex˜oes entre os participantes
do curso, proporcionando automatiza¸c˜ao de
tarefas usuais, otimiza¸c˜ao de tempo, mitiga¸c˜ao de erros
e redu¸c˜ao de recursos envolvidos nos processos do curso.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29293,"o customer relationship management ´e uma estrat´egia de neg´ocios amplamente adotada, com o objetivo de melhorar a intera¸c˜ao entre uma empresa e seus clientes. sua implementa¸c˜ao utiliza ferramentas de software para compilar, armazenar e analisar informa¸c˜oes sobre os clientes, permitindo que a empresa compreenda melhor quem s˜ao, como interagem com a marca e quais servi¸cos desejam. nos ´ultimos anos, algumas institui¸c˜oes de ensino superior tˆem estudado o uso dessa pr´atica, devido ao seu grande potencial de influenciar a gest˜ao acadˆemica e a experiˆencia dos estudantes. diante disso, o sistema computacao@ ufcg foi concebido, a fim de melhorar a comunica¸c˜ao, o envolvimento e as conex˜oes entre os participantes do curso, proporcionando automatiza¸c˜ao de tarefas usuais, otimiza¸c˜ao de tempo, mitiga¸c˜ao de erros e redu¸c˜ao de recursos envolvidos nos processos do curso."
256,2023,Desmistificando a LGPD: avanços e desafios para adequação das organizações.,"SOUSA, Bruno Henrique Assis de.","GARCIA, Franceline Procópio.","Com o avanço da tecnologia e o uso massivo da internet, além da
necessidade de proteger a privacidade do usuário foi necessário a
criação da Lei Geral de Proteção de Dados Pessoais, visto que
antes da LGPD o compartilhamento de dados era ""livre"", uma vez
que as empresas podiam realizar trocas de informações do
usuário, como padrões de compra, sem que o titular soubesse.
Agora com a LGPD o tratamento de dados pessoais é definido de
maneira estruturada, com a padronização de regulamentos e
práticas. Muitas empresas ainda buscam se adequar a essa nova
realidade, principalmente as pequenas e médias, que geralmente
não possuem um setor especializado sobre o tema. Este trabalho
tem como objetivo analisar os principais pontos da lei, além de
mostrar os principais desafios enfrentados pelas empresas para se
adequar à LGPD.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29292,"com o avanço da tecnologia e o uso massivo da internet, além da necessidade de proteger a privacidade do usuário foi necessário a criação da lei geral de proteção de dados pessoais, visto que antes da lgpd o compartilhamento de dados era ""livre"", uma vez que as empresas podiam realizar trocas de informações do usuário, como padrões de compra, sem que o titular soubesse. agora com a lgpd o tratamento de dados pessoais é definido de maneira estruturada, com a padronização de regulamentos e práticas. muitas empresas ainda buscam se adequar a essa nova realidade, principalmente as pequenas e médias, que geralmente não possuem um setor especializado sobre o tema. este trabalho tem como objetivo analisar os principais pontos da lei, além de mostrar os principais desafios enfrentados pelas empresas para se adequar à lgpd."
257,2023,SchemaCheck: corretor automático de esquemas SQL.,"ARRUDA, Caio José dos Santos.","CAMPELO, Claudio Elízio Calazans.","Corrigir e fornecer feedbacks a respeito dos esquemas SQL criados
pelos alunos de cursos de banco de dados pode ser um processo
longo e árduo para os professores. Isso se deve à complexidade
dos esquemas, que podem ser escritos de diversas formas, mesmo
com um roteiro, que contém os requisitos funcionais sobre o que
deve ser implementado, exigindo que o professor tenha bastante
atenção durante a correção do esquema para identiicar possíveis
problemas ou erros no esquema do aluno. Além disso, os critérios de
correção dos esquemas costumam ser bastante especíicos, exigindo
que o professor descreva exatamente no que o aluno errou e o que
poderia ter feito de melhor. Dessa forma, pode ser difícil para os
professores de cursos de Banco de Dados acompanharem o ritmo
de entrega dos esquemas dos alunos e, consequentemente - garantir
que cada aluno receba um feedback a respeito do esquema criado,
sem atrasos. Neste trabalho foi desenvolvido uma aplicação de linha
de comando que visa ser uma ferramenta para auxiliar a correção
dos esquemas criados pelos alunos, com base em critérios de correção
à serem deinidos pelo professor. Espera-se que a aplicação
auxilie os professores de cursos de Banco de Dados nas correções
de esquemas SQL, tornando-a correção mais automatizada e menos
manual.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29291,"corrigir e fornecer feedbacks a respeito dos esquemas sql criados pelos alunos de cursos de banco de dados pode ser um processo longo e árduo para os professores. isso se deve à complexidade dos esquemas, que podem ser escritos de diversas formas, mesmo com um roteiro, que contém os requisitos funcionais sobre o que deve ser implementado, exigindo que o professor tenha bastante atenção durante a correção do esquema para identiicar possíveis problemas ou erros no esquema do aluno. além disso, os critérios de correção dos esquemas costumam ser bastante especíicos, exigindo que o professor descreva exatamente no que o aluno errou e o que poderia ter feito de melhor. dessa forma, pode ser difícil para os professores de cursos de banco de dados acompanharem o ritmo de entrega dos esquemas dos alunos e, consequentemente - garantir que cada aluno receba um feedback a respeito do esquema criado, sem atrasos. neste trabalho foi desenvolvido uma aplicação de linha de comando que visa ser uma ferramenta para auxiliar a correção dos esquemas criados pelos alunos, com base em critérios de correção à serem deinidos pelo professor. espera-se que a aplicação auxilie os professores de cursos de banco de dados nas correções de esquemas sql, tornando-a correção mais automatizada e menos manual."
258,2023,Atomic design no contexto de desenvolvimento: um relato de experiência.,"QUEVEDO, Brener Nosse.","MONTEIRO, João Arthur Brunet.","A importância do Atomic Design no desenvolvimento de software é
pouco discutida no meio acadêmico, mas é importante destacar o
valor de um sistema de design que estabelece diretrizes para criar
interfaces de usuário e facilita o desenvolvimento de aplicações web.
O Atomic Design permite construir um sistema de componentes
que seguem uma hierarquia bem deinida, resultando na construção
de interfaces lexíveis. Porém, essa lexibilidade e escalabilidade
podem não ser tão simples de serem implementadas e possuem
algumas limitações. Diante disto, com o intuito de observar de que
maneira o Atomic Design pode ser utilizado como uma metodologia
que facilita a forma de pensamento e organização dos projetos, este
trabalho relata a experiência de adaptar as diretrizes do Atomic De-
sign em uma aplicação conidencial de um e-commerce; trata-se de
um projeto interno de gerenciamento e integração de APIs de uma
empresa privada. Além disso, são propostas alguns critérios gerais
de avaliação para realização da análise da estratégia. O objetivo
geral é destacar fatores de sucesso, diiculdades e pontos negativos
do modelo diante da observação de sua aplicação na prática.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29290,"a importância do atomic design no desenvolvimento de software é pouco discutida no meio acadêmico, mas é importante destacar o valor de um sistema de design que estabelece diretrizes para criar interfaces de usuário e facilita o desenvolvimento de aplicações web. o atomic design permite construir um sistema de componentes que seguem uma hierarquia bem deinida, resultando na construção de interfaces lexíveis. porém, essa lexibilidade e escalabilidade podem não ser tão simples de serem implementadas e possuem algumas limitações. diante disto, com o intuito de observar de que maneira o atomic design pode ser utilizado como uma metodologia que facilita a forma de pensamento e organização dos projetos, este trabalho relata a experiência de adaptar as diretrizes do atomic de- sign em uma aplicação conidencial de um e-commerce; trata-se de um projeto interno de gerenciamento e integração de apis de uma empresa privada. além disso, são propostas alguns critérios gerais de avaliação para realização da análise da estratégia. o objetivo geral é destacar fatores de sucesso, diiculdades e pontos negativos do modelo diante da observação de sua aplicação na prática."
259,2023,Clean Code e SOLID na construção da aplicação Oratio: melhorando a manutenibilidade e escalabilidade.,"AZEVEDO, Beatriz Alice Alves Santos.","MASSONI, Tiago Lima.","Oratio é uma aplicação web criada para facilitar o trabalho dos
professores responsáveis pela disciplina de Trabalho e Conclusão
de Curso (TCC) de Ciência da Computação da Universidade
Federal de Campina Grande . Ela permite que o professor aloque
facilmente avaliadores e tenha o controle de todas as informações
relacionadas a um projeto e a um aluno. Desenvolvida em Flutter
e Java, Oratio foi projetada com a filosofia de Clean Code e
SOLID, garantindo assim a qualidade, a eficiência e a
escalabilidade do código. Embora o projeto Oratio tenha seguido
boas práticas de programação, não foram utilizados todos os
conceitos do clean code, mas sim uma modificação dos mesmos
para melhorar o desenvolvimento e a manutenção do projeto. Isso
foi feito para garantir que as características do SOLID sejam
atendidas, visando aumentar a manutenção e a flexibilidade do
código e tornar o projeto mais robusto e de fácil escalabilidade em
um curto tempo de desenvolvimento.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29289,"oratio é uma aplicação web criada para facilitar o trabalho dos professores responsáveis pela disciplina de trabalho e conclusão de curso (tcc) de ciência da computação da universidade federal de campina grande . ela permite que o professor aloque facilmente avaliadores e tenha o controle de todas as informações relacionadas a um projeto e a um aluno. desenvolvida em flutter e java, oratio foi projetada com a filosofia de clean code e solid, garantindo assim a qualidade, a eficiência e a escalabilidade do código. embora o projeto oratio tenha seguido boas práticas de programação, não foram utilizados todos os conceitos do clean code, mas sim uma modificação dos mesmos para melhorar o desenvolvimento e a manutenção do projeto. isso foi feito para garantir que as características do solid sejam atendidas, visando aumentar a manutenção e a flexibilidade do código e tornar o projeto mais robusto e de fácil escalabilidade em um curto tempo de desenvolvimento."
260,2022,Avaliação de desempenho no armazenamento de dados para um sistema de processamento de imagens de satélite.,"SOUZA, Thiago Yuri Evaristo de.","SILVA, Thiago Emmanuel Pereira da Cunha.","SAPS é um sistema que executa algoritmos para aquisição, pré-processamento e processamento de
imagem de satélite. Durante a execução dos algoritmos, arquivos são compartilhados entre os processos
que compõem cada um dos estágios (aquisição, pré-processamento e processamento). Atualmente, o
SAPS utiliza um sistema de arquivos NFS centralizado como solução para compartilhamento de dados. O
NFS é uma solução conhecida por apresentar alguns problemas, tais como implicar em ponto único de
falha e não ser escalável. Existem outras abordagens mais recentes que resolvem os problemas do NFS.
Uma dessas, o ObjectiveFS é um sistema de arquivos em Cloud que permite a escalabilidade do storage
possuindo uma performance similar ao armazenamento via NFS. Neste trabalho projetarei e
implementarei mudanças no projeto do SAPS permitindo o uso de uma nova abordagem que possibilite
resolver os problemas do NFS. A solução escolhida lida com o uso de uma SDK desenvolvida para lidar
com a nuvem do Openstack e um dos seus serviços de armazenamento, o Object Storage (Swift). Este
trabalho gerou uma melhoria no design do SAPS, porém seu desempenho não atendeu as expectativas
de ser superior, existindo um trade-off entre ambas as versões.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29286,"saps é um sistema que executa algoritmos para aquisição, pré-processamento e processamento de imagem de satélite. durante a execução dos algoritmos, arquivos são compartilhados entre os processos que compõem cada um dos estágios (aquisição, pré-processamento e processamento). atualmente, o saps utiliza um sistema de arquivos nfs centralizado como solução para compartilhamento de dados. o nfs é uma solução conhecida por apresentar alguns problemas, tais como implicar em ponto único de falha e não ser escalável. existem outras abordagens mais recentes que resolvem os problemas do nfs. uma dessas, o objectivefs é um sistema de arquivos em cloud que permite a escalabilidade do storage possuindo uma performance similar ao armazenamento via nfs. neste trabalho projetarei e implementarei mudanças no projeto do saps permitindo o uso de uma nova abordagem que possibilite resolver os problemas do nfs. a solução escolhida lida com o uso de uma sdk desenvolvida para lidar com a nuvem do openstack e um dos seus serviços de armazenamento, o object storage (swift). este trabalho gerou uma melhoria no design do saps, porém seu desempenho não atendeu as expectativas de ser superior, existindo um trade-off entre ambas as versões."
261,2022,Desenvolvimento de aplicação web para o projeto leitores da alegria.,"NASCIMENTO, Thalyta Barbosa do.","ARAÚJO, Joseana Macêdo Fechine Régis de.","Diante da grande desvalorização da leitura no Brasil, originou-se
o projeto łLeitores da Alegriaž, com o intuito de incentivar e expandir
este hábito entre crianças e adolescentes. Após a divulgação
dessa iniciativa, surgiu a necessidade de propagar a visibilidade
dos Leitores da Alegria e permitir um contato mais prático e dinâmico
com os seus possíveis contratantes e pessoas que tenham
interesse em participar das ações. Além disso, surgiu também o
entusiasmo dos membros em promover a valorização da leitura
e permitir que crianças e adolescentes despertem a motivação e
curiosidade e adquiram esse hábito por meio dos Leitores da Alegria.
Diante desse cenário, a equipe do projeto, desenvolveu um site
para disponibilizar informações relevantes sobre suas ações. Porém,
surgiu a necessidade de desenvolver uma versão mais atualizada
do referido site. Com base na versão desenvolvida anteriormente
e em requisitos apresentados durante reuniões com membros do
projeto, uma nova aplicação web foi implementada, a qual possui
novas funcionalidades, expandindo possibilidades e promovendo
um impacto positivo na vida de crianças e adolescentes a partir da
leitura.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29285,"diante da grande desvalorização da leitura no brasil, originou-se o projeto łleitores da alegriaž, com o intuito de incentivar e expandir este hábito entre crianças e adolescentes. após a divulgação dessa iniciativa, surgiu a necessidade de propagar a visibilidade dos leitores da alegria e permitir um contato mais prático e dinâmico com os seus possíveis contratantes e pessoas que tenham interesse em participar das ações. além disso, surgiu também o entusiasmo dos membros em promover a valorização da leitura e permitir que crianças e adolescentes despertem a motivação e curiosidade e adquiram esse hábito por meio dos leitores da alegria. diante desse cenário, a equipe do projeto, desenvolveu um site para disponibilizar informações relevantes sobre suas ações. porém, surgiu a necessidade de desenvolver uma versão mais atualizada do referido site. com base na versão desenvolvida anteriormente e em requisitos apresentados durante reuniões com membros do projeto, uma nova aplicação web foi implementada, a qual possui novas funcionalidades, expandindo possibilidades e promovendo um impacto positivo na vida de crianças e adolescentes a partir da leitura."
262,2022,Modeligado: gerando diagramas de sequência.,"ARAÚJO, Rayla Medeiros.","RÊGO, Matheus Gaudencio do.","O Modeligado é uma ferramenta utilizada em sala de aula que busca auxiliar o usuário na criação e
visualização de diagramas de classes, facilitando a correção desses diagramas por parte dos professores e
monitores. Porém, o sistema ainda possuía algumas limitações, sendo difícil observar o fluxo de execução
ao executar uma tarefa. Pensando nisso, neste projeto foi acrescentada a funcionalidade de gerar um
diagrama de sequência a partir da interação com o diagrama de classe. Os resultados obtidos
demonstram que os usuários ficaram satisfeitos com a usabilidade do sistema, mas ainda há pontos a
serem melhorados, principalmente quanto à responsividade e exibição de erros.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29284,"o modeligado é uma ferramenta utilizada em sala de aula que busca auxiliar o usuário na criação e visualização de diagramas de classes, facilitando a correção desses diagramas por parte dos professores e monitores. porém, o sistema ainda possuía algumas limitações, sendo difícil observar o fluxo de execução ao executar uma tarefa. pensando nisso, neste projeto foi acrescentada a funcionalidade de gerar um diagrama de sequência a partir da interação com o diagrama de classe. os resultados obtidos demonstram que os usuários ficaram satisfeitos com a usabilidade do sistema, mas ainda há pontos a serem melhorados, principalmente quanto à responsividade e exibição de erros."
263,2022,Hip-Hop e Rap: uma análise da evolução das composições.,"ALVES, Thallyson José Silva.","MARINHO, Leandro Balby.","A música é uma forma de arte e um instrumento de expressão da cultura que surge desde o início da
história humana. Ao longo do tempo, a música evoluiu ao redor dos contextos sociais em que estava
inserida, exercendo um importante papel na construção de identidades na sociedade. O hip-hop é um
movimento cultural e artístico que surgiu no meio das comunidades afro-americanas dos Estados Unidos
e tem como um dos seus pilares principais o gênero musical rap. Concebido na Jamaica na década de 60,
o rap foi ganhando mais força a partir dos anos 70, principalmente nos bairros pobres das grandes
cidades e atualmente é um dos gêneros musicais mais ouvidos em todo o mundo. O objetivo deste
trabalho é utilizar Web Scraping para gerar uma base de dados de letras musicais e através da aplicação
de conceitos de Processamento de Linguagem Natural e Análise Exploratória de Dados, extrair
informações sobre as composições de alguns dos artistas norte-americanos mais conceituados do gênero
buscando compreender melhor a evolução das letras ao longo do tempo, identificando quais temas
foram mais abordados em cada época e desenvolver um pequeno site interativo para demonstrar os
resultados encontrados.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29283,"a música é uma forma de arte e um instrumento de expressão da cultura que surge desde o início da história humana. ao longo do tempo, a música evoluiu ao redor dos contextos sociais em que estava inserida, exercendo um importante papel na construção de identidades na sociedade. o hip-hop é um movimento cultural e artístico que surgiu no meio das comunidades afro-americanas dos estados unidos e tem como um dos seus pilares principais o gênero musical rap. concebido na jamaica na década de , o rap foi ganhando mais força a partir dos anos , principalmente nos bairros pobres das grandes cidades e atualmente é um dos gêneros musicais mais ouvidos em todo o mundo. o objetivo deste trabalho é utilizar web scraping para gerar uma base de dados de letras musicais e através da aplicação de conceitos de processamento de linguagem natural e análise exploratória de dados, extrair informações sobre as composições de alguns dos artistas norte-americanos mais conceituados do gênero buscando compreender melhor a evolução das letras ao longo do tempo, identificando quais temas foram mais abordados em cada época e desenvolver um pequeno site interativo para demonstrar os resultados encontrados."
264,2022,Cidadania digital na prática: um estudo sobre as principais redes sociais utilizadas por adolescentes.,"PAZ, Raiany Rufino Costa da.","CAMPOS, Lívia Maria Rodrigues Sampaio.","Em um mundo onde as pessoas têm cada vez mais contato com as tecnologias, surgiram também
questões sobre como utilizá-las adequadamente. Muitas vezes, essas questões surgem em respostas a
perigos percebidos ou comportamentos inapropriados como roubo de identidade, cyberbullying ou
disseminação de notícias falsas, especialmente no mundo online. Tais abusos podem ser ainda mais
prejudiciais aos adolescentes que cada vez mais cedo são inseridos nesse contexto tecnológico. Apesar
de os usuários terem capacidade de avaliar uma conduta online adequada e identificar riscos, é
necessário que eles desenvolvam um senso crítico para utilizar a internet de forma responsável, ou seja,
usar o ambiente online sem prejudicar a si mesmos e aos outros. Para isso, a cidadania digital surge como
um conjunto de normas de comportamento que devem ser seguidas para o uso amigável, seguro e ético
das tecnologias. Logo, a presente pesquisa tem como objetivo analisar as principais tecnologias digitais
utilizadas por adolescentes e, a partir delas, listar formas de uso responsável de acordo com os
elementos da cidadania digital a fim de conduzir de forma positiva o comportamento de adolescentes na
sociedade e constituir uma cultura de uso seguro das tecnologias digitais.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29282,"em um mundo onde as pessoas têm cada vez mais contato com as tecnologias, surgiram também questões sobre como utilizá-las adequadamente. muitas vezes, essas questões surgem em respostas a perigos percebidos ou comportamentos inapropriados como roubo de identidade, cyberbullying ou disseminação de notícias falsas, especialmente no mundo online. tais abusos podem ser ainda mais prejudiciais aos adolescentes que cada vez mais cedo são inseridos nesse contexto tecnológico. apesar de os usuários terem capacidade de avaliar uma conduta online adequada e identificar riscos, é necessário que eles desenvolvam um senso crítico para utilizar a internet de forma responsável, ou seja, usar o ambiente online sem prejudicar a si mesmos e aos outros. para isso, a cidadania digital surge como um conjunto de normas de comportamento que devem ser seguidas para o uso amigável, seguro e ético das tecnologias. logo, a presente pesquisa tem como objetivo analisar as principais tecnologias digitais utilizadas por adolescentes e, a partir delas, listar formas de uso responsável de acordo com os elementos da cidadania digital a fim de conduzir de forma positiva o comportamento de adolescentes na sociedade e constituir uma cultura de uso seguro das tecnologias digitais."
265,2022,"Análise do desempenho dos alunos de Ciência da Computação, na Universidade Federal de Campina Grande, nos períodos presenciais e remotos emergenciais.","GOUVEIA, Talita Galdino.","ARAÚJO, Joseana Macêdo Fechine Régis de.","Na atualidade, nota-se uma crescente valorização da área de tecnologia no Brasil e no mundo.
Ainda que as mulheres tenham tido um papel fundamental na história da computação, sabe-se
que sua presença no meio é consideravelmente inferior quando comparada à dos homens,
mesmo com o aumento dessa valorização. Aliado a esse fato, com o início da pandemia no
ano de 2020, as universidades tiveram que aderir ao modelo remoto de ensino, o que pode ter
impactado no desempenho dos alunos (homens e mulheres). Nesse contexto, o trabalho de
conclusão de curso ora descrito tem como objetivo analisar o desempenho dos discentes no
curso de Ciência da Computação da UFCG, durante a pandemia de COVID-19, que
promoveu o ensino à distância, fato este que provocou mudanças no ensino de graduação da
instituição. Para tanto, foram realizadas análises quantitativas, a partir de dados relativos ao
desempenho acadêmico. Ao final deste trabalho foi possível notar que o desempe- nho
acadêmico dos alunos foi maior durante os períodos de ensino remoto e que o sexo dos alunos
não influencia nesse desempenho.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29281,"na atualidade, nota-se uma crescente valorização da área de tecnologia no brasil e no mundo. ainda que as mulheres tenham tido um papel fundamental na história da computação, sabe-se que sua presença no meio é consideravelmente inferior quando comparada à dos homens, mesmo com o aumento dessa valorização. aliado a esse fato, com o início da pandemia no ano de , as universidades tiveram que aderir ao modelo remoto de ensino, o que pode ter impactado no desempenho dos alunos (homens e mulheres). nesse contexto, o trabalho de conclusão de curso ora descrito tem como objetivo analisar o desempenho dos discentes no curso de ciência da computação da ufcg, durante a pandemia de covid- , que promoveu o ensino à distância, fato este que provocou mudanças no ensino de graduação da instituição. para tanto, foram realizadas análises quantitativas, a partir de dados relativos ao desempenho acadêmico. ao final deste trabalho foi possível notar que o desempe- nho acadêmico dos alunos foi maior durante os períodos de ensino remoto e que o sexo dos alunos não influencia nesse desempenho."
266,2022,Estratégia de monitoramento e análise de engajamento de estudantes em cursos de banco de dados.,"SANTOS, Yuri Souza dos.","CAMPELO, Cláudio Elízio Calazans.","O monitoramento do engajamento dos estudantes possibilita um
enriquecimento do sistema educacional. Através dele é possível obter
informações relacionadas a dedicação e desempenho dos alunos
em determinadas atividades. Entretanto, tratando-se dos cursos de
Banco de Dados, há uma escassez de estratégias para monitorar o
engajamento dos discentes, diicultando a realização de pesquisas e
análises do desempenho do estudante. Diante dessa problemática,
desenvolvemos um mecanismo capaz de monitorar a interação dos
estudantes com o banco de dados e gerar um conjunto de dados
envolvendo o uso dos comandos Data Deinition Language e Data
Manipulation Language efetuados. Posteriormente, com esse mecanismo,
monitoramos 95 discentes da disciplina Banco de Dados,
do curso de Ciência da Computação da Universidade Federal de
Campina Grande. Com isso, realizamos um estudo de caso, no qual
utilizamos, além das informações colhidas dos bancos de dados,
outras informações relacionadas à participação dos alunos da disciplina,
como as notas obtidas e a submissão dos roteiros práticos.
Dessa forma, contribuímos com uma ferramenta capaz de monitorar
as atividades práticas dos estudantes e extrair informações que
podem ser úteis no sistema educacional.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29280,"o monitoramento do engajamento dos estudantes possibilita um enriquecimento do sistema educacional. através dele é possível obter informações relacionadas a dedicação e desempenho dos alunos em determinadas atividades. entretanto, tratando-se dos cursos de banco de dados, há uma escassez de estratégias para monitorar o engajamento dos discentes, diicultando a realização de pesquisas e análises do desempenho do estudante. diante dessa problemática, desenvolvemos um mecanismo capaz de monitorar a interação dos estudantes com o banco de dados e gerar um conjunto de dados envolvendo o uso dos comandos data deinition language e data manipulation language efetuados. posteriormente, com esse mecanismo, monitoramos discentes da disciplina banco de dados, do curso de ciência da computação da universidade federal de campina grande. com isso, realizamos um estudo de caso, no qual utilizamos, além das informações colhidas dos bancos de dados, outras informações relacionadas à participação dos alunos da disciplina, como as notas obtidas e a submissão dos roteiros práticos. dessa forma, contribuímos com uma ferramenta capaz de monitorar as atividades práticas dos estudantes e extrair informações que podem ser úteis no sistema educacional."
267,2022,Arrebol - sistema elástico de processamento em lote de aplicações single-node.,"SILVA, Vinicius Barbosa da.","BRASILEIRO, Francisco Vilar.","Com o avanço dos computadores e seu crescente uso nas mais diferentes áreas, pesquisas que usam
computação de forma intensa para obter resultados, também conhecidas por e-researches, vêm se tornando
cada vez mais presentes na academia e em empresas que necessitam executar aplicações que processam grande quantidade de dados. Durante muito tempo, o ambiente mais comum para execução dessas aplicações eram os supercomputadores, que são infraestruturas de elevado custo de instalação e manutenção e que em sua maioria estão presentes em locais específicos, como grandes empresas e instituições acadêmicas. Portanto, esse tipo de infraestrutura nem sempre é acessível para todos os pesquisadores. Os supercomputadores dispõem de recursos computacionais (CPU, RAM, armazenamento) previamente alocados que se não forem usados adequadamente, seja por uma política de escalonamento ineficaz ou por uma baixa demanda, acabam sendo desperdiçados. Com
isso em mente, propomos o Arrebol: um sistema de processamento em lote baseado em nuvem, que tira proveito
da elasticidade desse ambiente e aloca recursos sob demanda. O Arrebol monitora a carga de trabalho do cluster
e procura equilibrá-la com os recursos disponíveis. Sempre que possível, tenta otimizar a utilização de recursos
mantendo a menor possível. O presente trabalho dá continuação ao desenvolvimento Arrebol, implementando o
servidor de gerenciamento de recursos (Resource Manager).",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29279,"com o avanço dos computadores e seu crescente uso nas mais diferentes áreas, pesquisas que usam computação de forma intensa para obter resultados, também conhecidas por e-researches, vêm se tornando cada vez mais presentes na academia e em empresas que necessitam executar aplicações que processam grande quantidade de dados. durante muito tempo, o ambiente mais comum para execução dessas aplicações eram os supercomputadores, que são infraestruturas de elevado custo de instalação e manutenção e que em sua maioria estão presentes em locais específicos, como grandes empresas e instituições acadêmicas. portanto, esse tipo de infraestrutura nem sempre é acessível para todos os pesquisadores. os supercomputadores dispõem de recursos computacionais (cpu, ram, armazenamento) previamente alocados que se não forem usados adequadamente, seja por uma política de escalonamento ineficaz ou por uma baixa demanda, acabam sendo desperdiçados. com isso em mente, propomos o arrebol: um sistema de processamento em lote baseado em nuvem, que tira proveito da elasticidade desse ambiente e aloca recursos sob demanda. o arrebol monitora a carga de trabalho do cluster e procura equilibrá-la com os recursos disponíveis. sempre que possível, tenta otimizar a utilização de recursos mantendo a menor possível. o presente trabalho dá continuação ao desenvolvimento arrebol, implementando o servidor de gerenciamento de recursos (resource manager)."
268,2022,MeuTreino: aplicativo para gerenciamento de atividades físicas.,"EZIQUIEL, Matheus Ferreira.","MOURA, José Antão Beltrão.","Com o crescimento do mercado fitness, a crescente conscientização sobre hábitos saudáveis torna-se
cada vez mais comum o uso das tecnologias da informação para auxiliar o gerenciamento deste modo
de vida. Entretanto, dificilmente os aplicativos de gerenciamento de treino oferecem a possibilidade
de um profissional de educação física se conectar com seu aluno para que o treino seja criado e
acompanhado, em sua maioria, essa responsabilidade é do próprio estudante, que na maioria dos
casos, não possui o conhecimento necessário. Perante o exposto, surgiu o tema principal para este
trabalho, o desenvolvimento de uma aplicação que auxilia pessoas adeptas deste modo de vida
saudável a realizar o gerenciamento de suas atividades físicas e que permita a conexão de
personal-trainers com seus alunos. O aplicativo disponibilizado para Android, foi desenvolvido em
Flutter, um framework open source, e para armazenamento de dados, um servidor remoto utilizando
Firebase. O objetivo do aplicativo é fornecer uma aplicação mobile na qual o usuário poderá
estabelecer o contato com seu profissional de educação física para facilitar o gerenciamento de suas
atividades físicas, de modo que aborda os processos de desenvolvimento de software, desde a fase de
levantamento e análise de requisitos, projeto, implementação e por fim implantação.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29278,"com o crescimento do mercado fitness, a crescente conscientização sobre hábitos saudáveis torna-se cada vez mais comum o uso das tecnologias da informação para auxiliar o gerenciamento deste modo de vida. entretanto, dificilmente os aplicativos de gerenciamento de treino oferecem a possibilidade de um profissional de educação física se conectar com seu aluno para que o treino seja criado e acompanhado, em sua maioria, essa responsabilidade é do próprio estudante, que na maioria dos casos, não possui o conhecimento necessário. perante o exposto, surgiu o tema principal para este trabalho, o desenvolvimento de uma aplicação que auxilia pessoas adeptas deste modo de vida saudável a realizar o gerenciamento de suas atividades físicas e que permita a conexão de personal-trainers com seus alunos. o aplicativo disponibilizado para android, foi desenvolvido em flutter, um framework open source, e para armazenamento de dados, um servidor remoto utilizando firebase. o objetivo do aplicativo é fornecer uma aplicação mobile na qual o usuário poderá estabelecer o contato com seu profissional de educação física para facilitar o gerenciamento de suas atividades físicas, de modo que aborda os processos de desenvolvimento de software, desde a fase de levantamento e análise de requisitos, projeto, implementação e por fim implantação."
269,2022,Entre dois mundos: Movimento Empresa Júnior e graduação em Ciência da Computação: co o o MEJ pode impactar na jornada de um discente em um curso de tecnologia?,"BEZERRA, Luan Carlos da Silva.","GARCIA, Francilene Procópio.","Este trabalho tem como objetivo analisar como é dada a dinâmica entre o fomento ao empreendedorismo na graduação e a formação dos discentes da Universidade Federal de Campina Grande - PB (UFCG). Para realização dessa análise vamos utilizar das experiências dos discentes, tanto os que participam do Movimento Empresa Júnior (MEJ), quanto o que não tiveram essa vivência, também teremos um maior foco voltado aos graduandos em Ciência da Computação. A principal motivação que permeia este trabalho, é a de evidenciar o alto potencial de inflexão positiva que o MEJ carrega, sobre a experiência e formação dos discentes, mas também sobre o impacto social gerado pelos projetos desenvolvidos neste ambiente. Com isso, esperamos validar o potencial de transformação da realidade e de mindset que o MEJ proporciona. Bem como o grau de impacto sobre a formação dos discentes que o empreendedorismo pode ter, principalmente dentro do curso de Ciência da Computação na UFCG, pela pluralidade de experiências que o MEJ carrega.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29277,"este trabalho tem como objetivo analisar como é dada a dinâmica entre o fomento ao empreendedorismo na graduação e a formação dos discentes da universidade federal de campina grande - pb (ufcg). para realização dessa análise vamos utilizar das experiências dos discentes, tanto os que participam do movimento empresa júnior (mej), quanto o que não tiveram essa vivência, também teremos um maior foco voltado aos graduandos em ciência da computação. a principal motivação que permeia este trabalho, é a de evidenciar o alto potencial de inflexão positiva que o mej carrega, sobre a experiência e formação dos discentes, mas também sobre o impacto social gerado pelos projetos desenvolvidos neste ambiente. com isso, esperamos validar o potencial de transformação da realidade e de mindset que o mej proporciona. bem como o grau de impacto sobre a formação dos discentes que o empreendedorismo pode ter, principalmente dentro do curso de ciência da computação na ufcg, pela pluralidade de experiências que o mej carrega."
270,2022,Reconhecimento de eventos usando sensores móveis.,"AZEVÊDO, Rafael Dantas Santos de.","GOMES, Herman Martins.","A partir da disseminação do uso de smartphones nos últimos anos, tem crescido o interesse em
utilizar os dados produzidos por seus sensores para monitorar temporalmente ações e eventos
associados ao usuário ou ao ambiente onde se encontra o dispositivo. Tal monitoramento pode
ajudar na compreensão do comportamento de portadores de smartphones de determinada
localização geográfica e na formação de possíveis agrupamentos a partir das sequências de
eventos/ações realizados ao longo do dia (e.g. caminhar, pular, correr, sentar etc.). O resultado deste
processo pode ser útil ao levantamento de perfis de grupos populacionais. Neste contexto, o
presente trabalho de conclusão de curso propõe um método para o treinamento e a predição de
eventos/ações por meio de dados adquiridos de sensores móveis. Para tal, foi criado um aplicativo
para realizar a aquisição dos dados, sendo obtidos dados do acelerômetro, giroscópio, microfone e
GPS para formação de uma base de dados integrada. Ao executar o aplicativo os dados são gravados
e o usuário pode rotular determinados eventos que estiverem acontecendo num determinado
instante de tempo. Posteriormente, tais rótulos irão servir para que algoritmos de aprendizagem de
máquina possam construir um modelo preditivo para os eventos.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29276,"a partir da disseminação do uso de smartphones nos últimos anos, tem crescido o interesse em utilizar os dados produzidos por seus sensores para monitorar temporalmente ações e eventos associados ao usuário ou ao ambiente onde se encontra o dispositivo. tal monitoramento pode ajudar na compreensão do comportamento de portadores de smartphones de determinada localização geográfica e na formação de possíveis agrupamentos a partir das sequências de eventos/ações realizados ao longo do dia (e.g. caminhar, pular, correr, sentar etc.). o resultado deste processo pode ser útil ao levantamento de perfis de grupos populacionais. neste contexto, o presente trabalho de conclusão de curso propõe um método para o treinamento e a predição de eventos/ações por meio de dados adquiridos de sensores móveis. para tal, foi criado um aplicativo para realizar a aquisição dos dados, sendo obtidos dados do acelerômetro, giroscópio, microfone e gps para formação de uma base de dados integrada. ao executar o aplicativo os dados são gravados e o usuário pode rotular determinados eventos que estiverem acontecendo num determinado instante de tempo. posteriormente, tais rótulos irão servir para que algoritmos de aprendizagem de máquina possam construir um modelo preditivo para os eventos."
271,2022,Análise de acessibilidade visual na usabilidade da plataforma moodle para deficientes visuais e baixa visão.,"OLIVEIRA, Mateus de Lima.","MASSONI, Tiago Lima.","Nos últimos anos, o uso de plataformas de ensino ganhou mais espaço nas instituições de educação,
seja de modo complementar ao ensino presencial, ou para cursos totalmente remotos. Dessa forma,
é de grande importância o acesso às informações e funcionalidades nesses serviços à usuários com
algum tipo de deficiência. No entanto, grande parte dos sistemas ainda não são projetados
priorizando requisitos e padrões de usabilidade e acessibilidade para pessoas com deficiência, onde
se pode destacar o grupo dos deficientes visuais, que segundo a Organização Mundial da Saúde, no
mundo, são 39 milhões de pessoas. Na Universidade Federal de Campina Grande (UFCG), uma das
plataformas usadas para o ensino remoto é o Moodle. Neste contexto, este artigo apresenta um
estudo para avaliar o nível de acessibilidade visual da plataforma Moodle usando ferramentas
automáticas e testes de usabilidade com participantes quem tinham algum grau de deficiência visual,
com o intuito de encontrar possíveis problemas de interação. Os resultados mostram que a
plataforma não pode ser considerada totalmente acessível a todo e qualquer aluno com deficiência
visual para usar plenamente todos os serviços disponibilizados nele, devido às violações das diretrizes
utilizadas nas avaliações automáticas e de usabilidade.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29275,"nos últimos anos, o uso de plataformas de ensino ganhou mais espaço nas instituições de educação, seja de modo complementar ao ensino presencial, ou para cursos totalmente remotos. dessa forma, é de grande importância o acesso às informações e funcionalidades nesses serviços à usuários com algum tipo de deficiência. no entanto, grande parte dos sistemas ainda não são projetados priorizando requisitos e padrões de usabilidade e acessibilidade para pessoas com deficiência, onde se pode destacar o grupo dos deficientes visuais, que segundo a organização mundial da saúde, no mundo, são milhões de pessoas. na universidade federal de campina grande (ufcg), uma das plataformas usadas para o ensino remoto é o moodle. neste contexto, este artigo apresenta um estudo para avaliar o nível de acessibilidade visual da plataforma moodle usando ferramentas automáticas e testes de usabilidade com participantes quem tinham algum grau de deficiência visual, com o intuito de encontrar possíveis problemas de interação. os resultados mostram que a plataforma não pode ser considerada totalmente acessível a todo e qualquer aluno com deficiência visual para usar plenamente todos os serviços disponibilizados nele, devido às violações das diretrizes utilizadas nas avaliações automáticas e de usabilidade."
272,2022,Análise e desenvolvimento de material didático para auxílio na formação do pensamento computacional em crianças com deficiência visual.,"MEDEIROS, Matheus Silva.","ARAÚJO, Elaine Cristina de.","Sabemos que a infância é o período onde há maior
desenvolvimento de habilidades do indivíduo. Nessa fase, a
criança está aberta a novos conhecimentos, tendo a criatividade e
curiosidade como fortes características. Em tempos atuais,
percebemos que grande parte das crianças conseguem ter boa
desenvoltura com a tecnologia, meio facilitador do processo de
aprendizado e resolução de problemas, por exemplo. Nesse
sentido, consolidar um Pensamento Computacional ainda na fase
infantil é algo bastante relevante, pois a fará pensar de forma mais
eficaz, simples e ágil em momentos que precisar tomar certas
decisões ou, ainda, solucionar problemas do seu dia a dia. No
contexto das crianças com deficiência visual, esse fator não muda,
mesmo com as dificuldades enfrentadas pela falta de inclusão no
nosso país, a capacidade de desenvolver esse pensamento
computacional é a mesma. Tendo foco, portanto, no trabalho com
crianças com deficiência visual, foi desenvolvido um material
didático que servirá como auxiliador na consolidação do
pensamento computacional em crianças cegas e com baixa visão,
uma vez que existe pouco acervo bibliográfico com essa
abordagem. O material desenvolvido por meio de técnicas da
Computação Desplugada e da Programação em Blocos foi levado
ao Instituto dos Cegos da cidade de Campina Grande e aplicado
com algumas crianças, obtendo resultados satisfatórios.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29274,"sabemos que a infância é o período onde há maior desenvolvimento de habilidades do indivíduo. nessa fase, a criança está aberta a novos conhecimentos, tendo a criatividade e curiosidade como fortes características. em tempos atuais, percebemos que grande parte das crianças conseguem ter boa desenvoltura com a tecnologia, meio facilitador do processo de aprendizado e resolução de problemas, por exemplo. nesse sentido, consolidar um pensamento computacional ainda na fase infantil é algo bastante relevante, pois a fará pensar de forma mais eficaz, simples e ágil em momentos que precisar tomar certas decisões ou, ainda, solucionar problemas do seu dia a dia. no contexto das crianças com deficiência visual, esse fator não muda, mesmo com as dificuldades enfrentadas pela falta de inclusão no nosso país, a capacidade de desenvolver esse pensamento computacional é a mesma. tendo foco, portanto, no trabalho com crianças com deficiência visual, foi desenvolvido um material didático que servirá como auxiliador na consolidação do pensamento computacional em crianças cegas e com baixa visão, uma vez que existe pouco acervo bibliográfico com essa abordagem. o material desenvolvido por meio de técnicas da computação desplugada e da programação em blocos foi levado ao instituto dos cegos da cidade de campina grande e aplicado com algumas crianças, obtendo resultados satisfatórios."
273,2022,Utilizando técnicas de aprendizagem de máquina e NLP para extração de informações em licitações do Diário Oficial do Estado do Acre.,"RAMALHO, Rich Elton Carvalho.","BAPTISTA, Cláudio de Souza.","Sistemas de Extração de Informação auxiliam humanos na busca
de informação específica em documentos. No entanto, a maioria
destes sistemas não dão suporte a documentos no formato Portable
Document Format (PDF), que é largamente utilizado. Em um documento
PDF, o conteúdo do texto é misturado com metadados ou
dados semi-estruturados, que dificultam os algoritmos de Processamento
de Linguagem Natural (PLN) na extração da informação
requerida. O Tribunal de Contas do Estado do Acre (TCE-AC) é o
órgão fiscalizador e controlador do uso do dinheiro público e da
administração orçamentária e financeira do estado do Acre, responsável
por analisar e julgar as contas públicas dos jurisdicionados.
Os jurisdicionados devem publicar informações relacionadas às licitações
tanto no sistema de gerenciamento de licitações do TCE-AC
como também no Diário Oficial do Estado do Acre (DOE), que usa
o formato PDF. É de responsabilidade do TCE-AC verificar se as
informações da licitação estão nos dois lugares, gerando assim, um
grande trabalho manual. Neste trabalho, apresentamos uma solução
de PLN com objetivo de extrair os atos do DOE, categorizar automaticamente
os atos como licitação ou não, em caso afirmativo, serão
utilizadas técnicas avançadas de PLN para processar e extrair as
entidades e informações da licitação para que seja possível auxiliar
o TCE-AC a verificar se a licitação",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29273,"sistemas de extração de informação auxiliam humanos na busca de informação específica em documentos. no entanto, a maioria destes sistemas não dão suporte a documentos no formato portable document format (pdf), que é largamente utilizado. em um documento pdf, o conteúdo do texto é misturado com metadados ou dados semi-estruturados, que dificultam os algoritmos de processamento de linguagem natural (pln) na extração da informação requerida. o tribunal de contas do estado do acre (tce-ac) é o órgão fiscalizador e controlador do uso do dinheiro público e da administração orçamentária e financeira do estado do acre, responsável por analisar e julgar as contas públicas dos jurisdicionados. os jurisdicionados devem publicar informações relacionadas às licitações tanto no sistema de gerenciamento de licitações do tce-ac como também no diário oficial do estado do acre (doe), que usa o formato pdf. é de responsabilidade do tce-ac verificar se as informações da licitação estão nos dois lugares, gerando assim, um grande trabalho manual. neste trabalho, apresentamos uma solução de pln com objetivo de extrair os atos do doe, categorizar automaticamente os atos como licitação ou não, em caso afirmativo, serão utilizadas técnicas avançadas de pln para processar e extrair as entidades e informações da licitação para que seja possível auxiliar o tce-ac a verificar se a licitação"
274,2022,MockTests: uma ferramenta para modelagem eficiente de testes envolvendo end-points de aplicações Back-end..,"TRAJANO, Mathias Abreu.","FARIAS, Adalberto Cajueiro de.","Objetos sintéticos são utilizados no desenvolvimento de software para simular o comportamento
de objetos reais de forma controlada. Durante o desenvolvimento de servidores back-end, existe
uma constante necessidade de modelar testes com objetos simulados para garantir o
funcionamento adequado de funcionalidades dos mesmos. Todavia, essa tarefa acaba por se
tornar repetitiva e complicada conforme a aplicação cresce. Ademais, testes que envolvam
endpoints de aplicações se mostram mais complexos por ter necessidade de modelar requisições
completas do tipo HTTP. A biblioteca MockTests tem por finalidades principais promover uma
elaboração de testes sem a necessidade de inserção repetitiva de alguns componentes a cada caso
de teste, simplificando assim diversos aspectos e solucionando empecilhos que podem surgir
durante o desenvolvimento. Este presente trabalho tem por finalidade relatar as etapas do
desenvolvimento da biblioteca MockTests, concebida para solucionar percalços durante a criação
de testes envolvendo endpoints de aplicações. Os resultados obtidos demonstraram como a
ferramenta se adequou ao ser usada em testes de uma aplicação backend real, e como a mesma
solucionou diversos problemas encontrados na logística de construção dos respectivos testes.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29272,"objetos sintéticos são utilizados no desenvolvimento de software para simular o comportamento de objetos reais de forma controlada. durante o desenvolvimento de servidores back-end, existe uma constante necessidade de modelar testes com objetos simulados para garantir o funcionamento adequado de funcionalidades dos mesmos. todavia, essa tarefa acaba por se tornar repetitiva e complicada conforme a aplicação cresce. ademais, testes que envolvam endpoints de aplicações se mostram mais complexos por ter necessidade de modelar requisições completas do tipo http. a biblioteca mocktests tem por finalidades principais promover uma elaboração de testes sem a necessidade de inserção repetitiva de alguns componentes a cada caso de teste, simplificando assim diversos aspectos e solucionando empecilhos que podem surgir durante o desenvolvimento. este presente trabalho tem por finalidade relatar as etapas do desenvolvimento da biblioteca mocktests, concebida para solucionar percalços durante a criação de testes envolvendo endpoints de aplicações. os resultados obtidos demonstraram como a ferramenta se adequou ao ser usada em testes de uma aplicação backend real, e como a mesma solucionou diversos problemas encontrados na logística de construção dos respectivos testes."
275,2022,Acidentes na prática de TDD: percepções e consequências.,"MATOS, Rerisson Daniel Costa Silva.","MASSONI, Tiago Lima.","Apesar da existência de alguns estudos inconclusivos [8], é observável a proeminência de
evidências que apontam como a técnica de Desenvolvimento Orientado a Testes (Test Driven
Development, TDD) pode aumentar a qualidade de código e a confiabilidade de um sistema
de software [1]. Apesar de ser uma prática relativamente elementar, um estudo [2] realizado
em 2010 verificou que muitos programadores não executam todos os passos em conformidade
com a proposta da técnica. Nosso objetivo neste trabalho é reproduzir parte desse estudo
através de um novo questionário, utilizando alguns dos acidentes levantados em [2]
acrescidos de perguntas discursivas que investigam as circunstâncias e consequências de sua
existência. Como resultado, percebemos que a frequência de alguns acidentes foi similar às
apresentadas em [2]. Além disso, também notamos que os desenvolvedores percebem as
consequências de não executar algumas das etapas de TDD e que eles próprios possuem
consciência que a prática deve ser aliada a outras técnicas de design para que o tempo
investido tenha retorno compatível e a execução da técnica não seja onerosa.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29271,"apesar da existência de alguns estudos inconclusivos [ ], é observável a proeminência de evidências que apontam como a técnica de desenvolvimento orientado a testes (test driven development, tdd) pode aumentar a qualidade de código e a confiabilidade de um sistema de software [ ]. apesar de ser uma prática relativamente elementar, um estudo [ ] realizado em verificou que muitos programadores não executam todos os passos em conformidade com a proposta da técnica. nosso objetivo neste trabalho é reproduzir parte desse estudo através de um novo questionário, utilizando alguns dos acidentes levantados em [ ] acrescidos de perguntas discursivas que investigam as circunstâncias e consequências de sua existência. como resultado, percebemos que a frequência de alguns acidentes foi similar às apresentadas em [ ]. além disso, também notamos que os desenvolvedores percebem as consequências de não executar algumas das etapas de tdd e que eles próprios possuem consciência que a prática deve ser aliada a outras técnicas de design para que o tempo investido tenha retorno compatível e a execução da técnica não seja onerosa."
276,2022,Reconhecimento de Libras em frames estáticos de vídeos utilizando CNN e técnicas de pré-processamento de imagens.,"CLAUDINO, Matheus Macêdo.","GOMES, Herman Martins.","Embora a língua de sinais brasileira (Libras) tenha sido
reconhecida como uma língua oficial do Brasil em 2002 [1],
medidas legais que regularizem e exijam a oferta de ensino de
Libras nas escolas em algum grau, apenas foram revertidas em um
projeto de lei em 2019 [2]. Resultando numa falta de contato de
pessoas sem problemas auditivos com Libras, e combinado à
constatação da World Federation of the Deaf (WFD) de que cerca
de 80% dos surdos do mundo possuem problemas de
compreensão nas línguas escritas de seus respectivos países [3],
gera um isolamento social daqueles que dependem do uso de
Libras para se comunicar. Neste contexto, existe o campo de
reconhecimento de linguagens de sinais (RLS), que se propõe a
criar interfaces tecnológicas que possam atuar no problema
descrito. Este trabalho utiliza de quadros de vídeos estáticos
extraídos do dataset MINDS-Libras [17] para analisar o impacto
do uso de métodos de pré-processamento de imagens no
treinamento de uma Rede Neural Convolucional (CNN), com o
intuito de se obter um modelo capaz de classificar 20 sinais
diversos de Libras de forma eficiente. Ao final, o método proposto
alcançou acurácia média de 91.08% no conjunto de dados
utilizado.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29270,"embora a língua de sinais brasileira (libras) tenha sido reconhecida como uma língua oficial do brasil em [ ], medidas legais que regularizem e exijam a oferta de ensino de libras nas escolas em algum grau, apenas foram revertidas em um projeto de lei em [ ]. resultando numa falta de contato de pessoas sem problemas auditivos com libras, e combinado à constatação da world federation of the deaf (wfd) de que cerca de % dos surdos do mundo possuem problemas de compreensão nas línguas escritas de seus respectivos países [ ], gera um isolamento social daqueles que dependem do uso de libras para se comunicar. neste contexto, existe o campo de reconhecimento de linguagens de sinais (rls), que se propõe a criar interfaces tecnológicas que possam atuar no problema descrito. este trabalho utiliza de quadros de vídeos estáticos extraídos do dataset minds-libras [ ] para analisar o impacto do uso de métodos de pré-processamento de imagens no treinamento de uma rede neural convolucional (cnn), com o intuito de se obter um modelo capaz de classificar sinais diversos de libras de forma eficiente. ao final, o método proposto alcançou acurácia média de . % no conjunto de dados utilizado."
277,2022,Express-image-server: uma biblioteca para construção de servidor de imagens com Node.js.,"BARBOSA, Marcus Vinícius de Farias.","MONTEIRO, João Arthur Brunet.","Aplicações web que lidam com um grande volume de imagens precisam de estratégias para garantir
uma boa performance. Uma delas é requisitar as imagens ao servidor especificando os atributos
esperados. Existem serviços de terceiros que implementam essa estratégia e oferecem uma API para
comunicação com um servidor com capacidades de manipulação de imagens e CDN. No entanto, tais
serviços não são completamente gratuitos e não permitem que o desenvolvedor construa um
servidor próprio sem um grande esforço para implementar todos os componentes necessários. Neste
trabalho é apresentada a express-image-server, uma biblioteca Node.js open source cujo objetivo é
auxiliar no processo de construção desse tipo de servidor. A express-image-server oferece recursos
para processamento dinâmico de imagens e comunicação com bases de dados para busca e
armazenamento, abstraindo toda a lógica necessária para verificação, transformação e geração de
imagens variantes. Assim, a express-image-server se apresenta como uma solução alternativa para os
desenvolvedores que desejam construir seus próprios sistemas para serviço e processamento de
imagens com Node.js.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29269,"aplicações web que lidam com um grande volume de imagens precisam de estratégias para garantir uma boa performance. uma delas é requisitar as imagens ao servidor especificando os atributos esperados. existem serviços de terceiros que implementam essa estratégia e oferecem uma api para comunicação com um servidor com capacidades de manipulação de imagens e cdn. no entanto, tais serviços não são completamente gratuitos e não permitem que o desenvolvedor construa um servidor próprio sem um grande esforço para implementar todos os componentes necessários. neste trabalho é apresentada a express-image-server, uma biblioteca node.js open source cujo objetivo é auxiliar no processo de construção desse tipo de servidor. a express-image-server oferece recursos para processamento dinâmico de imagens e comunicação com bases de dados para busca e armazenamento, abstraindo toda a lógica necessária para verificação, transformação e geração de imagens variantes. assim, a express-image-server se apresenta como uma solução alternativa para os desenvolvedores que desejam construir seus próprios sistemas para serviço e processamento de imagens com node.js."
278,2022,Contrato inteligente de três pontas: pagamento seguro.,"MEDEIROS FILHO, Marcos Barros de.","MOURA, José Antão Beltrão.","Contratos inteligentes são programas executados de forma
descentralizada em uma rede de computadores que tem o poder de
descrever um fluxo de eventos e consequẽncias para cada ação.
Um dos desafios ainda existentes é como modelar eventos do
mundo real que não podem ser obtidos por meios digitais ou
oracles descentralizados. O presente trabalho desenvolve uma
aplicação modelo, utilizando um contrato inteligente na rede
Ethereum, com caso de uso real, para estudar a modelagem de
uma interface que permite que informações não digitalizadas
possam ser inseridas e validadas por agentes externos à
blockchain, além de explorar as técnicas de desenvolvimento de
contratos inteligentes e suas limitações.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29268,"contratos inteligentes são programas executados de forma descentralizada em uma rede de computadores que tem o poder de descrever um fluxo de eventos e consequẽncias para cada ação. um dos desafios ainda existentes é como modelar eventos do mundo real que não podem ser obtidos por meios digitais ou oracles descentralizados. o presente trabalho desenvolve uma aplicação modelo, utilizando um contrato inteligente na rede ethereum, com caso de uso real, para estudar a modelagem de uma interface que permite que informações não digitalizadas possam ser inseridas e validadas por agentes externos à blockchain, além de explorar as técnicas de desenvolvimento de contratos inteligentes e suas limitações."
279,2022,Um sistema para gerenciamento de empresas juniores.,"OLIVEIRA, Lucas Anthony Ferreira de.","MOURA, José Antão Beltrão.","Empresas juniores são associações civis sem fins lucrativos, que são formadas e geridas por estudantes de um ou
mais cursos superiores, ocasionando assim, uma grande rotatividade de membros. Por esse motivo, diversas
vezes o gerenciamento das pessoas, projetos e relatórios e a passagem de tais dados para as diretorias posteriores
apresentam dificuldades, pois eles se encontram descentralizados em diversas planilhas e documentos. Desse
modo, este trabalho tem como objetivos centralizar as informações através de um sistema web, trazendo mais
facilidade e praticidade no gerenciamento da empresa, bem como apresentar as estratégias utilizadas e decisões
que foram tomadas, tais como elicitação de requisitos, escolhas de tecnologias e plano de testes.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29267,"empresas juniores são associações civis sem fins lucrativos, que são formadas e geridas por estudantes de um ou mais cursos superiores, ocasionando assim, uma grande rotatividade de membros. por esse motivo, diversas vezes o gerenciamento das pessoas, projetos e relatórios e a passagem de tais dados para as diretorias posteriores apresentam dificuldades, pois eles se encontram descentralizados em diversas planilhas e documentos. desse modo, este trabalho tem como objetivos centralizar as informações através de um sistema web, trazendo mais facilidade e praticidade no gerenciamento da empresa, bem como apresentar as estratégias utilizadas e decisões que foram tomadas, tais como elicitação de requisitos, escolhas de tecnologias e plano de testes."
280,2022,A case study of proactive auto-scaling for an ecommerce workload.,"ALMEIDA, Marcella Medeiros Siqueira Coutinho de.","SILVA, Thiago Emmanuel Pereira da Cunha.",,http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29266,
281,2022,Deu Trader.,"AIRES, Lucas Gomes.","GOMES, Herman Martins.","O mercado de criptomoedas ganhou muita
visibilidade nos últimos anos. Segundo a Forbes,
o Brasil está entre os 5 países com maior número
de investidores no mundo, chegando a 10 milhões
de investidores1 em 2022. Apesar do grande
número de investidores, o mercado de
criptomoedas representa um alto grau de risco.
Este trabalho propõe um método preditivo para
mitigação de perdas no mercado de criptomoedas
utilizando técnicas de aprendizado de máquina.
Para tanto, foi desenvolvida uma ferramenta
baseada em indicadores matemáticos e gráficos
para apoiar as decisões de compra e venda do
ativo digital. A moeda Gala/USDT foi escolhida
para a realização dos experimentos, utilizou-se a
linguagem Python [9], como apoio para criação e
manipulação do Data Frame e no final obtivemos
uma precisão em torno de 90% no conjunto de
testes que representou 30% do Data Frame.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29265,"o mercado de criptomoedas ganhou muita visibilidade nos últimos anos. segundo a forbes, o brasil está entre os países com maior número de investidores no mundo, chegando a milhões de investidores1 em . apesar do grande número de investidores, o mercado de criptomoedas representa um alto grau de risco. este trabalho propõe um método preditivo para mitigação de perdas no mercado de criptomoedas utilizando técnicas de aprendizado de máquina. para tanto, foi desenvolvida uma ferramenta baseada em indicadores matemáticos e gráficos para apoiar as decisões de compra e venda do ativo digital. a moeda gala/usdt foi escolhida para a realização dos experimentos, utilizou-se a linguagem python [ ], como apoio para criação e manipulação do data frame e no final obtivemos uma precisão em torno de % no conjunto de testes que representou % do data frame."
282,2022,EasyCondomínio: aplicação web para gerenciamento de condomínios residenciais.,"CAVALCANTI, Lucas Jarrier de Aquino.","MOURA, José Antão Beltrão.","EasyCondomínio é uma aplicação Web que
proporciona a simplificação da gestão de
condomínios e suas áreas comuns, bem como
eventos e informativos. Este trabalho visa
desenvolver uma aplicação Web que solucione
problemas de organizações condominiais no geral,
como reserva de horários das áreas comuns, poder
de permissibilidade ao síndico e criação de avisos
e reclamações pelos moradores em um ambiente
intuitivo e simplificado. A aplicação web traz
consigo um baixo custo de implantação e
manutenção do sistema, já que não requer grandes
movimentações monetárias para pôr o sistema em
produção. No processo de mapeamento de
sistemas concorrentes e suas falhas, foram
realizadas conferências com o síndico do
Residencial Paraíso do Mirante (Campina
Grande/PB), usuário do BRCondomínio, e com
morador do Residencial Artefato Residence (João
Pessoa/PB), usuário do Nextin, e foi constatado
que o primeiro sistema requer um alto custo
mensal para funcionamento e manutenção deste,
bem como valores diferentes para utilização do site
ou do aplicativo. Já para o segundo, apresentou um
problema em relação à reserva de espaços, bem
como na visualização do status da área comum,
que não funcionava de maneira simples e intuitiva.
Nesse cenário, o conceito EasyCondomínio foi
desenvolvido para além de entregar uma solução
mais enxuta (com funcionalidades a depender da
necessidade do cliente), atendendo até a
condomínios menores, gerando acessibilidade para
todos. Buscando entregar um sistema de alta
qualidade com um preço acessível, que não pese
no orçamento mensal do residencial, além de oferecer um sistema moderno permitindo
customizações exclusivas para cada cliente e
trazendo o custo benefício pautado na
possibilidade de gerir um condomínio de forma
eficiente e inteligente, sem grandes custos e com
um sistema que conta com uma interface limpa e
intuitiva para que não exista necessidade de
treinamento prévio.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29263,"easycondomínio é uma aplicação web que proporciona a simplificação da gestão de condomínios e suas áreas comuns, bem como eventos e informativos. este trabalho visa desenvolver uma aplicação web que solucione problemas de organizações condominiais no geral, como reserva de horários das áreas comuns, poder de permissibilidade ao síndico e criação de avisos e reclamações pelos moradores em um ambiente intuitivo e simplificado. a aplicação web traz consigo um baixo custo de implantação e manutenção do sistema, já que não requer grandes movimentações monetárias para pôr o sistema em produção. no processo de mapeamento de sistemas concorrentes e suas falhas, foram realizadas conferências com o síndico do residencial paraíso do mirante (campina grande/pb), usuário do brcondomínio, e com morador do residencial artefato residence (joão pessoa/pb), usuário do nextin, e foi constatado que o primeiro sistema requer um alto custo mensal para funcionamento e manutenção deste, bem como valores diferentes para utilização do site ou do aplicativo. já para o segundo, apresentou um problema em relação à reserva de espaços, bem como na visualização do status da área comum, que não funcionava de maneira simples e intuitiva. nesse cenário, o conceito easycondomínio foi desenvolvido para além de entregar uma solução mais enxuta (com funcionalidades a depender da necessidade do cliente), atendendo até a condomínios menores, gerando acessibilidade para todos. buscando entregar um sistema de alta qualidade com um preço acessível, que não pese no orçamento mensal do residencial, além de oferecer um sistema moderno permitindo customizações exclusivas para cada cliente e trazendo o custo benefício pautado na possibilidade de gerir um condomínio de forma eficiente e inteligente, sem grandes custos e com um sistema que conta com uma interface limpa e intuitiva para que não exista necessidade de treinamento prévio."
283,2022,Uma aplicação de análise de sentimentos para medir popularidade dos candidatos à presidência.,"MOTA, Leonardo Rodrigues da.","GOMES, Herman Martins.","Este trabalho consistiu na criação de uma inteligência artificial para classificação de Tweets sobre os
principais candidatos a presidência do Brasil no ano de 2022. O resultado foi uma inteligência
artificial que para o conjunto de dados de teste atingiu um percentual de 93% de precisão, usando
como modelo arvore de decisão. Também foi criada uma aplicação Web feita com as tecnologias
Javascript, React, Python e Firebase, usada para exibir os resultados obtidos.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29262,"este trabalho consistiu na criação de uma inteligência artificial para classificação de tweets sobre os principais candidatos a presidência do brasil no ano de . o resultado foi uma inteligência artificial que para o conjunto de dados de teste atingiu um percentual de % de precisão, usando como modelo arvore de decisão. também foi criada uma aplicação web feita com as tecnologias javascript, react, python e firebase, usada para exibir os resultados obtidos."
284,2022,"Chatbot para auxílio ao ensino da disciplina Laboratório de Organização e Arquitetura de Computadores, do Curso de Ciência da Computação, da Universidade Federal de Campina Grande.","SILVA, Jonathan Allisson de Lima.","ARAÚJO, Joseana Macêdo Fechine Régis de.","É comum, entre alunos que cursam determinada disciplina de um curso de graduação em ciência da
computação, a exemplo de Laboratório de Organização e Arquitetura de Computadores (LOAC),
apresentar dificuldades para entendimento de determinados conteúdos, apresentar dúvidas sobre
temas que já foram elucidados, não se sentir à vontade para fazer questionamentos diretamente ao
professor ou apresentar dúvidas em horários inadequados ao contato, dentre outros. Assim, com o
intuito de fortalecer o aprendizado dos alunos, visando mitigar as dificuldades citadas com o auxílio
de uma ferramenta computacional, no trabalho ora descrito é desenvolvido um chatbot para LOAC. O
chatbot teve como objetivo principal apresentar informações, de forma clara e ágil aos estudantes,
sobre um tópico bastante relevante para a disciplina, a saber: linguagem de descrição de hardware.
Com o chatbot, o aluno poderá sanar suas principais dúvidas, em qualquer horário, de forma fácil e
ágil. O chatbot foi hospedado em uma plataforma na nuvem gratuita e sua avaliação se deu por meio
de testes de conhecimento, bem como a partir do feedback dos alunos, utilizando uma ferramenta
para avaliação subjetiva (questionário), que proporcionou o refinamento da ferramenta desenvolvida.
O chatbot consiste, portanto, em uma ferramenta complementar ao ensino da disciplina LOAC.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29261,"é comum, entre alunos que cursam determinada disciplina de um curso de graduação em ciência da computação, a exemplo de laboratório de organização e arquitetura de computadores (loac), apresentar dificuldades para entendimento de determinados conteúdos, apresentar dúvidas sobre temas que já foram elucidados, não se sentir à vontade para fazer questionamentos diretamente ao professor ou apresentar dúvidas em horários inadequados ao contato, dentre outros. assim, com o intuito de fortalecer o aprendizado dos alunos, visando mitigar as dificuldades citadas com o auxílio de uma ferramenta computacional, no trabalho ora descrito é desenvolvido um chatbot para loac. o chatbot teve como objetivo principal apresentar informações, de forma clara e ágil aos estudantes, sobre um tópico bastante relevante para a disciplina, a saber: linguagem de descrição de hardware. com o chatbot, o aluno poderá sanar suas principais dúvidas, em qualquer horário, de forma fácil e ágil. o chatbot foi hospedado em uma plataforma na nuvem gratuita e sua avaliação se deu por meio de testes de conhecimento, bem como a partir do feedback dos alunos, utilizando uma ferramenta para avaliação subjetiva (questionário), que proporcionou o refinamento da ferramenta desenvolvida. o chatbot consiste, portanto, em uma ferramenta complementar ao ensino da disciplina loac."
285,2022,Análise de viabilidade de uma infraestrutura baseada em blockchain para o controle acadêmico.,"SILVA JÚNIOR, João Marcelo Fernandes da.","GORGÔNIO, Kyller Costa.","Documentos acadêmicos são utilizados para registrar todos os dados relativos à vida acadêmica de
um aluno, tais como habilidades adquiridas, disciplinas cursadas, cursos realizados, entre outros.
Esses documentos são utilizados para comprovar os seus dados como aluno e também o vínculo com
uma instituição de ensino. Entretanto, ao decidir solicitar esse documentos, a confecção e
compartilhamento com outras instituições torna-se um problema devido ao tempo gasto e a
burocracia envolvida nesses processos, principalmente no que diz respeito à checagem de
autenticidade dos documentos. A blockchain é uma tecnologia que permite o registro de dados
descentralizados que podem ser compartilhados com segurança, ou seja, é uma base de dados
distribuída e com segurança garantida. Esse trabalho pretende analisar soluções baseadas em
blockchain para permitir o registro, verificação e autenticidade de dados acadêmicos de um aluno de
graduação e propor uma infraestrutura para uso sistema de controle acadêmico da Universidade
Federal de Campina Grande.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29260,"documentos acadêmicos são utilizados para registrar todos os dados relativos à vida acadêmica de um aluno, tais como habilidades adquiridas, disciplinas cursadas, cursos realizados, entre outros. esses documentos são utilizados para comprovar os seus dados como aluno e também o vínculo com uma instituição de ensino. entretanto, ao decidir solicitar esse documentos, a confecção e compartilhamento com outras instituições torna-se um problema devido ao tempo gasto e a burocracia envolvida nesses processos, principalmente no que diz respeito à checagem de autenticidade dos documentos. a blockchain é uma tecnologia que permite o registro de dados descentralizados que podem ser compartilhados com segurança, ou seja, é uma base de dados distribuída e com segurança garantida. esse trabalho pretende analisar soluções baseadas em blockchain para permitir o registro, verificação e autenticidade de dados acadêmicos de um aluno de graduação e propor uma infraestrutura para uso sistema de controle acadêmico da universidade federal de campina grande."
286,2022,Compressão de arestas de grafos utilizando árvore de segmentos.,"MEDEIROS, João Marcos Lima.","GHEYI, Rohit.","No contexto de teoria dos grafos, é comum encontrarmos otimizações
centradas no łinterior do algoritmož, de maneira a tentar
reduzir a complexidade assintótica do mesmo. Porém, em determinados
casos, não é possível reduzir a complexidade do algoritmo,
mas isso não deine o mínimo de operações a ser feitas para resolver
determinado problema. Isso acontece pois podem ser feitas manipulações
no próprio grafo recebido como entrada, possibilitando
que um algoritmo especíico possa executar de maneira mais eiciente.
Nesse contexto, apresentamos uma otimização que permite
criar arestas de um vértice para todos os vértices de determinado
intervalo num grafo ou até criar arestas entre todos os vértices de
dois intervalos, com um custo equivalente ao de adicionar apenas
O(log(u) + log(v) arestas, sendo u e v o tamanho do primeiro e
segundo intervalos respectivamente. Isso pode ser feito através
da adição de duas árvores de segmentos no grafo, preservando as
distâncias e a conectividade do mesmo. Após isso, veriicamos o
nível de diminuição de arestas obtido através desse algoritmo em
grafos densos, onde podem existir várias arestas entre intervalos
de vértices, ainda que de maneira aleatória. Com essa otimização,
conseguimos diminuir a quantidade de arestas em cerca de 50% em
grafos com pelo menos 80% das arestas possíveis presentes.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29259,"no contexto de teoria dos grafos, é comum encontrarmos otimizações centradas no łinterior do algoritmož, de maneira a tentar reduzir a complexidade assintótica do mesmo. porém, em determinados casos, não é possível reduzir a complexidade do algoritmo, mas isso não deine o mínimo de operações a ser feitas para resolver determinado problema. isso acontece pois podem ser feitas manipulações no próprio grafo recebido como entrada, possibilitando que um algoritmo especíico possa executar de maneira mais eiciente. nesse contexto, apresentamos uma otimização que permite criar arestas de um vértice para todos os vértices de determinado intervalo num grafo ou até criar arestas entre todos os vértices de dois intervalos, com um custo equivalente ao de adicionar apenas o(log(u) + log(v) arestas, sendo u e v o tamanho do primeiro e segundo intervalos respectivamente. isso pode ser feito através da adição de duas árvores de segmentos no grafo, preservando as distâncias e a conectividade do mesmo. após isso, veriicamos o nível de diminuição de arestas obtido através desse algoritmo em grafos densos, onde podem existir várias arestas entre intervalos de vértices, ainda que de maneira aleatória. com essa otimização, conseguimos diminuir a quantidade de arestas em cerca de % em grafos com pelo menos % das arestas possíveis presentes."
287,2022,Uma avaliação do modelo function as a service para execução de algoritmos de processamento de linguagem natural.,"OLIVEIRA, Iago Tito.","SILVA, Thiago Emmanuel Pereira da Cunha.","O projeto ePol, parceria da Polícia Federal com a Universidade Federal de Campina Grande, tem como objetivo
desenvolver tecnologias para execução de algoritmos de processamento de linguagem natural que manipulam
grandes quantidades de dados provenientes de processos de investigação policial. Um dos requisitos das
tecnologias é que os programadores dos algoritmos não se preocupem com a implantação de seus programas no
ambiente de execução. Ainda, é importante que a execução dos algoritmos seja eficiente. Nesse contexto, o
modelo arquitetural de Function as a Service (FaaS) pode ser uma opção viável por permitir que
desenvolvedores criem algoritmos quaisquer sem se preocupar com a infraestrutura de execução. Considerando
este problema e os requisitos para sua solução, este trabalho analisa uma abordagem com a ferramenta
OpenFaas e compara com a abordagem criada durante o projeto, elencando vantagens e desvantagens e
avaliando se existe uma melhor solução para o problema enfrentado. A comparação foi feita através da análise
de métricas coletadas de protótipos do sistema, construídos utilizando as abordagens selecionadas. Ao final do
estudo, foi constatado que utilizar o OpenFaas para gerenciar os processos oferece desempenho equivalente em
relação ao sistema desenvolvido até então no projeto, além de trazer funcionalidades adicionais.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29258,"o projeto epol, parceria da polícia federal com a universidade federal de campina grande, tem como objetivo desenvolver tecnologias para execução de algoritmos de processamento de linguagem natural que manipulam grandes quantidades de dados provenientes de processos de investigação policial. um dos requisitos das tecnologias é que os programadores dos algoritmos não se preocupem com a implantação de seus programas no ambiente de execução. ainda, é importante que a execução dos algoritmos seja eficiente. nesse contexto, o modelo arquitetural de function as a service (faas) pode ser uma opção viável por permitir que desenvolvedores criem algoritmos quaisquer sem se preocupar com a infraestrutura de execução. considerando este problema e os requisitos para sua solução, este trabalho analisa uma abordagem com a ferramenta openfaas e compara com a abordagem criada durante o projeto, elencando vantagens e desvantagens e avaliando se existe uma melhor solução para o problema enfrentado. a comparação foi feita através da análise de métricas coletadas de protótipos do sistema, construídos utilizando as abordagens selecionadas. ao final do estudo, foi constatado que utilizar o openfaas para gerenciar os processos oferece desempenho equivalente em relação ao sistema desenvolvido até então no projeto, além de trazer funcionalidades adicionais."
288,2022,AcademicBlock: aplicação descentralizada de históricos acadêmicos hospedados em uma blockchain.,"ARRIEL, Henrique Castro.","GORGÔNIO, Kyller Costa.","Este documento apresenta o relato de desenvolvimento de uma aplicação
descentralizada (dApp) utilizando o conceito de Web3, que é
a Web baseada na tecnologia blockchain, incorporando principalmente
a descentralização. Com isso, é proposto o AcademicBlock,
uma aplicação descentralizada com objetivo de permitir a visualização
e criação de históricos acadêmicos dos alunos como NFTs
(non-fungible token) hospedados na blockchain, introduzindo digitalmente
a especiicidade, individualidade e propriedade aos históricos
dos alunos.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29257,"este documento apresenta o relato de desenvolvimento de uma aplicação descentralizada (dapp) utilizando o conceito de web3, que é a web baseada na tecnologia blockchain, incorporando principalmente a descentralização. com isso, é proposto o academicblock, uma aplicação descentralizada com objetivo de permitir a visualização e criação de históricos acadêmicos dos alunos como nfts (non-fungible token) hospedados na blockchain, introduzindo digitalmente a especiicidade, individualidade e propriedade aos históricos dos alunos."
289,2022,Aprendizagem de máquina aplicada ao controle de rebanho bovinos.,"ANSELMO, Hércules Rodrigues.","ARAÚJO, Joseana Macêdo Fechine Régis de.","A pecuária de corte de bovinos é uma das atividades mais importantes para o setor pecuário no
Brasil. Neste contexto, proprietários de grandes confinamentos possuem dificuldade em manter o
controle sobre a quantidade de animais que possuem e sobre sua segurança antifurto. A proposta
deste trabalho consiste em apresentar uma técnica capaz de identificar “faces” de animais da espécie
bovina (“cabeças de gado”), em especial, para as raças Nelores, a partir de imagens desses animais,
seguida da contagem dessas faces, informando ao proprietário a quantidade de animais do seu
rebanho presente na imagem. A técnica foi desenvolvida utilizando conceitos de aprendizagem de
máquina, com aprendizagem supervisionada, baseada em classificadores de cascatas de Haar,
contando com datasets públicos disponibilizados e obtenção de novos dados amostrais. O modelo
possui precisão total acima de 95% para detecção de faces em uma imagem.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29256,"a pecuária de corte de bovinos é uma das atividades mais importantes para o setor pecuário no brasil. neste contexto, proprietários de grandes confinamentos possuem dificuldade em manter o controle sobre a quantidade de animais que possuem e sobre sua segurança antifurto. a proposta deste trabalho consiste em apresentar uma técnica capaz de identificar “faces” de animais da espécie bovina (“cabeças de gado”), em especial, para as raças nelores, a partir de imagens desses animais, seguida da contagem dessas faces, informando ao proprietário a quantidade de animais do seu rebanho presente na imagem. a técnica foi desenvolvida utilizando conceitos de aprendizagem de máquina, com aprendizagem supervisionada, baseada em classificadores de cascatas de haar, contando com datasets públicos disponibilizados e obtenção de novos dados amostrais. o modelo possui precisão total acima de % para detecção de faces em uma imagem."
290,2022,Sei Services: uma aplicação para o gerenciamento financeiro e visualização de impostos sobre consumo.,"CIPRIANO, Guilherme França Batista.","GARCIA, Franceline Procópio.","O Sei Services vem com o objetivo de ser uma aplicação
mobile, Android e iOS, de gerenciamento financeiro, com
foco especial na quantidade de imposto pago sobre produtos, e
na automaticidade.
Tendo como principal público alvo pessoas economicamente
ativas, que recebem notas fiscais de compras em
supermercados ou internet.
Com a possibilidade de cadastrar notas fiscais,
automaticamente, através da leitura de códigos QR e de
barras, ou manualmente, através da digitação do código da
nota fiscal.
Após as notas serem lidas e processadas, estas podem ser
visualizadas, incluindo detalhes dessas e de seus produtos,
como: preço, imposto pago, códigos de identificação, origem
e categoria (feita automaticamente). Podendo ainda ser
visualizadas todas as notas fiscais de um determinado mês.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29255,"o sei services vem com o objetivo de ser uma aplicação mobile, android e ios, de gerenciamento financeiro, com foco especial na quantidade de imposto pago sobre produtos, e na automaticidade. tendo como principal público alvo pessoas economicamente ativas, que recebem notas fiscais de compras em supermercados ou internet. com a possibilidade de cadastrar notas fiscais, automaticamente, através da leitura de códigos qr e de barras, ou manualmente, através da digitação do código da nota fiscal. após as notas serem lidas e processadas, estas podem ser visualizadas, incluindo detalhes dessas e de seus produtos, como: preço, imposto pago, códigos de identificação, origem e categoria (feita automaticamente). podendo ainda ser visualizadas todas as notas fiscais de um determinado mês."
291,2022,"Uma análise do uso do serviço prestado dos pequenos provedores de internet no Bairro das Malvinas, em Campina Grande, no contexto da pandemia da COVID-19.","SILVA, Gilmar Gonzaga da.","GARCIA, Francilene Procópio.","A pandemia, causada pela COVID-19, alterou o modo de trabalhar, estudar e realizar atividades
comuns ao dia a dia. Neste cenário, o uso da Internet tornou-se uma ferramenta indispensável para
diminuir o contato presencial entre as pessoas. Entretanto o acesso pode ser dificultado devido aos
custos para instalação e manutenção em regiões afastadas dos grandes centros. Os Pequenos
Provedores de Internet atendem clientes dos bairros mais remotos até a zona rural com preços mais
acessíveis. Neste trabalho, realizou-se uma pesquisa exploratória que avaliou a atuação dos Pequenos
Provedores no bairro das Malvinas em Campina Grande. Coletou-se dados de usuários e provedores
locais, evidenciando que os usuários utilizam os serviços dos provedores locais devido à qualidade e
preço acessível. Por outro lado, os provedores compreendem que atendem majoritariamente pessoas
de baixa renda e buscam manter os preços acessíveis.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29254,"a pandemia, causada pela covid- , alterou o modo de trabalhar, estudar e realizar atividades comuns ao dia a dia. neste cenário, o uso da internet tornou-se uma ferramenta indispensável para diminuir o contato presencial entre as pessoas. entretanto o acesso pode ser dificultado devido aos custos para instalação e manutenção em regiões afastadas dos grandes centros. os pequenos provedores de internet atendem clientes dos bairros mais remotos até a zona rural com preços mais acessíveis. neste trabalho, realizou-se uma pesquisa exploratória que avaliou a atuação dos pequenos provedores no bairro das malvinas em campina grande. coletou-se dados de usuários e provedores locais, evidenciando que os usuários utilizam os serviços dos provedores locais devido à qualidade e preço acessível. por outro lado, os provedores compreendem que atendem majoritariamente pessoas de baixa renda e buscam manter os preços acessíveis."
292,2022,“UFCG Pro”: evolução do sistema de controle acadêmico da UFCG.,"SANTOS, Hemillainy Suellen Sousa.","MONTEIRO, João Arthur Brunet.","A UFCG Pro é uma ferramenta open source
que foi criada como uma extensão para os
navegadores Chrome e Firefox com o intuito
de fornecer funcionalidades extras para o
sistema de Controle Acadêmico da UFCG. O
objetivo principal deste trabalho foi evoluir a
UFCG Pro para que atendesse ainda mais as
expectativas da comunidade acadêmica, em
particular, dentro do contexto do curso de
Ciência da Computação. Este documento
descreve não somente o levantamento das
necessidades/requisitos com a comunidade
acadêmica, como também a implementação e
validação da ferramenta.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29253,"a ufcg pro é uma ferramenta open source que foi criada como uma extensão para os navegadores chrome e firefox com o intuito de fornecer funcionalidades extras para o sistema de controle acadêmico da ufcg. o objetivo principal deste trabalho foi evoluir a ufcg pro para que atendesse ainda mais as expectativas da comunidade acadêmica, em particular, dentro do contexto do curso de ciência da computação. este documento descreve não somente o levantamento das necessidades/requisitos com a comunidade acadêmica, como também a implementação e validação da ferramenta."
293,2022,AppCER: aplicação web para dar suporte aos profissionais do CER Campina Grande.,"MEDEIROS, Danilo César Ribeiro Garcia de.","ANDRADE, Wilkerson de Lucena.","A cidade de Campina Grande abriga uma unidade do CER-IV, um centro especializado em tratamentos de reabilitação, é responsável por atender diversos municípios, incluindo Campina Grande. Isto acarreta em uma enorme quantidade de pacientes visitando o centro por ano, gerando uma enorme carga de trabalho para todos os profissionais alocados no centro, como fisioterapeutas, enfermeiras, fonoaudiólogos, entre outros. Após algumas visitas e entrevistas realizadas com profissionais do centro, foi proposta a criação de uma plataforma web, que funcionaria como um apoio para os profissionais cadastrarem diversas informações relacionadas ao tratamento dos pacientes, além de prover formas de enviar dúvidas ao centro por meio da plataforma. Entre as informações, algumas podem ser citadas como: descrição de atividades que são realizadas com os pacientes e podem ser feitas em casa; utensílios que auxiliam a realizar o tratamento como brinquedos e móveis adaptados, por exemplo. A escolha de implementar a plataforma para web é pelo fácil acesso atualmente que as pessoas têm aos navegadores comuns em seus celulares, facilitando o acesso de todos à informações para o tratamento adequado dos pacientes. Ao final, o aplicativo foi validado por meio de uma entrevista a três fisioterapeutas do CER para que fosse inicializada a utilização do aplicativo no centro de Campina Grande.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29252,"a cidade de campina grande abriga uma unidade do cer-iv, um centro especializado em tratamentos de reabilitação, é responsável por atender diversos municípios, incluindo campina grande. isto acarreta em uma enorme quantidade de pacientes visitando o centro por ano, gerando uma enorme carga de trabalho para todos os profissionais alocados no centro, como fisioterapeutas, enfermeiras, fonoaudiólogos, entre outros. após algumas visitas e entrevistas realizadas com profissionais do centro, foi proposta a criação de uma plataforma web, que funcionaria como um apoio para os profissionais cadastrarem diversas informações relacionadas ao tratamento dos pacientes, além de prover formas de enviar dúvidas ao centro por meio da plataforma. entre as informações, algumas podem ser citadas como: descrição de atividades que são realizadas com os pacientes e podem ser feitas em casa; utensílios que auxiliam a realizar o tratamento como brinquedos e móveis adaptados, por exemplo. a escolha de implementar a plataforma para web é pelo fácil acesso atualmente que as pessoas têm aos navegadores comuns em seus celulares, facilitando o acesso de todos à informações para o tratamento adequado dos pacientes. ao final, o aplicativo foi validado por meio de uma entrevista a três fisioterapeutas do cer para que fosse inicializada a utilização do aplicativo no centro de campina grande."
294,2022,A modernização do jogo: análise e caracterização de jogadores das 5 principais ligas de futebol europeias.,"FREITAS, Danilo de Menezes.","MORAIS, Fábio Jorge Almeida.","O futebol, assim como diversas outras atividades do nosso cotidiano, recebeu e vem recebendo grandes
mudanças com o advento da tecnologia. A grande evolução desse esporte no século XXI foi guiada, em
certa parte, pelo avanço tecnológico implementado. A análise estatística é um grande expoente desses
avanços, a maioria dos grandes clubes de futebol de hoje possuem um setor que alia essa análise a parte
tática do jogo, essas atividades norteiam dirigentes e treinadores em como fazer as contratações corretas
para o time e quais jogadores estão com bom desempenho em campo. Diante do exposto, utilizando
dados extraídos de uma base chamada StatsBomb, disponível no site fbref.com, este trabalho busca
fazer um estudo do impacto dos jogadores a partir da análise e visualização de dados. A partir da
extração desses dados, o objetivo é observar, a partir do cálculo de uma métrica, os fundamentos e
estilos de jogo presentes e observados hoje no esporte moderno, como construção de jogo, criação
ofensiva, finalização, capacidade defensiva, etc. A partir dessa métrica, é possível ainda fazer uma análise,
levando em consideração a posição dos jogadores, o que mostra onde cada uma das características está
mais concentrada em campo. A partir disso, é possível observar, por exemplo, quantos defensores
possuem tal característica ofensiva ou atacantes que realizam ações defensivas. Essa análise pode ser
feita para várias posições e funções do futebol e ajuda a entender e demonstrar o impacto que cada um
dos jogadores tem dentro de campo.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29251,"o futebol, assim como diversas outras atividades do nosso cotidiano, recebeu e vem recebendo grandes mudanças com o advento da tecnologia. a grande evolução desse esporte no século xxi foi guiada, em certa parte, pelo avanço tecnológico implementado. a análise estatística é um grande expoente desses avanços, a maioria dos grandes clubes de futebol de hoje possuem um setor que alia essa análise a parte tática do jogo, essas atividades norteiam dirigentes e treinadores em como fazer as contratações corretas para o time e quais jogadores estão com bom desempenho em campo. diante do exposto, utilizando dados extraídos de uma base chamada statsbomb, disponível no site fbref.com, este trabalho busca fazer um estudo do impacto dos jogadores a partir da análise e visualização de dados. a partir da extração desses dados, o objetivo é observar, a partir do cálculo de uma métrica, os fundamentos e estilos de jogo presentes e observados hoje no esporte moderno, como construção de jogo, criação ofensiva, finalização, capacidade defensiva, etc. a partir dessa métrica, é possível ainda fazer uma análise, levando em consideração a posição dos jogadores, o que mostra onde cada uma das características está mais concentrada em campo. a partir disso, é possível observar, por exemplo, quantos defensores possuem tal característica ofensiva ou atacantes que realizam ações defensivas. essa análise pode ser feita para várias posições e funções do futebol e ajuda a entender e demonstrar o impacto que cada um dos jogadores tem dentro de campo."
295,2022,EcoCalc: sistema de gerenciamento de despesas residenciais e pessoais.,"LEITE, Daniel José Di Navaronne Gaudêncio.","MOURA, José Antão Beltrão.","Muitas pessoas acabam tendo dificuldade com despesas todos os meses e não conseguem
controlar e gerir com o que pode tá gastando, pois acaba não anotando ou se preocupando
com os consumos seus e dos seus dependentes. Com isso, esse trabalho tem como objetivo
desenvolver uma aplicação Android, com o intuito de fornecer uma plataforma na qual o
usuário possa gerir e ter controle das suas despesas pessoais e residenciais mensalmente.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29249,"muitas pessoas acabam tendo dificuldade com despesas todos os meses e não conseguem controlar e gerir com o que pode tá gastando, pois acaba não anotando ou se preocupando com os consumos seus e dos seus dependentes. com isso, esse trabalho tem como objetivo desenvolver uma aplicação android, com o intuito de fornecer uma plataforma na qual o usuário possa gerir e ter controle das suas despesas pessoais e residenciais mensalmente."
296,2022,Uso de processamento de linguagem natural e aprendizagem de máquina para a extração de informação em editais de licitações não-estruturados.,"ANDRADE, Ígor Silveira de.","BAPTISTA, Cláudio de Souza.","A licitação é o meio adotado pela administração pública para assegurar
igualdade de condições a todos que queiram realizar contratações
de produtos ou serviços com o poder público. Também é
papel do poder público, realizar a análise e auditoria dos documentos
derivados desse processo, de forma a garantir princípios legais
como isonomia, legalidade, impessoalidade, moralidade, publicidade,
e probidade administrativa. Grande parte dos documentos
relacionados aos processos licitatórios utilizam o formato Portable
Document Format (PDF). Tal formato, não estruturado, torna a análise
textual automatizada mais complexa. O presente trabalho, tem
como objetivo o desenvolvimento de um modelo de indução, baseado
em classiicação supervisionada, que seja capaz de identiicar
informações especíicas contidas em um edital de licitação, e assim
adicionar uma camada de automação ao processo de auditoria do
documento. Para isso, foram utilizadas técnicas de processamento
de linguagem natural, e foram analisados diferentes modelos de
aprendizagem de máquina, para a seleção do melhor modelo a ser
utilizado na tarefa de classiicação. A base de dados utilizada foi
extraída do Portal do Governo do Estado do Acre. Ao inal da implementação,
o modelo obteve bons resultados e mostrou-se capaz de
identiicar as informações de interesse presentes nos documentos
de maneira satisfatória.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29248,"a licitação é o meio adotado pela administração pública para assegurar igualdade de condições a todos que queiram realizar contratações de produtos ou serviços com o poder público. também é papel do poder público, realizar a análise e auditoria dos documentos derivados desse processo, de forma a garantir princípios legais como isonomia, legalidade, impessoalidade, moralidade, publicidade, e probidade administrativa. grande parte dos documentos relacionados aos processos licitatórios utilizam o formato portable document format (pdf). tal formato, não estruturado, torna a análise textual automatizada mais complexa. o presente trabalho, tem como objetivo o desenvolvimento de um modelo de indução, baseado em classiicação supervisionada, que seja capaz de identiicar informações especíicas contidas em um edital de licitação, e assim adicionar uma camada de automação ao processo de auditoria do documento. para isso, foram utilizadas técnicas de processamento de linguagem natural, e foram analisados diferentes modelos de aprendizagem de máquina, para a seleção do melhor modelo a ser utilizado na tarefa de classiicação. a base de dados utilizada foi extraída do portal do governo do estado do acre. ao inal da implementação, o modelo obteve bons resultados e mostrou-se capaz de identiicar as informações de interesse presentes nos documentos de maneira satisfatória."
297,2022,Investigando mudanças em relatórios de bugs do Bugzilla.,"CALIXTO, Felipe Emerson de Oliveira.","RAMALHO, Franklin de Souza.","O comportamento da ocorrência de mudanças, em sistemas de rastreamento de bugs, pode
identificar problemas relacionados à dificuldade do autor de um relatório de bug em preencher
informações corretamente e/ou a falta delas. Além disso, estudos com relatórios de bugs pouco
exploram a utilização de features de mudanças na construção de modelos/ferramentas. Este estudo
investiga as mudanças para identificar quais campos de um relatório mais se alteram, qual o perfil
dos bugs que mais são alterados e a existência de relações entre mudanças. Descobrimos que os
campos mais alterados são flagtypes.name e cc. Relatórios tendem a terem mais modificações
quando são relatórios de bugs válidos, com prioridade média/alta e severidade média/alta. E, existem
correlações de grau moderado a alto, entre as mudanças dos pares de campos: product/component,
priority/severity e platform/op_sys.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29247,"o comportamento da ocorrência de mudanças, em sistemas de rastreamento de bugs, pode identificar problemas relacionados à dificuldade do autor de um relatório de bug em preencher informações corretamente e/ou a falta delas. além disso, estudos com relatórios de bugs pouco exploram a utilização de features de mudanças na construção de modelos/ferramentas. este estudo investiga as mudanças para identificar quais campos de um relatório mais se alteram, qual o perfil dos bugs que mais são alterados e a existência de relações entre mudanças. descobrimos que os campos mais alterados são flagtypes.name e cc. relatórios tendem a terem mais modificações quando são relatórios de bugs válidos, com prioridade média/alta e severidade média/alta. e, existem correlações de grau moderado a alto, entre as mudanças dos pares de campos: product/component, priority/severity e platform/op_sys."
298,2022,Analisando estratégias de navegação em websites de ecommerce.,"SILVA, Jadson Luan Soares da.","REGO, Matheus Gaudêncio de.","O ecommerce é um modelo de negócio que possibilita a compra
e venda através da internet. Para a construção de um ecommerce
de sucesso, um aspecto importante é a navegabilidade. No entanto,
pouco se sabe sobre opções de componentes de navegação e práticas
comuns na hora de construir um bom sistema de navegação.
Realizamos uma pesquisa com os ecommerces mais acessados do
Brasil e obtivemos um catálogo com um conjunto de componentes
comumente utilizados, sendo eles: barra de busca, menu de
categorias, breadcrumb e iltros. Além disso também extraímos, a
partir de uma avaliação qualitativa, um grupo de características e
comportamentos sobre cada componente observado.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29246,"o ecommerce é um modelo de negócio que possibilita a compra e venda através da internet. para a construção de um ecommerce de sucesso, um aspecto importante é a navegabilidade. no entanto, pouco se sabe sobre opções de componentes de navegação e práticas comuns na hora de construir um bom sistema de navegação. realizamos uma pesquisa com os ecommerces mais acessados do brasil e obtivemos um catálogo com um conjunto de componentes comumente utilizados, sendo eles: barra de busca, menu de categorias, breadcrumb e iltros. além disso também extraímos, a partir de uma avaliação qualitativa, um grupo de características e comportamentos sobre cada componente observado."
299,2022,Investigando bugs reabertos: um estudo de caso no Bugzilla.,"ARAÚJO FILHO, Euclides Ramos de.","RAMALHO, Franklin de Souza.","Dentre as atividades típicas de um processo de software, podemos destacar as tarefas de testar,
analisar, reportar e corrigir bugs. A realização dessas tarefas é importante para identificar erros
comuns ou complexos durante todas as etapas do desenvolvimento, evitando retrabalho e entregando
um software com mais qualidade e confiabilidade [1]. Em um relatório de bug, geralmente, seu autor
oferece detalhes da anormalidade que vem ocorrendo. Tipicamente, um relatório de bug é aberto, o
bug é corrigido e o relatório é fechado. Contudo, por vezes, é verificado que a correção do bug não foi
eficaz, seja por falta de descrição mais objetiva no relatório, seja por dificuldade de entendimento por
parte do desenvolvedor. Assim, faz-se necessária a reabertura do bug, adicionando tempo no processo
de desenvolvimento, tornando o software mais custoso. Por isso, é importante investigar o que pode
ser feito para mitigar tais problemas. Neste trabalho, investigamos as características que levam um bug
a ser reaberto. Os resultados deste trabalho podem ajudar aos usuários finais e desenvolvedores a
melhor escrever relatórios de bugs, bem como aos desenvolvedores a melhor entendê-los e tratá-los. O
estudo utilizou um dataset extraído da ferramenta Bugzilla.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29245,"dentre as atividades típicas de um processo de software, podemos destacar as tarefas de testar, analisar, reportar e corrigir bugs. a realização dessas tarefas é importante para identificar erros comuns ou complexos durante todas as etapas do desenvolvimento, evitando retrabalho e entregando um software com mais qualidade e confiabilidade [ ]. em um relatório de bug, geralmente, seu autor oferece detalhes da anormalidade que vem ocorrendo. tipicamente, um relatório de bug é aberto, o bug é corrigido e o relatório é fechado. contudo, por vezes, é verificado que a correção do bug não foi eficaz, seja por falta de descrição mais objetiva no relatório, seja por dificuldade de entendimento por parte do desenvolvedor. assim, faz-se necessária a reabertura do bug, adicionando tempo no processo de desenvolvimento, tornando o software mais custoso. por isso, é importante investigar o que pode ser feito para mitigar tais problemas. neste trabalho, investigamos as características que levam um bug a ser reaberto. os resultados deste trabalho podem ajudar aos usuários finais e desenvolvedores a melhor escrever relatórios de bugs, bem como aos desenvolvedores a melhor entendê-los e tratá-los. o estudo utilizou um dataset extraído da ferramenta bugzilla."
300,2022,Crimes cibernéticos e segurança digital.,"ALMEIDA, Gabriel Guimarães de.","BARROS, Marcelo Alves de.","É fácil esquecer, em meio a crises mundiais, que a
revolução digital dos últimos anos trouxe consigo, além
de inovações e soluções tecnológicas, uma série de
problemas e desafios. Um desses problemas é
provavelmente o mais retratado nos últimos anos,
tratando-se de uma nova modalidade de atividades
ilícitas, os Crimes Cibernéticos. E esta nova prática de
organizações criminosas na Internet possui diversas
formas, dentre as quais se incluem as invasões a redes
privadas de organizações e empresas, roubos e
exposições de dados privados, discursos de ódio online, e
estelionato, mediante fraude praticada com o uso de
dispositivos eletrônicos. Acerca desses fatos, o presente
trabalho visa, por meio da análise de dados estatísticos e
de estudos bibliográficos, trazer uma exposição para a
questão de Crimes Cibernéticos e gerar reflexões sobre
este assunto através da criação de um jogo digital
educativo, por meio do qual a sociedade será informada a
respeito da problemática dos Crimes Cibernéticos mais
comuns nos últimos anos. O jogo terá a finalidade de
educar os usuários sobre os perigos e riscos presente nas
redes, apresentando a temática de uma forma lúdica e de
fácil entendimento para o público geral.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29244,"é fácil esquecer, em meio a crises mundiais, que a revolução digital dos últimos anos trouxe consigo, além de inovações e soluções tecnológicas, uma série de problemas e desafios. um desses problemas é provavelmente o mais retratado nos últimos anos, tratando-se de uma nova modalidade de atividades ilícitas, os crimes cibernéticos. e esta nova prática de organizações criminosas na internet possui diversas formas, dentre as quais se incluem as invasões a redes privadas de organizações e empresas, roubos e exposições de dados privados, discursos de ódio online, e estelionato, mediante fraude praticada com o uso de dispositivos eletrônicos. acerca desses fatos, o presente trabalho visa, por meio da análise de dados estatísticos e de estudos bibliográficos, trazer uma exposição para a questão de crimes cibernéticos e gerar reflexões sobre este assunto através da criação de um jogo digital educativo, por meio do qual a sociedade será informada a respeito da problemática dos crimes cibernéticos mais comuns nos últimos anos. o jogo terá a finalidade de educar os usuários sobre os perigos e riscos presente nas redes, apresentando a temática de uma forma lúdica e de fácil entendimento para o público geral."
301,2022,Agile Ateasy Software: um sistema para guiar o uso de testes exploratórios no contexto de metodologias ágeis.,"PEREIRA JÚNIOR, Fernando Jorge.","ANDRADE, Wilkerson de Lucena.","Organizações que trabalham com
desenvolvimento de sistemas, sejam elas
grandes instituições ou pequenos grupos de
desenvolvedores, lidam com o desafio de
preservar a qualidade do software, enquanto
criam ou evoluem o mesmo. Porém o ritmo com
que os requisitos e regras de negócio se
transformam, torna essa tarefa árdua e repetitiva,
resultando em desperdício de tempo e retrabalho.
Esse trabalho tem como objetivo o
desenvolvimento de um sistema que ajude as
organizações e equipes a realizarem e manterem
testes exploratórios em um contexto ágil de
maneira consistente, através da aplicação das
técnicas e tarefas propostas pelo método Agile
ETeasy.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29243,"organizações que trabalham com desenvolvimento de sistemas, sejam elas grandes instituições ou pequenos grupos de desenvolvedores, lidam com o desafio de preservar a qualidade do software, enquanto criam ou evoluem o mesmo. porém o ritmo com que os requisitos e regras de negócio se transformam, torna essa tarefa árdua e repetitiva, resultando em desperdício de tempo e retrabalho. esse trabalho tem como objetivo o desenvolvimento de um sistema que ajude as organizações e equipes a realizarem e manterem testes exploratórios em um contexto ágil de maneira consistente, através da aplicação das técnicas e tarefas propostas pelo método agile eteasy."
302,2022,Comparação entre modelos com diferentes abordagens para classificação de sotaques brasileiros.,"ALMEIDA, Diego Ribeiro de.","CAMPELO, Claudio Elízio Calazans.","O sotaque se apresenta como uma das variáveis mais desaiadoras
para a eicácia de sistemas de Automatic Speech Recognition.
Além disso, sua classiicação automática possui diversas aplicações
potenciais, como a seleção de modelos especializados para text-tospeech
e speech-to-text. Neste trabalho, avaliamos dois modelos de
classiicação de sotaques a partir da base de dados Braccent, a im
de compará-los com os métodos GMM-UBM, GMM-SVM, iVector,
CNN 1D, CNN 2D e CNN 1D + LSTM. Os resultados experimentais
obtidos demonstram que as abordagens aqui avaliadas apresentam
desempenhos consideravelmente abaixo dos reportados na literatura
em métricas como acurácia, precisão, revocação, e F1-score,
corroborando com a premissa de que sistemas de reconhecimento
automático de sotaques no português brasileiro ainda são um desaio.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29242,"o sotaque se apresenta como uma das variáveis mais desaiadoras para a eicácia de sistemas de automatic speech recognition. além disso, sua classiicação automática possui diversas aplicações potenciais, como a seleção de modelos especializados para text-tospeech e speech-to-text. neste trabalho, avaliamos dois modelos de classiicação de sotaques a partir da base de dados braccent, a im de compará-los com os métodos gmm-ubm, gmm-svm, ivector, cnn 1d, cnn 2d e cnn 1d + lstm. os resultados experimentais obtidos demonstram que as abordagens aqui avaliadas apresentam desempenhos consideravelmente abaixo dos reportados na literatura em métricas como acurácia, precisão, revocação, e f1-score, corroborando com a premissa de que sistemas de reconhecimento automático de sotaques no português brasileiro ainda são um desaio."
303,2022,Desagregação distribuída: evolução arquitetural do desagregador NIALM da LiteMe.,"GAMA, Diego Alves.","BRITO, Andrey Elísio Monteiro.","A LiteMe é uma empresa de inteligência energética em ascensão
que desagrega dados de consumo de energia de seus clientes via
modelo NIALM, distinguindo o consumo de cada um dos
aparelhos registrados, e os processa para oferecer seus serviços.
Isso faz da desagregação um dos alicerces do negócio, e conforme
a LiteMe se expande, dados de mais clientes precisam ser
desagregados, o que leva à necessidade de replicar o desagregador
NIALM. Atualmente o desagregador faz parte de uma arquitetura
monolítica fortemente acoplada com o backend robusto da
empresa, chamado de núcleo. Ele realiza as operações mais
custosas da plataforma, que elevam o requisito de hardware para
executá-la, e atua como servidor sempre disponível. Esse
acoplamento prejudica a escalabilidade do NIALM, que não pode
ser replicado sozinho. Uma arquitetura distribuída de
microsserviço que permita separar o NIALM do núcleo, mantendo
comunicação entre os dois, pode fornecer ao desagregador melhor
escalabilidade, desacoplamento, menores requisitos de hardware e
de disponibilidade. Este trabalho propõe uma arquitetura de
desagregação distribuída para substituir a monolítica, de forma a
executar em nuvem pública com uso de instâncias oportunistas
(e.g. ""Spots"" na AWS). A arquitetura foi validada com apoio da
empresa e testada em ambiente simulado. Após análise, foi
possível alcançar os objetivos e reduzir custos de hospedagem em
nuvem em até 72,59% em comparação à arquitetura monolítica.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29241,"a liteme é uma empresa de inteligência energética em ascensão que desagrega dados de consumo de energia de seus clientes via modelo nialm, distinguindo o consumo de cada um dos aparelhos registrados, e os processa para oferecer seus serviços. isso faz da desagregação um dos alicerces do negócio, e conforme a liteme se expande, dados de mais clientes precisam ser desagregados, o que leva à necessidade de replicar o desagregador nialm. atualmente o desagregador faz parte de uma arquitetura monolítica fortemente acoplada com o backend robusto da empresa, chamado de núcleo. ele realiza as operações mais custosas da plataforma, que elevam o requisito de hardware para executá-la, e atua como servidor sempre disponível. esse acoplamento prejudica a escalabilidade do nialm, que não pode ser replicado sozinho. uma arquitetura distribuída de microsserviço que permita separar o nialm do núcleo, mantendo comunicação entre os dois, pode fornecer ao desagregador melhor escalabilidade, desacoplamento, menores requisitos de hardware e de disponibilidade. este trabalho propõe uma arquitetura de desagregação distribuída para substituir a monolítica, de forma a executar em nuvem pública com uso de instâncias oportunistas (e.g. ""spots"" na aws). a arquitetura foi validada com apoio da empresa e testada em ambiente simulado. após análise, foi possível alcançar os objetivos e reduzir custos de hospedagem em nuvem em até , % em comparação à arquitetura monolítica."
304,2022,Identificação automática de tweets homofóbicos em português.,"LIMA, Douglas Pereira de.","CAMPELO, Cláudio Elízio Calazans.","Discursos de ódio com conteúdo homofóbico são cada dia mais frequentes nas redes sociais. Muitas
dessas plataformas, como o Twitter, disponibilizam algumas ferramentas, como a denúncia, para
contornar esses problemas, mas não são efetivas. A sociedade precisa se haver de técnicas, que não
dependam dessas plataformas, para lidar com esse tipo de violência e garantir que vidas e corpos
distintos sejam respeitados. Uma das ações possíveis, em relação a esse problema, é a detecção
automática desse conteúdo. Técnicas de aprendizagem de máquina foram criadas para automatizar
essa detecção, mas diversos estudos mostram que essas técnicas podem ser refinadas e melhoradas.
Com isso, essa pesquisa propõe utilizar técnicas de aprendizagem de máquina para identificar
automaticamente discursos de ódio com conteúdo homofóbico em tweets em português. Os
resultados mostram que métricas satisfatórias de classificação automática podem ser atingidas e os
modelos produzidos tem potencial, de serem utilizados para auxiliar a população LGBTQIA+, na luta
contra a violência em redes sociais.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29240,"discursos de ódio com conteúdo homofóbico são cada dia mais frequentes nas redes sociais. muitas dessas plataformas, como o twitter, disponibilizam algumas ferramentas, como a denúncia, para contornar esses problemas, mas não são efetivas. a sociedade precisa se haver de técnicas, que não dependam dessas plataformas, para lidar com esse tipo de violência e garantir que vidas e corpos distintos sejam respeitados. uma das ações possíveis, em relação a esse problema, é a detecção automática desse conteúdo. técnicas de aprendizagem de máquina foram criadas para automatizar essa detecção, mas diversos estudos mostram que essas técnicas podem ser refinadas e melhoradas. com isso, essa pesquisa propõe utilizar técnicas de aprendizagem de máquina para identificar automaticamente discursos de ódio com conteúdo homofóbico em tweets em português. os resultados mostram que métricas satisfatórias de classificação automática podem ser atingidas e os modelos produzidos tem potencial, de serem utilizados para auxiliar a população lgbtqia+, na luta contra a violência em redes sociais."
305,2022,BooKollection.,"PEREIRA, Diego Amancio.","MONTEIRO, João Arthur Brunet.","Os sites e aplicativos direcionados a colecionadores de obras literárias são importantes, pois possuem
funcionalidades capazes de organizar coleções, selecionar a ordem de leitura e opinar sobre os títulos presentes na
plataforma. Todavia, faltam funções importantes para o usuário nas plataformas existentes acerca da sua coleção,
por exemplo, as informações financeiras acerca do quanto foi investido, conservação dos livros, detalhamento das
obras, entre outras. Diante do constante aumento no valor dos livros e queda na sua qualidade [26], nota-se uma
decisão mais seletiva por parte do usuário, que por sua vez, demandará de mais tempo, devido à escassez de
informações mais específicas acerca dos títulos.
Este trabalho teve como objetivo criar uma plataforma voltada para colecionadores de obras literárias,
trazendo diferenciais, tais como um comparador de livros com informações sobre a obra (material, quantidade de
páginas, preço, resumo), notas baseadas na opinião dos usuários na plataforma (custo benefício e dificuldade de
adquirir um título ou coleção) e um leitor de código de barras que, ao escanear um livro irá fornecer um
identificador, o International Standard Book Number (ISBN). Isto possibilita ao usuário realizar uma busca da
obra no site e obter dados sobre os títulos sem a necessidade de tê-los de forma manual.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29239,"os sites e aplicativos direcionados a colecionadores de obras literárias são importantes, pois possuem funcionalidades capazes de organizar coleções, selecionar a ordem de leitura e opinar sobre os títulos presentes na plataforma. todavia, faltam funções importantes para o usuário nas plataformas existentes acerca da sua coleção, por exemplo, as informações financeiras acerca do quanto foi investido, conservação dos livros, detalhamento das obras, entre outras. diante do constante aumento no valor dos livros e queda na sua qualidade [ ], nota-se uma decisão mais seletiva por parte do usuário, que por sua vez, demandará de mais tempo, devido à escassez de informações mais específicas acerca dos títulos. este trabalho teve como objetivo criar uma plataforma voltada para colecionadores de obras literárias, trazendo diferenciais, tais como um comparador de livros com informações sobre a obra (material, quantidade de páginas, preço, resumo), notas baseadas na opinião dos usuários na plataforma (custo benefício e dificuldade de adquirir um título ou coleção) e um leitor de código de barras que, ao escanear um livro irá fornecer um identificador, o international standard book number (isbn). isto possibilita ao usuário realizar uma busca da obra no site e obter dados sobre os títulos sem a necessidade de tê-los de forma manual."
306,2022,Node-Red: low-code para resolver problemas de sistemas orientados a eventos.,"BEZERRA, Dácio Silva.","BRITO, Andrey Elísio Monteiro.","A crise resultante da pandemia de COVID-19 ainda não foi embora, mas já deixou várias lições.
Países como Malásia e Coréia do Sul foram exemplos na contenção de diversos efeitos da crise,
implementando sistemas de rastreamento de contato e distribuição de recursos. Essas duas atividades
são exemplos de coordenação de dados em tempo real. A coordenação de recursos deveria ser mais
fácil, mas cada fabricante, distribuidor e sistema hospitalar possuem sistemas que são diferentes e não
podem compartilhar dados facilmente. De fato, nos próximos anos, tecnologias irão se consolidar de
tal forma que haverão protocolos de comunicação assim como temos os nossos protocolos de rede para
harmonização entre agentes. O presente artigo se importa em detalhar e exemplificar o uso da
ferramenta Node-Red como uma forma de resolver tais problemas de harmonização e integração de
dados em tempo real por meio do Low-Code, utilizando-se de um cenário acadêmico real. Além da
exemplificação da construção de um plugin tendo em vista a ferramenta supracitada para suporte da
solução de integração.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29238,"a crise resultante da pandemia de covid- ainda não foi embora, mas já deixou várias lições. países como malásia e coréia do sul foram exemplos na contenção de diversos efeitos da crise, implementando sistemas de rastreamento de contato e distribuição de recursos. essas duas atividades são exemplos de coordenação de dados em tempo real. a coordenação de recursos deveria ser mais fácil, mas cada fabricante, distribuidor e sistema hospitalar possuem sistemas que são diferentes e não podem compartilhar dados facilmente. de fato, nos próximos anos, tecnologias irão se consolidar de tal forma que haverão protocolos de comunicação assim como temos os nossos protocolos de rede para harmonização entre agentes. o presente artigo se importa em detalhar e exemplificar o uso da ferramenta node-red como uma forma de resolver tais problemas de harmonização e integração de dados em tempo real por meio do low-code, utilizando-se de um cenário acadêmico real. além da exemplificação da construção de um plugin tendo em vista a ferramenta supracitada para suporte da solução de integração."
307,2022,Desafios da inclusão digital de micro e pequenas empresas.,"SILVA, Caroliny Mylena Bezerra e.","PROCÓPIO, Francilene García.","O avanço das tecnologias da informação e comunicação exigem transformações nas
organizações em todo o mundo. Em paralelo a isso, as micro e pequenas empresas (MPEs)
cresceram de forma acelerada e correspondem a 90% dos negócios brasileiros. A crise da Covid-19
escancarou muitos desafios ao microempreendedor; se antes da pandemia ter uma presença digital
era fundamental para maximizar as vendas, no período de isolamento social se tornou essencial à
sobrevivência das micro e pequenas empresas. Entretanto, ainda há muitos desafios a serem
ultrapassados para digitalizar a economia e os setores produtivos, por exemplo, a escassez de
funcionários com conhecimento e habilidades no ambiente digital, a falta de capital financeiro, dentre
outros. Este estudo explora os fatores que determinam a falta de democratização e maturidade digital
das MPEs, bem como indicadores e dados relacionados à questão que auxiliam na compreensão
desses desafios. De acordo com a problemática, foi realizada uma pesquisa bibliográfica sobre o
assunto, utilizando palavras-chave como diretrizes de busca. Além disso, foram obtidos e analisados
dados descritivos, qualitativos e quantitativos, obtidos junto aos micro e pequenos empreendedores,
através de entrevistas e um questionário. A partir disso, no final do estudo, foi possível fazer um
levantamento dos principais desafios da inclusão e maturidade digital das MPEs e apresentar
algumas das ferramentas motivacionais necessárias para mitigar esses obstáculos, por exemplo, a
necessidade de uma educação digital complementar para os funcionários das MPEs.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29237,"o avanço das tecnologias da informação e comunicação exigem transformações nas organizações em todo o mundo. em paralelo a isso, as micro e pequenas empresas (mpes) cresceram de forma acelerada e correspondem a % dos negócios brasileiros. a crise da covid- escancarou muitos desafios ao microempreendedor; se antes da pandemia ter uma presença digital era fundamental para maximizar as vendas, no período de isolamento social se tornou essencial à sobrevivência das micro e pequenas empresas. entretanto, ainda há muitos desafios a serem ultrapassados para digitalizar a economia e os setores produtivos, por exemplo, a escassez de funcionários com conhecimento e habilidades no ambiente digital, a falta de capital financeiro, dentre outros. este estudo explora os fatores que determinam a falta de democratização e maturidade digital das mpes, bem como indicadores e dados relacionados à questão que auxiliam na compreensão desses desafios. de acordo com a problemática, foi realizada uma pesquisa bibliográfica sobre o assunto, utilizando palavras-chave como diretrizes de busca. além disso, foram obtidos e analisados dados descritivos, qualitativos e quantitativos, obtidos junto aos micro e pequenos empreendedores, através de entrevistas e um questionário. a partir disso, no final do estudo, foi possível fazer um levantamento dos principais desafios da inclusão e maturidade digital das mpes e apresentar algumas das ferramentas motivacionais necessárias para mitigar esses obstáculos, por exemplo, a necessidade de uma educação digital complementar para os funcionários das mpes."
308,2022,Uma interface web para um contrato inteligente.,"LIRA, Caio Sanches Batista de.","MOURA, José Antão Beltrão.","Contrato inteligente é um conjunto de protocolos de
transações, que representam termos reais de negócios. O
lançamento da rede Ethereum, possibilitou uma infraestrutura
facilitadora para os contratos inteligentes. Apesar da
popularização de aplicações descentralizadas, o acesso por
parte de usuários comuns ainda é restrito. Um dos limitantes a
tal acesso, é a ausência de interfaces facilitadoras que
aproximem o usuário com o contexto que já estão
familiarizados. Na tentativa de atenuar um dos limitantes ao
acesso de aplicações descentralizadas, o presente trabalho
implementa uma interface web amigável, personalizada para
um contrato inteligente de três-pontas (contratante, validador e
beneficiário), disponível na blockchain, que permite a criação
e interação com transações validáveis.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29236,"contrato inteligente é um conjunto de protocolos de transações, que representam termos reais de negócios. o lançamento da rede ethereum, possibilitou uma infraestrutura facilitadora para os contratos inteligentes. apesar da popularização de aplicações descentralizadas, o acesso por parte de usuários comuns ainda é restrito. um dos limitantes a tal acesso, é a ausência de interfaces facilitadoras que aproximem o usuário com o contexto que já estão familiarizados. na tentativa de atenuar um dos limitantes ao acesso de aplicações descentralizadas, o presente trabalho implementa uma interface web amigável, personalizada para um contrato inteligente de três-pontas (contratante, validador e beneficiário), disponível na blockchain, que permite a criação e interação com transações validáveis."
309,2022,Análise do comportamento do indicador de volume de vendas com variação no tempo.,"MEDEIROS, Caio Henrique Ribeiro Garcia de.","SABINO, Melina Mongiovi Cunha Lima.","No mundo dos negócios, a análise de indicadores para tomada de decisões é muito importante . Um
indicador comumente avaliado é o de Volume de Vendas, o qual pode ser decomposto por mercado, linha
de produto, meios de distribuição etc. Com base nesse indicador, pode-se compreender como as vendas da
empresa se comportam e, então, decidir que ações deverão ser tomadas para aumentar os lucros ou reduzir
prejuízos de uma empresa. Desta forma, este estudo teve como objetivo analisar o comportamento do
indicador Volume de Vendas de algumas empresas vendedoras de café, para identificar possíveis
correlações e tendências entre mercados e estimar o Volume de Vendas para o ano seguinte. Para isto,
foram aplicadas algumas técnicas de extração e análise de dados, de correlação e de auto regressão, para
predição deste indicador de vendas. Na realização do trabalho, foi utilizado uma base de dados de quatro
empresas vendedoras de café, clientes de uma empresa de consultoria em análise de dados.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29235,"no mundo dos negócios, a análise de indicadores para tomada de decisões é muito importante . um indicador comumente avaliado é o de volume de vendas, o qual pode ser decomposto por mercado, linha de produto, meios de distribuição etc. com base nesse indicador, pode-se compreender como as vendas da empresa se comportam e, então, decidir que ações deverão ser tomadas para aumentar os lucros ou reduzir prejuízos de uma empresa. desta forma, este estudo teve como objetivo analisar o comportamento do indicador volume de vendas de algumas empresas vendedoras de café, para identificar possíveis correlações e tendências entre mercados e estimar o volume de vendas para o ano seguinte. para isto, foram aplicadas algumas técnicas de extração e análise de dados, de correlação e de auto regressão, para predição deste indicador de vendas. na realização do trabalho, foi utilizado uma base de dados de quatro empresas vendedoras de café, clientes de uma empresa de consultoria em análise de dados."
310,2022,Investigações do uso de deepfake audio com uma técnica de aumento de dados utilizados no treinamento de transcritores automáticos.,"FERREIRA, Alexandre Ribeiro.","CAMPELO, Cláudio Elízio Calazans.","Para o treinamento de modelos transcritores que produzam resultados robustos, são necessários
dados rotulados em grande quantidade e diversificados. Encontrar tais dados com as características
necessárias é uma tarefa difícil, principalmente em idiomas menos populares do que o inglês. Além
disso, produzir tais dados requer bastante esforço, tempo e, quase sempre, dinheiro. Logo, uma
estratégia para mitigar esse problema é a utilização de técnicas de aumento de dados. Nesse
trabalho, foi investigada a utilização de deepfake audio para o aumento de dados, utilizando um
clonador de voz capaz de gerar novos áudios mantendo características da voz do falante original,
como, por exemplo, o sotaque. Para tanto, foi selecionado um pequeno conjunto de dados produzido
por indianos no idioma inglês, garantindo a presença de apenas um sotaque no conjunto. Para a
realização das investigações, experimentos foram conduzidos utilizando o clonador para o aumento
de dados. Em seguida, os dados aumentados foram utilizados no treinamento dos transcritores, em
diversos cenários. Surpreendentemente, a estratégia não teve um impacto positivo após a realização
dos treinamentos, tendo como possível causa a qualidade dos áudios gerados pelos clonadores
atuais.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/29234,"para o treinamento de modelos transcritores que produzam resultados robustos, são necessários dados rotulados em grande quantidade e diversificados. encontrar tais dados com as características necessárias é uma tarefa difícil, principalmente em idiomas menos populares do que o inglês. além disso, produzir tais dados requer bastante esforço, tempo e, quase sempre, dinheiro. logo, uma estratégia para mitigar esse problema é a utilização de técnicas de aumento de dados. nesse trabalho, foi investigada a utilização de deepfake audio para o aumento de dados, utilizando um clonador de voz capaz de gerar novos áudios mantendo características da voz do falante original, como, por exemplo, o sotaque. para tanto, foi selecionado um pequeno conjunto de dados produzido por indianos no idioma inglês, garantindo a presença de apenas um sotaque no conjunto. para a realização das investigações, experimentos foram conduzidos utilizando o clonador para o aumento de dados. em seguida, os dados aumentados foram utilizados no treinamento dos transcritores, em diversos cenários. surpreendentemente, a estratégia não teve um impacto positivo após a realização dos treinamentos, tendo como possível causa a qualidade dos áudios gerados pelos clonadores atuais."
311,2021,Segurança residencial não dissuasiva.,"SARAIVA, Wesley Roseno.","ARAÚJO, Joseana Macêdo Fechine Régis de.","Atualmente, os sistemas de segurança residencial são focados em registrar invasores e potenciais invasores, tendo como um dos objetivos a prisão do invasor, em momento posterior ao ato da invasão.
Contudo, a adição de mecanismos de notificação aos residentes, não dissuasivos ao invasor, permitirá melhorar as condições para se efetuar a prisão do invasor, mantendo-se ainda a segurança dos
residentes.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/25018,"atualmente, os sistemas de segurança residencial são focados em registrar invasores e potenciais invasores, tendo como um dos objetivos a prisão do invasor, em momento posterior ao ato da invasão. contudo, a adição de mecanismos de notificação aos residentes, não dissuasivos ao invasor, permitirá melhorar as condições para se efetuar a prisão do invasor, mantendo-se ainda a segurança dos residentes."
312,2021,NodeGIS: simplificando o desenvolvimento de aplicações web de geoprocessamento.,"CUNHA, Mateus Queiroz.","BAPTISTA, Cláudio de Souza.","Diante da vasta presença da informação espacial nas aplicações
atuais, surgiram várias ferramentas que fomentam o desenvolvimento
de aplicações web de Sistemas de Informações Geográficas
(GIS). Apesar de haver um grande número de soluções, muitas são
complexas, requerendo habilidades específicas dos desenvolvedores.
Portanto, há a necessidade de uma ferramenta que simplifique o
processo de desenvolver e publicar uma aplicação web GIS, com a
vantagem de ser de código aberto. Neste trabalho é apresentado o
NodeGIS, uma ferramenta de código aberto que provê uma interface
gráfica para o desenvolvimento de aplicações de web GIS, sem escrita
de código ou configuração complexa de servidores. O NodeGIS
utiliza-se de uma arquitetura baseada em contêineres, fazendo uso
de REST, e facilitando o deployment de uma aplicação web GIS. A
ferramenta apresentada permite ao usuário plotar mapas vetoriais,
realizar operações de overlay e de personalização de camadas,
zooming, panning, tooltip, consultas em atributos convencionais e
espaciais. O NodeGIS também pode ser utilizado no ensino de GIS,
não necessitando instalação de software por parte dos alunos.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/25017,"diante da vasta presença da informação espacial nas aplicações atuais, surgiram várias ferramentas que fomentam o desenvolvimento de aplicações web de sistemas de informações geográficas (gis). apesar de haver um grande número de soluções, muitas são complexas, requerendo habilidades específicas dos desenvolvedores. portanto, há a necessidade de uma ferramenta que simplifique o processo de desenvolver e publicar uma aplicação web gis, com a vantagem de ser de código aberto. neste trabalho é apresentado o nodegis, uma ferramenta de código aberto que provê uma interface gráfica para o desenvolvimento de aplicações de web gis, sem escrita de código ou configuração complexa de servidores. o nodegis utiliza-se de uma arquitetura baseada em contêineres, fazendo uso de rest, e facilitando o deployment de uma aplicação web gis. a ferramenta apresentada permite ao usuário plotar mapas vetoriais, realizar operações de overlay e de personalização de camadas, zooming, panning, tooltip, consultas em atributos convencionais e espaciais. o nodegis também pode ser utilizado no ensino de gis, não necessitando instalação de software por parte dos alunos."
313,2021,Sistema de Gestão do Comitê Sanitário de Defesa Popular de Campina Grande.,"PEREIRA, Thiago Lima.","MASSONI, Tiago Lima.","Com o surgimento da pandemia do novo coronavírus no ano de 2020, em um país que possui grande desigualdade social como o Brasil, fez-se necessário a união do povo como ferramenta de combate à crise sanitária que agravou uma crise econômica já existente, especialmente para as pessoas mais
vulneráveis que residem em periferias. Nesse cenário, em todo o país, emergem os Comitês Sanitários de Defesa Popular, compostos por acadêmicos e líderes comunitários, como meio de organização popular para superar a crise. Diante disso, como uma proposta para agregar melhorias na gestão e ações do Comitê Sanitário de Defesa Popular da cidade de Campina Grande - PB, surgiu a ideia da criação de um sistema web de gestão, que possibilite o cadastro de pessoas e suas demandas, a fim de otimizar os resultados obtidos pelo comitê em auxiliar a população.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/25016,"com o surgimento da pandemia do novo coronavírus no ano de , em um país que possui grande desigualdade social como o brasil, fez-se necessário a união do povo como ferramenta de combate à crise sanitária que agravou uma crise econômica já existente, especialmente para as pessoas mais vulneráveis que residem em periferias. nesse cenário, em todo o país, emergem os comitês sanitários de defesa popular, compostos por acadêmicos e líderes comunitários, como meio de organização popular para superar a crise. diante disso, como uma proposta para agregar melhorias na gestão e ações do comitê sanitário de defesa popular da cidade de campina grande - pb, surgiu a ideia da criação de um sistema web de gestão, que possibilite o cadastro de pessoas e suas demandas, a fim de otimizar os resultados obtidos pelo comitê em auxiliar a população."
314,2021,Escala Vest: informatização de uma escala para avaliação de vazio existencial e sentido da vida.,"ARAÚJO, Lucas Victor Silva.","ANDRADE, Wilkerson de Lucena.","A Psicologia, especialmente no campo da Avaliação Psicológica,
tem procurado cada vez mais desenvolver ferramentas
psicológicas informatizadas que sejam consistentes com a prática
dos psicólogos. Considerando que os testes tradicionais realizados
na área de Psicologia, em sua maioria, estão sendo aplicados de
forma escrita com lápis e papel, visando facilitar a aplicação,
correção de dados e coleta de resultados, foi proposto neste
trabalho uma abordagem para realizar a informatização de uma
escala sobre o Vazio Existencial e o Sentido da vida, para jovens e
adultos. Deste modo, foi necessário desenvolver uma plataforma
para que os profissionais de psicologia possam disponibilizar um
questionário intuitivo para seus pacientes a fim de coletar
informações sobre seu estado psíquico, oferecendo uma aplicação
de forma dinâmica e acessível, que corrobora com a hipótese
diagnóstica. Portanto, neste trabalho, será conduzida a
implementação de uma plataforma progressive-web-app (PWA)
para atender a necessidade dos profissionais de psicologia de
aplicar o exame descrito acima com mais precisão e agilidade, e
também, prover a gestão dos dados dos pacientes que serão
submetidos a esse processo.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/25015,"a psicologia, especialmente no campo da avaliação psicológica, tem procurado cada vez mais desenvolver ferramentas psicológicas informatizadas que sejam consistentes com a prática dos psicólogos. considerando que os testes tradicionais realizados na área de psicologia, em sua maioria, estão sendo aplicados de forma escrita com lápis e papel, visando facilitar a aplicação, correção de dados e coleta de resultados, foi proposto neste trabalho uma abordagem para realizar a informatização de uma escala sobre o vazio existencial e o sentido da vida, para jovens e adultos. deste modo, foi necessário desenvolver uma plataforma para que os profissionais de psicologia possam disponibilizar um questionário intuitivo para seus pacientes a fim de coletar informações sobre seu estado psíquico, oferecendo uma aplicação de forma dinâmica e acessível, que corrobora com a hipótese diagnóstica. portanto, neste trabalho, será conduzida a implementação de uma plataforma progressive-web-app (pwa) para atender a necessidade dos profissionais de psicologia de aplicar o exame descrito acima com mais precisão e agilidade, e também, prover a gestão dos dados dos pacientes que serão submetidos a esse processo."
315,2021,The code: utilizando lógica de programação para desenvolver um jogo de raciocínio lógico.,"COSTA, Misael Augusto Silva da.","BARROS, Marcelo Alves de.","No início da jornada de aprender a programar, o primeiro passo apresentado é o de praticar a lógica
de programação. Isto é, a capacidade de pensar e desenvolver algoritmos capazes de resolver problemas computacionais [1]. Aprender a programar, significa desenvolver esse tipo de raciocínio, o qual pode ser utilizado para criar soluções para problemas do mundo real, que podem se tornar produtos de software. Neste trabalho, o objetivo é desenvolver um produto de software utilizando lógica de programação e programação orientada a objetos, como principais conceitos. O resultado deste trabalho é um jogo 2D chamado The code, no qual o jogador deve utilizar o raciocínio lógico para adivinhar uma combinação de números para passar de nível. Espera-se mostrar com o desenvolvimento desse projeto, que é possível desenvolver um produto de software a partir dos conhecimentos básicos adquiridos no primeiro ano do curso de Ciência da Computação.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/25014,"no início da jornada de aprender a programar, o primeiro passo apresentado é o de praticar a lógica de programação. isto é, a capacidade de pensar e desenvolver algoritmos capazes de resolver problemas computacionais [ ]. aprender a programar, significa desenvolver esse tipo de raciocínio, o qual pode ser utilizado para criar soluções para problemas do mundo real, que podem se tornar produtos de software. neste trabalho, o objetivo é desenvolver um produto de software utilizando lógica de programação e programação orientada a objetos, como principais conceitos. o resultado deste trabalho é um jogo 2d chamado the code, no qual o jogador deve utilizar o raciocínio lógico para adivinhar uma combinação de números para passar de nível. espera-se mostrar com o desenvolvimento desse projeto, que é possível desenvolver um produto de software a partir dos conhecimentos básicos adquiridos no primeiro ano do curso de ciência da computação."
316,2021,Monitora Santa Cruz: uma ferramenta web para auxiliar o cidadão no monitoramento dos gastos da Prefeitura de Santa Cruz do Capibaribe.,"DANTAS, Maria Clara Moraes.","GOMES, Herman Martins.","De acordo com a lei da transparência, informações sobre receitas
e gastos públicos devem ser divulgadas em tempo real, com prazo
máximo de 24 horas, em um sítio da Internet, comumente
denominado portal da transparência. Apesar da disponibilidade
dos dados ser um passo na direção de um governo mais
transparente e auditável pela população, a monitoração desses
dados ainda é uma tarefa complexa. Os portais não são obrigados
a fornecer quaisquer meios de visualização que facilitem a
inspeção e a compreensão dos dados e, no caso específico do
portal da transparência do município de Santa Cruz do Capibaribe,
em Pernambuco, os dados estão disponíveis apenas em tabelas.
Desse modo, para a maior parte da população, não é possível
extrair valor ou informações relevantes dos dados. Neste contexto,
o presente trabalho de conclusão de curso tem como objetivo
empoderar o cidadão, provendo uma aplicação web que faz a
aquisição automática dos dados de despesas, consolida
informações relevantes destes dados e fornece diferentes
visualizações interativas que auxiliam a compreensão dos gastos
por cidadãos comuns.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/25013,"de acordo com a lei da transparência, informações sobre receitas e gastos públicos devem ser divulgadas em tempo real, com prazo máximo de horas, em um sítio da internet, comumente denominado portal da transparência. apesar da disponibilidade dos dados ser um passo na direção de um governo mais transparente e auditável pela população, a monitoração desses dados ainda é uma tarefa complexa. os portais não são obrigados a fornecer quaisquer meios de visualização que facilitem a inspeção e a compreensão dos dados e, no caso específico do portal da transparência do município de santa cruz do capibaribe, em pernambuco, os dados estão disponíveis apenas em tabelas. desse modo, para a maior parte da população, não é possível extrair valor ou informações relevantes dos dados. neste contexto, o presente trabalho de conclusão de curso tem como objetivo empoderar o cidadão, provendo uma aplicação web que faz a aquisição automática dos dados de despesas, consolida informações relevantes destes dados e fornece diferentes visualizações interativas que auxiliam a compreensão dos gastos por cidadãos comuns."
317,2021,Preferências de áreas no contexto do desenvolvimento de software: um estudo exploratório.,"FONSECA, Raquel Ambrozio da.","MASSONI, Tiago Lima.","A escolha da área preferida e/ou de atuação dentro do contexto do
desenvolvimento de software pode estar relacionada a diversos
fatores. Reconhecer e entender como esses fatores afetam esses
profissionais é muito importante, para que assim, as pessoas dos
diferentes gêneros possam trabalhar juntos da melhor maneira
possível. Por isso, o objetivo dessa pesquisa é identificar quais são
as áreas de preferências, entre os desenvolvedores, se essas áreas
podem estar relacionados com um determinado gênero, e em
segundo plano, queremos estudar o preconceito de gênero no
desenvolvimento de software, analisando se as áreas geralmente
preferidas entre o gênero feminino são consideradas inferiores ou
de menos importância que as áreas escolhidas pelo gênero
masculino. Para isso, foi realizado um estudo exploratório
qualitativo através de entrevistas, com 10 profissionais
brasileiros(as) de equipes de software, de 6 empresas diferentes.
Foi identificado que as áreas preferidas entre os homens são
variadas, mas estão diretamente relacionadas ao desenvolvimento,
já as das mulheres vão além do desenvolvimento, e são mais
voltadas para a parte de qualidade de software e funcional, por
exemplo. Se as áreas geralmente escolhidas como
preferidas/atuantes pelas mulheres são consideradas inferiores, ou
menos importantes, não foi possível confirmar com os dados
dessa pesquisa, visto que a amostra utilizada foi muito pequena.
Com esses resultados, é possível criar hipóteses que podem ser
consideradas em estudos futuros.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/25012,"a escolha da área preferida e/ou de atuação dentro do contexto do desenvolvimento de software pode estar relacionada a diversos fatores. reconhecer e entender como esses fatores afetam esses profissionais é muito importante, para que assim, as pessoas dos diferentes gêneros possam trabalhar juntos da melhor maneira possível. por isso, o objetivo dessa pesquisa é identificar quais são as áreas de preferências, entre os desenvolvedores, se essas áreas podem estar relacionados com um determinado gênero, e em segundo plano, queremos estudar o preconceito de gênero no desenvolvimento de software, analisando se as áreas geralmente preferidas entre o gênero feminino são consideradas inferiores ou de menos importância que as áreas escolhidas pelo gênero masculino. para isso, foi realizado um estudo exploratório qualitativo através de entrevistas, com profissionais brasileiros(as) de equipes de software, de empresas diferentes. foi identificado que as áreas preferidas entre os homens são variadas, mas estão diretamente relacionadas ao desenvolvimento, já as das mulheres vão além do desenvolvimento, e são mais voltadas para a parte de qualidade de software e funcional, por exemplo. se as áreas geralmente escolhidas como preferidas/atuantes pelas mulheres são consideradas inferiores, ou menos importantes, não foi possível confirmar com os dados dessa pesquisa, visto que a amostra utilizada foi muito pequena. com esses resultados, é possível criar hipóteses que podem ser consideradas em estudos futuros."
318,2021,Comparação entre modelos com diferentes abordagens para classificação de fake news.,"BRASIL, Lucas Cordeiro.","BAPTISTA, Cláudio de Souza.","Atualmente, notícias falsas estão cada vez mais em evidência. Pode-se definir tais notícias como informações não verídicas propagadas intencionalmente. Com o grande uso de redes sociais como fonte de informação, torna-se necessário o maior controle e detecção de Fake News, de forma eficaz e rápida. Assim, este trabalho busca utilizar algoritmos já consolidados na área de aprendizagem de máquina - Naive Bayes, XGBoost e BERT - para criar modelos de detecção de notícias falsas, comparando os resultados obtidos em cada modelo com trabalhos anteriormente realizados na área que tenham os melhores resultados até o momento.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/25007,"atualmente, notícias falsas estão cada vez mais em evidência. pode-se definir tais notícias como informações não verídicas propagadas intencionalmente. com o grande uso de redes sociais como fonte de informação, torna-se necessário o maior controle e detecção de fake news, de forma eficaz e rápida. assim, este trabalho busca utilizar algoritmos já consolidados na área de aprendizagem de máquina - naive bayes, xgboost e bert - para criar modelos de detecção de notícias falsas, comparando os resultados obtidos em cada modelo com trabalhos anteriormente realizados na área que tenham os melhores resultados até o momento."
319,2021,Avaliação de desempenho de bancos de dados para armazenamento de séries temporais.,"LACERDA, Javan Kauê Tavares.","BRITO, Andrey Elísio Monteiro.","Este trabalho busca avaliar o desempenho de algumas soluções
de bancos de dados aplicadas para o armazenamento
de séries de dados temporais no contexto de um sistema
de apoio à eficiência energética. Nesta avaliação comparamos
experimentalmente dois sistemas: MariaDB e InfluxDB.
Sendo o MariaDB um banco de dados de propósito geral, e o
InfluxDB um banco especifico para armazenamento de séries
temporais. Os resultados obtidos em nossos experimentos
indicam que o MariaDB, mesmo não sendo especifico para
séries temporais, consegue suprir bem as demandas, apresentando
desempenho superior ao InfluxDB.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/25006,"este trabalho busca avaliar o desempenho de algumas soluções de bancos de dados aplicadas para o armazenamento de séries de dados temporais no contexto de um sistema de apoio à eficiência energética. nesta avaliação comparamos experimentalmente dois sistemas: mariadb e influxdb. sendo o mariadb um banco de dados de propósito geral, e o influxdb um banco especifico para armazenamento de séries temporais. os resultados obtidos em nossos experimentos indicam que o mariadb, mesmo não sendo especifico para séries temporais, consegue suprir bem as demandas, apresentando desempenho superior ao influxdb."
320,2021,Rumo ao estrelato: uma análise com estatísticas de jogadores recém ingressados na NBA.,"MENEZES, João Lucas Galvão.","ANDRADE, Nazareno Ferreira de.","O basquete é um esporte que gera uma grande quantidade de
dados e estatísticas durante o jogo e, inclusive, durante toda a vida
de um jogador de alto nível. A cada ano, inúmeros jovens são
contratados por grandes times sob a promessa de ser a próxima
estrela da franquia. Com a disponibilização desses dados na
Internet, surgiu o interesse de conhecer mais como os números de
um jogador podem falar e prever sobre seu sucesso nas quadras.
Nesse contexto, este trabalho pretende criar um site interativo,
utilizando dados da liga americana de basquete (NBA), para criar
comparações entre os números de jovens promessas, em seu
primeiro ano na liga, e o ano de iniciação de grandes astros da
atualidade. Comparações essas que serão baseadas nas principais
estatísticas para cada função em quadra, sendo elas: média de
pontos por jogo, de assistências, de rebotes, porcentagem de
arremessos convertidos. A partir dessas comparações, poderemos
analisar o quão parecido é o perfil de cada jogador novato com o
de estrelas, como Lebron James e Kevin Durant.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/25005,"o basquete é um esporte que gera uma grande quantidade de dados e estatísticas durante o jogo e, inclusive, durante toda a vida de um jogador de alto nível. a cada ano, inúmeros jovens são contratados por grandes times sob a promessa de ser a próxima estrela da franquia. com a disponibilização desses dados na internet, surgiu o interesse de conhecer mais como os números de um jogador podem falar e prever sobre seu sucesso nas quadras. nesse contexto, este trabalho pretende criar um site interativo, utilizando dados da liga americana de basquete (nba), para criar comparações entre os números de jovens promessas, em seu primeiro ano na liga, e o ano de iniciação de grandes astros da atualidade. comparações essas que serão baseadas nas principais estatísticas para cada função em quadra, sendo elas: média de pontos por jogo, de assistências, de rebotes, porcentagem de arremessos convertidos. a partir dessas comparações, poderemos analisar o quão parecido é o perfil de cada jogador novato com o de estrelas, como lebron james e kevin durant."
321,2021,Caracterização de componentes outliers em sistemas front-end react: um estudo a partir de métricas de Engenharia de Software.,"FARIAS, Igor Araújo Tavares de.","RÊGO, Matheus Gaudencio do.","A produção de softwares estruturados em componentes é uma
tarefa complexa. Apesar do surgimento de novas ferramentas e
tecnologias para facilitar a produção de sistemas front-end, não há
consenso quanto à forma de construção de componentes e
organização da arquitetura de código para esse tipo de
desenvolvimento. Portanto, este trabalho se propõe a analisar
grandes projetos front-end de código aberto que fazem uso da
biblioteca React, baseando-se em métricas da engenharia de
software e atributos específicos do desenvolvimento React
moderno, para caracterizar componentes que se destacam para
essas métricas e descrever como eles são estruturados em sistemas
de grande relevância para a comunidade. Com isso, objetiva-se
destacar tipos de componentes incomuns nos projetos,
características relevantes da construção desses, e de que maneira
as decisões de arquitetura impactaram as métricas da engenharia
de software, visando proporcionar melhor compreensão do
processo de desenvolvimento de sistemas front-end e favorecer a
tomada de decisões para a construção de novos projetos da área.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/25004,"a produção de softwares estruturados em componentes é uma tarefa complexa. apesar do surgimento de novas ferramentas e tecnologias para facilitar a produção de sistemas front-end, não há consenso quanto à forma de construção de componentes e organização da arquitetura de código para esse tipo de desenvolvimento. portanto, este trabalho se propõe a analisar grandes projetos front-end de código aberto que fazem uso da biblioteca react, baseando-se em métricas da engenharia de software e atributos específicos do desenvolvimento react moderno, para caracterizar componentes que se destacam para essas métricas e descrever como eles são estruturados em sistemas de grande relevância para a comunidade. com isso, objetiva-se destacar tipos de componentes incomuns nos projetos, características relevantes da construção desses, e de que maneira as decisões de arquitetura impactaram as métricas da engenharia de software, visando proporcionar melhor compreensão do processo de desenvolvimento de sistemas front-end e favorecer a tomada de decisões para a construção de novos projetos da área."
322,2021,A utilização do scrum em projetos de pesquisa e desenvolvimento: uma análise sobre a adequação na implementação.,"DANTAS, Helena Mylena Cunha.","SABINO, Melina Mongiovi Cunha Lima.","Diante das mudanças ocorridas na sociedade, em que as incertezas
e dinamismo causam mudanças contínuas nos requisitos dos
stakeholders, ferramentas de projetos em que há um escopo fixo
não conseguem acompanhar algumas das demandas sociais.
Assim, as necessidades do mercado acompanharam essa
inconstância, necessitando-se de abordagens metodológicas de
desenvolvimento de projetos mais ágeis, que se tornassem um
canal de adaptação. Em face das alterações de requisitos no
decorrer do projeto, o Scrum surgiu como uma alternativa
tornando-se uma solução utilizada por muitas empresas,
principalmente de Tecnologia da Informação. Porém, a falta de
uma estrutura adequada de implementação de metodologias ágeis
em ambientes de pesquisa e desenvolvimento provocou uma
necessidade por customizações nas práticas do Scrum. O presente
estudo analisou se as alterações aplicadas estão de acordo com os
valores da metodologia Scrum em projetos de pesquisa e
desenvolvimento de computação na Universidade Federal de
Campina Grande, por meio da obtenção de dados descritivos,
quantitativos e qualitativos através de contato direto com a
situação alvo, questionários com os colaboradores e VOC (Voz do
Consumidor). Grande parte dos projetos possuem uma estrutura
hierárquica e não realizavam todas as cerimônias do Scrum,
gerando dificuldades de autogestão e retrabalho.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/25003,"diante das mudanças ocorridas na sociedade, em que as incertezas e dinamismo causam mudanças contínuas nos requisitos dos stakeholders, ferramentas de projetos em que há um escopo fixo não conseguem acompanhar algumas das demandas sociais. assim, as necessidades do mercado acompanharam essa inconstância, necessitando-se de abordagens metodológicas de desenvolvimento de projetos mais ágeis, que se tornassem um canal de adaptação. em face das alterações de requisitos no decorrer do projeto, o scrum surgiu como uma alternativa tornando-se uma solução utilizada por muitas empresas, principalmente de tecnologia da informação. porém, a falta de uma estrutura adequada de implementação de metodologias ágeis em ambientes de pesquisa e desenvolvimento provocou uma necessidade por customizações nas práticas do scrum. o presente estudo analisou se as alterações aplicadas estão de acordo com os valores da metodologia scrum em projetos de pesquisa e desenvolvimento de computação na universidade federal de campina grande, por meio da obtenção de dados descritivos, quantitativos e qualitativos através de contato direto com a situação alvo, questionários com os colaboradores e voc (voz do consumidor). grande parte dos projetos possuem uma estrutura hierárquica e não realizavam todas as cerimônias do scrum, gerando dificuldades de autogestão e retrabalho."
323,2021,Um estudo comparativo entre Pull Requests com e sem refatoramentos através da análise de revisões de códigos.,"GALVÃO, Hugo Addobbati.","MASSONI, Tiago Lima.","Com o passar dos anos, a revisão de código vem mudando; antes,
era feita uma inspeção manual (rigorosa e síncrona), já nos dias
atuais, é feita uma revisão mais moderna (assíncrona e menos
rigorosa). Atualmente, o Git, através da plataforma Github, é o
sistema de controle de versões mais popular, favorecendo diversas
discussões relacionadas a mudanças no código-fonte. Com o
auxílio de ferramentas como RefactoringMiner, que fornece a
detecção de refatoramentos aplicados aos códigos-fonte e,
utilizando-se de uma amostra de repositórios provenientes do
projeto do Apache no Github, este trabalho, através de inspeções
manuais de comentários de revisão, visa entender e caracterizar os
comentários que induziram refatoramentos nos PRs, com o intuito
de entender as características próprias e diferenças dos
comentários de revisão em PRs com e sem refatoramentos.
Através das hipóteses levantadas, tentamos complementar o
entendimento da parte qualitativa dos comentários de revisão,
abordados anteriormente de forma similar em outra pesquisa, que
analisava dados qualitativos e quantitativos de PRs que induziram
refatoramentos e de PRs que não induziram refatoramentos, com a
intenção de entender melhor as diferenças entre os dois tipos de
PRs, no nível de Pull Request.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/25002,"com o passar dos anos, a revisão de código vem mudando; antes, era feita uma inspeção manual (rigorosa e síncrona), já nos dias atuais, é feita uma revisão mais moderna (assíncrona e menos rigorosa). atualmente, o git, através da plataforma github, é o sistema de controle de versões mais popular, favorecendo diversas discussões relacionadas a mudanças no código-fonte. com o auxílio de ferramentas como refactoringminer, que fornece a detecção de refatoramentos aplicados aos códigos-fonte e, utilizando-se de uma amostra de repositórios provenientes do projeto do apache no github, este trabalho, através de inspeções manuais de comentários de revisão, visa entender e caracterizar os comentários que induziram refatoramentos nos prs, com o intuito de entender as características próprias e diferenças dos comentários de revisão em prs com e sem refatoramentos. através das hipóteses levantadas, tentamos complementar o entendimento da parte qualitativa dos comentários de revisão, abordados anteriormente de forma similar em outra pesquisa, que analisava dados qualitativos e quantitativos de prs que induziram refatoramentos e de prs que não induziram refatoramentos, com a intenção de entender melhor as diferenças entre os dois tipos de prs, no nível de pull request."
324,2021,Análise de desempenho da Api io_uring em uma aplicação de uso intenso de dados.,"ALVES, Gustavo Daniel Farias.","SILVA, Thiago Emmanuel Pereira da Cunha.","Em maio de 2019, no lançamento da versão 5.1 do kernel Linux,
foi introduzida uma nova API chamada io_uring. A interface veio
como uma nova opção de realizar operações de I/O assíncrono,
com propostas de simplicidade, melhor desempenho e cobertura
de casos de uso em que seus predecessores, a exemplo da interface
aio, não davam suporte. Desde a introdução da API, alguns projetos
de software vêm tentando introduzir io_uring nas suas bases de
código. Desses, houveram alguns relatos de ganhos significativos
de desempenho, chegando em alguns casos ao dobro da velocidade
antes da implementação da interface. Este artigo traz uma breve
introdução à interface, o contexto em que ela está inserida e uma
análise comparativa entre o desempenho em operações de IO de
uma aplicação real de uso intensivo de dados antes e após a utilização
de io_uring. Os resultados após a modificação indicam que a
simples introdução de io_uring trouxe uma queda de desempenho
considerável à aplicação, que após análise foi demonstrado que
ela possui comportamento naturalmente síncrono e bloqueante,
nulificando os possíveis benefícios do uso de I/O assíncrono porém
mantendo o overhead decorrente do gerenciamento da interface
io_uring.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/25001,"em maio de , no lançamento da versão . do kernel linux, foi introduzida uma nova api chamada io_uring. a interface veio como uma nova opção de realizar operações de i/o assíncrono, com propostas de simplicidade, melhor desempenho e cobertura de casos de uso em que seus predecessores, a exemplo da interface aio, não davam suporte. desde a introdução da api, alguns projetos de software vêm tentando introduzir io_uring nas suas bases de código. desses, houveram alguns relatos de ganhos significativos de desempenho, chegando em alguns casos ao dobro da velocidade antes da implementação da interface. este artigo traz uma breve introdução à interface, o contexto em que ela está inserida e uma análise comparativa entre o desempenho em operações de io de uma aplicação real de uso intensivo de dados antes e após a utilização de io_uring. os resultados após a modificação indicam que a simples introdução de io_uring trouxe uma queda de desempenho considerável à aplicação, que após análise foi demonstrado que ela possui comportamento naturalmente síncrono e bloqueante, nulificando os possíveis benefícios do uso de i/o assíncrono porém mantendo o overhead decorrente do gerenciamento da interface io_uring."
325,2021,Gamificação em um aplicativo de finanças pessoais para aumentar a retenção na primeira semana de uso.,"COURA, Daniel Rodrigues.","SABINO, Melina Mongiovi Cunha Lima.","Diversos indicadores e pesquisas mostram a baixa performance financeira dos brasileiros. Muitos não conseguem chegar ao fim do mês com dinheiro sobrando e pouquíssimos conseguem arcar com algum imprevisto. Pensando nisso, foi desenvolvido o Julius, um aplicativo para gestão financeira pessoal de autoria do primeiro autor deste artigo. O Julius surgiu para ajudar as pessoas a aumentarem seu bem-estar financeiro. Para isso ocorrer, é essencial o engajamento do usuário. Entretanto, a baixa retenção mostra que o aplicativo está deixando a desejar nesse aspecto.
Este trabalho visa implementar elementos de jogos no Julius para aumentar a retenção na primeira semana de uso e avaliar o desempenho da versão gamificada utilizando os dados de retenção do Google Analytics e um questionário. Os resultados mostram que, apesar de grande parte dos usuários terem gostado da gamificação, não é plausível que ela tenha melhorado a retenção de forma relevante.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/25000,"diversos indicadores e pesquisas mostram a baixa performance financeira dos brasileiros. muitos não conseguem chegar ao fim do mês com dinheiro sobrando e pouquíssimos conseguem arcar com algum imprevisto. pensando nisso, foi desenvolvido o julius, um aplicativo para gestão financeira pessoal de autoria do primeiro autor deste artigo. o julius surgiu para ajudar as pessoas a aumentarem seu bem-estar financeiro. para isso ocorrer, é essencial o engajamento do usuário. entretanto, a baixa retenção mostra que o aplicativo está deixando a desejar nesse aspecto. este trabalho visa implementar elementos de jogos no julius para aumentar a retenção na primeira semana de uso e avaliar o desempenho da versão gamificada utilizando os dados de retenção do google analytics e um questionário. os resultados mostram que, apesar de grande parte dos usuários terem gostado da gamificação, não é plausível que ela tenha melhorado a retenção de forma relevante."
326,2021,Estudo comparativo entre frameworks fronted para a criação de um progressive web app (PWA).,"CRISPINIANO, Almir Gonçalves.","ALVES, Everton Leandro Galdino.","Com a ascensão de Javascript como uma das principais linguagem
de programação para Web, diversos frameworks surgiram para auxiliar
a criação de projetos complexos e escaláveis. Uma tendência
dos dias atuais é a utilização da Web através de dispositivos móveis.
Neste contexto, ocorre um aumento na demanda por aplicações
leves que substituam as aplicações nativas. Essa demanda resultou
em uma metodologia que combina recursos oferecidos pelos navegadores
com as vantagens do uso de um celular. O Progressive
Web App (PWA) é uma metodologia de desenvolvimento que busca
trazer para aplicações Web, acessadas por navegadores móveis, a
mesma experiência (leve e responsiva) vivenciada nos aplicativos
nativos. Atualmente, existe uma enorme variedade de bibliotecas
e frameworks, o que causa dúvidas na tomada de decisão para a
construção de um PWA. O objetivo deste trabalho é realizar um
estudo comparativo entre três tecnologias, para a implementação
de um PWA. Para isso, foi desenvolvido um mesmo sistema utilizando
Angular, Vue e React para coletar métricas e realizar análises
sobre suas vantagens e desvantagens. Como as tecnologias seguem
o mesmo paradigma, o estudo apresenta as características, de cada
uma, associando essas a implementação de um PWA que consume
uma API Rest. Por fim, foram estabelecidos guidelines para ajudar
programadores Web a escolher entre as várias tecnologias disponíveis.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/24999,"com a ascensão de javascript como uma das principais linguagem de programação para web, diversos frameworks surgiram para auxiliar a criação de projetos complexos e escaláveis. uma tendência dos dias atuais é a utilização da web através de dispositivos móveis. neste contexto, ocorre um aumento na demanda por aplicações leves que substituam as aplicações nativas. essa demanda resultou em uma metodologia que combina recursos oferecidos pelos navegadores com as vantagens do uso de um celular. o progressive web app (pwa) é uma metodologia de desenvolvimento que busca trazer para aplicações web, acessadas por navegadores móveis, a mesma experiência (leve e responsiva) vivenciada nos aplicativos nativos. atualmente, existe uma enorme variedade de bibliotecas e frameworks, o que causa dúvidas na tomada de decisão para a construção de um pwa. o objetivo deste trabalho é realizar um estudo comparativo entre três tecnologias, para a implementação de um pwa. para isso, foi desenvolvido um mesmo sistema utilizando angular, vue e react para coletar métricas e realizar análises sobre suas vantagens e desvantagens. como as tecnologias seguem o mesmo paradigma, o estudo apresenta as características, de cada uma, associando essas a implementação de um pwa que consume uma api rest. por fim, foram estabelecidos guidelines para ajudar programadores web a escolher entre as várias tecnologias disponíveis."
327,2021,"Backstage: organize seu evento de forma leve e intuitiva, sem impedimentos e preocupações desnecessárias.","SILVA, Lucas Christopher de Souza.","ARAÚJO, Eliane Cristina de.","Organizar um evento é sempre um desafio. Tudo por trás dos bastidores exige cautela, muito
planejamento e caso haja falta de compromisso ou negligência em algum aspecto, podemos ver tudo
indo por água abaixo e sentir a consequência das coisas não saírem como esperávamos. Para
organizar eventos de porte relevante, como grandes conferências, shows e até cerimônias religiosas que envolvem muitas pessoas, é comum recorrer-se a alguma ferramenta que traga auxílio na gestão de tudo o que é do nosso interesse. É para isto que o Backstage surgiu, uma aplicação mobile que auxilia a organização dos seus eventos, gerenciando pessoas, cronograma e demais aspectos.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/24997,"organizar um evento é sempre um desafio. tudo por trás dos bastidores exige cautela, muito planejamento e caso haja falta de compromisso ou negligência em algum aspecto, podemos ver tudo indo por água abaixo e sentir a consequência das coisas não saírem como esperávamos. para organizar eventos de porte relevante, como grandes conferências, shows e até cerimônias religiosas que envolvem muitas pessoas, é comum recorrer-se a alguma ferramenta que traga auxílio na gestão de tudo o que é do nosso interesse. é para isto que o backstage surgiu, uma aplicação mobile que auxilia a organização dos seus eventos, gerenciando pessoas, cronograma e demais aspectos."
328,2021,Uso de Automated Machine Learning (Auto ML) em Sistemas de Recomendação.,"SILVA, Leonardo Lima Felix da.","CAMPELO, Claudio Elízio Calazans.","Os Sistemas de recomendação (SR) são responsáveis por filtrar conteúdos e realizar recomendações baseadas nas preferências dos usuários, esses modelos inteligentes estão sendo utilizados por diversas empresas e em diferentes áreas. Com o avanço dos modelos de aprendizado de máquina, está cada vez maior o número de pesquisas ou ferramentas que buscam automatizar a tarefa realizada por elas, essas ferramentas também são conhecidas como AutoML. AutoML vem sendo uma ferramenta para sugerir o melhor modelo e os melhores hiperparâmetros para um conjunto de dados. Dessa forma, este trabalho propõe discutir e comparar, dentre algumas ferramentas de AutoML, se podem ser adequadas para o uso em cenários de sistemas de recomendação.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/24996,"os sistemas de recomendação (sr) são responsáveis por filtrar conteúdos e realizar recomendações baseadas nas preferências dos usuários, esses modelos inteligentes estão sendo utilizados por diversas empresas e em diferentes áreas. com o avanço dos modelos de aprendizado de máquina, está cada vez maior o número de pesquisas ou ferramentas que buscam automatizar a tarefa realizada por elas, essas ferramentas também são conhecidas como automl. automl vem sendo uma ferramenta para sugerir o melhor modelo e os melhores hiperparâmetros para um conjunto de dados. dessa forma, este trabalho propõe discutir e comparar, dentre algumas ferramentas de automl, se podem ser adequadas para o uso em cenários de sistemas de recomendação."
329,2021,Padrões na preferência musical dos(as) brasileiros(as) sob a ótica do Spotify.,"CUSTÓDIO, Kelvin Cirne de Lacerda.","ANDRADE, Nazareno Ferreira de.","Embora a música esteja presente no cotidiano de boa parte da humanidade, durante a pandemia de Covid-19, muitos artistas da indústria fonográfica viram suas opções para faturar com música diminuírem. Com a proibição aos shows e a baixa venda de produtos físicos, o mercado musical teve que se adaptar a diferentes modelos de negócio para sobreviver. Neste cenário, o Spotify, serviço digital que paga aos artistas por quantidade de streams[1], vem representando um fôlego para o ramo, que já vinha sofrendo duros golpes pela pirataria. Em abril de 2021, o serviço já possuía mais de 350 milhões de usuários ativos mensais[2]; havia pagado bilhões de dólares aos artistas e gravadoras[7]; e, no Brasil, país que é um dos maiores consumidores de streaming - tanto no modelo gratuito, quanto no pago[8] - é um dos grandes responsáveis pelo crescimento, nos últimos 2 anos, de mais de 24% da renda com músicas gravadas - o maior desde 1996, segundo a Federação Internacional da Indústria Fonográfica[3]. Em 2019, a relevância do streaming foi tão alta que representou mais da metade da receita mundial de música gravada[9]. Com isso, pode-se afirmar que, hoje em dia, a quantidade de streamings de uma música passou a ser parâmetro de sucesso e até a ser um indicativo do que a sociedade, em geral, ouve. Diante disso, este presente artigo apresenta uma análise de dados quantitativa das músicas mais ouvidas no Spotify Brasil, no período de 2017 até o presente ano, com objetivo de ajudar a compreender o gosto musical dos(as) brasileiros(as) através do estudo das características musicais de cada canção. Com isso, buscamos identificar os padrões apresentados por essas características ao longo dos anos. Os resultados indicam que, na amostra estudada, os(as) brasileiros(as) tendem a preferir canções com duração mais curta , instrumentalidade baixa, volume alto (em decibéis), e baixa presença de palavras faladas. Palavras-chave: Spotify, Análise de Dados, Música, Mercado Fonográfico.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/24993,"embora a música esteja presente no cotidiano de boa parte da humanidade, durante a pandemia de covid- , muitos artistas da indústria fonográfica viram suas opções para faturar com música diminuírem. com a proibição aos shows e a baixa venda de produtos físicos, o mercado musical teve que se adaptar a diferentes modelos de negócio para sobreviver. neste cenário, o spotify, serviço digital que paga aos artistas por quantidade de streams[ ], vem representando um fôlego para o ramo, que já vinha sofrendo duros golpes pela pirataria. em abril de , o serviço já possuía mais de milhões de usuários ativos mensais[ ]; havia pagado bilhões de dólares aos artistas e gravadoras[ ]; e, no brasil, país que é um dos maiores consumidores de streaming - tanto no modelo gratuito, quanto no pago[ ] - é um dos grandes responsáveis pelo crescimento, nos últimos anos, de mais de % da renda com músicas gravadas - o maior desde , segundo a federação internacional da indústria fonográfica[ ]. em , a relevância do streaming foi tão alta que representou mais da metade da receita mundial de música gravada[ ]. com isso, pode-se afirmar que, hoje em dia, a quantidade de streamings de uma música passou a ser parâmetro de sucesso e até a ser um indicativo do que a sociedade, em geral, ouve. diante disso, este presente artigo apresenta uma análise de dados quantitativa das músicas mais ouvidas no spotify brasil, no período de até o presente ano, com objetivo de ajudar a compreender o gosto musical dos(as) brasileiros(as) através do estudo das características musicais de cada canção. com isso, buscamos identificar os padrões apresentados por essas características ao longo dos anos. os resultados indicam que, na amostra estudada, os(as) brasileiros(as) tendem a preferir canções com duração mais curta , instrumentalidade baixa, volume alto (em decibéis), e baixa presença de palavras faladas. palavras-chave: spotify, análise de dados, música, mercado fonográfico."
330,2021,Utilizando Protocol Buffers para facilitar a colaboração no projeto DadosJusBR.,"SOUZA, Joeberth Augusto Cordeiro de.","ANDRADE, Nazareno Ferreira de.","O DadosJusBr é um projeto sem fins lucrativos com o objetivo de apresentar de forma detalhada e consolidada as informações de remuneração dos órgãos que constituem o sistema de justiça brasileiro, formado pelos Ministérios Públicos, Defensorias, Procuradorias e o Judiciário com os tribunais e conselhos, juntos somam 156 órgãos. Esse processo é chamado de ‘Libertação dos dados’ e possui quatro estágios: Coleta, Validação, Empacotamento e Armazenamento. É no estágio da coleta que o crescimento do projeto está associado, pois é necessária a codificação dos coletores, um para cada órgão. O DadosJusBr é um projeto de código fonte livre aberto, sendo assim a comunidade pode participar, escrevendo coletores em múltiplas linguagens de programação, como Go e Python. Com o uso de mais uma linguagem de programação, englobando também a tipagem dinâmica onde é mais difícil forçar um esquema considerando o tipo, surgem diversos problemas para restringir o esquema de dados. O principal deles é a consistência na serialização dos dados coletados, que é muito importante para armazenamento e transmissão entre estágios, pois o modo padrão que as linguagens serializam dados é diferente. Neste trabalho propusemos e implementamos a utilização de Protocol Buffers (PB) para tornar mais fácil manter, transmitir e armazenar dados consolidados pelo DadosJusBr. Atualmente temos 52 órgãos coletados, dentre eles o MPPB, codificado em Golang, o site do Conselho Nacional de Justiça (CNJ), codificado em python, que foram os nossos coletores de dados que utilizamos neste trabalho. Adaptar os crawlers e parsers, alterando todos os campos desses coletores para lidar com o novo formato de transmissão de dados, acarretou em dificuldades inesperadas, como lidar com timestamp entre as duas linguagens e transmitir o dado em PB no formato de texto, conseguindo assim a serialização dos dados em todos os estágios. Assim, consolidando a serialização e transmissão dos dados entre coletores de diferentes linguagens, tornando o DadosJusBr mais democrático e abrangente, facilitando a contribuição.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/24992,"o dadosjusbr é um projeto sem fins lucrativos com o objetivo de apresentar de forma detalhada e consolidada as informações de remuneração dos órgãos que constituem o sistema de justiça brasileiro, formado pelos ministérios públicos, defensorias, procuradorias e o judiciário com os tribunais e conselhos, juntos somam órgãos. esse processo é chamado de ‘libertação dos dados’ e possui quatro estágios: coleta, validação, empacotamento e armazenamento. é no estágio da coleta que o crescimento do projeto está associado, pois é necessária a codificação dos coletores, um para cada órgão. o dadosjusbr é um projeto de código fonte livre aberto, sendo assim a comunidade pode participar, escrevendo coletores em múltiplas linguagens de programação, como go e python. com o uso de mais uma linguagem de programação, englobando também a tipagem dinâmica onde é mais difícil forçar um esquema considerando o tipo, surgem diversos problemas para restringir o esquema de dados. o principal deles é a consistência na serialização dos dados coletados, que é muito importante para armazenamento e transmissão entre estágios, pois o modo padrão que as linguagens serializam dados é diferente. neste trabalho propusemos e implementamos a utilização de protocol buffers (pb) para tornar mais fácil manter, transmitir e armazenar dados consolidados pelo dadosjusbr. atualmente temos órgãos coletados, dentre eles o mppb, codificado em golang, o site do conselho nacional de justiça (cnj), codificado em python, que foram os nossos coletores de dados que utilizamos neste trabalho. adaptar os crawlers e parsers, alterando todos os campos desses coletores para lidar com o novo formato de transmissão de dados, acarretou em dificuldades inesperadas, como lidar com timestamp entre as duas linguagens e transmitir o dado em pb no formato de texto, conseguindo assim a serialização dos dados em todos os estágios. assim, consolidando a serialização e transmissão dos dados entre coletores de diferentes linguagens, tornando o dadosjusbr mais democrático e abrangente, facilitando a contribuição."
331,2021,Bem-estar digital: análise de aplicativos que monitoram hábitos digitais.,"COURA, Daniele Aparecida de Melo Silva.","SABINO, Melina Mongiovi Cunha Lima.","Em um mundo em que existem cada vez menos barreiras entre o plano físico e o digital, estar sempre conectado possibilita criar e aumentar vínculos com outras pessoas, aprender coisas novas e compartilhar aventuras. Essas ações apresentam um novo desafio: como utilizar a tecnologia digital sem prejudicar nosso bem-estar? A consciência do impacto que os dispositivos e a rede podem causar é a essência do bem-estar digital. Neste trabalho, foram selecionados cinco aplicativos Android que auxiliam a monitorar o bem-estar digital, para uma análise de suas funcionalidades e da eficácia e satisfação após sua utilização por um grupo de 35 voluntários. Os resultados mostram que a visualização dos dados de uso é uma forma bastante útil para conhecer e acompanhar a rotina de utilização do smartphone. Além disso, alguns aplicativos foram mais eficazes quanto à promoção do bem-estar digital e se sobressaíram sobre os outros na satisfação de uso.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/24991,"em um mundo em que existem cada vez menos barreiras entre o plano físico e o digital, estar sempre conectado possibilita criar e aumentar vínculos com outras pessoas, aprender coisas novas e compartilhar aventuras. essas ações apresentam um novo desafio: como utilizar a tecnologia digital sem prejudicar nosso bem-estar? a consciência do impacto que os dispositivos e a rede podem causar é a essência do bem-estar digital. neste trabalho, foram selecionados cinco aplicativos android que auxiliam a monitorar o bem-estar digital, para uma análise de suas funcionalidades e da eficácia e satisfação após sua utilização por um grupo de voluntários. os resultados mostram que a visualização dos dados de uso é uma forma bastante útil para conhecer e acompanhar a rotina de utilização do smartphone. além disso, alguns aplicativos foram mais eficazes quanto à promoção do bem-estar digital e se sobressaíram sobre os outros na satisfação de uso."
332,2021,Scalable Web-Based FPGA Board simulator.,"LIMA, Ícaro Dantas de Araújo.","MELCHER, Elmar Uwe Kurt.","Os métodos de aprendizagem de HDLs (linguagens de descrição de hardware) incluem principalmente a prática com placas reprogramáveis e simuladores. Os maiores obstáculos para o aprendizado são o custo dessas placas, a interface hostil desses simuladores e, às vezes, a tediosa configuração do ambiente, necessária até mesmo para executar uma única linha de código. Este trabalho apresenta um simulador de placa FPGA (field-programmable gate array) baseado em web. O sistema é composto por 2 componentes principais: um front-end e um back-end, seguindo uma arquitetura de micros-serviços. É possível escrever código em SystemVerilog e interagir com ele usando uma placa FPGA virtual, exigindo apenas um navegador e acesso à internet. As etapas envolvidas entre a submissão do código do usuário e a simulação, são duas conversões de código. Uma vez que essas conversões podem ser executadas em uma única tarefa, o sistema pode ser escalado horizontalmente. Graças aos eventos enviados pelo servidor e um emulador de console, o usuário pode ver tudo o que está acontecendo nessas tarefas em tempo real.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/24990,"os métodos de aprendizagem de hdls (linguagens de descrição de hardware) incluem principalmente a prática com placas reprogramáveis e simuladores. os maiores obstáculos para o aprendizado são o custo dessas placas, a interface hostil desses simuladores e, às vezes, a tediosa configuração do ambiente, necessária até mesmo para executar uma única linha de código. este trabalho apresenta um simulador de placa fpga (field-programmable gate array) baseado em web. o sistema é composto por componentes principais: um front-end e um back-end, seguindo uma arquitetura de micros-serviços. é possível escrever código em systemverilog e interagir com ele usando uma placa fpga virtual, exigindo apenas um navegador e acesso à internet. as etapas envolvidas entre a submissão do código do usuário e a simulação, são duas conversões de código. uma vez que essas conversões podem ser executadas em uma única tarefa, o sistema pode ser escalado horizontalmente. graças aos eventos enviados pelo servidor e um emulador de console, o usuário pode ver tudo o que está acontecendo nessas tarefas em tempo real."
333,2021,Leia rapidinho: uma aplicação para exercitar a leitura de palavras da língua portuguesa.,"BRAGA, Pedro Guedes.","MOURA, José Antão Beltrão.","A leitura fluente é uma característica importante que deve ser
adquirida durante o processo de alfabetização. Diferentes
indicadores evidenciam problemas preocupantes no nível de
alfabetização dos estudantes brasileiros, incluindo a característica
de ser um leitor fluente. Este trabalho relata o desenvolvimento de
uma aplicação web gamificada que busca aprimorar, a partir do
uso de uma API de reconhecimento de voz disponível em alguns
browsers, a habilidade de leitura de palavras nos estudantes em
processo de alfabetização. Ao final do desenvolvimento, foi
conduzida uma pesquisa e os resultados revelam que a aplicação
pode ser útil como instrumento didático na educação básica.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/24982,"a leitura fluente é uma característica importante que deve ser adquirida durante o processo de alfabetização. diferentes indicadores evidenciam problemas preocupantes no nível de alfabetização dos estudantes brasileiros, incluindo a característica de ser um leitor fluente. este trabalho relata o desenvolvimento de uma aplicação web gamificada que busca aprimorar, a partir do uso de uma api de reconhecimento de voz disponível em alguns browsers, a habilidade de leitura de palavras nos estudantes em processo de alfabetização. ao final do desenvolvimento, foi conduzida uma pesquisa e os resultados revelam que a aplicação pode ser útil como instrumento didático na educação básica."
334,2021,Cuidar: sistema para auxílio no tratamento de crianças com microcefalia em ambiente domiciliar.,"GONÇALVES, Thaynnara Raiany Uchôa.","ANDRADE , Wilkerson de Lucena.","Em outubro de 2015, a Secretaria de Saúde de Pernambuco emitiu
uma declaração de estado de emergência para uma epidemia de
microcefalia. Em novembro do mesmo ano foi identificado o vírus da
Zika (ZIKV) como responsável pela microcefalia ocorrida em bebês.
Nesse contexto, o CER (Centro Especializado em Reabilitação) da
cidade de Campina Grande-PB, atua na reabilitação de crianças
com microcefalia por Zika vírus (MSC-ZIKV). Parte do tratamento
é conduzido por meio de procedimentos de estimulação motora
a serem continuados em ambiente domiciliar. Após entrevistas e
visitas realizadas ao CER, descobriu-se que esses cuidados não vêm
sendo feitos de forma adequada, havendo uma diferença entre as
tarefas prescritas e as que são realizadas de fato pelos cuidadores.
Tais diferenças podem comprometer a eficácia do tratamento e
prejudicar a evolução do paciente. Este trabalho tem como objetivo
o desenvolvimento de uma aplicação capaz de auxiliar os cuidadores
no processo de estimulação motora de crianças com MSC-ZIKV. A
aplicação foi desenvolvida em duas plataformas distintas, sendo elas
web e mobile. A aplicação web tem como objetivo possibilitar aos
profissionais de saúde do CER o cadastro de atividades e prescrevêlas
aos seus pacientes. Já a parte mobile é usada pelos cuidadores,
a fim de obter melhores instruções quanto às atividades a serem
executadas em ambiente domiciliar e o registro dessas atividades.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/24981,"em outubro de , a secretaria de saúde de pernambuco emitiu uma declaração de estado de emergência para uma epidemia de microcefalia. em novembro do mesmo ano foi identificado o vírus da zika (zikv) como responsável pela microcefalia ocorrida em bebês. nesse contexto, o cer (centro especializado em reabilitação) da cidade de campina grande-pb, atua na reabilitação de crianças com microcefalia por zika vírus (msc-zikv). parte do tratamento é conduzido por meio de procedimentos de estimulação motora a serem continuados em ambiente domiciliar. após entrevistas e visitas realizadas ao cer, descobriu-se que esses cuidados não vêm sendo feitos de forma adequada, havendo uma diferença entre as tarefas prescritas e as que são realizadas de fato pelos cuidadores. tais diferenças podem comprometer a eficácia do tratamento e prejudicar a evolução do paciente. este trabalho tem como objetivo o desenvolvimento de uma aplicação capaz de auxiliar os cuidadores no processo de estimulação motora de crianças com msc-zikv. a aplicação foi desenvolvida em duas plataformas distintas, sendo elas web e mobile. a aplicação web tem como objetivo possibilitar aos profissionais de saúde do cer o cadastro de atividades e prescrevêlas aos seus pacientes. já a parte mobile é usada pelos cuidadores, a fim de obter melhores instruções quanto às atividades a serem executadas em ambiente domiciliar e o registro dessas atividades."
335,2021,A study of confidential computing as a way to prevent sensitive information exposure on information systems.,"ALMEIDA, Matheus da Cunha Melo.","BRITO, Andrey Elisio Monteiro.","A privacidade do usuário é uma das maiores preocupações dos desenvolvedores de aplicações hoje
em dia. Com o advento de novas regulamentações e ciber ataques se tornando mais comuns e caros,
a demanda por novas tecnologias que podem ajudar a reduzir ou mitigar o risco de exposição da
informação está aumentando. Como os humanos são os mais suscetíveis à falha na maioria dos
sistemas, é importante procurar um método para reduzir potenciais erros humanos ou exposição
intencional de informações. Neste artigo, a computação confidencial é estudada como uma forma de
prevenir tais vazamentos de dados executando aplicações dentro de um ambiente de execução
confiável.. Neste contexto, um ambiente de execução confiável é definido como uma área segura de
um processador principal, o que garante que o código e os dados carregados internamente são
protegidos com respeito à confidencialidade e integridade. Para avaliação, um sistema de informação
usando SCONE foi implementado e uma série de testes de segurança e desempenho em uma
aplicação genérica foram executados. Os resultados mostraram uma melhoria considerável na
segurança do aplicativo e uma deterioração considerável no desempenho da aplicação. Os resultados
sugerem que a computação confidencial pode proteger os aplicativos contra os ataques de nível de
administrador mencionados, mas seu uso deve se adequar a certos casos de uso onde o desempenho
não é fundamental para o aplicativo comportamento ou o fato de que são necessários mais recursos
para funcionar no mesmo nível de desempenho.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/24980,"a privacidade do usuário é uma das maiores preocupações dos desenvolvedores de aplicações hoje em dia. com o advento de novas regulamentações e ciber ataques se tornando mais comuns e caros, a demanda por novas tecnologias que podem ajudar a reduzir ou mitigar o risco de exposição da informação está aumentando. como os humanos são os mais suscetíveis à falha na maioria dos sistemas, é importante procurar um método para reduzir potenciais erros humanos ou exposição intencional de informações. neste artigo, a computação confidencial é estudada como uma forma de prevenir tais vazamentos de dados executando aplicações dentro de um ambiente de execução confiável.. neste contexto, um ambiente de execução confiável é definido como uma área segura de um processador principal, o que garante que o código e os dados carregados internamente são protegidos com respeito à confidencialidade e integridade. para avaliação, um sistema de informação usando scone foi implementado e uma série de testes de segurança e desempenho em uma aplicação genérica foram executados. os resultados mostraram uma melhoria considerável na segurança do aplicativo e uma deterioração considerável no desempenho da aplicação. os resultados sugerem que a computação confidencial pode proteger os aplicativos contra os ataques de nível de administrador mencionados, mas seu uso deve se adequar a certos casos de uso onde o desempenho não é fundamental para o aplicativo comportamento ou o fato de que são necessários mais recursos para funcionar no mesmo nível de desempenho."
336,2021,Revisão sistemática da literatura: os desafios encontrados na migração de uma arquitetura monolítica para uma orientada a microsserviços.,"LUCENA, Mariana Araújo.","MONTEIRO, João Arthur Brunet.","Mesmo com o grande avanço da tecnologia e a contribuição de
grandes empresas em aderir ou transicionar seus códigos
monólitos para microsserviços, ainda não há na literatura um
conjunto de regras ou passos que possam ser seguidos para tornar
a transição mais fácil. Este trabalho tem como objetivo investigar
os principais desafios enfrentados, como: segurança da aplicação,
armazenamento dos dados, gerenciamento, monitoramento e
consumo de recursos. Além de sugerir etapas que irão facilitar a
migração. Para alcançar este objetivo foi obtido um acervo
literário que estivesse relacionado com o tema, os trabalhos foram
selecionados e os dados relevantes, extraídos. Concluímos que
para aplicações pequenas ou que ainda estão no início do
desenvolvimento a arquitetura indicada é a monolítica, porém,
com o crescimento da aplicação é desejável que a transição para
microsserviços aconteça da melhor forma possível. Para isso, é
necessário uma boa cobertura de testes antes de realizar a
transição, assim como, ter conhecimento do sistema e como
ocorrerá o relacionamento entre os componentes, um bom
processo baseado na capacidade de obter feedback, como a
construção de logs completos e informativos, além de uma
metodologia ágil oferecendo integração e entrega contínua.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/24979,"mesmo com o grande avanço da tecnologia e a contribuição de grandes empresas em aderir ou transicionar seus códigos monólitos para microsserviços, ainda não há na literatura um conjunto de regras ou passos que possam ser seguidos para tornar a transição mais fácil. este trabalho tem como objetivo investigar os principais desafios enfrentados, como: segurança da aplicação, armazenamento dos dados, gerenciamento, monitoramento e consumo de recursos. além de sugerir etapas que irão facilitar a migração. para alcançar este objetivo foi obtido um acervo literário que estivesse relacionado com o tema, os trabalhos foram selecionados e os dados relevantes, extraídos. concluímos que para aplicações pequenas ou que ainda estão no início do desenvolvimento a arquitetura indicada é a monolítica, porém, com o crescimento da aplicação é desejável que a transição para microsserviços aconteça da melhor forma possível. para isso, é necessário uma boa cobertura de testes antes de realizar a transição, assim como, ter conhecimento do sistema e como ocorrerá o relacionamento entre os componentes, um bom processo baseado na capacidade de obter feedback, como a construção de logs completos e informativos, além de uma metodologia ágil oferecendo integração e entrega contínua."
337,2021,Requirements specification for developers in agile projects: evaluation by one industrial case.,"CARVALHO, João Maurício Alves Valverde.","MASSONI, Tiago Lima.","A adoção de métodos de desenvolvimento ágil cresceu nos últimos anos. Os métodos ágeis tratam a
Especificação de Requisitos de Software (SRS) de forma diferente dos métodos de desenvolvimento tradicionais.
As ‘User Stories’ são uma das abordagens mais amplamente utilizadas para especificar requisitos em projetos
ágeis. No entanto, estudos empíricos na indústria apontam que as USs são direcionadas aos clientes, cobrem
apenas requisitos simples e funcionais visíveis para os usuários e não abordam requisitos de sistema e não
funcionais. A abordagem de Especificação de Requisitos para Desenvolvedores (RSD) visa fornecer informações
mais próximas das necessidades de desenvolvimento. Este artigo apresenta um estudo empírico avaliando a
abordagem RSD em um caso industrial.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/24978,"a adoção de métodos de desenvolvimento ágil cresceu nos últimos anos. os métodos ágeis tratam a especificação de requisitos de software (srs) de forma diferente dos métodos de desenvolvimento tradicionais. as ‘user stories’ são uma das abordagens mais amplamente utilizadas para especificar requisitos em projetos ágeis. no entanto, estudos empíricos na indústria apontam que as uss são direcionadas aos clientes, cobrem apenas requisitos simples e funcionais visíveis para os usuários e não abordam requisitos de sistema e não funcionais. a abordagem de especificação de requisitos para desenvolvedores (rsd) visa fornecer informações mais próximas das necessidades de desenvolvimento. este artigo apresenta um estudo empírico avaliando a abordagem rsd em um caso industrial."
338,2021,Um estudo do impacto da aplicação das melhores práticas de configuração em sistemas baseados em kubernetes usando kube-bench.,"NASCIMENTO, Luiz Ricardo Siqueira Rodrigues.","GOMES, Reinaldo Cézar de Morais.","A portabilidade e facilidade de implantação e manutenção de software e serviços quando utilizando contêineres, fazem com que esse tipo de plataforma seja amplamente aplicada nas comunidades de desenvolvimento e administração de sistemas. Definições padrão de configuração de container runtimes e dos orquestradores de contêineres não são ideais à segurança dos ambientes a serem implantados, mas em muitos dos casos são utilizadas por praticidade ou falta de atenção do administrador do sistema na hora da implantação. Essa prática traz grandes riscos de segurança ao ambiente, sendo que em várias ocasiões é a brecha utilizada para violar ativamente os dados e serviços hospedados em nuvem ou conectados de outra forma à rede. Desse modo, foi construída uma proposta de configurações básicas a ser seguida em um ambiente de produção, baseada nas recomendações de configuração de segurança apontadas na documentação do Kubernetes, a partir de testes realizados sobre um cluster que simula um ambiente de produção. Foi utilizada a ferramenta de código aberto Kube-bench, que é bem difundida nas comunidades de segurança e administração de sistemas para análise e verificação dos impactos das configurações realizadas.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/24977,"a portabilidade e facilidade de implantação e manutenção de software e serviços quando utilizando contêineres, fazem com que esse tipo de plataforma seja amplamente aplicada nas comunidades de desenvolvimento e administração de sistemas. definições padrão de configuração de container runtimes e dos orquestradores de contêineres não são ideais à segurança dos ambientes a serem implantados, mas em muitos dos casos são utilizadas por praticidade ou falta de atenção do administrador do sistema na hora da implantação. essa prática traz grandes riscos de segurança ao ambiente, sendo que em várias ocasiões é a brecha utilizada para violar ativamente os dados e serviços hospedados em nuvem ou conectados de outra forma à rede. desse modo, foi construída uma proposta de configurações básicas a ser seguida em um ambiente de produção, baseada nas recomendações de configuração de segurança apontadas na documentação do kubernetes, a partir de testes realizados sobre um cluster que simula um ambiente de produção. foi utilizada a ferramenta de código aberto kube-bench, que é bem difundida nas comunidades de segurança e administração de sistemas para análise e verificação dos impactos das configurações realizadas."
339,2021,Um estudo qualitativo sobre o impacto de revisões de código em refatoramentos no contexto de pull requests.,"SILVA, José Ramon Fragoso da.","ALVES, Everton Leandro Galdino.","Os comentários feitos em pull requests (PRs) de repositórios Git,
podem induzir a refatoramentos, que são melhorias feitas no
código-fonte, preservando o seu comportamento. Com base nos
comentários de revisão, desenvolvedores são capazes de decidir
por refatorar o código-fonte. Este trabalho tem como objetivo
analisar PRs de repositórios Java do projeto Apache [19] no
GitHub à luz dos comentários dos revisores e refatoramentos
realizados em tempo de revisão de código (minerados previamente
pelo RefactoringMiner - uma ferramenta estado-da-arte para a
detecção de refatoramentos). Para tanto, propõem-se uma análise
manual de comentários de revisão em uma base de dados que
contém 118 PRs. Foram definidos pontos específicos a serem
analisados em cada comentário, buscando atingir objetivos
específicos definidos para ajudar na pesquisa. Essa análise foi feita
de forma manual, lendo, caracterizando e verificando o
comportamento desses pontos levantados e fazendo anotações
sobre cada Pull Request. Ao final deste trabalho foram notados
diversos padrões que se repetiam entre os PRs, esses padrões foram
compilados e serão apresentados, e com isso espera-se entender de
que forma os comentários de revisão influenciam nos
refatoramentos de código-fonte.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/24976,"os comentários feitos em pull requests (prs) de repositórios git, podem induzir a refatoramentos, que são melhorias feitas no código-fonte, preservando o seu comportamento. com base nos comentários de revisão, desenvolvedores são capazes de decidir por refatorar o código-fonte. este trabalho tem como objetivo analisar prs de repositórios java do projeto apache [ ] no github à luz dos comentários dos revisores e refatoramentos realizados em tempo de revisão de código (minerados previamente pelo refactoringminer - uma ferramenta estado-da-arte para a detecção de refatoramentos). para tanto, propõem-se uma análise manual de comentários de revisão em uma base de dados que contém prs. foram definidos pontos específicos a serem analisados em cada comentário, buscando atingir objetivos específicos definidos para ajudar na pesquisa. essa análise foi feita de forma manual, lendo, caracterizando e verificando o comportamento desses pontos levantados e fazendo anotações sobre cada pull request. ao final deste trabalho foram notados diversos padrões que se repetiam entre os prs, esses padrões foram compilados e serão apresentados, e com isso espera-se entender de que forma os comentários de revisão influenciam nos refatoramentos de código-fonte."
340,2021,Desenvolvimento de um serviço de apoio à gerência de recursos da nuvem do LSD.,"ARAÚJO, Adriano Ribeiro de.","SILVA, Thiago Emmanuel Pereira da Cunha.","O serviço de nuvem privada mantido pelo Laboratório de Sistemas
Distribuídos da UFCG disponibiliza recursos computacionais para
a comunidade de funcionários e alunos da UASC/UFCG. Como não
existe cobrança para os usuários, por vezes temos mau uso dos recursos
reservados, sendo preciso manter uma infraestrutura maior
que o necessário. Dessa forma, este trabalho apresenta um serviço
de monitoramento dos recursos disponibilizados, gerando relatórios
periódicos para os administradores e usuários com a bilhetagem dos
recursos utilizados, bem como indicações de recursos subutilizados.
No ponto de vista do usuário, o objetivo é torná-lo ciente se está
usando os recursos de forma eficiente ou não, enquanto na operação,
facilitar o mapeamento de como está sendo feita a alocação
dos recursos de forma agregada e individual dentre os diferentes
projetos na nuvem.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/24975,"o serviço de nuvem privada mantido pelo laboratório de sistemas distribuídos da ufcg disponibiliza recursos computacionais para a comunidade de funcionários e alunos da uasc/ufcg. como não existe cobrança para os usuários, por vezes temos mau uso dos recursos reservados, sendo preciso manter uma infraestrutura maior que o necessário. dessa forma, este trabalho apresenta um serviço de monitoramento dos recursos disponibilizados, gerando relatórios periódicos para os administradores e usuários com a bilhetagem dos recursos utilizados, bem como indicações de recursos subutilizados. no ponto de vista do usuário, o objetivo é torná-lo ciente se está usando os recursos de forma eficiente ou não, enquanto na operação, facilitar o mapeamento de como está sendo feita a alocação dos recursos de forma agregada e individual dentre os diferentes projetos na nuvem."
341,2021,Adaptação do uso do CRM para projetos de software utilizando métodos ágeis.,"FERNANDES, Eddie Kaleb Lopes.","CAMPELO, Cláudio Elízio Calazans.","O software CRM (Customer Relationship Management) realiza a
gestão de diversos tipos de processos, tais como: edição gráfica,
pós-venda, atendimento e prospecção de clientes, entre outros. Entretanto,
tem-se notado que agências de marketing também atuam
em projetos de software. Idealmente, projetos de software devem
ser gerenciados de forma ágil, através de metodologias consolidadas
na engenharia de software, como o SCRUM e XP, utilizando
ferramentas especializadas. Todavia, lidar com duas ou mais ferramentas
para atender demandas menores é laborioso e problemático
para agências que, há anos, utilizam CRMs. Diante disso, o objetivo
central do trabalho é propor uma estratégia para adaptação
do uso do CRM para agregar os conceitos das metodologias ágeis
em projetos de software e avaliar os ganhos obtidos. Nesse sentido,
foi realizado um levantamento das principais ferramentas de CRM
do mercado; conduziu-se um estudo de caso em uma agência de
marketing em um projeto real de implantação de e-commerce; e
avaliou-se a estratégia proposta através de uma pesquisa de opinião
com os participantes do estudo, constatando-se que o êxito da
entrega do projeto teve influência direta dos ganhos obtidos com a
adaptação do uso da ferramenta CRM na fase de implantação.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/24974,"o software crm (customer relationship management) realiza a gestão de diversos tipos de processos, tais como: edição gráfica, pós-venda, atendimento e prospecção de clientes, entre outros. entretanto, tem-se notado que agências de marketing também atuam em projetos de software. idealmente, projetos de software devem ser gerenciados de forma ágil, através de metodologias consolidadas na engenharia de software, como o scrum e xp, utilizando ferramentas especializadas. todavia, lidar com duas ou mais ferramentas para atender demandas menores é laborioso e problemático para agências que, há anos, utilizam crms. diante disso, o objetivo central do trabalho é propor uma estratégia para adaptação do uso do crm para agregar os conceitos das metodologias ágeis em projetos de software e avaliar os ganhos obtidos. nesse sentido, foi realizado um levantamento das principais ferramentas de crm do mercado; conduziu-se um estudo de caso em uma agência de marketing em um projeto real de implantação de e-commerce; e avaliou-se a estratégia proposta através de uma pesquisa de opinião com os participantes do estudo, constatando-se que o êxito da entrega do projeto teve influência direta dos ganhos obtidos com a adaptação do uso da ferramenta crm na fase de implantação."
342,2021,Análise de correlação entre comentários e curtidas/descurtidas de vídeos do youtube por meio de análise de sentimentos.,"SILVA, Geovane do Nascimento.","PEREIRA, Eanes Torres.","A análise de sentimentos é uma tarefa para identificar os sentimentos expressos em determinados textos, rotulando-os como positivos, negativos ou neutros. A ascensão das mídias sociais elevou essa técnica a um patamar industrial de grande interesse, uma vez que as empresas necessitam saber se suas estratégias de marketing têm tido o efeito esperado no público alvo. Tendo em foco demonstrar o uso da análise de sentimento em dados textuais, mais especificamente em comentários de mídias sociais, o presente trabalho tem como objetivo realizar uma análise de dados e verificar se existe correlação entre os sentimentos reconhecidos nos comentários e a quantidade de curtidas e descurtidas de vídeos do Youtube.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/24973,"a análise de sentimentos é uma tarefa para identificar os sentimentos expressos em determinados textos, rotulando-os como positivos, negativos ou neutros. a ascensão das mídias sociais elevou essa técnica a um patamar industrial de grande interesse, uma vez que as empresas necessitam saber se suas estratégias de marketing têm tido o efeito esperado no público alvo. tendo em foco demonstrar o uso da análise de sentimento em dados textuais, mais especificamente em comentários de mídias sociais, o presente trabalho tem como objetivo realizar uma análise de dados e verificar se existe correlação entre os sentimentos reconhecidos nos comentários e a quantidade de curtidas e descurtidas de vídeos do youtube."
343,2020,Introdução à Ciência da Computação: um estudo misto sobre a metodologia de ensino aplicada em cursos da UFCG.,"SILVA, Yuri Kelvin Moura Sousa e.","MASSONI, Tiago Lima.","As transformações tecnológicas vividas nos dias atuais impactam diretamente a produção de trabalho dos profissionais em qualquer área do conhecimento. Diante disso, a Unidade Acadêmica de Sistemas e Computação (UASC) da Universidade Federal de Campina
Grande (UFCG) oferta a disciplina “Introdução à Ciência da Computação” para os cursos envolvidos com ciências exatas ligados a outras unidades da instituição. Porém, tendo em vista que os alunos pertencem a vários cursos, torna-se desafiador aplicar uma metodologia apropriada a essas variedades e atender todas as demandas da formação profissional destes estudantes. Sendo assim, neste trabalho investigamos a contribuição desse componente curricular para a formação dos acadêmicos. Além disso, identificamos quais são as necessidades requeridas para os alunos que a cursam. Para responder isso, desenvolvemos um estudo misto, quantitativo e qualitativo baseado em entrevistas que foram aplicadas a dois grupos: I. Alunos Egressos e II. Coordenadores dos Cursos. Os relatos revelam que o principal requisito para os alunos desta disciplina é o conhecimento básico de programação, utilizando uma linguagem de programação que seja mais didática e atualizada. Além disso, identificamos nos relatos a necessidade do uso e manipulação de planilhas, requisito esse que foi mais evidenciado pelas áreas que envolve engenharia. Ademais, os entrevistados acreditam que a disciplina é de extrema
relevância para a formação dos acadêmicos. Porém, dentre os relatos analisados, percebe-se que a atual forma como a disciplina é ofertada não está sendo suficiente para suprir as necessidades dos alunos que a cursam, dentre as causas mais importantes que levaram a esta afirmação estão: conteúdo defasado, dessincronização das turmas e dificuldade para aplicar os conhecimentos adquiridos.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/20346,"as transformações tecnológicas vividas nos dias atuais impactam diretamente a produção de trabalho dos profissionais em qualquer área do conhecimento. diante disso, a unidade acadêmica de sistemas e computação (uasc) da universidade federal de campina grande (ufcg) oferta a disciplina “introdução à ciência da computação” para os cursos envolvidos com ciências exatas ligados a outras unidades da instituição. porém, tendo em vista que os alunos pertencem a vários cursos, torna-se desafiador aplicar uma metodologia apropriada a essas variedades e atender todas as demandas da formação profissional destes estudantes. sendo assim, neste trabalho investigamos a contribuição desse componente curricular para a formação dos acadêmicos. além disso, identificamos quais são as necessidades requeridas para os alunos que a cursam. para responder isso, desenvolvemos um estudo misto, quantitativo e qualitativo baseado em entrevistas que foram aplicadas a dois grupos: i. alunos egressos e ii. coordenadores dos cursos. os relatos revelam que o principal requisito para os alunos desta disciplina é o conhecimento básico de programação, utilizando uma linguagem de programação que seja mais didática e atualizada. além disso, identificamos nos relatos a necessidade do uso e manipulação de planilhas, requisito esse que foi mais evidenciado pelas áreas que envolve engenharia. ademais, os entrevistados acreditam que a disciplina é de extrema relevância para a formação dos acadêmicos. porém, dentre os relatos analisados, percebe-se que a atual forma como a disciplina é ofertada não está sendo suficiente para suprir as necessidades dos alunos que a cursam, dentre as causas mais importantes que levaram a esta afirmação estão: conteúdo defasado, dessincronização das turmas e dificuldade para aplicar os conhecimentos adquiridos."
344,2020,MobUFCG: aplicativo smart campus para localização e sugestões.,"QUEIROZ, Wesley Lucena.","GARCIA,  Francilene Procópio.","Campus Inteligente é um conjunto de práticas que procuram formar dentro das universidades cidades  inteligentes  por  meio  de  ideias  inovadoras  em diversas  áreas  utilizando­se  da  tecnologia.  A Universidade Federal de Campina Grande (UFCG) aderiu recentemente tal proposta, e nessa temática, este  trabalho  visa  desenvolver  uma  aplicação mobile para algumas soluções de problemas dentro do  campus  universitário  da  UFCG,  como reclamações  e  sugestões  de melhorias  pelos estudantes  e  um  mapa  interativo  com  todas  as informações  sobre  os  laboratórios  do  campus. 
Espera-­se  que  tal  ferramenta  possa  auxiliar  e contribuir  nas  melhorias  de  problemas  da universidade,  como  também  promover  a participação  de estudantes  nas transformações  do campus.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/20345,"campus inteligente é um conjunto de práticas que procuram formar dentro das universidades cidades inteligentes por meio de ideias inovadoras em diversas áreas utilizando­se da tecnologia. a universidade federal de campina grande (ufcg) aderiu recentemente tal proposta, e nessa temática, este trabalho visa desenvolver uma aplicação mobile para algumas soluções de problemas dentro do campus universitário da ufcg, como reclamações e sugestões de melhorias pelos estudantes e um mapa interativo com todas as informações sobre os laboratórios do campus. espera-­se que tal ferramenta possa auxiliar e contribuir nas melhorias de problemas da universidade, como também promover a participação de estudantes nas transformações do campus."
345,2020,Um estudo sobre a influência do assistente de ensino no feedback provido aos alunos em uma disciplina de programação orientada a objetos.,"SAMPAIO, Samara Sonale Santos.","CAMPOS,  Lívia Maria Sampaio.","Na disciplina Laboratório de Programação II, da Universidade Federal de Campina Grande, os alunos aprendem na prática conceitos de Programação Orientada a Objeto. Eles desenvolvem atividades de Laboratório e recebem um feedback, atribuído por um aluno assistente, que contém um feedback sumativo e formativo de acordo com o que foi desenvolvido. No entanto, esses assistentes possuem diferentes experiências e características que podem ou não impactar na produção do feedback produzido. Neste trabalho, realizamos um estudo sobre a influência que as características e experiência dos assistentes podem ter sobre o feedback fornecido. Nele observou-se que é importante os assistentes receberem orientações para a elaboração do feedback como maneira de reduzir influências externas.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/20344,"na disciplina laboratório de programação ii, da universidade federal de campina grande, os alunos aprendem na prática conceitos de programação orientada a objeto. eles desenvolvem atividades de laboratório e recebem um feedback, atribuído por um aluno assistente, que contém um feedback sumativo e formativo de acordo com o que foi desenvolvido. no entanto, esses assistentes possuem diferentes experiências e características que podem ou não impactar na produção do feedback produzido. neste trabalho, realizamos um estudo sobre a influência que as características e experiência dos assistentes podem ter sobre o feedback fornecido. nele observou-se que é importante os assistentes receberem orientações para a elaboração do feedback como maneira de reduzir influências externas."
346,2020,Using a thesaurus in traceability recovery between bug reports and test cases.,"ARAÚJO, Victor Eduardo Borges.","RAMALHO, Franklin de Souza.",,http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/20342,
347,2020,Sistema para monitoramento do nível de água em recipientes de animais domésticos.,"GADELHA, Thalys Menezes Cunha.","ARAÚJO, Joseana Macêdo Fechine Régis de.","Atualmente, é muito comum que donos de animais domésticos (pets) por vezes esqueçam de repor a água dos recipientes dos seus animais logo que esta acaba. Com isto, é comum que seus pets fiquem muito tempo sem beber água, correndo o risco de até mesmo sofrer desidratação. Assim, o trabalho ora descrito consiste no desenvolvimento de um sistema para monitoramento remoto do nível de água em recipientes de animais domésticos. O sistema pode ser utilizado para animais de pequeno porte (cães pequenos e gatos), até animais maiores e, de outros contextos, como por exemplo, cavalos e bois.Para tanto, foi desenvolvida uma solução hardware e
software, com sensor de nível de água e dispositivo da família ESP32, a partir da qual, no momento em que o nível da água atinge certo ponto, uma notificação é enviada para dispositivos móveis, como smartphones. Espera-se, que este sistema auxilie os donos de pets a manter o recipiente de água de seus animais sempre abastecido, evitando assim que seus pets fiquem sem água por tempo prolongado.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/20341,"atualmente, é muito comum que donos de animais domésticos (pets) por vezes esqueçam de repor a água dos recipientes dos seus animais logo que esta acaba. com isto, é comum que seus pets fiquem muito tempo sem beber água, correndo o risco de até mesmo sofrer desidratação. assim, o trabalho ora descrito consiste no desenvolvimento de um sistema para monitoramento remoto do nível de água em recipientes de animais domésticos. o sistema pode ser utilizado para animais de pequeno porte (cães pequenos e gatos), até animais maiores e, de outros contextos, como por exemplo, cavalos e bois.para tanto, foi desenvolvida uma solução hardware e software, com sensor de nível de água e dispositivo da família esp32, a partir da qual, no momento em que o nível da água atinge certo ponto, uma notificação é enviada para dispositivos móveis, como smartphones. espera-se, que este sistema auxilie os donos de pets a manter o recipiente de água de seus animais sempre abastecido, evitando assim que seus pets fiquem sem água por tempo prolongado."
348,2020,Análise comparativa de ferramentas de perfilhamento de dados.,"SOARES, Vinícius de Medeiros.","PIRES, Carlos Eduardo Santos.","A qualidade de dados é o valor atribuído às propriedades da informação disponibilizada e, certamente, impacta na eficiência de uma organização. O perfilamento de dados (PD) é a atividade de coletar dados sobre dados, ou seja, metadados, e é crucial do processo de gerenciar a qualidade de dados. Para isto, um analista de dados precisa recorrer ao uso de ferramentas especializadas. Esta pesquisa apresenta uma análise comparativa de cinco ferramentas de perfilamento de dados: Ataccama DQ Analyzer, DataCleaner, DataMartist, Oracle Enterprise Data Quality e Talend Open Studio. A avaliação é feita com base em uma classificação de tarefas de perfilamento de dados que elenca 27 pontos de análise. A pesquisa busca conhecer as ferramentas disponíveis e em quais tarefas as
aplicações focam. O artigo destaca a ferramenta mais completa, dentre as avaliadas, para a tarefa de perfilamento de dados.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/20340,"a qualidade de dados é o valor atribuído às propriedades da informação disponibilizada e, certamente, impacta na eficiência de uma organização. o perfilamento de dados (pd) é a atividade de coletar dados sobre dados, ou seja, metadados, e é crucial do processo de gerenciar a qualidade de dados. para isto, um analista de dados precisa recorrer ao uso de ferramentas especializadas. esta pesquisa apresenta uma análise comparativa de cinco ferramentas de perfilamento de dados: ataccama dq analyzer, datacleaner, datamartist, oracle enterprise data quality e talend open studio. a avaliação é feita com base em uma classificação de tarefas de perfilamento de dados que elenca pontos de análise. a pesquisa busca conhecer as ferramentas disponíveis e em quais tarefas as aplicações focam. o artigo destaca a ferramenta mais completa, dentre as avaliadas, para a tarefa de perfilamento de dados."
349,2020,Performance analysis between Apache Kafka and RabbitMQ.,"SOUZA, Ronan de Araújo.","SILVA, Thiago Emmanuel Pereira da Cunha.",,http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/20339,
350,2020,A resilient and cloud-based batch processing system for high performance computing.,"SMANEOTO, Raoni Matos.","BRASILEIRO, Francisco Vilar.",,http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/20338,
351,2020,Natural language processing techniques for session-based recommendation.,"COSTA, Júlio Barreto Guedes da.","MARINHO, Leandro Balby.","Sistemas de Recomendação é um campo de pesquisa e aplicação que objetiva identificar e recuperar itens relevantes, dadas as preferências do usuário. Existem muitos cenários em que Sistemas de Recomendação podem ser aplicados, mas sua performance usualmente depende da disponibilidade de dados relacionados ao histórico de consumo do usuário. Neste trabalho, nós avaliamos a performance de Sistemas de Recomendação no cenário baseado em sessões, em que o usuário não pode ser identificado, comparando a performance de métodos ingênuos, baseados em matrizes, sequenciais, e baseados em sessões, além de introduzir uma implementação alternativa de um destes, cuja implementação faz uso de um tipo específico de Rede Neural Recorrente chamado Gated Recurrent Unit. Nós usamos técnicas de Processamento de Linguagem Natural para criar três diferentes estratégias de entrada para os dados e gerar Embeddings
das sessões, analisando a performance da nossa implementação, percebendo possíveis melhorias, e aplicando ajustes finos para obter melhores resultados. Este trabalho foi avaliado usando uma base de dados real extraída da plataforma Last.fm.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/20337,"sistemas de recomendação é um campo de pesquisa e aplicação que objetiva identificar e recuperar itens relevantes, dadas as preferências do usuário. existem muitos cenários em que sistemas de recomendação podem ser aplicados, mas sua performance usualmente depende da disponibilidade de dados relacionados ao histórico de consumo do usuário. neste trabalho, nós avaliamos a performance de sistemas de recomendação no cenário baseado em sessões, em que o usuário não pode ser identificado, comparando a performance de métodos ingênuos, baseados em matrizes, sequenciais, e baseados em sessões, além de introduzir uma implementação alternativa de um destes, cuja implementação faz uso de um tipo específico de rede neural recorrente chamado gated recurrent unit. nós usamos técnicas de processamento de linguagem natural para criar três diferentes estratégias de entrada para os dados e gerar embeddings das sessões, analisando a performance da nossa implementação, percebendo possíveis melhorias, e aplicando ajustes finos para obter melhores resultados. este trabalho foi avaliado usando uma base de dados real extraída da plataforma last.fm."
352,2020,Evaluating Karate-do movements using Kinect V2 camera and tools.,"FREITAS, Matheus Barbosa de.","GOMES, Herman Martins.",,http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/20336,
353,2020,"Estudo comparativo de ferramentas de apoio a compiladores: JFlex, XText e CUP.","CRUZ, Maria Suelany Brito da.","RAMALHO, Franklin de Souza.","Existem diversos geradores de analisadores léxicos, sintáticos e semânticos, como, por exemplo, XText, CUP e JFlex. Apesar da variedade, não existe atualmente ferramentas completas, que atendam às necessidades dos usuários de forma abrangente, por causa da grande complexidade deste tema. A presente pesquisa procura analisar estas três ferramentas principais, e, para tanto, elaboramos alguns critérios buscando mostrar quais as principais diferenças entre elas. Através deste estudo, pretendemos auxiliar os usuários na escolha de qual ferramenta usar de acordo com suas necessidades específicas. Para guiar o estudo usamos a gramática de PostgreSQL e implementamos parte dessa gramática em cada ferramenta. A partir desses desenvolvimentos demos
valores aos critérios de comparação. Concluímos que o XText é a ferramenta com mais recursos disponíveis, entretanto o desenvolvimento nela é complexo. Já a implementação da análise léxica e sintática com o CUP e o JFlex é mais fácil, mas tais ferramentas omitem estruturas importantes para o desenvolvimento de um compilador, além disso a implementação da análise semântica no CUP é complexa e a ferramenta dispõe de uma documentação insuficiente para o auxílio na construção desta etapa. A construção de um compilador simples é recomendado o uso do CUP e do JFlex, mas para um compilador complexo é recomendado o uso de XText.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/20334,"existem diversos geradores de analisadores léxicos, sintáticos e semânticos, como, por exemplo, xtext, cup e jflex. apesar da variedade, não existe atualmente ferramentas completas, que atendam às necessidades dos usuários de forma abrangente, por causa da grande complexidade deste tema. a presente pesquisa procura analisar estas três ferramentas principais, e, para tanto, elaboramos alguns critérios buscando mostrar quais as principais diferenças entre elas. através deste estudo, pretendemos auxiliar os usuários na escolha de qual ferramenta usar de acordo com suas necessidades específicas. para guiar o estudo usamos a gramática de postgresql e implementamos parte dessa gramática em cada ferramenta. a partir desses desenvolvimentos demos valores aos critérios de comparação. concluímos que o xtext é a ferramenta com mais recursos disponíveis, entretanto o desenvolvimento nela é complexo. já a implementação da análise léxica e sintática com o cup e o jflex é mais fácil, mas tais ferramentas omitem estruturas importantes para o desenvolvimento de um compilador, além disso a implementação da análise semântica no cup é complexa e a ferramenta dispõe de uma documentação insuficiente para o auxílio na construção desta etapa. a construção de um compilador simples é recomendado o uso do cup e do jflex, mas para um compilador complexo é recomendado o uso de xtext."
354,2020,Métodos de análise de dados no transporte público urbano.,"CRUZ JÚNIOR, José Ivan Silva da.","CAMPELO, Claudio Elízio Calazans.","Com o crescimento cada vez maior dos centros urbanos e da demanda pelo transporte público, cresceu o interesse por mecanismos que ajudem na análise de dados para melhor compreender a dinâmica do sistema de transporte. Neste artigo, propomos um conjunto de métodos de análise de dados que oferece uma gama de funções úteis para análise dos dados de transporte público, incluindo: a análise espacial das origens e destinos das viagens; a análise da lotação dos ônibus por rota; e a detecção de outliers na velocidade das viagens realizadas. Os métodos foram avaliados através de um
estudo de caso na cidade de Curitiba, Brasil, contendo 4169274 viagens percorridas por 246 rotas. Acreditamos que o conhecimento extraído por esse conjunto de métodos de análise e outros similares podem contribuir para melhorar o serviço oferecido a cidadãos em diferentes cidades.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/20333,"com o crescimento cada vez maior dos centros urbanos e da demanda pelo transporte público, cresceu o interesse por mecanismos que ajudem na análise de dados para melhor compreender a dinâmica do sistema de transporte. neste artigo, propomos um conjunto de métodos de análise de dados que oferece uma gama de funções úteis para análise dos dados de transporte público, incluindo: a análise espacial das origens e destinos das viagens; a análise da lotação dos ônibus por rota; e a detecção de outliers na velocidade das viagens realizadas. os métodos foram avaliados através de um estudo de caso na cidade de curitiba, brasil, contendo viagens percorridas por rotas. acreditamos que o conhecimento extraído por esse conjunto de métodos de análise e outros similares podem contribuir para melhorar o serviço oferecido a cidadãos em diferentes cidades."
355,2020,Evolucionary procedural content generation for a endless platform game.,"PONTES, Rafael Guerra de.","GOMES, Herman Martins.",,http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/20221,
356,2020,Um relato de experiência sobre a inserção de práticas de qualidade de software no ambiente de desenvolvimento da startup proj4me.,"OLIVEIRA NETO, Oliveiros Cavalcanti de.","ANDRADE, Wilkerson de Lucena.","Práticas relacionadas à qualidade de software são bem vistas, principalmente por grandes empresas, pois agregam valor ao produto final. Entretanto, o cenário em pequenas empresas e startups tende a ser diferente. Empresas menores ou recém criadas, em muitos casos, precisam lançar seus produtos rapidamente e em tempo hábil para se estabelecer no mercado. Do outro lado da balança observamos que programas com níveis de qualidade superior conseguem mais espaço entre os consumidores, logo é necessário existir um equilíbrio entre agilidade e qualidade. Neste trabalho conduzirei estudo de caso sobre a implantação dessas práticas em uma dessas empresas de pequeno porte, inserindo padrões comuns da área de qualidade ao processo de desenvolvimento da empresa buscando aumentar a confiabilidade da solução desenvolvida e diminuir as taxas de incidentes que são reportadas pelos clientes da mesma.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/20219,"práticas relacionadas à qualidade de software são bem vistas, principalmente por grandes empresas, pois agregam valor ao produto final. entretanto, o cenário em pequenas empresas e startups tende a ser diferente. empresas menores ou recém criadas, em muitos casos, precisam lançar seus produtos rapidamente e em tempo hábil para se estabelecer no mercado. do outro lado da balança observamos que programas com níveis de qualidade superior conseguem mais espaço entre os consumidores, logo é necessário existir um equilíbrio entre agilidade e qualidade. neste trabalho conduzirei estudo de caso sobre a implantação dessas práticas em uma dessas empresas de pequeno porte, inserindo padrões comuns da área de qualidade ao processo de desenvolvimento da empresa buscando aumentar a confiabilidade da solução desenvolvida e diminuir as taxas de incidentes que são reportadas pelos clientes da mesma."
357,2020,Implementação do garbage collector control interceptor para .net core common language runtime,"SILVA, Lucas Henrique de Lima e.","SILVA, Thiago Emmanuel Pereira da Cunha.",,http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/20181,
358,2020,Proposal of a low­cost device to support remote  diabetic retinopathy detecting based on fundus images.,"TENORIO, Marcus Antonio Rocha.","GOMES, Herman Martins.",,http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/20180,
359,2020,Seu modelo está em perigo? Um estudo de caso sobre replicação de modelos usando destilação de conhecimento com dados fora do escopo,"SCHMID, José Ignácio Morsch.","Marinho, Leandro Balby","Destilação do conhecimento é uma técnica que permite transferir o conhecimento de um modelo de aprendizagem de máquina já treinado para um outro modelo utilizando apenas suas saídas. Sabendo que a replicação do comportamento de um modelo utilizando apenas esses dados é factível, torna-se relevante considerar o fator de proteção da propriedade intelectual quando oferecendo as predições de um modelo em um ambiente em que os usuários possam fazer um grande número de acessos. Neste trabalho iremos fazer o uso da destilação do conhecimento como meio para replicar um modelo convolucional de classificação, tendo acesso apenas a suas predições em um dado fora do escopo original de classificação de modo a avaliar se existe um risco do modelo ser roubado uma vez que alguém tenha amplo acesso a ele.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/20177,"destilação do conhecimento é uma técnica que permite transferir o conhecimento de um modelo de aprendizagem de máquina já treinado para um outro modelo utilizando apenas suas saídas. sabendo que a replicação do comportamento de um modelo utilizando apenas esses dados é factível, torna-se relevante considerar o fator de proteção da propriedade intelectual quando oferecendo as predições de um modelo em um ambiente em que os usuários possam fazer um grande número de acessos. neste trabalho iremos fazer o uso da destilação do conhecimento como meio para replicar um modelo convolucional de classificação, tendo acesso apenas a suas predições em um dado fora do escopo original de classificação de modo a avaliar se existe um risco do modelo ser roubado uma vez que alguém tenha amplo acesso a ele."
360,2020,Superresolução em sistemas de videovigilância: um estudo comparativo.,"SILVA, Jhonatan Batista da.","GOMES, Herman Martins.","Gravações de sistemas de videovigilância podem ser consultadas por sistemas inteligentes com o objetivo de identificação de placas de veículos, faces, entre outros elementos. As imagens encontradas, muitas vezes, não possuem um nível de detalhamento necessário para o reconhecimento automático destes componentes. Esta pesquisa objetiva comparar técnicas que permitam realizar o aprimoramento de imagens de baixa resolução, com foco na identificação de placas de veículos licenciados no Brasil. Para alcançar o objetivo proposto, técnicas do estado-da-arte (superresolução via redes neurais artificiais profundas) são comparadas com técnicas convencionais (a exemplo de redimensionamento com interpolação) com o propósito de verificar a capacidade de melhoria de cada técnica. As avaliações qualitativas e quantitativas foram realizadas sobre os resultados relativos ao reconhecimento dos caracteres presentes nas placas dos veículos com o objetivo de contrastar as técnicas estudadas. Foi concluído, em razão dos resultados produzidos, que as técnicas de superresolução do estado-da-arte superam os métodos convencionais quando aplicadas ao contexto de identificação de elementos em sistemas de videovigilância.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/20168,"gravações de sistemas de videovigilância podem ser consultadas por sistemas inteligentes com o objetivo de identificação de placas de veículos, faces, entre outros elementos. as imagens encontradas, muitas vezes, não possuem um nível de detalhamento necessário para o reconhecimento automático destes componentes. esta pesquisa objetiva comparar técnicas que permitam realizar o aprimoramento de imagens de baixa resolução, com foco na identificação de placas de veículos licenciados no brasil. para alcançar o objetivo proposto, técnicas do estado-da-arte (superresolução via redes neurais artificiais profundas) são comparadas com técnicas convencionais (a exemplo de redimensionamento com interpolação) com o propósito de verificar a capacidade de melhoria de cada técnica. as avaliações qualitativas e quantitativas foram realizadas sobre os resultados relativos ao reconhecimento dos caracteres presentes nas placas dos veículos com o objetivo de contrastar as técnicas estudadas. foi concluído, em razão dos resultados produzidos, que as técnicas de superresolução do estado-da-arte superam os métodos convencionais quando aplicadas ao contexto de identificação de elementos em sistemas de videovigilância."
361,2020,Automação para o projeto Laserterapia da Universidade Federal de Campina Grande.,"XAVIER JUNIOR, Agnaldo Souto.","MASSONI, Tiago Lima.","Coleta e análise de dados de forma fácil e simples está deixando de ser uma opção e se tornando uma necessidade para quem trabalha com isso. Atualmente, é notável a dificuldade de quem trabalha anotando coisas em cadernos ou planilhas para poder
organizar ou visualizar esses dados depois. É esse o caso do projeto Laserterapia e Ações Educativas Transdisciplinares na Oncologia Pediátrica, que atualmente trabalha diariamente com coleta de dados dos pacientes, porém encontrando bastante
dificuldade no processo. Tendo em vista essa necessidade, apresento neste trabalho um sistema web que permite uma fácil coleta e um armazenamento desses dados coletados, facilitando bastante o trabalho da equipe em questão e evitando perda de dados. Para avaliar a qualidade do sistema implementado para eles, 10 colaboradores do projeto responderam um formulário que consiste de 9 questões. Como resultado, o sistema apresentou um grau de satisfação de 4.9 de 5, sendo considerado pelo professor
orientador do projeto e pelos colaboradores uma importante ferramenta que irá auxiliá-los no dia-a-dia.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/20166,"coleta e análise de dados de forma fácil e simples está deixando de ser uma opção e se tornando uma necessidade para quem trabalha com isso. atualmente, é notável a dificuldade de quem trabalha anotando coisas em cadernos ou planilhas para poder organizar ou visualizar esses dados depois. é esse o caso do projeto laserterapia e ações educativas transdisciplinares na oncologia pediátrica, que atualmente trabalha diariamente com coleta de dados dos pacientes, porém encontrando bastante dificuldade no processo. tendo em vista essa necessidade, apresento neste trabalho um sistema web que permite uma fácil coleta e um armazenamento desses dados coletados, facilitando bastante o trabalho da equipe em questão e evitando perda de dados. para avaliar a qualidade do sistema implementado para eles, colaboradores do projeto responderam um formulário que consiste de questões. como resultado, o sistema apresentou um grau de satisfação de . de , sendo considerado pelo professor orientador do projeto e pelos colaboradores uma importante ferramenta que irá auxiliá-los no dia-a-dia."
362,2020,Uma alternativa para gerar planos semafóricos equilibrados e fluidos utilizando algoritmos genéricos.,"MITRE, Daniel Bezerra Galvão.","ARAÚJO, Joseana Macêdo Fechine Régis de.","Vários critérios são considerados na otimização de planos semafóricos das malha de trânsito de cidades com semáforos inteligentes. Enquanto a ideia de equilibrar o atraso de rotas não é tão abordada na literatura, sugerimos minimizar o atraso padronizado médio da malha como critério de otimização para gerar planos balanceados e
fluidos. Com auxílio de um microssimulador de trânsito, desenvolvemos um algoritmo genético para validar o potencial dessa abordagem, que gerou planos 41% mais fluidos e 31% mais balanceados, em média, do que as alternativas consideradas. Enquanto observamos resultados promissores, trabalhos futuros devem avaliar a estratégia
em diferentes malhas sob diferentes níveis de saturação.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/20163,"vários critérios são considerados na otimização de planos semafóricos das malha de trânsito de cidades com semáforos inteligentes. enquanto a ideia de equilibrar o atraso de rotas não é tão abordada na literatura, sugerimos minimizar o atraso padronizado médio da malha como critério de otimização para gerar planos balanceados e fluidos. com auxílio de um microssimulador de trânsito, desenvolvemos um algoritmo genético para validar o potencial dessa abordagem, que gerou planos % mais fluidos e % mais balanceados, em média, do que as alternativas consideradas. enquanto observamos resultados promissores, trabalhos futuros devem avaliar a estratégia em diferentes malhas sob diferentes níveis de saturação."
363,2020,Most higher mutants are useless for method-level mutation operators using weak mutation.,"SOUZA, Beatriz Bezerra de.","GHEYI, Rohit.",,http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/20158,
364,2020,Challenges in the use of Scrum in Global Software Engineering and how to face them.,"VITAL, Anderson Dalbert Carvalho.","MOURA, José Antão Beltrão.",,http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/20152,
365,2020,Análise descritiva da eficiência do sistema de integração temporal no transporte público de Campina Grande – PB: um estudo de caso na Linha 944.,"MEDEIROS, Hector Hiago de.","PIRES, Carlos Eduardo Santos.","Atender a demanda da população de uma cidade a respeito da mobilidade urbana é um dos maiores desafios para os gestores de um município. No contexto do transporte público surgem várias estratégias visando solucionar esta problemática, dentre elas é possível destacar o sistema de ônibus integrado onde um passageiro pode utilizar de dois ou mais ônibus com o uso de apenas uma passagem. No município de Campina Grande - PB é adotado um sistema integrado onde os passageiros podem realizar a troca de ônibus em qualquer lugar da cidade desde que o faça dentro de um limite de tempo preestabelecido. Este trabalho apresenta um estudo sobre a viabilidade do uso desse tipo de sistema para inferir se atende as demandas da população. Os resultados mostraram que o tempo estipulado pelos órgãos competentes para a realização da integração
temporal não apresenta uma alta taxa de eficiência para os casos estudados nesse trabalho.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/20150,"atender a demanda da população de uma cidade a respeito da mobilidade urbana é um dos maiores desafios para os gestores de um município. no contexto do transporte público surgem várias estratégias visando solucionar esta problemática, dentre elas é possível destacar o sistema de ônibus integrado onde um passageiro pode utilizar de dois ou mais ônibus com o uso de apenas uma passagem. no município de campina grande - pb é adotado um sistema integrado onde os passageiros podem realizar a troca de ônibus em qualquer lugar da cidade desde que o faça dentro de um limite de tempo preestabelecido. este trabalho apresenta um estudo sobre a viabilidade do uso desse tipo de sistema para inferir se atende as demandas da população. os resultados mostraram que o tempo estipulado pelos órgãos competentes para a realização da integração temporal não apresenta uma alta taxa de eficiência para os casos estudados nesse trabalho."
366,2020,Consumerhub: a product’s review platform.,"SILVA, Gabriel Fernandes da.","ARAÚJO, Eliane Cristina de.",,http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/20149,
367,2020,Análise do perfil dos alunos que buscam o pré-vestibular solidário da Universidade Federal de Campina Grande.,"GOMES, Fabiana Alves.","CAMPOS, Lívia Maria Sampaio.","A presente pesquisa procura investigar qual o perfil dos alunos que buscam o Projeto Pré-Vestibular Solidário (PVS) da Universidade Federal de Campina Grande. O PVS/CG é um programa vinculado à Pró-Reitora de Pesquisa e Extensão da UFCG com objetivo de
contribuir para a construção de políticas sociais afirmativas, viabilizando a ampliação das condições de acesso de jovens e adultos de baixa renda na educação superior, especialmente de afro-descendentes e indígenas. O programa busca ajudar os alunos
que desejam ingressar no ensino superior através de aulas gratuitas preparatórias para o Enem.[9] Para a coleta dos dados, foi aplicado um questionário socioeconômico, bem como dados já coletados nas fichas de inscrições. A partir dos resultados com base na análise dos dados, usando ciência de dados e visualização de dados, foi verificado o perfil do aluno que busca o programa e se está de acordo com os objetivos propostos pelo projeto, além de sugestões de melhorias para o PVS/CG.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/20129,"a presente pesquisa procura investigar qual o perfil dos alunos que buscam o projeto pré-vestibular solidário (pvs) da universidade federal de campina grande. o pvs/cg é um programa vinculado à pró-reitora de pesquisa e extensão da ufcg com objetivo de contribuir para a construção de políticas sociais afirmativas, viabilizando a ampliação das condições de acesso de jovens e adultos de baixa renda na educação superior, especialmente de afro-descendentes e indígenas. o programa busca ajudar os alunos que desejam ingressar no ensino superior através de aulas gratuitas preparatórias para o enem.[ ] para a coleta dos dados, foi aplicado um questionário socioeconômico, bem como dados já coletados nas fichas de inscrições. a partir dos resultados com base na análise dos dados, usando ciência de dados e visualização de dados, foi verificado o perfil do aluno que busca o programa e se está de acordo com os objetivos propostos pelo projeto, além de sugestões de melhorias para o pvs/cg."
368,2020,Optimizing aho­corasick for word counting.,"LUCENA, Emerson Leonardo.","GHEYI, Rohit.",,http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/20128,
369,2020,A survey on developer’s intention upon refactoring:  Assessing refactoringminer’s efficacy.,"ARAUJO, Aramis Sales.","GHEYI , Rohit.",,http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/20122,
370,2020,Um estudo de caso sobre motivações para baixa  participação de mulheres em olimpíadas de informática,"SILVA, Camila Carvalho da.","CAMPOS, Lívia Maria Rodrigues Sampaio.","As olimpíadas de informática são competições anuais entre alunos que tem o objetivo de desenvolver habilidades para trabalho em grupo, resolução de problemas, dentre outros benefícios. Ao analisar a participação durante os anos é possível perceber que poucas
mulheres estão envolvidas. Por isso, este trabalho busca entender as razões para este problema e sugerir soluções. Nesse sentido, foi realizado um estudo qualitativo com ex-competidoras e mulheres que nunca competiram, atualmente alunas no curso de computação da UFCG. Através da análise dos dados coletados foi observado que motivos como o ambiente muito competitivo, a falta de tempo e de recursos financeiros podem ser fatores desmotivadores para a participação. Com isso, entendesse que é necessário tomar ações motivacionais direcionadas a este gênero para a sua maior inclusão, como chamadas especiais, aulas preparatórias e mini competições.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/20121,"as olimpíadas de informática são competições anuais entre alunos que tem o objetivo de desenvolver habilidades para trabalho em grupo, resolução de problemas, dentre outros benefícios. ao analisar a participação durante os anos é possível perceber que poucas mulheres estão envolvidas. por isso, este trabalho busca entender as razões para este problema e sugerir soluções. nesse sentido, foi realizado um estudo qualitativo com ex-competidoras e mulheres que nunca competiram, atualmente alunas no curso de computação da ufcg. através da análise dos dados coletados foi observado que motivos como o ambiente muito competitivo, a falta de tempo e de recursos financeiros podem ser fatores desmotivadores para a participação. com isso, entendesse que é necessário tomar ações motivacionais direcionadas a este gênero para a sua maior inclusão, como chamadas especiais, aulas preparatórias e mini competições."
371,2020,Aplicando algoritmos de learning to rank sobre features no github para recomendação de projetos.,"NASCIMENTO, Dayvson Weslley Cantalice do.","RAMALHO, Franklin de Souza.","O GitHub é a plataforma de hospedagem de código e controle de versão mais utilizada atualmente. Diariamente, inúmeros projetos são criados, estendidos e modificados por diferentes usuários. Entretanto, muitos projetos que possivelmente seriam do interesse
de determinados usuários, acabam por passar despercebidos diante da grande quantidade de projetos disponíveis. Neste contexto, surge a necessidade de algum mecanismo que possa auxiliar o usuário a encontrar projetos que podem ser de seu interesse. Já existe na literatura trabalhos que buscam analisar fatores de interesse com o objetivo de recomendar projetos, entretanto ainda há margem para utilização de outros fatores e critérios na tentativa de obter resultados melhores. Para tanto, o presente trabalho busca utilizar features, algumas já propostas na literatura e outras ainda não utilizadas nesse contexto, disponíveis em projetos do GitHub, com o auxílio de algoritmos de learning to rank, para encontrar relações de interesse em projetos e assim recomendá-los para o usuário. Verificamos a
efetividade de learning to rank para recomendação de projetos usando os algoritmos LambdaMART, Random Forest e Coordinate Ascent, utilizando como base 826 repositórios e 3464 usuários do GitHub. Os resultados mostram que a abordagem de learning to rank para recomendação de projetos é promissora e efetiva, ao mesmo tempo que oferece muito espaço para aprimoramento.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/20120,"o github é a plataforma de hospedagem de código e controle de versão mais utilizada atualmente. diariamente, inúmeros projetos são criados, estendidos e modificados por diferentes usuários. entretanto, muitos projetos que possivelmente seriam do interesse de determinados usuários, acabam por passar despercebidos diante da grande quantidade de projetos disponíveis. neste contexto, surge a necessidade de algum mecanismo que possa auxiliar o usuário a encontrar projetos que podem ser de seu interesse. já existe na literatura trabalhos que buscam analisar fatores de interesse com o objetivo de recomendar projetos, entretanto ainda há margem para utilização de outros fatores e critérios na tentativa de obter resultados melhores. para tanto, o presente trabalho busca utilizar features, algumas já propostas na literatura e outras ainda não utilizadas nesse contexto, disponíveis em projetos do github, com o auxílio de algoritmos de learning to rank, para encontrar relações de interesse em projetos e assim recomendá-los para o usuário. verificamos a efetividade de learning to rank para recomendação de projetos usando os algoritmos lambdamart, random forest e coordinate ascent, utilizando como base repositórios e usuários do github. os resultados mostram que a abordagem de learning to rank para recomendação de projetos é promissora e efetiva, ao mesmo tempo que oferece muito espaço para aprimoramento."
372,2020,Análise de dados de remunerações do sistema judiciário brasileiro.,"PEREIRA, David Eduardo.","MORAIS, Fábio Jorge Almeida.","Após os históricos e correntes eventos políticos envolvendo corrupção e uso inadequado do dinheiro público, a transparência na administração pública tornou-se um tema popular e ações, como vidinha de balada[1] e brasil.io[2], foram criadas para fiscalizar e compreender o uso do dinheiro no poder executivo e legislativo. Porém, pouco tem sido feito para melhorar a transparência dos gastos no sistema judiciário brasileiro. As conhecidas Lei de acesso à informação (Brasil, 2011) e Lei de Responsabilidade Fiscal (Brasil, 2000) exigem que os órgãos públicos disponibilizem seus dados de gastos na internet, mas não especifica a forma como devem ser disponibilizados, levando a dados descentralizados e não estruturados. Projetos recentes de recuperação e libertação de dados, como o DadosJusBr [3], buscam disponibilizar dados estruturados sobre remunerações do sistema judiciário brasileiro. Entretanto, mesmo com esse nível de organização, a compreensão da sociedade sobre os dados é limitada. Por exemplo, não é trivial entender como é constituída a remuneração de um funcionário, quais benefícios são usados com mais frequência e por quais cargos, se em determinada época do ano é mais comum o uso de algum auxílio, dentre outras informações. Isso ocorre devido a escassez de análises descritivas, visualizações e interpretações que mostrem para a sociedade aspectos de como esses gastos são realizados e distribuídos. Desta forma, este trabalho tem como objetivo gerar análises descritivas sobre dados de remuneração do sistema judiciário e desenvolver técnicas e resultados que possibilitem uma melhor compreensão de suas características e particularidades, promovendo um maior controle social sobre essas despesas.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/20117,"após os históricos e correntes eventos políticos envolvendo corrupção e uso inadequado do dinheiro público, a transparência na administração pública tornou-se um tema popular e ações, como vidinha de balada[ ] e brasil.io[ ], foram criadas para fiscalizar e compreender o uso do dinheiro no poder executivo e legislativo. porém, pouco tem sido feito para melhorar a transparência dos gastos no sistema judiciário brasileiro. as conhecidas lei de acesso à informação (brasil, ) e lei de responsabilidade fiscal (brasil, ) exigem que os órgãos públicos disponibilizem seus dados de gastos na internet, mas não especifica a forma como devem ser disponibilizados, levando a dados descentralizados e não estruturados. projetos recentes de recuperação e libertação de dados, como o dadosjusbr [ ], buscam disponibilizar dados estruturados sobre remunerações do sistema judiciário brasileiro. entretanto, mesmo com esse nível de organização, a compreensão da sociedade sobre os dados é limitada. por exemplo, não é trivial entender como é constituída a remuneração de um funcionário, quais benefícios são usados com mais frequência e por quais cargos, se em determinada época do ano é mais comum o uso de algum auxílio, dentre outras informações. isso ocorre devido a escassez de análises descritivas, visualizações e interpretações que mostrem para a sociedade aspectos de como esses gastos são realizados e distribuídos. desta forma, este trabalho tem como objetivo gerar análises descritivas sobre dados de remuneração do sistema judiciário e desenvolver técnicas e resultados que possibilitem uma melhor compreensão de suas características e particularidades, promovendo um maior controle social sobre essas despesas."
373,2021,Analyzing stock funds metrics by means of causal relationships with their management skills.,"DINIZ, Vitor Braga.","GOMES, Herman Martins.","Com a forte alta do número de fundos de investimento no Brasil, há uma necessidade
urgente de identificar aqueles que têm melhores habilidades de gestão. Dessa forma, este estudo foi desenvolvido com o objetivo de descobrir quais das métricas mais comuns presentes em fundos de ações brasileiros têm uma relação de causalidade com suas habilidades de gestão, medidas pelo Alfa de Jensen. Para tanto, selecionamos 14 métricas de fundos, a fim de verificar uma relação causal existente entre cada uma e o Alpha. Por fim, indicamos seis métricas que são capazes de ser utilizadas como proxy para a geração alfa.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19956,"com a forte alta do número de fundos de investimento no brasil, há uma necessidade urgente de identificar aqueles que têm melhores habilidades de gestão. dessa forma, este estudo foi desenvolvido com o objetivo de descobrir quais das métricas mais comuns presentes em fundos de ações brasileiros têm uma relação de causalidade com suas habilidades de gestão, medidas pelo alfa de jensen. para tanto, selecionamos métricas de fundos, a fim de verificar uma relação causal existente entre cada uma e o alpha. por fim, indicamos seis métricas que são capazes de ser utilizadas como proxy para a geração alfa."
374,2021,Ataux: uma ferramenta para auxiliar o acompanhamento de submissões de questões de programação.,"SILVA, José Thiago dos Santos.","MONGIOVI, Melina.","O Codeforces é uma plataforma utilizada para treinar o desenvolvimento de algoritmos para resolver problemas de programação. No entanto, ela possui algumas limitações para que seja usada diretamente na sala de aula, pois este não consegue suprir algumas necessidades acadêmicas que uma disciplina requer, por exemplo, ter controle das respostas, acompanhar os alunos da turma, gerar planilha de notas, entre outras. Diante disso, o presente sistema tem como objetivo oferecer essas funcionalidades na criação e acompanhamento de listas com problemas de programação. A metodologia adotada no desenvolvimento do sistema foi baseada no scrum, além disso, para avaliar sua usabilidade, foi adotado o método baseado no Post-Study System Usability Questionnaire (PSSUQ). Os resultados obtidos na avaliação do sistema demonstraram bom grau de satisfação dos usuários que o testaram, de tal forma que os professores possam contar com o Ataux para auxiliar em uma disciplina de algoritmos.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19951,"o codeforces é uma plataforma utilizada para treinar o desenvolvimento de algoritmos para resolver problemas de programação. no entanto, ela possui algumas limitações para que seja usada diretamente na sala de aula, pois este não consegue suprir algumas necessidades acadêmicas que uma disciplina requer, por exemplo, ter controle das respostas, acompanhar os alunos da turma, gerar planilha de notas, entre outras. diante disso, o presente sistema tem como objetivo oferecer essas funcionalidades na criação e acompanhamento de listas com problemas de programação. a metodologia adotada no desenvolvimento do sistema foi baseada no scrum, além disso, para avaliar sua usabilidade, foi adotado o método baseado no post-study system usability questionnaire (pssuq). os resultados obtidos na avaliação do sistema demonstraram bom grau de satisfação dos usuários que o testaram, de tal forma que os professores possam contar com o ataux para auxiliar em uma disciplina de algoritmos."
375,2021,Um estudo sobre dificuldades e potencial de gamificação para tratar dificuldades com metodologias ágeis em ambiente comercial de desenvolvimento de software.,"GONÇALVES, Melissa Diniz.","MOURA, José Antão Beltrão.","Na área de desenvolvimento de software é importante que exista organização e gerência, e para auxiliar nesse processo foram desenvolvidas as metodologias ágeis, que compreendem metodologias de desenvolvimento de software baseadas em um forte esforço colaborativo de equipes auto-organizáveis e multifuncionais entre seus clientes e usuários [2]. Em suas rotinas, é comum as equipes ágeis se depararem com tarefas que são consideradas chatas, repetitivas e desmotivadoras, nesse contexto a aplicação de gamificação nestas atividades traria benefícios para aqueles que aplicam metodologias ágeis em seu dia-a-dia. Este trabalho de Conclusão de Curso tem como objetivo fazer uma reprodução dos resultados obtidos em [1], com os seguintes propósitos i) aplicar o mesmo questionário em um ambiente comercial (fábrica de desenvolvimento de software da empresa Accenture, em Campina Grande, PB); e ii) reproduzir a análise estatística quantitativa aplicada na pesquisa citada anteriormente, visando comparar os resultados obtidos para corroborar com os resultados, a fim de reforçar ou refutar a proposta de gamificação das práticas de DAS.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19950,"na área de desenvolvimento de software é importante que exista organização e gerência, e para auxiliar nesse processo foram desenvolvidas as metodologias ágeis, que compreendem metodologias de desenvolvimento de software baseadas em um forte esforço colaborativo de equipes auto-organizáveis e multifuncionais entre seus clientes e usuários [ ]. em suas rotinas, é comum as equipes ágeis se depararem com tarefas que são consideradas chatas, repetitivas e desmotivadoras, nesse contexto a aplicação de gamificação nestas atividades traria benefícios para aqueles que aplicam metodologias ágeis em seu dia-a-dia. este trabalho de conclusão de curso tem como objetivo fazer uma reprodução dos resultados obtidos em [ ], com os seguintes propósitos i) aplicar o mesmo questionário em um ambiente comercial (fábrica de desenvolvimento de software da empresa accenture, em campina grande, pb); e ii) reproduzir a análise estatística quantitativa aplicada na pesquisa citada anteriormente, visando comparar os resultados obtidos para corroborar com os resultados, a fim de reforçar ou refutar a proposta de gamificação das práticas de das."
376,2021,Inhaí: aplicativo para mapear locais LGBTI+ friendly de forma colaborativa.,"NASCIMENTO, Lucas Arcoverde do.","MONTEIRO, João Arthur Brunet.","Para a comunidade LGBTI+ é muito importante ter conhecimento sobre o quanto um local é receptivo e aberto à diversidade, principalmente, devido ao fato de que o preconceito,
ainda hoje, é bastante recorrente. Diante desse contexto, são constantes os casos noticiados de indivíduos, que vivenciam situações constrangedoras ou que são violentados - física e moralmente - em determinados estabelecimentos. Sendo assim, este trabalho visa desenvolver uma aplicação web que possibilita um ambiente virtual para avaliação de locais, de acordo com a receptividade ao público LGBTI+ e de modo que permita que os colaboradores os julguem de forma objetiva (estrelas) e subjetiva (comentários). Este artigo apresenta uma visão geral da arquitetura do aplicativo e, também, uma análise da interação dos seus usuários com as funcionalidades disponibilizadas. Os dados coletados das avaliações subjetivas foram organizados em 3 grupos (fora do foco do aplicativo; positivas; e negativas) e analisados, o que resultou em um total de 52 avaliações disponíveis. Nesse sentido, observou-se alguns comportamentos semelhantes nessas interações, a exemplo de: avaliações fora do contexto, contraditórias com a nota atribuída, o tipo dos locais avaliados (Bar, Restaurante, Escola etc.) e lugares que começaram com uma avaliação positiva, mas após um certo período tiveram uma queda na média. O aplicativo Inhaí 1 está disponível desde 1 de maio de 2021 e congrega 298 usuários que interagem socialmente e colaboram nesse mapeamento, o que revela um impacto promissor nas trocas de  experiências vivenciadas nesses lugares e demonstra potencial para expansão e ampliação de suas funcionalidades.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19940,"para a comunidade lgbti+ é muito importante ter conhecimento sobre o quanto um local é receptivo e aberto à diversidade, principalmente, devido ao fato de que o preconceito, ainda hoje, é bastante recorrente. diante desse contexto, são constantes os casos noticiados de indivíduos, que vivenciam situações constrangedoras ou que são violentados - física e moralmente - em determinados estabelecimentos. sendo assim, este trabalho visa desenvolver uma aplicação web que possibilita um ambiente virtual para avaliação de locais, de acordo com a receptividade ao público lgbti+ e de modo que permita que os colaboradores os julguem de forma objetiva (estrelas) e subjetiva (comentários). este artigo apresenta uma visão geral da arquitetura do aplicativo e, também, uma análise da interação dos seus usuários com as funcionalidades disponibilizadas. os dados coletados das avaliações subjetivas foram organizados em grupos (fora do foco do aplicativo; positivas; e negativas) e analisados, o que resultou em um total de avaliações disponíveis. nesse sentido, observou-se alguns comportamentos semelhantes nessas interações, a exemplo de: avaliações fora do contexto, contraditórias com a nota atribuída, o tipo dos locais avaliados (bar, restaurante, escola etc.) e lugares que começaram com uma avaliação positiva, mas após um certo período tiveram uma queda na média. o aplicativo inhaí está disponível desde de maio de e congrega usuários que interagem socialmente e colaboram nesse mapeamento, o que revela um impacto promissor nas trocas de experiências vivenciadas nesses lugares e demonstra potencial para expansão e ampliação de suas funcionalidades."
377,2021,Adoçãopet CG: um aplicativo para simplificar o processo de adoção de animais em CG.,"GUIMARÃES, Filipe Pires.","MOURA, José Antão Beltrão.","Um grande problema das cidades brasileiras é o alto índice de animais abandonados, que segundo uma pesquisa da OMS existem mais de 20 milhões de cães sem lares no Brasil [1]. Além desse número muito alto, há um outro problema na adoção que é adotar um animal, não se adaptar ao seu comportamento, temperamento daquele animal, então algumas pessoas acabam abandonando esses animais, novamente. Existem ONGs e pessoas que gostariam de fazer a diferença nesse meio. Nessa plataforma, auxiliaremos de algumas formas, como: ajudar na avaliação do adotante e do pet, mostrar os animais disponíveis para adoção podendo classificar e/ou filtrar, além disso abrir um canal de comunicação entre as organizações e os adotantes. Para o desenvolvimento desta plataforma, será utilizada uma biblioteca de javascript bem conhecida no mercado, o React-Native [2]. Espera-se que o aplicativo sirva para disseminar a ideia da adoção de animais, além de ajudar a evitar a reintrodução desse animal ao abandono e assim aumentar o número de animais adotados.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19931,"um grande problema das cidades brasileiras é o alto índice de animais abandonados, que segundo uma pesquisa da oms existem mais de milhões de cães sem lares no brasil [ ]. além desse número muito alto, há um outro problema na adoção que é adotar um animal, não se adaptar ao seu comportamento, temperamento daquele animal, então algumas pessoas acabam abandonando esses animais, novamente. existem ongs e pessoas que gostariam de fazer a diferença nesse meio. nessa plataforma, auxiliaremos de algumas formas, como: ajudar na avaliação do adotante e do pet, mostrar os animais disponíveis para adoção podendo classificar e/ou filtrar, além disso abrir um canal de comunicação entre as organizações e os adotantes. para o desenvolvimento desta plataforma, será utilizada uma biblioteca de javascript bem conhecida no mercado, o react-native [ ]. espera-se que o aplicativo sirva para disseminar a ideia da adoção de animais, além de ajudar a evitar a reintrodução desse animal ao abandono e assim aumentar o número de animais adotados."
378,2021,Avaliação de desempenho de métodos de snapshot para aquecer o cold-start de funções como serviço.,"SILVA, Paulo Felipe Feitosa da.","SILVA, Emmanuel Pereira da Cunha.","O modelo de computação serverless fortaleceu a tendência da computação em nuvem de tornar transparente o gerenciamento da infraestrutura. Ao simplificar o gerenciamento, o modelo serverless deixa a responsabilidade de implantação e escalonamento para a
plataforma. Aliado a isso, com um modelo de cobrança que considera somente o tempo despendido com a execução de requisições, há um forte incentivo para o uso eficiente dos recursos. Essa busca por eficiência, traz à tona o problema de cold-start, que se configura como um atraso na execução de aplicações serverless. Dentre as soluções propostas para lidar com o cold-start, se destacam as baseadas no método de snapshot. Apesar da exploração desse método, existe uma carência de trabalhos que avaliam os trade-ofs de cada proposta. Nessa direção, este trabalho compara duas estratégias de
mitigação do cold-start: Prebaking e SEUSS. Avaliamos o desempenho das estratégias experimentalmente com funções de diferentes níveis de complexidade: NoOp, uma função que converte markdown para HTML, e uma que carrega 41 MB de dependências. Resultados preliminares indicam que Prebaking apresentou desempenho 33% e 25% superior para inicializar NoOp e Markdown, respectivamente e processou a primeira requisição de Markdown com um tempo 69% inferior ao SEUSS.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19930,"o modelo de computação serverless fortaleceu a tendência da computação em nuvem de tornar transparente o gerenciamento da infraestrutura. ao simplificar o gerenciamento, o modelo serverless deixa a responsabilidade de implantação e escalonamento para a plataforma. aliado a isso, com um modelo de cobrança que considera somente o tempo despendido com a execução de requisições, há um forte incentivo para o uso eficiente dos recursos. essa busca por eficiência, traz à tona o problema de cold-start, que se configura como um atraso na execução de aplicações serverless. dentre as soluções propostas para lidar com o cold-start, se destacam as baseadas no método de snapshot. apesar da exploração desse método, existe uma carência de trabalhos que avaliam os trade-ofs de cada proposta. nessa direção, este trabalho compara duas estratégias de mitigação do cold-start: prebaking e seuss. avaliamos o desempenho das estratégias experimentalmente com funções de diferentes níveis de complexidade: noop, uma função que converte markdown para html, e uma que carrega mb de dependências. resultados preliminares indicam que prebaking apresentou desempenho % e % superior para inicializar noop e markdown, respectivamente e processou a primeira requisição de markdown com um tempo % inferior ao seuss."
379,2021,Andromedev: uma análise sobre a experiência em desenvolvimento de código aberto na UFCG.,"BARROS, Juan Victor Lyra Barros e.","CAMPOS, Lívia Maria Rodrigues Sampaio.","O Andromedev foi um evento de mentoria em desenvolvimento de código aberto que teve sua primeira edição baseada em eventos consolidados de mesma natureza. Para avaliá-lo, foram utilizados formulários para a captura de dados sobre o processo de desenvolvimento e informações sobre os projetos. Contudo, o volume de dados coletados impactou negativamente em sua interpretabilidade. Nesse contexto, o presente trabalho desenvolve uma análise descritiva sobre as entregas geradas no Andromedev, a fim de identificar o
público-alvo do evento; examinar seus artefatos avaliadores; verificar possíveis características que levaram ao sucesso de projetos; e buscar fatores que engajaram estudantes a continuar contribuindo após o fim do evento. Notou-se uma boa aderência ao público-alvo esperado, contudo alguns aspectos precisam ser melhorados para
próximas edições, como as entregas semanais, o período da realização do evento e a divisão de tempo de mentor entre vários projetos, sendo esta uma característica que impactou na conclusão de projetos e no desejo de continuar contribuindo pelos aprendizes.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19929,"o andromedev foi um evento de mentoria em desenvolvimento de código aberto que teve sua primeira edição baseada em eventos consolidados de mesma natureza. para avaliá-lo, foram utilizados formulários para a captura de dados sobre o processo de desenvolvimento e informações sobre os projetos. contudo, o volume de dados coletados impactou negativamente em sua interpretabilidade. nesse contexto, o presente trabalho desenvolve uma análise descritiva sobre as entregas geradas no andromedev, a fim de identificar o público-alvo do evento; examinar seus artefatos avaliadores; verificar possíveis características que levaram ao sucesso de projetos; e buscar fatores que engajaram estudantes a continuar contribuindo após o fim do evento. notou-se uma boa aderência ao público-alvo esperado, contudo alguns aspectos precisam ser melhorados para próximas edições, como as entregas semanais, o período da realização do evento e a divisão de tempo de mentor entre vários projetos, sendo esta uma característica que impactou na conclusão de projetos e no desejo de continuar contribuindo pelos aprendizes."
380,2021,Análise de léxico argumentativo como recurso para mineração textual.,"LIMA, Filipe Gomes de.","CAMPELO, Cláudio Elízio Calazans.","Mineração de Argumentos é uma área de pesquisa que visa identificar estruturas argumentativas em textos a partir da identificação dos componentes argumentativos e das relações entre eles. A identificação automática das estruturas pode ser considerada um problema pelo fato de não existirem padrões ou regras para esta etapa. Além disso, a escassez de trabalhos direcionados ao idioma português brasileiro dificulta tal atividade. Dessa forma, este trabalho propõe discutir e analisar a influência de léxicos argumentativos na etapa de identificação de argumentos em sentenças argumentativas. Para isto, foi utilizada a técnica de distância semântica WMD entre textos com a finalidade de analisar a presença de léxicos argumentativos em sentenças que contém
argumentatividade ou não. Este trabalho visa contribuir como uma análise exploratória entre diferentes tipos de léxicos argumentativos.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19923,"mineração de argumentos é uma área de pesquisa que visa identificar estruturas argumentativas em textos a partir da identificação dos componentes argumentativos e das relações entre eles. a identificação automática das estruturas pode ser considerada um problema pelo fato de não existirem padrões ou regras para esta etapa. além disso, a escassez de trabalhos direcionados ao idioma português brasileiro dificulta tal atividade. dessa forma, este trabalho propõe discutir e analisar a influência de léxicos argumentativos na etapa de identificação de argumentos em sentenças argumentativas. para isto, foi utilizada a técnica de distância semântica wmd entre textos com a finalidade de analisar a presença de léxicos argumentativos em sentenças que contém argumentatividade ou não. este trabalho visa contribuir como uma análise exploratória entre diferentes tipos de léxicos argumentativos."
381,2021,Aperfeiçoando o processo de classificação automática de questões de matemática quanto às competências do pensamento computacional.,"TAKEI NETO, Diego Eizi.","CAMPELO, Cláudio Elízio Calazans.","O pensamento computacional (PC) é um processo de raciocínio que consiste em formular um problema e sua solução em passos que um computador é capaz de realizar. Este processo é tão importante que autores o consideram como um potencializador das competências operacionais do ser humano, que pode ser usado em algumas vertentes, como por exemplo, no desenvolvimento interdisciplinar em disciplinas do ensino básico, tais como Matemática e Física, e no desenvolvimento a partir de disciplinas específicas da Ciência da Computação. No contexto da disciplina de Matemática, pode-se
relacionar uma questão dentre nove competências do pensamento computacional. Identificar questões que exploram estas competências pode ser extremamente útil para alunos e professores que possuem interesse em se aprofundar neste tema, pois o estímulo ao PC pode aumentar a capacidade de resolução de problemas. Neste
contexto, a concepção de modelos inteligentes capazes de predizer automaticamente competências do PC em questões de matemática seria um grande facilitador no processo de estímulo à resolução de problemas. Neste trabalho, utilizamos uma nova base de dados de questões para extrair características a partir de destaques atribuídos
às questões por avaliações manuais advindas de especialistas. A partir destas questões, foram desenvolvidos classificadores utilizando Term Frequency-Inverse Document Frequency (TF-IDF) e Latent Dirichlet Allocation (LDA) como características do modelo,
recalculando os valores destas características através do uso dos destaques, com o objetivo de aumentar a importância daqueles termos que pertencem ao trechos destacados pelos avaliadores, e com isso aumentar a eficácia da classificação de questões em relação às competências do pensamento computacional estimuladas.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19903,"o pensamento computacional (pc) é um processo de raciocínio que consiste em formular um problema e sua solução em passos que um computador é capaz de realizar. este processo é tão importante que autores o consideram como um potencializador das competências operacionais do ser humano, que pode ser usado em algumas vertentes, como por exemplo, no desenvolvimento interdisciplinar em disciplinas do ensino básico, tais como matemática e física, e no desenvolvimento a partir de disciplinas específicas da ciência da computação. no contexto da disciplina de matemática, pode-se relacionar uma questão dentre nove competências do pensamento computacional. identificar questões que exploram estas competências pode ser extremamente útil para alunos e professores que possuem interesse em se aprofundar neste tema, pois o estímulo ao pc pode aumentar a capacidade de resolução de problemas. neste contexto, a concepção de modelos inteligentes capazes de predizer automaticamente competências do pc em questões de matemática seria um grande facilitador no processo de estímulo à resolução de problemas. neste trabalho, utilizamos uma nova base de dados de questões para extrair características a partir de destaques atribuídos às questões por avaliações manuais advindas de especialistas. a partir destas questões, foram desenvolvidos classificadores utilizando term frequency-inverse document frequency (tf-idf) e latent dirichlet allocation (lda) como características do modelo, recalculando os valores destas características através do uso dos destaques, com o objetivo de aumentar a importância daqueles termos que pertencem ao trechos destacados pelos avaliadores, e com isso aumentar a eficácia da classificação de questões em relação às competências do pensamento computacional estimuladas."
382,2021,Analisando suítes de teste manuais e automáticas para identificar faltas de refatoramento.,"CORDEIRO, Cássio Eduardo Gabriel.","ALVES, Everton Leandro Galdino.","Desenvolver sistemas com alta qualidade envolve atividades que permitam fácil manutenção e forneçam confiança sobre o código produzido. Testes de software se relacionam com a confiabilidade, já refatoramentos, com manutenibilidade. Por definição, edições de refatoramento objetivam melhorar estrutura do código, mas preservando seu comportamento. Porém, refatoramentos mal feitos podem alterar o comportamento do sistema, são as chamadas faltas de refatoramento. Tais faltas, podem não ser detectadas por suítes de teste pouco confiáveis. Uma alternativa para criação sistemática de suítes de teste é a utilização de ferramentas de geração automática. Este trabalho tem como objetivo avaliar a efetividade de suítes de teste geradas manual e automaticamente para detectar faltas de refatoramento do tipo Extract Method. Para isso, foram selecionados
projetos escritos em Java, com suítes de teste geradas manualmente, novas suítes de testes foram criadas automaticamente com as ferramentas Randoop e EvoSuite, um conjunto de faltas foram injetadas nos sistemas. As suítes manuais detectaram 61,9% das faltas injetadas, enquanto a suíte Randoop detectou apenas 46,7% e a EvoSuite
55,8%. A Randoop obteve uma taxa de detecção baixa, a EvoSuite, no entanto, obteve um resultado significantemente comparável ao de suítes manuais.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19902,"desenvolver sistemas com alta qualidade envolve atividades que permitam fácil manutenção e forneçam confiança sobre o código produzido. testes de software se relacionam com a confiabilidade, já refatoramentos, com manutenibilidade. por definição, edições de refatoramento objetivam melhorar estrutura do código, mas preservando seu comportamento. porém, refatoramentos mal feitos podem alterar o comportamento do sistema, são as chamadas faltas de refatoramento. tais faltas, podem não ser detectadas por suítes de teste pouco confiáveis. uma alternativa para criação sistemática de suítes de teste é a utilização de ferramentas de geração automática. este trabalho tem como objetivo avaliar a efetividade de suítes de teste geradas manual e automaticamente para detectar faltas de refatoramento do tipo extract method. para isso, foram selecionados projetos escritos em java, com suítes de teste geradas manualmente, novas suítes de testes foram criadas automaticamente com as ferramentas randoop e evosuite, um conjunto de faltas foram injetadas nos sistemas. as suítes manuais detectaram , % das faltas injetadas, enquanto a suíte randoop detectou apenas , % e a evosuite , %. a randoop obteve uma taxa de detecção baixa, a evosuite, no entanto, obteve um resultado significantemente comparável ao de suítes manuais."
383,2021,Violência contra a mulher: análise comparativa de dados públicos antes e durante a pandemia de Covid-19.,"MONTENEGRO, Thiago Cunha.","MORAES, Fábio Jorge Almeida.","A violência contra a mulher é um problema de saúde pública, com índices alarmantes no Brasil. No contexto da pandemia de coronavírus, espera-se que tal problemática pode se agravar tendo em vista que as medidas de isolamento social, em que homens e mulheres estão convivendo por mais tempo em suas casas, podem tornar os lares com histórico de violência doméstica em um verdadeiro pesadelo para essas mulheres. Dados da ONU indicam, que durante este período de quarentena, os índices de violência doméstica aumentaram. Por este motivo, a partir da coleta de dados públicos, técnicas de análise e visualização de dados foram aplicadas para estudar os indicadores de violência contra a mulher antes e durante o período de isolamento social, com o objetivo de entender os impactos da pandemia de COVID-19 nos casos de violência contra a mulher no Brasil.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19900,"a violência contra a mulher é um problema de saúde pública, com índices alarmantes no brasil. no contexto da pandemia de coronavírus, espera-se que tal problemática pode se agravar tendo em vista que as medidas de isolamento social, em que homens e mulheres estão convivendo por mais tempo em suas casas, podem tornar os lares com histórico de violência doméstica em um verdadeiro pesadelo para essas mulheres. dados da onu indicam, que durante este período de quarentena, os índices de violência doméstica aumentaram. por este motivo, a partir da coleta de dados públicos, técnicas de análise e visualização de dados foram aplicadas para estudar os indicadores de violência contra a mulher antes e durante o período de isolamento social, com o objetivo de entender os impactos da pandemia de covid- nos casos de violência contra a mulher no brasil."
384,2021,Uso de business intelligence para avaliação de indicadores de desempenho na educação básica: um estudo de caso no Estado do Acre.,"WANDERLEY, Pedro Farias.","BAPTISTA, Cláudio de Souza.","Na área de educação, a quantidade massiva de dados que são pro duzidos anualmente é um ponto chave para o progresso deste segmento, que é tão importante para o desenvolvimento humano, econômico e social de uma nação. Sistemas de Apoio à Decisão,
principalmente os que utilizam técnicas de Business Intelligence (BI), têm um papel crucial na gestão, pois conseguem traduzir tais in formações para uma linguagem mais amigável e direta, facilitando os processos decisórios de gestores e levando informação para a população em geral. Neste trabalho, apresentamos uma solução de BI voltada para a construção de painéis de indicadores de de sempenho (KPI) que, de forma interativa, fornecem informações de desempenho escolar na educação básica em municípios do estado do Acre. Essa solução tem potencial para auxiliar os gestores na avaliação da eiciência e eicácia das políticas públicas educacionais implantadas, bem como para planejar novas diretrizes e ações para melhorar o desempenho na educação básica.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19899,"na área de educação, a quantidade massiva de dados que são pro duzidos anualmente é um ponto chave para o progresso deste segmento, que é tão importante para o desenvolvimento humano, econômico e social de uma nação. sistemas de apoio à decisão, principalmente os que utilizam técnicas de business intelligence (bi), têm um papel crucial na gestão, pois conseguem traduzir tais in formações para uma linguagem mais amigável e direta, facilitando os processos decisórios de gestores e levando informação para a população em geral. neste trabalho, apresentamos uma solução de bi voltada para a construção de painéis de indicadores de de sempenho (kpi) que, de forma interativa, fornecem informações de desempenho escolar na educação básica em municípios do estado do acre. essa solução tem potencial para auxiliar os gestores na avaliação da eiciência e eicácia das políticas públicas educacionais implantadas, bem como para planejar novas diretrizes e ações para melhorar o desempenho na educação básica."
385,2021,Classificação automática de questões conforme a Taxonomia de Bloom.,"DANTAS, Paulo Vitor Souto.","PIRES , Carlos Eduardo Santos.","A diversificação de dificuldade das questões propostas para alunos tem um impacto direto no seu processo de aprendizagem. Assim, o papel fundamental do professor é fornecer questões que provoquem o senso crítico dos alunos para o aprimoramento de suas
habilidades cognitivas. Portanto, uma taxonomia que visa auxiliar nesse processo, classificando o nível cognitivo exigido pelas questões, é a taxonomia de Bloom. Nesse contexto, a computação pode oferecer ferramentas para a classificação automática de questões de acordo com a taxonomia de Bloom, beneficiando professores e alunos. Embora existam trabalhos com o objetivo de criar classificadores automáticos para a taxonomia de Bloom, alguns algoritmos que utilizam técnicas de Gradient Boosting não são comumente utilizados para este processo. Portanto, este trabalho propõe a utilização dos algoritmos XGBoost e CatBoost para serem comparados com os algoritmos SVM e Random Forest no processo de classificação de questões. Além disso, propomos o uso de técnicas automáticas para aumentar o número de questões, classificadas de acordo com a taxonomia de Bloom, disponíveis na base de dados. Com isso, acreditamos que o resultado deste trabalho contribui para o aprimoramento dos modelos de classificação de questões.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19898,"a diversificação de dificuldade das questões propostas para alunos tem um impacto direto no seu processo de aprendizagem. assim, o papel fundamental do professor é fornecer questões que provoquem o senso crítico dos alunos para o aprimoramento de suas habilidades cognitivas. portanto, uma taxonomia que visa auxiliar nesse processo, classificando o nível cognitivo exigido pelas questões, é a taxonomia de bloom. nesse contexto, a computação pode oferecer ferramentas para a classificação automática de questões de acordo com a taxonomia de bloom, beneficiando professores e alunos. embora existam trabalhos com o objetivo de criar classificadores automáticos para a taxonomia de bloom, alguns algoritmos que utilizam técnicas de gradient boosting não são comumente utilizados para este processo. portanto, este trabalho propõe a utilização dos algoritmos xgboost e catboost para serem comparados com os algoritmos svm e random forest no processo de classificação de questões. além disso, propomos o uso de técnicas automáticas para aumentar o número de questões, classificadas de acordo com a taxonomia de bloom, disponíveis na base de dados. com isso, acreditamos que o resultado deste trabalho contribui para o aprimoramento dos modelos de classificação de questões."
386,2021,Gaja: responsabilidade social é o que se espera de todos.,"FIGUEIRÊDO FILHO, Francisco Angelim de.","PIRES, Carlos Eduardo Santos.","Trabalhos voluntários são atividades prestadas à sociedade sem recebimento de qualquer
remuneração ou lucro. Este tipo de atividade ainda é pouco praticada pela população brasileira. Logo, uma aplicação (sistema) com o objetivo de facilitar e incentivar a busca destas atividades pode ser considerada uma solução para amenizar este problema. Neste trabalho, propomos uma aplicação na qual usuários podem cadastrar atividades voluntárias. Como resultado, essas atividades ficam disponíveis para que voluntários possam se engajar. As atividades podem ser encontradas mediante buscas (consultas) por trabalhos próximos à localização do voluntário e compatíveis com as suas habilidades e interesses. Por fim, realizamos um experimento com o intuito de analisar a usabilidade e qualidade da solução proposta. A partir do resultado deste, observamos um nível de satisfação positivo quanto ao uso da aplicação.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19894,"trabalhos voluntários são atividades prestadas à sociedade sem recebimento de qualquer remuneração ou lucro. este tipo de atividade ainda é pouco praticada pela população brasileira. logo, uma aplicação (sistema) com o objetivo de facilitar e incentivar a busca destas atividades pode ser considerada uma solução para amenizar este problema. neste trabalho, propomos uma aplicação na qual usuários podem cadastrar atividades voluntárias. como resultado, essas atividades ficam disponíveis para que voluntários possam se engajar. as atividades podem ser encontradas mediante buscas (consultas) por trabalhos próximos à localização do voluntário e compatíveis com as suas habilidades e interesses. por fim, realizamos um experimento com o intuito de analisar a usabilidade e qualidade da solução proposta. a partir do resultado deste, observamos um nível de satisfação positivo quanto ao uso da aplicação."
387,2021,Pygrid: uma plataforma descentralizada para computação confidencial e aprendizagem de máquina federada.,"COSTA JÚNIOR, Ionésio Lima da.","MARINHO, Leandro Balby.","A preocupação com segurança e privacidade de dados tornou-se tema recorrente em
diferentes esferas sociais e tecnológicas, sendo amplamente debatida por companhias e órgãos governamentais na busca por alternativas que assegurem tais direitos. Diante disso, este trabalho tem por objetivo, contribuir na construção de soluções aplicadas à preservação e privacidade de dados, auxiliando no desenvolvimento de uma plataforma ""open-source"" para computação confidencial e aprendizagem de máquina federada.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19893,"a preocupação com segurança e privacidade de dados tornou-se tema recorrente em diferentes esferas sociais e tecnológicas, sendo amplamente debatida por companhias e órgãos governamentais na busca por alternativas que assegurem tais direitos. diante disso, este trabalho tem por objetivo, contribuir na construção de soluções aplicadas à preservação e privacidade de dados, auxiliando no desenvolvimento de uma plataforma ""open-source"" para computação confidencial e aprendizagem de máquina federada."
388,2021,TDD: um estudo de caso sobre sua utilização nos projetos de desenvolvimento de software.,"SOUSA, Rubens Batista Araújo de.","SABINO, Melina Mongiovi Cunha Lima.","O Test Driven Development (TDD) é uma prática considerada por muitos de grande importância no desenvolvimento de um software, deixando claro as regras de negócio antes mesmo de se iniciar o desenvolvimento e ajudando na construção de um código
limpo e de melhor qualidade. Porém, mesmo com todos os seus benefícios, muitos desenvolvedores preferem não utilizar esta metodologia nos seus projetos. Neste estudo irei analisar o atual cenário da utilização do TDD nos projetos de software e quais são
os principais motivos que levam os desenvolvedores a não utilizarem a prática nos seus projetos. O estudo foi realizado por meio de um questionário com 101 programadores de 43 empresas, que utilizam ou já utilizaram o TDD na prática ou que possuem pelo menos conhecimento teórico sobre o assunto. Os resultados mostraram uma baixa aceitação do TDD por parte dos participantes e foi observado que o acréscimo de tempo no
desenvolvimento é o principal motivador que leva os desenvolvedores a desistirem de empregar a prática.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19887,"o test driven development (tdd) é uma prática considerada por muitos de grande importância no desenvolvimento de um software, deixando claro as regras de negócio antes mesmo de se iniciar o desenvolvimento e ajudando na construção de um código limpo e de melhor qualidade. porém, mesmo com todos os seus benefícios, muitos desenvolvedores preferem não utilizar esta metodologia nos seus projetos. neste estudo irei analisar o atual cenário da utilização do tdd nos projetos de software e quais são os principais motivos que levam os desenvolvedores a não utilizarem a prática nos seus projetos. o estudo foi realizado por meio de um questionário com programadores de empresas, que utilizam ou já utilizaram o tdd na prática ou que possuem pelo menos conhecimento teórico sobre o assunto. os resultados mostraram uma baixa aceitação do tdd por parte dos participantes e foi observado que o acréscimo de tempo no desenvolvimento é o principal motivador que leva os desenvolvedores a desistirem de empregar a prática."
389,2021,Lei geral de proteção de dados: uma análise sobre os direitos dos titulares e os deveres das organizações perante a lei.,"BENEDITO, Matheus Braga.","NICOLLETTI, Pedro Sergio.","Com o intuito de criar um amparo legal quanto à privacidade e à proteção de dados pessoais digitais de usuários na internet, foi criada a Lei Geral de Proteção de Dados, que regula todo tratamento de dados de cidadãos brasileiros dentro e fora do Brasil. 
Este trabalho se propõe a apresentar uma análise sobre os principais pontos do conjunto normativo da lei, numa abordagem voltada aos direitos dos titulares, práticas de segurança e governança que desenvolvedores e empresas devem adotar para garantir 
conformidade com as propostas da lei, por meio de uma pesquisa ampla utilizando além do texto integral da lei, artigos científicos em áreas correlacionadas e informações dispostas em sites governamentais, com o objetivo de relacionar o que foi proposto 
em lei com a prática do ponto de vista do usuário e organizações.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19884,"com o intuito de criar um amparo legal quanto à privacidade e à proteção de dados pessoais digitais de usuários na internet, foi criada a lei geral de proteção de dados, que regula todo tratamento de dados de cidadãos brasileiros dentro e fora do brasil. este trabalho se propõe a apresentar uma análise sobre os principais pontos do conjunto normativo da lei, numa abordagem voltada aos direitos dos titulares, práticas de segurança e governança que desenvolvedores e empresas devem adotar para garantir conformidade com as propostas da lei, por meio de uma pesquisa ampla utilizando além do texto integral da lei, artigos científicos em áreas correlacionadas e informações dispostas em sites governamentais, com o objetivo de relacionar o que foi proposto em lei com a prática do ponto de vista do usuário e organizações."
390,2021,Aprendizagem de máquina aplicada ao monitoramento da presença de animais em reservas naturais de ambientes industriais.,"SILVA, Vinícius Jorge Pereira da.","ARAÚJO, Joseana Macêdo Fechine Régis de.","Diversas indústrias brasileiras consomem diariamente recursos naturais. Algumas delas possuem suas próprias regiões de reservas ambientais. Nesse contexto, essas indústrias objetivam continuamente prover proteção para os seus recursos. Contudo, um complicador presente na maioria desses espaços, são os animais. Seus hábitos por vezes acarretam na danificação dessas áreas. Nesse sentido, este artigo tem como proposta, o monitoramento da presença dos animais nos ambientes de reservas naturais de ambientes industriais. Para tanto, foram utilizadas técnicas de processamento digital de imagens para identificação da presença de animais nesses ambientes. Em virtude da impossibilidade momentânea de aquisição de imagens em um ambiente industrial, o trabalho apresenta uma prova de conceito, com aquisição dos dados a partir de uma base de dados pública. Para identificação das imagens de animais foram utilizadas redes de aprendizagem profunda. A abordagem apresentada possibilitou a identificação de animais de diferentes portes e espécies, com acurácia relevante em comparação com
outras pesquisas similares. Esses resultados permitem validar a metodologia proposta, possibilitando a sua instalação em um ambiente industrial, de forma a realizar o monitoramento da presença de animais .",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19834,"diversas indústrias brasileiras consomem diariamente recursos naturais. algumas delas possuem suas próprias regiões de reservas ambientais. nesse contexto, essas indústrias objetivam continuamente prover proteção para os seus recursos. contudo, um complicador presente na maioria desses espaços, são os animais. seus hábitos por vezes acarretam na danificação dessas áreas. nesse sentido, este artigo tem como proposta, o monitoramento da presença dos animais nos ambientes de reservas naturais de ambientes industriais. para tanto, foram utilizadas técnicas de processamento digital de imagens para identificação da presença de animais nesses ambientes. em virtude da impossibilidade momentânea de aquisição de imagens em um ambiente industrial, o trabalho apresenta uma prova de conceito, com aquisição dos dados a partir de uma base de dados pública. para identificação das imagens de animais foram utilizadas redes de aprendizagem profunda. a abordagem apresentada possibilitou a identificação de animais de diferentes portes e espécies, com acurácia relevante em comparação com outras pesquisas similares. esses resultados permitem validar a metodologia proposta, possibilitando a sua instalação em um ambiente industrial, de forma a realizar o monitoramento da presença de animais ."
391,2021,Shape-sorter: uma ferramenta de linha de comando para automação de criação e manutenção de micro frontends.,"MORAIS, Hebert Lucas de Lima.","MONTEIRO, João Arthur Brunet.","Visto que houve uma crescente popularização na arquitetura de microsserviços, que são
majoritariamente implementados no backend, observou-se a possibilidade da sua
implementação no frontend, concebendo-se o termo micro frontends. Apesar de micro
frontends ser um termo conhecido, sua proposta ainda está sendo difundida entre a
comunidade e o mercado. Sendo assim, ainda não existem ferramentas de fácil utilização
que auxiliem os desenvolvedores a implementarem a infraestrutura de micro frontends de forma otimizada. Para solucionar esse problema foi criado uma ferramenta de CLI que busca auxiliar os desenvolvedores a criarem e manterem seus micro frontends de
forma interativa em seus terminais, criando componentes compartilhados de forma
automática, e permitindo que as configurações sejam criadas sem que haja uma pesquisa
aprofundada ou um conhecimento técnico específico sobre o tema.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19815,"visto que houve uma crescente popularização na arquitetura de microsserviços, que são majoritariamente implementados no backend, observou-se a possibilidade da sua implementação no frontend, concebendo-se o termo micro frontends. apesar de micro frontends ser um termo conhecido, sua proposta ainda está sendo difundida entre a comunidade e o mercado. sendo assim, ainda não existem ferramentas de fácil utilização que auxiliem os desenvolvedores a implementarem a infraestrutura de micro frontends de forma otimizada. para solucionar esse problema foi criado uma ferramenta de cli que busca auxiliar os desenvolvedores a criarem e manterem seus micro frontends de forma interativa em seus terminais, criando componentes compartilhados de forma automática, e permitindo que as configurações sejam criadas sem que haja uma pesquisa aprofundada ou um conhecimento técnico específico sobre o tema."
392,2021,Uma análise sobre o acoplamento em atividades dos alunos da disciplina de programação OO,"COSTA, Amanda Vivian Alves de Luna e.","REGO , Matheus Gaudêncio do.","Um código de boa qualidade pode ser considerado uma propriedade essencial do software. Se a qualidade do código não for boa o suficiente, pode haver perda financeira ou perda de
tempo devido a manutenção, modificações ou ajustes. Neste estudo, usaremos o CodeMR Um plugin que realiza análise de código para extrair mais informações sobre a aplicação, com foco em design e acoplamento. Com a métrica CBO(Coupling Between Objects), utilizada para medir acoplamento, avaliamos o impacto do agrupamento na nota e encontramos que o valor de CBO não influencia nas notas de design e possui uma influência moderada na nota geral.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19812,"um código de boa qualidade pode ser considerado uma propriedade essencial do software. se a qualidade do código não for boa o suficiente, pode haver perda financeira ou perda de tempo devido a manutenção, modificações ou ajustes. neste estudo, usaremos o codemr um plugin que realiza análise de código para extrair mais informações sobre a aplicação, com foco em design e acoplamento. com a métrica cbo(coupling between objects), utilizada para medir acoplamento, avaliamos o impacto do agrupamento na nota e encontramos que o valor de cbo não influencia nas notas de design e possui uma influência moderada na nota geral."
393,2021,Anima: uma técnica para criar animações a partir de imagens estáticas em jogos.,"MORAIS, Thomas Diniz Pinto de.","BARROS, Marcelo Alves de.","Um dos desafios na criação de jogos digitais é tornar os gráficos de um jogo o mais atrativo possível para os seus jogadores. Desta forma, para fazer um produto de sucesso, é necessário investir tempo e recursos para tornar os gráficos atrativos aos potenciais
jogadores. Uma API (Application Programming Interface) comum em jogos é a OpenGL [1] que é utilizada para renderizar gráficos em 2D e 3D. Desenvolvedores interagem com a GPU usando as funções da OpenGL e os comandos da GLSL [1] (OpenGL Shading Language). Neste trabalho, criamos e descrevemos uma técnica de distorção para transformar imagens estáticas em animações, focando em simular o efeito das imperfeições de animações feitas à mão. Além disso, avaliamos a técnica através de uma pesquisa utilizando uma versão modificada de um jogo comercial que estamos desenvolvendo e descobrimos que dos entrevistados 96.7% preferem imagens com a técnica sendo aplicada e 93.3% responderam que se sentem mais confiantes ao
desenharem com a técnica sendo aplicada.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19806,"um dos desafios na criação de jogos digitais é tornar os gráficos de um jogo o mais atrativo possível para os seus jogadores. desta forma, para fazer um produto de sucesso, é necessário investir tempo e recursos para tornar os gráficos atrativos aos potenciais jogadores. uma api (application programming interface) comum em jogos é a opengl [ ] que é utilizada para renderizar gráficos em 2d e 3d. desenvolvedores interagem com a gpu usando as funções da opengl e os comandos da glsl [ ] (opengl shading language). neste trabalho, criamos e descrevemos uma técnica de distorção para transformar imagens estáticas em animações, focando em simular o efeito das imperfeições de animações feitas à mão. além disso, avaliamos a técnica através de uma pesquisa utilizando uma versão modificada de um jogo comercial que estamos desenvolvendo e descobrimos que dos entrevistados . % preferem imagens com a técnica sendo aplicada e . % responderam que se sentem mais confiantes ao desenharem com a técnica sendo aplicada."
394,2021,Hall das placas virtual: uma alternativa para placas de formaturas físicas.,"DELA BIANCA, Mariana Marques dos Santos.","CAMPOS, Lívia Maria Rodrigues Sampaio.","A placa de formatura consiste em uma placa com informações sobre uma turma de concluintes de um curso em um certo ano ou período. Elas são expostas nos prédios das instituições de ensino, e, por conta disso, o espaço para alocá-las torna-se escasso com o passar do tempo. Dessa forma, é importante que haja uma solução que não
necessite o uso de espaços físicos, já que estes são limitados. Este trabalho tem como objetivo o desenvolvimento de uma aplicação web para a criação e exposição de placas de formatura virtuais, visando reduzir o número de placas expostas em espaços físicos, a
redução de custos, trazer maior praticidade no momento de criá-las e também transportar essa mídia para o formato digital. Os resultados obtidos demonstram que os usuários ficaram satisfeitos com a usabilidade do sistema, mas ainda há pontos a serem melhorados.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19796,"a placa de formatura consiste em uma placa com informações sobre uma turma de concluintes de um curso em um certo ano ou período. elas são expostas nos prédios das instituições de ensino, e, por conta disso, o espaço para alocá-las torna-se escasso com o passar do tempo. dessa forma, é importante que haja uma solução que não necessite o uso de espaços físicos, já que estes são limitados. este trabalho tem como objetivo o desenvolvimento de uma aplicação web para a criação e exposição de placas de formatura virtuais, visando reduzir o número de placas expostas em espaços físicos, a redução de custos, trazer maior praticidade no momento de criá-las e também transportar essa mídia para o formato digital. os resultados obtidos demonstram que os usuários ficaram satisfeitos com a usabilidade do sistema, mas ainda há pontos a serem melhorados."
395,2021,Um estudo qualitativo sobre propriedades de liderança e seus efeitos em desenvolvedores de software.,"CHAVES, Rafaella Priscilla Evangelista.","MASSONI, Tiago Lima.","Desenvolvedores de software podem vir a deixar seus empregos atuais devido a vários fatores como oportunidades melhores que surgem ou impactos causados por relacionamentos com colegas no ambiente de trabalho. Este trabalho tem como objetivo analisar esses relacionamentos, principalmente no que diz respeito à influência das lideranças nas equipes de desenvolvimento de software. Para isso, foram entrevistados sete desenvolvedores, ocupando cargos de liderança, ou não, a fim de identificar quais fatores podem motivar um desenvolvedor a permanecer ou deixar uma equipe de software, ou mesmo a empresa em que trabalha.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19785,"desenvolvedores de software podem vir a deixar seus empregos atuais devido a vários fatores como oportunidades melhores que surgem ou impactos causados por relacionamentos com colegas no ambiente de trabalho. este trabalho tem como objetivo analisar esses relacionamentos, principalmente no que diz respeito à influência das lideranças nas equipes de desenvolvimento de software. para isso, foram entrevistados sete desenvolvedores, ocupando cargos de liderança, ou não, a fim de identificar quais fatores podem motivar um desenvolvedor a permanecer ou deixar uma equipe de software, ou mesmo a empresa em que trabalha."
396,2021,"Controle de acesso a ambiente restrito, a partir da identidade vocal, utilizando coeficientes MFCC e classificador K-means.","AZEVEDO, Gabriel Almeida.","ARAÚJO, Joseana Macêdo Fechine Régis de.","A área de aprendizagem de máquina é uma grande aliada para garantir privacidade e segurança, pois promove avanços nos métodos empregados para controle de acesso. O uso de técnicas para Reconhecimento Automático da Identidade Vocal de Locutores, para fins de autenticação, representa um desses avanços. Diante do exposto, este artigo objetiva apresentar um sistema para verificação automática da identidade vocal de locutores, buscando aplicá-lo para autenticação e liberação de acesso a ambiente restrito. O sistema baseia-se numa tarefa de reconhecimento de padrões, dividida em duas etapas: treinamento
e verificação. No treinamento, foram aplicadas técnicas para pré-processamento do sinal (pré-ênfase, divisão em frames e janelamento), extração de características (Mel-Frequency Cepstral Coefficients - MFCC) e construção de um padrão representativo da identidade vocal de cada locutor (clusterização). Na verificação, ocorreram o pré-processamento do sinal, extração de características e autenticação, esta última a partir da comparação entre as características de teste e o padrão previamente armazenado do locutor. Na lógica de decisão, foram utilizados limiares para autenticação de um locutor (aceitação, rejeição e
indeterminação). Os resultados obtidos demonstram uma autenticação correta do locutor em 81% dos casos e uma taxa de 94,89% de rejeição de impostores, comprovando a eficiência da abordagem proposta.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19780,"a área de aprendizagem de máquina é uma grande aliada para garantir privacidade e segurança, pois promove avanços nos métodos empregados para controle de acesso. o uso de técnicas para reconhecimento automático da identidade vocal de locutores, para fins de autenticação, representa um desses avanços. diante do exposto, este artigo objetiva apresentar um sistema para verificação automática da identidade vocal de locutores, buscando aplicá-lo para autenticação e liberação de acesso a ambiente restrito. o sistema baseia-se numa tarefa de reconhecimento de padrões, dividida em duas etapas: treinamento e verificação. no treinamento, foram aplicadas técnicas para pré-processamento do sinal (pré-ênfase, divisão em frames e janelamento), extração de características (mel-frequency cepstral coefficients - mfcc) e construção de um padrão representativo da identidade vocal de cada locutor (clusterização). na verificação, ocorreram o pré-processamento do sinal, extração de características e autenticação, esta última a partir da comparação entre as características de teste e o padrão previamente armazenado do locutor. na lógica de decisão, foram utilizados limiares para autenticação de um locutor (aceitação, rejeição e indeterminação). os resultados obtidos demonstram uma autenticação correta do locutor em % dos casos e uma taxa de , % de rejeição de impostores, comprovando a eficiência da abordagem proposta."
397,2021,Car security: plataforma web para monitoramento de placas veiculares.,"COSTA, Marcus Vinícius Leite.","MARINHO, Leandro Balby.","Esse trabalho consiste em fornecer um sistema web de detecção de placas veiculares em tempo real utilizando algoritmos de aprendizado de máquina. Com isso, propõe-se o Car Security, uma plataforma cujo objetivo é fornecer serviços voltados ao monitoramento de
placas veiculares. Além do monitoramento, a plataforma fornece um ferramental de consulta de situação para as placas detectadas, a fim de entregar um sistema completo para quem deseja implementar uma solução de segurança veicular automática em sua localidade. Espera-se que com esse trabalho, seja possível com que universidades, prédios ou quaisquer outros estabelecimentos implementem uma solução de segurança sem burocracia.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19779,"esse trabalho consiste em fornecer um sistema web de detecção de placas veiculares em tempo real utilizando algoritmos de aprendizado de máquina. com isso, propõe-se o car security, uma plataforma cujo objetivo é fornecer serviços voltados ao monitoramento de placas veiculares. além do monitoramento, a plataforma fornece um ferramental de consulta de situação para as placas detectadas, a fim de entregar um sistema completo para quem deseja implementar uma solução de segurança veicular automática em sua localidade. espera-se que com esse trabalho, seja possível com que universidades, prédios ou quaisquer outros estabelecimentos implementem uma solução de segurança sem burocracia."
398,2021,Sistema para itens achados e perdidos usando ferramenta de comparação de texto – me acher.,"ANIBAL, Wesley Gonçalves.","RÊGO, Matheus Gaudencio do.","Atualmente um dos problemas, não só da UFCG, como também de diversos ambientes públicos, é o controle de itens perdidos. A ausência de um controle, gera mais trabalho aos funcionários da universidade, onde na maioria dos casos deixam o item guardado e esperam um parecer do dono confiando naqueles que se apresentam como donos. Este trabalho compreende o desenvolvimento de um sistema de achados e perdidos, denominado Me Acher, onde o usuário poderá cadastrar itens que foram encontrados e pesquisar por itens perdidos, onde o sistema realizará pareamento automático de ambas descrições, e retornará o item com maior probabilidade de ser o que está sendo procurado.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19758,"atualmente um dos problemas, não só da ufcg, como também de diversos ambientes públicos, é o controle de itens perdidos. a ausência de um controle, gera mais trabalho aos funcionários da universidade, onde na maioria dos casos deixam o item guardado e esperam um parecer do dono confiando naqueles que se apresentam como donos. este trabalho compreende o desenvolvimento de um sistema de achados e perdidos, denominado me acher, onde o usuário poderá cadastrar itens que foram encontrados e pesquisar por itens perdidos, onde o sistema realizará pareamento automático de ambas descrições, e retornará o item com maior probabilidade de ser o que está sendo procurado."
399,2021,Meu MicroEmpreendimento: sistema de gestão de fluxo de caixa.,"DUARTE, Lucas Venancio.","GUERRERO, Dalton Dario Serey.","Segundo dados oficiais, o número total de registros de microempreendedores individuais
(MEIs) no Brasil ultrapassou pela primeira vez a marca de 10 milhões nos 4 primeiros meses de 2020 [1], muitos desses novos e mesmo os antigos empreendedores enfrentam dificuldades na hora de gerenciar o fluxo de caixa, além de contabilizar o
estoque e as vendas. A partir desses problemas, o trabalho apresentado neste documento se propôs a desenvolver um sistema capaz de amenizar os problemas enfrentados nesse contexto. O sistema que foi desenvolvido, auxilia e contribui para
melhorar o gerenciamento de microempresas, além de ser fácil e simples seu uso, como também, promover o incentivo ao uso mais tecnologia em pequenas empresas.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19757,"segundo dados oficiais, o número total de registros de microempreendedores individuais (meis) no brasil ultrapassou pela primeira vez a marca de milhões nos primeiros meses de [ ], muitos desses novos e mesmo os antigos empreendedores enfrentam dificuldades na hora de gerenciar o fluxo de caixa, além de contabilizar o estoque e as vendas. a partir desses problemas, o trabalho apresentado neste documento se propôs a desenvolver um sistema capaz de amenizar os problemas enfrentados nesse contexto. o sistema que foi desenvolvido, auxilia e contribui para melhorar o gerenciamento de microempresas, além de ser fácil e simples seu uso, como também, promover o incentivo ao uso mais tecnologia em pequenas empresas."
400,2021,Reconhecimento automático de temas abordados e desvios temáticos em comissões da Câmara dos Deputados.,"SANTOS, Matheus Alves dos.","ANDRADE, Nazareno Ferreira de.","O acesso à informação é imprescindível para a construção de uma sociedade politicamente participativa. No Brasil, são numerosas as iniciativas que visam garantir transparência às ações do Poder Legislativo. Contudo, as comissões do Congresso Nacional ainda recebem apenas uma fração da atenção midiática dedicada aos plenários. Esse cenário é prejudicial à sociedade civil, uma vez que as comissões são o verdadeiro palco dos embates e discussões políticas dos parlamentares brasileiros. Utilizando técnicas de Processamento
de Linguagem Natural, especialmente o modelo estatístico generativo Latent Dirichlet Allocation (LDA), este trabalho descreve uma abordagem para reconhecimento automático dos temas abordados e dos desvios temáticos em eventos das comissões permanentes da
Câmara dos Deputados. Os resultados obtidos comprovam a aplicabilidade desse modelo estatístico no acompanhamento dos debates políticos vigentes, definindo tópicos latentes alinhados aos temas das comissões e permitindo a detecção do conjunto de eventos cujos
debates foram afetados por desvios temáticos.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19755,"o acesso à informação é imprescindível para a construção de uma sociedade politicamente participativa. no brasil, são numerosas as iniciativas que visam garantir transparência às ações do poder legislativo. contudo, as comissões do congresso nacional ainda recebem apenas uma fração da atenção midiática dedicada aos plenários. esse cenário é prejudicial à sociedade civil, uma vez que as comissões são o verdadeiro palco dos embates e discussões políticas dos parlamentares brasileiros. utilizando técnicas de processamento de linguagem natural, especialmente o modelo estatístico generativo latent dirichlet allocation (lda), este trabalho descreve uma abordagem para reconhecimento automático dos temas abordados e dos desvios temáticos em eventos das comissões permanentes da câmara dos deputados. os resultados obtidos comprovam a aplicabilidade desse modelo estatístico no acompanhamento dos debates políticos vigentes, definindo tópicos latentes alinhados aos temas das comissões e permitindo a detecção do conjunto de eventos cujos debates foram afetados por desvios temáticos."
401,2021,Sistema de hardware e software para monitoramento estrutural de edificações.,"VITORINO, Marcelo Gabriel dos Santos Queiroz.","ARAÚJO, Joseana Macêdo Fechine Régis de.","O monitoramento estrutural (Structural Health Monitoring - SHM) é feito com o objetivo de manter a confiabilidade de segurança da construção durante sua utilização, e identificar
antecipadamente possíveis problemas que danifiquem as estruturas. De maneira geral, um SHM dinâmico convencional é composto por acelerômetros, sistemas de aquisição de sinais e softwares de visualização. Entretanto, essas soluções possuem um alto custo, sobretudo no que diz respeito ao hardware que compõe um SHM, o que dificulta a popularização desse tipo de monitoramento. Neste trabalho, foi desenvolvida uma solução hardware-software para monitoramento estrutural, cujos dados de aceleração são coletados a partir de um acelerômetro, processados em uma placa NodeMCU, transmitidos via wireless, para um servidor que exibe em um Dashboard os dados do
monitoramento. A solução foi avaliada a partir do funcionamento adequado dos módulos de aquisição, processamento, transmissão e exibição. O sistema foi apresentado a professores de Engenharia Civil da Universidade Federal de Campina Grande, os quais
relataram o alto potencial da solução para utilização em projetos com edificações reais.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19754,"o monitoramento estrutural (structural health monitoring - shm) é feito com o objetivo de manter a confiabilidade de segurança da construção durante sua utilização, e identificar antecipadamente possíveis problemas que danifiquem as estruturas. de maneira geral, um shm dinâmico convencional é composto por acelerômetros, sistemas de aquisição de sinais e softwares de visualização. entretanto, essas soluções possuem um alto custo, sobretudo no que diz respeito ao hardware que compõe um shm, o que dificulta a popularização desse tipo de monitoramento. neste trabalho, foi desenvolvida uma solução hardware-software para monitoramento estrutural, cujos dados de aceleração são coletados a partir de um acelerômetro, processados em uma placa nodemcu, transmitidos via wireless, para um servidor que exibe em um dashboard os dados do monitoramento. a solução foi avaliada a partir do funcionamento adequado dos módulos de aquisição, processamento, transmissão e exibição. o sistema foi apresentado a professores de engenharia civil da universidade federal de campina grande, os quais relataram o alto potencial da solução para utilização em projetos com edificações reais."
402,2021,Mineração de poemas através de técnicas de processamento de linguagem natural.,"ARAÚJO JUNIOR, José Robson da Silva.","CAMPOS, Lívia Maria Rodrigues Sampaio.","O contato com poemas na educação básica é um incentivo para que os alunos descubram o prazer proporcionado pela experiência com a linguagem poética. O Projeto Coletânea de Poesias, realizado anualmente no FERA Colégio e Curso, é uma iniciativa que se propõe a promover esse contato através da leitura, apreciação e escrita de poemas, gerando a cada ano um livro com textos redigidos por alunos dos ensinos fundamental e médio. Como a análise desses poemas seria custosa se feita manualmente, o presente trabalho empregou técnicas de Processamento de Linguagem Natural, como Part-of-Speech tagging e modelagem de tópicos, a fim de fazer a
mineração dos textos produzidos nas dez edições mais recentes do projeto. Os resultados obtidos reforçam aspectos ligados à liberdade de criação envolvida na produção poética e que os temas abordados pelos alunos variam de acordo com a sua maturidade e o seu ambiente.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19712,"o contato com poemas na educação básica é um incentivo para que os alunos descubram o prazer proporcionado pela experiência com a linguagem poética. o projeto coletânea de poesias, realizado anualmente no fera colégio e curso, é uma iniciativa que se propõe a promover esse contato através da leitura, apreciação e escrita de poemas, gerando a cada ano um livro com textos redigidos por alunos dos ensinos fundamental e médio. como a análise desses poemas seria custosa se feita manualmente, o presente trabalho empregou técnicas de processamento de linguagem natural, como part-of-speech tagging e modelagem de tópicos, a fim de fazer a mineração dos textos produzidos nas dez edições mais recentes do projeto. os resultados obtidos reforçam aspectos ligados à liberdade de criação envolvida na produção poética e que os temas abordados pelos alunos variam de acordo com a sua maturidade e o seu ambiente."
403,2021,Fracasso em projeto de software: um estudo de caso com um projeto de sistema WEB.,"COSTA, João Pedro Travassos.","MASSONI, Tiago Lima.","Fracassos em projetos de desenvolvimento de software se tornaram comuns. No dia a dia podemos observar a recorrência dessas falhas ao ler jornais, artigos, livros e sites sobre tecnologia. Esses erros são definidos em termos de atrasos das entregas, aumento dos custos e não cumprimento dos objetivos de negócios. Muitos projetos acabam sendo cancelados ou então geram muito mais despesas e consequências negativas para as empresas. Raramente, são observadas as perspectivas dos desenvolvedores que trabalharam nesses projetos. O estudo de caso presente provê as percepções dos desenvolvedores sobre um projeto de software com conclusões mistas sobre seu sucesso. Foram realizadas entrevistas com os mesmos e foi feita uma análise com base nas perspectivas dos entrevistados e o que dizem as literaturas sobre os temas abordados. O estudo mostra diversos pontos das impressões dos entrevistados sobre o que ocorreu durante o processo de desenvolvimento.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19711,"fracassos em projetos de desenvolvimento de software se tornaram comuns. no dia a dia podemos observar a recorrência dessas falhas ao ler jornais, artigos, livros e sites sobre tecnologia. esses erros são definidos em termos de atrasos das entregas, aumento dos custos e não cumprimento dos objetivos de negócios. muitos projetos acabam sendo cancelados ou então geram muito mais despesas e consequências negativas para as empresas. raramente, são observadas as perspectivas dos desenvolvedores que trabalharam nesses projetos. o estudo de caso presente provê as percepções dos desenvolvedores sobre um projeto de software com conclusões mistas sobre seu sucesso. foram realizadas entrevistas com os mesmos e foi feita uma análise com base nas perspectivas dos entrevistados e o que dizem as literaturas sobre os temas abordados. o estudo mostra diversos pontos das impressões dos entrevistados sobre o que ocorreu durante o processo de desenvolvimento."
404,2021,Reconhecimento de mensagens com teor transfóbico no twitter.,"BARBOSA, Iann Carvalho.","MONTEIRO, João Arthur Brunet.","Com o desenvolvimento da tecnologia, gerou-se uma expansão no uso de redes sociais, facilitando assim, a comunicação entre os indivíduos. Porém, alguns usam dessa liberdade como uma ferramenta para disseminar discursos de ódio a minorias sociais, em alguns casos configurando-se no crime de transfobia. Como a maioria dessas redes não passa por filtros sociais, conteúdos criminosos não recebem denúncias e ficam impunes. Nesse
contexto, o objetivo deste trabalho é utilizar estratégias de aprendizagem de máquina para identificar mensagens transfóbicas no Twitter.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19708,"com o desenvolvimento da tecnologia, gerou-se uma expansão no uso de redes sociais, facilitando assim, a comunicação entre os indivíduos. porém, alguns usam dessa liberdade como uma ferramenta para disseminar discursos de ódio a minorias sociais, em alguns casos configurando-se no crime de transfobia. como a maioria dessas redes não passa por filtros sociais, conteúdos criminosos não recebem denúncias e ficam impunes. nesse contexto, o objetivo deste trabalho é utilizar estratégias de aprendizagem de máquina para identificar mensagens transfóbicas no twitter."
405,2021,Geração de eventos dinâmicos para jogos digitais: uma abordagem sistêmica.,"ALMEIDA, João Marcos Aristides.","GOMES, Herman Martins.","A experiência do jogador é um importante fator no desenvolvimento de jogos e precisa ser instigada sempre. Cria atividades diversificadas no jogo que reforcem esse fator é fundamental para agregar valor e coerência ao jogo, assim como fomentar que jogadores voltem a experimentá-lo. No entanto, a geração manual deste tipo de conteúdo é custosa e pode resultar em divergência da experiência projetada. Dessa forma, utilizar eventos dinâmicos se torna uma estratégia interessante para permitir uma diversidade coerente, pois são atividades em constante alteração pela interação com os sistemas do jogo. Neste
contexto, a técnica de design sistêmico aplicada a jogos se mostra uma abordagem promissora, pois utiliza a interação entre os próprios sistemas do jogo para criar a experiência do jogador. Assim, este trabalho propõe um modelo para a geração de eventos
dinâmicos utilizando o design sistêmico como fundamento. Para isso, a abstração de um jogo digital foi criada para demonstrar tal modelo. A abstração é dividida em sistemas simples, que utilizam a interação de suas propriedades e atributos para criar atividades
variadas e coerentes. O modelo foi testado e resultados mostram que quanto mais eventos são gerados, menor é a taxa de dissimilaridade entre eles.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19707,"a experiência do jogador é um importante fator no desenvolvimento de jogos e precisa ser instigada sempre. cria atividades diversificadas no jogo que reforcem esse fator é fundamental para agregar valor e coerência ao jogo, assim como fomentar que jogadores voltem a experimentá-lo. no entanto, a geração manual deste tipo de conteúdo é custosa e pode resultar em divergência da experiência projetada. dessa forma, utilizar eventos dinâmicos se torna uma estratégia interessante para permitir uma diversidade coerente, pois são atividades em constante alteração pela interação com os sistemas do jogo. neste contexto, a técnica de design sistêmico aplicada a jogos se mostra uma abordagem promissora, pois utiliza a interação entre os próprios sistemas do jogo para criar a experiência do jogador. assim, este trabalho propõe um modelo para a geração de eventos dinâmicos utilizando o design sistêmico como fundamento. para isso, a abstração de um jogo digital foi criada para demonstrar tal modelo. a abstração é dividida em sistemas simples, que utilizam a interação de suas propriedades e atributos para criar atividades variadas e coerentes. o modelo foi testado e resultados mostram que quanto mais eventos são gerados, menor é a taxa de dissimilaridade entre eles."
406,2021,Análise de sentimentos em repositórios do GitHub.,"SANTOS, Rafael Oliveira.","PEREIRA, Eanes Torres.","Pull-requests são sugestões de mudanças ou melhorias, para um determinado repositório, de um projeto no ambiente do GitHub. Essas sugestões podem ser comentadas por outros desenvolvedores que, por sua vez, podem expressar diferentes sentimentos nos seus comentários. Neste estudo, foram analisados comentários presentes em pull-requests com o intuito de compreender se comentários positivos podem, ou não, influenciar na aceitação do pull-request. Para isso, foram aplicadas técnicas de extração de dados, uso de abordagens do estado da arte para lidar com Big Data e ferramentas pré-treinadas para produzir essa análise. O resultado final veriicado
neste estudo mostrou que, sim, existe uma relação entre comentários positivos e o sucesso na aceitação dos pull-requests. A partir de um cálculo de covariância, entendeu-se que existe uma correlação positiva entre as ""variáveis de score"" com a ""variável de sucesso"". Rejeitando, através de um teste de hipótese T-Student, a hipótese nula de que as médias de comentários expressando sentimentos positivos e expressando sentimentos negativos para pull-requests possuem médias iguais. Entendeu-se que se as médias entre as duas variáveis são diferentes, isso está fortemente agregado a comportamentos diferentes, caso os comentários possuam sentimentos com intensidades diferentes.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19697,"pull-requests são sugestões de mudanças ou melhorias, para um determinado repositório, de um projeto no ambiente do github. essas sugestões podem ser comentadas por outros desenvolvedores que, por sua vez, podem expressar diferentes sentimentos nos seus comentários. neste estudo, foram analisados comentários presentes em pull-requests com o intuito de compreender se comentários positivos podem, ou não, influenciar na aceitação do pull-request. para isso, foram aplicadas técnicas de extração de dados, uso de abordagens do estado da arte para lidar com big data e ferramentas pré-treinadas para produzir essa análise. o resultado final veriicado neste estudo mostrou que, sim, existe uma relação entre comentários positivos e o sucesso na aceitação dos pull-requests. a partir de um cálculo de covariância, entendeu-se que existe uma correlação positiva entre as ""variáveis de score"" com a ""variável de sucesso"". rejeitando, através de um teste de hipótese t-student, a hipótese nula de que as médias de comentários expressando sentimentos positivos e expressando sentimentos negativos para pull-requests possuem médias iguais. entendeu-se que se as médias entre as duas variáveis são diferentes, isso está fortemente agregado a comportamentos diferentes, caso os comentários possuam sentimentos com intensidades diferentes."
407,2021,Feridômetro: aplicativo de auxílio à aprendizagem do acrônimo timers.,"ROCHA, Adiel Andrade.","ALMEIDA, Hyggo Oliveira de.","O acrônimo TIMERS é uma ferramenta de avaliação utilizada por enfermeiros e médicos. Possui como objetivo ser implantada no tratamento e no cuidado às feridas, garantindo a avaliação e permitindo estabelecer as intervenções visando a promoção da cicatrização, considerando os parâmetros avaliados. Neste trabalho, tem-se como objetivo desenvolver uma aplicação para dispositivos portáteis que sirva como um ferramental de apoio de
ensino ao acrônimo para estudantes da área de saúde. O aplicativo foi desenvolvido inicialmente para sistemas Android e se comunica com um servidor remoto para persistência de dados. Espera-se que a aplicação possa auxiliar e contribuir na aprendizagem do tratamento de feridas, podendo ser usado em sala de aula.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19691,"o acrônimo timers é uma ferramenta de avaliação utilizada por enfermeiros e médicos. possui como objetivo ser implantada no tratamento e no cuidado às feridas, garantindo a avaliação e permitindo estabelecer as intervenções visando a promoção da cicatrização, considerando os parâmetros avaliados. neste trabalho, tem-se como objetivo desenvolver uma aplicação para dispositivos portáteis que sirva como um ferramental de apoio de ensino ao acrônimo para estudantes da área de saúde. o aplicativo foi desenvolvido inicialmente para sistemas android e se comunica com um servidor remoto para persistência de dados. espera-se que a aplicação possa auxiliar e contribuir na aprendizagem do tratamento de feridas, podendo ser usado em sala de aula."
408,2021,Atuação e influência dos parlamentares brasileiros no Twitter: um estudo de caso com tweets.,"SOUSA, Hiago Natan Fernandes de.","MORAIS, Fábio Jorge Almeida.","As redes sociais tornaram-se uma importante plataforma de posicionamento político dos parlamentares fora do Congresso Brasileiro. Especialmente o Twitter, que atualmente reúne perfis de 42% dos parlamentares. Apesar dessa importância como difusor não oficial do discurso político, existem poucos estudos que analisam o posicionamento, a atuação e a influência dos parlamentares na plataforma (e.g. parlamentares e partidos mais ativos, engajamento dos parlamentares, proposições mais mencionadas, etc.). Desta forma, este trabalho tem como principal objetivo analisar quantitativamente a influência e atuação dos parlamentares brasileiros no twitter, além de seu comportamento na rede. Análises dessa natureza possibilitam que a população acompanhe e fiscalize o posicionamento e o comportamento de parlamentares fora do congresso sobre temas fundamentais à sociedade. Além do mais, permite compreender como as redes sociais podem ser utilizadas como um elemento fundamental no processo de comunicação entre a sociedade civil e o setor político.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19690,"as redes sociais tornaram-se uma importante plataforma de posicionamento político dos parlamentares fora do congresso brasileiro. especialmente o twitter, que atualmente reúne perfis de % dos parlamentares. apesar dessa importância como difusor não oficial do discurso político, existem poucos estudos que analisam o posicionamento, a atuação e a influência dos parlamentares na plataforma (e.g. parlamentares e partidos mais ativos, engajamento dos parlamentares, proposições mais mencionadas, etc.). desta forma, este trabalho tem como principal objetivo analisar quantitativamente a influência e atuação dos parlamentares brasileiros no twitter, além de seu comportamento na rede. análises dessa natureza possibilitam que a população acompanhe e fiscalize o posicionamento e o comportamento de parlamentares fora do congresso sobre temas fundamentais à sociedade. além do mais, permite compreender como as redes sociais podem ser utilizadas como um elemento fundamental no processo de comunicação entre a sociedade civil e o setor político."
409,2021,Uma aplicação web para organizar programas de pesquisa em engenharia de software seguindo modelo ABC.,"SANTOS, Felipe Mota dos","MASSONI, Tiago Lima.","Durante a realização de um programa de pesquisa encontram-se diversos problemas, entre eles o de organizar os estudos realizados, como também escolher quais métodos e metodologias serão utilizados. Mesmo com o aumento no número de pesquisas na área da engenharia de software, ainda se vê a falta de uma ferramenta que facilite o processo da realização de programas de pesquisa nessa área. Pensando nisso, propõe-se uma ferramenta no formato de aplicação web seguindo o modelo ABC, que foi idealizado por Klaas-Jan Stol e Brian Fitzgerald. Com a ferramenta será facilitado o processo de organização de estudos e melhorado a forma de visualização dos estudos realizados.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19689,"durante a realização de um programa de pesquisa encontram-se diversos problemas, entre eles o de organizar os estudos realizados, como também escolher quais métodos e metodologias serão utilizados. mesmo com o aumento no número de pesquisas na área da engenharia de software, ainda se vê a falta de uma ferramenta que facilite o processo da realização de programas de pesquisa nessa área. pensando nisso, propõe-se uma ferramenta no formato de aplicação web seguindo o modelo abc, que foi idealizado por klaas-jan stol e brian fitzgerald. com a ferramenta será facilitado o processo de organização de estudos e melhorado a forma de visualização dos estudos realizados."
410,2021,Reviewbin: uma ferramenta de fácil uso para revisão de código.,"LUCIANO, José Renan Silva.","RÊGO, Matheus Gaudencio do.","Revisão de código é uma das etapas mais importantes do processo de desenvolvimento de software. A prática permite uma melhor qualidade e confiabilidade dos artefatos, pois os mesmos serão analisados e discutidos por outros desenvolvedores. Existem hoje
ferramentas que possibilitam esse processo, como o GitHub e ReviewBoard, porém, estas ferramentas são integradas a um Sistema de Controle de Versão (SCV), como Git e Subversion, impossibilitando seu uso por pessoas que não têm o conhecimento dessas tecnologias, como alunos iniciantes em cursos de programação. Há também ferramentas, como o Codepost.io, que se apresentam como uma solução proprietária para revisão em
salas de aula, porém que se limitam à correção de atividades e adicionam uma burocracia extra para a configuração de turmas e criação de atividades na plataforma. O objetivo deste trabalho é criar uma ferramenta com foco em revisão de código, que permita que alunos e professores aproveitem os benefícios desta prática em atividades de sala de aula, sem a necessidade de ter conhecimento de nenhuma tecnologia de SCV e também que seja livre para outros casos de uso, como o envio de um trecho de código para que alguém possa tirar uma dúvida, sem a necessidade de configurações extras.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19651,"revisão de código é uma das etapas mais importantes do processo de desenvolvimento de software. a prática permite uma melhor qualidade e confiabilidade dos artefatos, pois os mesmos serão analisados e discutidos por outros desenvolvedores. existem hoje ferramentas que possibilitam esse processo, como o github e reviewboard, porém, estas ferramentas são integradas a um sistema de controle de versão (scv), como git e subversion, impossibilitando seu uso por pessoas que não têm o conhecimento dessas tecnologias, como alunos iniciantes em cursos de programação. há também ferramentas, como o codepost.io, que se apresentam como uma solução proprietária para revisão em salas de aula, porém que se limitam à correção de atividades e adicionam uma burocracia extra para a configuração de turmas e criação de atividades na plataforma. o objetivo deste trabalho é criar uma ferramenta com foco em revisão de código, que permita que alunos e professores aproveitem os benefícios desta prática em atividades de sala de aula, sem a necessidade de ter conhecimento de nenhuma tecnologia de scv e também que seja livre para outros casos de uso, como o envio de um trecho de código para que alguém possa tirar uma dúvida, sem a necessidade de configurações extras."
411,2021,Ferramenta para visualização das dependências entre objetos em um banco de dados e simulação de alterações nos objetos.,"NASCIMENTO, Anarco Quaresma Zeferino.","PIRES, Carlos Eduardo Santos.","No contexto de sistemas de banco de dados, tanto o desenvolvimento quanto a manutenção são processos que demandam alterações nos seus modelos. Essas alterações causam consequências em todo o sistema. Os modelos lógico, conceitual e físico possuem versões que variam à medida que o sistema evolui. O modo como a equipe de desenvolvimento ou profissionais de manutenção de banco de dados, os DBAs, visualizam o sistema, mais especificamente as relações entre os objetos desse sistema, tem efeitos diretos na forma em que o sistema será gerenciado por eles. Sendo assim, desenvolvemos uma aplicação web que permita a visualização dessas relações e 
exiba ao usuário os objetos que sofreriam algum efeito colateral caso algum outro objeto do sistema for alterado. Para o escopo deste trabalho, consideraremos apenas as alterações causadas pela operação DROP sobre algum objeto do sistema gerenciador de 
banco de dados Oracle Autonomous Data Warehouse, do serviço Oracle. Essa ferramenta se mostra fundamentalmente útil na manutenção de sistemas de banco de dados.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19650,"no contexto de sistemas de banco de dados, tanto o desenvolvimento quanto a manutenção são processos que demandam alterações nos seus modelos. essas alterações causam consequências em todo o sistema. os modelos lógico, conceitual e físico possuem versões que variam à medida que o sistema evolui. o modo como a equipe de desenvolvimento ou profissionais de manutenção de banco de dados, os dbas, visualizam o sistema, mais especificamente as relações entre os objetos desse sistema, tem efeitos diretos na forma em que o sistema será gerenciado por eles. sendo assim, desenvolvemos uma aplicação web que permita a visualização dessas relações e exiba ao usuário os objetos que sofreriam algum efeito colateral caso algum outro objeto do sistema for alterado. para o escopo deste trabalho, consideraremos apenas as alterações causadas pela operação drop sobre algum objeto do sistema gerenciador de banco de dados oracle autonomous data warehouse, do serviço oracle. essa ferramenta se mostra fundamentalmente útil na manutenção de sistemas de banco de dados."
412,2021,LexFirma: sistema de gestão de contratos advocatícios.,"SANTOS, Alessandro Lia Fook.","ALMEIDA, Hyggo Oliveira de.","A informatização se tornou um caminho sem volta nos tempos atuais, com o poder de facilitar o acesso e compreensão das informações. Desta forma, as mais diversas áreas estão aderindo a sistemas online para armazenar e gerenciar informações. Com o ramo da advocacia não é diferente. Nos últimos anos, a virtualização dos processos tem tornado seus agentes cada vez mais familiarizados com sistemas eletrônicos. Contudo, ainda faltam sistemas para suporte à gestão das diversas facetas financeiras de um escritório de advocacia. Para isto, propomos o LexFirma. Com essa ferramenta, desde o advogado que trabalha sozinho até as bancas podem realizar a gestão financeira de seus contratos.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19649,"a informatização se tornou um caminho sem volta nos tempos atuais, com o poder de facilitar o acesso e compreensão das informações. desta forma, as mais diversas áreas estão aderindo a sistemas online para armazenar e gerenciar informações. com o ramo da advocacia não é diferente. nos últimos anos, a virtualização dos processos tem tornado seus agentes cada vez mais familiarizados com sistemas eletrônicos. contudo, ainda faltam sistemas para suporte à gestão das diversas facetas financeiras de um escritório de advocacia. para isto, propomos o lexfirma. com essa ferramenta, desde o advogado que trabalha sozinho até as bancas podem realizar a gestão financeira de seus contratos."
413,2021,Automação de testes em aplicações web utilizando uma abordagem ad-hoc.,"MOURA, Thiago Santos de.","BAPTISTA, Cláudio de Souza.","Em aplicações web, muitas vezes, não são investidos tempo e recursos na realização de testes automáticos, além de ser comum que apenas testes manuais sejam realizados pelos próprios desenvolvedores.Tal problemática pode introduzir falhas nas aplicações, que podem demorar muito tempo para serem detectadas, resultando em retrabalho, além de prejudicar a experiência do usuário quando as falhas chegam ao ambiente de produção. Para contribuir na detecção mais ágil dessas falhas, foi desenvolvida uma ferramenta capaz de gerar o código de testes que simula um usuário percorrendo os fluxos de utilização, de forma simplória e objetiva, efetuando o preenchimento e submissão de dados. A execução é feita de forma automática por um framework de testes automatizados. A avaliação da ferramenta foi feita através do desenvolvimento de uma aplicação web para cadastros, na qual os testes gerados tiveram sua cobertura de interfaces averiguada, e foi avaliados a utilidade em indicar as falhas, além da capacidade de utilização como testes de regressão.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19626,"em aplicações web, muitas vezes, não são investidos tempo e recursos na realização de testes automáticos, além de ser comum que apenas testes manuais sejam realizados pelos próprios desenvolvedores.tal problemática pode introduzir falhas nas aplicações, que podem demorar muito tempo para serem detectadas, resultando em retrabalho, além de prejudicar a experiência do usuário quando as falhas chegam ao ambiente de produção. para contribuir na detecção mais ágil dessas falhas, foi desenvolvida uma ferramenta capaz de gerar o código de testes que simula um usuário percorrendo os fluxos de utilização, de forma simplória e objetiva, efetuando o preenchimento e submissão de dados. a execução é feita de forma automática por um framework de testes automatizados. a avaliação da ferramenta foi feita através do desenvolvimento de uma aplicação web para cadastros, na qual os testes gerados tiveram sua cobertura de interfaces averiguada, e foi avaliados a utilidade em indicar as falhas, além da capacidade de utilização como testes de regressão."
414,2021,Novas revelações da survey sobre dificuldades com desenvolvimento ágile gamificação-reanálise dos dados,"SILVA, Wellington Araújo.","MOURA, José Antão Beltrão.","O Desenvolvimento Ágil de Software (DAS) compreende técnicas utilizadas para agilizar o desenvolvimento do trabalho de software, porém determinadas tarefas são exaustivas e    repetitivas, representando  também  um  constante  desafio  a  seus  praticantes. Neste contexto, a gamificação destas atividades poderia trazer benefícios para estes desafios. O objetivo deste trabalho de Conclusão de Curso é o de fazer uma reanálise retrabalhando dadosobtidos em um formulário, onde respondentes opinam sobre o graude  dificuldade  das  atividades de  DAS  consideradas  mais  difíceis, bem como a relevância de se gamificar cada uma delas. Sob estes dados obtidos, serão aplicados filtros que mostrem as opiniões dos praticantes  de  DAS  nos  principais  problemas,  sob  a  ótica  dos diferentes  papéis,  áreas  de  atuação  e  experiência  nas  atividades deste  framework  Scrum  de  metodologia  ágeis.    Desta  forma,  terá como   finalidade   apresentar   novos   insights   sobre   o   uso   da Gamificação  no  Desenvolvimento  Ágil  de  Software,  a  fim  de reforçar ou refutar a proposta de gamificação das práticas de DAS.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19625,"o desenvolvimento ágil de software (das) compreende técnicas utilizadas para agilizar o desenvolvimento do trabalho de software, porém determinadas tarefas são exaustivas e repetitivas, representando também um constante desafio a seus praticantes. neste contexto, a gamificação destas atividades poderia trazer benefícios para estes desafios. o objetivo deste trabalho de conclusão de curso é o de fazer uma reanálise retrabalhando dadosobtidos em um formulário, onde respondentes opinam sobre o graude dificuldade das atividades de das consideradas mais difíceis, bem como a relevância de se gamificar cada uma delas. sob estes dados obtidos, serão aplicados filtros que mostrem as opiniões dos praticantes de das nos principais problemas, sob a ótica dos diferentes papéis, áreas de atuação e experiência nas atividades deste framework scrum de metodologia ágeis. desta forma, terá como finalidade apresentar novos insights sobre o uso da gamificação no desenvolvimento ágil de software, a fim de reforçar ou refutar a proposta de gamificação das práticas de das."
415,2021,Expandindo o smartcampus: um guia baseado em storybook para desenvolvedores.,"PEREIRA, Amintas Victor Ramos.","BRITO, Andrey Elísio Monteiro.","As soluções de Cidades Inteligentes (CI) podem tornar um local físico mais seguro, eficiente e atrativo à população. Considerando isso, o SmartCampus UFCG surge como uma plataforma que utiliza o campus como área de estudo para desenvolver estas soluções e replicá-las nas cidades. Algo essencial nesta iniciativa é o seu dashboard: além de contribuir com o bom uso e gestão das informações, ele promove engajamento. Todavia, a construção e evolução de um bom dashboard para um projeto interdisciplinar não é trivial, necessitando de um artefato que auxilie a equipe de desenvolvimento. Com o objetivo de contornar esse problema, este trabalho consiste em documentar os principais componentes do dashboard SmartCampus e os procedimentos utilizados na customização de suas funcionalidades, além de informar boas práticas de desenvolvimento nesta aplicação. Para tal, será utilizada a tecnologia Storybook: uma ferramenta voltada à exploração de interfaces. Desta forma, auxiliamos os desenvolvedores através de uma documentação que evolui com a aplicação, rodando paralelamente a esta última, e que reduz o esforço nas alterações de código.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19592,"as soluções de cidades inteligentes (ci) podem tornar um local físico mais seguro, eficiente e atrativo à população. considerando isso, o smartcampus ufcg surge como uma plataforma que utiliza o campus como área de estudo para desenvolver estas soluções e replicá-las nas cidades. algo essencial nesta iniciativa é o seu dashboard: além de contribuir com o bom uso e gestão das informações, ele promove engajamento. todavia, a construção e evolução de um bom dashboard para um projeto interdisciplinar não é trivial, necessitando de um artefato que auxilie a equipe de desenvolvimento. com o objetivo de contornar esse problema, este trabalho consiste em documentar os principais componentes do dashboard smartcampus e os procedimentos utilizados na customização de suas funcionalidades, além de informar boas práticas de desenvolvimento nesta aplicação. para tal, será utilizada a tecnologia storybook: uma ferramenta voltada à exploração de interfaces. desta forma, auxiliamos os desenvolvedores através de uma documentação que evolui com a aplicação, rodando paralelamente a esta última, e que reduz o esforço nas alterações de código."
416,2021,Docs-checker: uma ferramenta de análise de documentações escritas a partir de geradores de sites estáticos em Markdown,"VIEIRA, Fanny Batista.","RÊGO, Matheus Gaudêncio do.","Documentações são artefatos cruciais no desenvolvimento de software. A documentação explica o propósito de projetos, unifica informações e de modo geral, evita possíveis dúvidas das partes interessadas. Para que a documentação seja efetiva, sua estrutura deve ser simples, amigável e direta, no entanto, garantir que esses requisitos sejam atendidos é um trabalho difícil, principalmente, porque atualmente é um processo realizado manualmente. Neste trabalho, criaremos uma ferramenta para analisar a conformidade de estruturas de documentação de APIs com uma especificação, se atendo àquelas escritas por meio de static site generators (SSGs) em markdown. O sistema estabelece regras que a documentação deve atender e assim automaticamente avalia a qualidade da documentação. O usuário consegue customizar essas regras, de acordo com suas necessidades. O desempenho da ferramenta foi avaliado e os dados obtidos revelaram que a solução possui um comportamento de complexidade linear, levando aproximadamente 300 milissegundos para documentações de pequeno porte e 1 minuto para aquelas de grande porte. Além
disso, ao avaliar a ferramenta em documentações populares como é o caso de React e Typescript obtivemos uma taxa de sucesso superior a 80%, comprovando que a solução consegue garantir a conformidade da estrutura de documentações.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19591,"documentações são artefatos cruciais no desenvolvimento de software. a documentação explica o propósito de projetos, unifica informações e de modo geral, evita possíveis dúvidas das partes interessadas. para que a documentação seja efetiva, sua estrutura deve ser simples, amigável e direta, no entanto, garantir que esses requisitos sejam atendidos é um trabalho difícil, principalmente, porque atualmente é um processo realizado manualmente. neste trabalho, criaremos uma ferramenta para analisar a conformidade de estruturas de documentação de apis com uma especificação, se atendo àquelas escritas por meio de static site generators (ssgs) em markdown. o sistema estabelece regras que a documentação deve atender e assim automaticamente avalia a qualidade da documentação. o usuário consegue customizar essas regras, de acordo com suas necessidades. o desempenho da ferramenta foi avaliado e os dados obtidos revelaram que a solução possui um comportamento de complexidade linear, levando aproximadamente milissegundos para documentações de pequeno porte e minuto para aquelas de grande porte. além disso, ao avaliar a ferramenta em documentações populares como é o caso de react e typescript obtivemos uma taxa de sucesso superior a %, comprovando que a solução consegue garantir a conformidade da estrutura de documentações."
417,2021,"Como me senti durante a pandemia? Visualização de dados sobre os impactos da pandemia no estilo de vida, sentimentos e hábitos.","OLIVEIRA, Rebeca Miranda Beltrão de.","ANDRADE, Nazareno Ferreira de.","A pandemia de COVID-19 é um problema de saúde pública que atingiu o mundo inteiro e demandou que medidas de isolamento social fossem adotadas a fim de proteger e impedir a
proliferação do vírus. Emergências de saúde pública afetam a saúde, segurança e bem estar dos indivíduos e suas comunidades. Esses efeitos se traduzem na formação de novos
hábitos, na modificação de comportamentos e estilos de vida. Neste trabalho, geramos um antropográfico, por meio da coleta e análise de dados, que retrata sentimentos e mudanças
vivenciadas por um grupo de pessoas durante a pandemia e, com isso, objetivamos sensibilizar e gerar reflexões sobre essas modificações.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19557,"a pandemia de covid- é um problema de saúde pública que atingiu o mundo inteiro e demandou que medidas de isolamento social fossem adotadas a fim de proteger e impedir a proliferação do vírus. emergências de saúde pública afetam a saúde, segurança e bem estar dos indivíduos e suas comunidades. esses efeitos se traduzem na formação de novos hábitos, na modificação de comportamentos e estilos de vida. neste trabalho, geramos um antropográfico, por meio da coleta e análise de dados, que retrata sentimentos e mudanças vivenciadas por um grupo de pessoas durante a pandemia e, com isso, objetivamos sensibilizar e gerar reflexões sobre essas modificações."
418,2021,Contest advisor: a tool to help with the creation of programming contests.,"RIBEIRO, Gustavo Bezerra.","GHEYI, Rohit .","Estar preparado para competições de programação não é uma tarefa fácil, requerendo muitas horas de prática com o objetivo de melhorar as habilidades em resolução de problemas. Para ajudar nesse processo preparatório, os estudantes do ramo buscam participar de grupos de estudos, acampamentos intensivos e cursos, onde são submetidos a aulas sobre tópicos comumente presentes na resolução de problemas destas competições, além de listas de exercícios e competições não oficiais. Embora existam diversas plataformas, chamadas Juízes Online, com vastos repositórios de problemas disponíveis para prática, selecioná-los para compor uma lista de exercícios ou competição
não oficial com alta qualidade geralmente é uma tarefa manual e difícil. Diante disso, o presente trabalho tem como objetivo apresentar a ferramenta Contest Advisor desenvolvida para automatizar tal processo de seleção de problemas e auxiliar na criação de competições de programação.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19556,"estar preparado para competições de programação não é uma tarefa fácil, requerendo muitas horas de prática com o objetivo de melhorar as habilidades em resolução de problemas. para ajudar nesse processo preparatório, os estudantes do ramo buscam participar de grupos de estudos, acampamentos intensivos e cursos, onde são submetidos a aulas sobre tópicos comumente presentes na resolução de problemas destas competições, além de listas de exercícios e competições não oficiais. embora existam diversas plataformas, chamadas juízes online, com vastos repositórios de problemas disponíveis para prática, selecioná-los para compor uma lista de exercícios ou competição não oficial com alta qualidade geralmente é uma tarefa manual e difícil. diante disso, o presente trabalho tem como objetivo apresentar a ferramenta contest advisor desenvolvida para automatizar tal processo de seleção de problemas e auxiliar na criação de competições de programação."
419,2021,Validation of a simulation model for FasS performance benchamarking using predictive validation.,"QUARESMA, David Ferreira.","SILVA, Thiago Emmanuel Pereira da Cunha.","No artigo Controlling Garbage Collection and Request Admission
to Improve Performance of FaaS Applications, nós verificamos e avaliamos o impacto dos mecanismos de gerência de memória das linguagens de programação no contexto de funções como Serviço (Function as a Service, FaaS) através de experimentos de simulação. Os resultados desse estudo apontaram um impacto de 11.68% no tempo de resposta das requisições quando os procedimentos de coleta de lixo foram executados durante a execução de uma função CPU intensiva. Como trabalhos futuros, nós listamos algumas ameaças à validade dos resultados obtidos, e entre eles, nós citamos a validação do modelo de simulação usado no trabalho anterior. Para atingir este objetivo, nós executamos experimentos de medição em uma plataforma FaaS pública e experimentos de simulação usando usando o mesmo simulador do artigo anterior. sendo assim, nós validamos o simulador do artigo anterior. Sendo assim, nós validamos o simulador comparando os resultados obtidos em ambos os experimentos para garantir que o resultado da simulação e o de medição são equivalentes.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19555,"no artigo controlling garbage collection and request admission to improve performance of faas applications, nós verificamos e avaliamos o impacto dos mecanismos de gerência de memória das linguagens de programação no contexto de funções como serviço (function as a service, faas) através de experimentos de simulação. os resultados desse estudo apontaram um impacto de . % no tempo de resposta das requisições quando os procedimentos de coleta de lixo foram executados durante a execução de uma função cpu intensiva. como trabalhos futuros, nós listamos algumas ameaças à validade dos resultados obtidos, e entre eles, nós citamos a validação do modelo de simulação usado no trabalho anterior. para atingir este objetivo, nós executamos experimentos de medição em uma plataforma faas pública e experimentos de simulação usando usando o mesmo simulador do artigo anterior. sendo assim, nós validamos o simulador do artigo anterior. sendo assim, nós validamos o simulador comparando os resultados obtidos em ambos os experimentos para garantir que o resultado da simulação e o de medição são equivalentes."
420,2021,Sobre oportunidades de redução de custo para o serviço AWS S3 através de alocações personalizadas.,"JULIÃO, Lívia Cavalcanti Bandeira.","SILVA, Thiago Emmanuel Pereira da Cunha.","A fim de atender à crescente demanda por
armazenamento de dados, provedores de
computação em nuvem oferecem
armazenamento como um serviço. Nesse
contexto, um mesmo provedor apresenta no seu
catálogo diferentes ofertas de armazenamento
que variam quanto aos níveis de
disponibilidade, durabilidade, desempenho e,
consequentemente, preço. Escolher a
configuração de armazenamento em nuvem que
atenda aos requisitos da aplicação pelo melhor
custo não é, portanto, uma tarefa trivial. Para
auxiliar essa escolha, a AWS disponibiliza o
Intelligent Tiering, uma camada de
armazenamento especial que automatiza a
alocação de objetos de acordo com os acessos,
a fim de diminuir custos. No entanto, essa
opção deve ser usada com cuidado, uma vez
que alocações personalizadas por objeto podem
significar uma economia significativa. Neste
trabalho, será mostrado que o estudo do perfil
de acesso do objeto é indispensável para a
otimização dos uso de recursos de
armazenamento em nuvem.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19554,"a fim de atender à crescente demanda por armazenamento de dados, provedores de computação em nuvem oferecem armazenamento como um serviço. nesse contexto, um mesmo provedor apresenta no seu catálogo diferentes ofertas de armazenamento que variam quanto aos níveis de disponibilidade, durabilidade, desempenho e, consequentemente, preço. escolher a configuração de armazenamento em nuvem que atenda aos requisitos da aplicação pelo melhor custo não é, portanto, uma tarefa trivial. para auxiliar essa escolha, a aws disponibiliza o intelligent tiering, uma camada de armazenamento especial que automatiza a alocação de objetos de acordo com os acessos, a fim de diminuir custos. no entanto, essa opção deve ser usada com cuidado, uma vez que alocações personalizadas por objeto podem significar uma economia significativa. neste trabalho, será mostrado que o estudo do perfil de acesso do objeto é indispensável para a otimização dos uso de recursos de armazenamento em nuvem."
421,2021,Recomendação de projetos do Github por meio de Algoritmos de Learning to Rank,"FARIAS, Ariann Michael Martins de Andrade.","RAMALHO, Franklin de Souza.","O GitHub, atualmente a maior plataforma para hospedagem de
código e controle de versionamento, possui um enorme fluxo
diário de interações entre usuários e repositórios. Com o número
de repositórios hospedados na casa dos milhões, alguns projetos
que poderiam ser do interesse de alguns usuários acabam
passando despercebidos, assim como projetos que necessitam de
desenvolvedores, acabam ficando no ostracismo. Para esses
casos, surge a necessidade de algum mecanismo que possa
facilitar a escolha de projetos, pelo usuário. Na literatura outros
trabalhos, já realizaram estudos sobre esse contexto,
recomendando projetos com diferentes abordagens. Entretanto,
ainda há espaço para novos estudos, utilizando novos aspectos,
na tentativa de verificar e validar outros resultados. Por isso, esse
trabalho busca encontrar projetos relevantes para o usuário,
baseando-se nos interesses do mesmo, na plataforma GitHub,
utilizando um conjunto de features com o auxílio de algoritmos de
learning to rank. Analisamos a efetividade learning to rank, no
contexto de recomendação de projetos, utilizando os algoritmos
RankNet, AdaRank e ListNet, usando como espaço amostral 826
repositórios e 3464 usuários do GitHub. Os resultados mostram,
a relevância da variável resposta e que a abordagem de learning
to rank para recomendação de projetos oferece muito espaço para
exploração.",http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19198,"o github, atualmente a maior plataforma para hospedagem de código e controle de versionamento, possui um enorme fluxo diário de interações entre usuários e repositórios. com o número de repositórios hospedados na casa dos milhões, alguns projetos que poderiam ser do interesse de alguns usuários acabam passando despercebidos, assim como projetos que necessitam de desenvolvedores, acabam ficando no ostracismo. para esses casos, surge a necessidade de algum mecanismo que possa facilitar a escolha de projetos, pelo usuário. na literatura outros trabalhos, já realizaram estudos sobre esse contexto, recomendando projetos com diferentes abordagens. entretanto, ainda há espaço para novos estudos, utilizando novos aspectos, na tentativa de verificar e validar outros resultados. por isso, esse trabalho busca encontrar projetos relevantes para o usuário, baseando-se nos interesses do mesmo, na plataforma github, utilizando um conjunto de features com o auxílio de algoritmos de learning to rank. analisamos a efetividade learning to rank, no contexto de recomendação de projetos, utilizando os algoritmos ranknet, adarank e listnet, usando como espaço amostral repositórios e usuários do github. os resultados mostram, a relevância da variável resposta e que a abordagem de learning to rank para recomendação de projetos oferece muito espaço para exploração."
422,2021,AutoFormValidation: validação dinâmica baseada nos metadados do banco de dados da aplicação.,"OLIVEIRA, Vinícius Souza Seixas de.","OLIVEIRA, Maxwell Guimarães de.",,http://dspace.sti.ufcg.edu.br:8080/jspui/handle/riufcg/19197,
