Topic,Count,Name,Representation,Representative_Docs
-1,298,-1_modelo_tcnicas_aplicaes_software,"['modelo', 'tcnicas', 'aplicaes', 'software', 'digital', 'aplicativo', 'abordagem', 'ensino', 'servios', 'modelos']","['à medida que um software envelhece, muitas das tecnologias que o compõem se tornam obsoletas e difíceis de evoluir. além disso, novas abordagens para construir serviços surgem, como a virtualização de ambientes de execução, que proporciona maior facilidade na integração de novos desenvolvedores e no gerenciamento de dependências. neste trabalho, o objetivo é aplicar processos de virtualização, refatoração e revitalização ao sistema web cursos ufcg, utilizado pelos alunos da universidade federal de campina grande para visualizar grades de cursos, simular composições curriculares e analisar matrículas. o sistema é composto por código legado e enfrenta desafios relacionados à evolução e gerenciamento de dependências. para lidar com essas questões, foi utilizada a plataforma docker para virtualização, combinada com análise da estrutura do projeto e suas dependências. o objetivo principal é modernizar o ambiente de execução e aplicar refatorações para se adequar a um novo conjunto de ferramentas e linguagem de programação. espera-se que esse trabalho melhore o ciclo de vida do desenvolvimento de software e atualize as tecnologias empregadas no projeto.', 'a licitação é o meio adotado pela administração pública para assegurar igualdade de condições a todos que queiram realizar contratações de produtos ou serviços com o poder público. também é papel do poder público, realizar a análise e auditoria dos documentos derivados desse processo, de forma a garantir princípios legais como isonomia, legalidade, impessoalidade, moralidade, publicidade, e probidade administrativa. grande parte dos documentos relacionados aos processos licitatórios utilizam o formato portable document format (pdf). tal formato, não estruturado, torna a análise textual automatizada mais complexa. o presente trabalho, tem como objetivo o desenvolvimento de um modelo de indução, baseado em classiicação supervisionada, que seja capaz de identiicar informações especíicas contidas em um edital de licitação, e assim adicionar uma camada de automação ao processo de auditoria do documento. para isso, foram utilizadas técnicas de processamento de linguagem natural, e foram analisados diferentes modelos de aprendizagem de máquina, para a seleção do melhor modelo a ser utilizado na tarefa de classiicação. a base de dados utilizada foi extraída do portal do governo do estado do acre. ao inal da implementação, o modelo obteve bons resultados e mostrou-se capaz de identiicar as informações de interesse presentes nos documentos de maneira satisfatória.', 'a área de recuperação de informações musicais (music information retrieval ou mir) engloba uma variedade de tópicos, incluindo a transcrição musical, a separação de fontes sonoras, o reconhecimento de instrumentos e/ou gêneros musicais. um exemplo prático de um desses campos é o spotify, que utiliza sistemas de recomendação capazes de aprender o padrão de conteúdo reproduzido e sugere aos usuários músicas similares. no entanto, o reconhecimento de instrumentos ainda pode ser desafiador de acordo com o conjunto de dados utilizado, dificultando o reconhecimento de padrões. nesse contexto, essa pesquisa tem como objetivo treinar um modelo capaz de detectar e identificar instrumentos, além de avaliá-lo em diferentes conjuntos de dados amplamente conhecidos na área de mir. para isso, foram utilizados áudios do openmic- no treinamento e os modelos foram avaliados em três conjuntos de dados, sendo estes: mtg-jamendo, nsynth e áudios de apresentações ao vivo com instrumentos separados utilizando o demucs. a acurácia será um dos critérios utilizados para avaliar o desempenho do modelo. ao abordar essa problemática, espera-se contribuir para avanços na área de mir, permitindo recomendações musicais mais personalizadas por meio do aprimoramento da precisão em sistemas de recomendação. além disso, deseja-se fornecer insights para a comunidade de mir, auxiliando na análise musical e em campos relacionados, a fim de permitir aplicações cada vez mais eficientes.']"
0,67,0_software_cdigo_comentrios_desenvolvedores,"['software', 'cdigo', 'comentrios', 'desenvolvedores', 'reviso', 'gerenciamento', 'github', 'arquitetura', 'code', 'infraestrutura']","['o sucesso de um software condiz com a atenção em todo processo de desenvolvimento que envolve uma série de etapas até que o produto esteja em produção. no contexto da qualidade deste software, a utilização de relatórios de bugs providos por usuários finais contribui em maior escala para um melhor entendimento para desenvolvedores, equipes de suporte e sustentação, por fornecerem informações cruciais para a execução de correções ou melhorias no sistema. entretanto, a falta de informações dificultam a compreensão dos bugs, justamente por existir casos onde o usuário relata falsos bugs, com isso, para reconhecer esses casos e alcançar a proficiência para atender às necessidades , é essencial obter detalhamento, seja ele com título, descrições de cenários, passo a passo para execução, grau de severidade, anexos como planilhas, capturas de tela. dessa forma, torna-se a leitura mais clara, objetiva e concisa. dado este cenário, através de uma análise qualitativa, avaliamos a qualidade das informações contidas nesses relatórios, se dentre eles existem ou não padronização, procurar entender também a dificuldade dos usuários ao realizar o repasse dessas informações, e, a partir disso, indicar quais os formatos das abordagens que satisfazem as partes envolvidas para o correto funcionamento do software.', 'a especificação e avaliação da qualidade de software e dos sistemas de computador com uso intensivo de software é um fator chave para garantir valor às partes interessadas. para isso, é importante que as características de qualidade sejam especificadas, medidas e avaliadas, sempre que possível, usando medidas e métodos validados e amplamente aceitos. em relação ao tema infrastructure as code (iac), não existem estudos que fazem um comparativo entre as ferramentas para gerenciamento de configuração de automação em software, em termos de métricas bem definidas, que são usadas como requisitos para a avaliação de uma boa qualidade de software, como por exemplo, as métricas definidas e documentadas pela iso/iec : [ ]. ao analisar todas as métricas definidas na especificação, um subconjunto foi escolhido para analisar algumas ferramentas de automação de infraestrutura. as métricas escolhidas foram: manutenibilidade, portabilidade e usabilidade. foi observado que todas as ferramentas desempenham bem o papel de configuração de infraestrutura como código, porém algumas se destacam pela simplicidade e fácil aprendizado, como é o caso do ansible e do terraform. além de que o terraform é capaz de não somente configurar máquinas virtuais, mas também provisioná-las. por outro lado, o puppet é um pouco mais complexo do que as demais ferramentas pelo fato de sua configuração de agentes ser mais complexa e a curva de aprendizado não ser acentuada, porém também funciona muito bem para a configuração de infraestrutura.', 'dentre as atividades típicas de um processo de software, podemos destacar as tarefas de testar, analisar, reportar e corrigir bugs. a realização dessas tarefas é importante para identificar erros comuns ou complexos durante todas as etapas do desenvolvimento, evitando retrabalho e entregando um software com mais qualidade e confiabilidade [ ]. em um relatório de bug, geralmente, seu autor oferece detalhes da anormalidade que vem ocorrendo. tipicamente, um relatório de bug é aberto, o bug é corrigido e o relatório é fechado. contudo, por vezes, é verificado que a correção do bug não foi eficaz, seja por falta de descrição mais objetiva no relatório, seja por dificuldade de entendimento por parte do desenvolvedor. assim, faz-se necessária a reabertura do bug, adicionando tempo no processo de desenvolvimento, tornando o software mais custoso. por isso, é importante investigar o que pode ser feito para mitigar tais problemas. neste trabalho, investigamos as características que levam um bug a ser reaberto. os resultados deste trabalho podem ajudar aos usuários finais e desenvolvedores a melhor escrever relatórios de bugs, bem como aos desenvolvedores a melhor entendê-los e tratá-los. o estudo utilizou um dataset extraído da ferramenta bugzilla.']"
1,31,1_modelos_natural_linguagem natural_chatgpt,"['modelos', 'natural', 'linguagem natural', 'chatgpt', 'processamento linguagem', 'processamento', 'baseadas', 'respostas', 'caractersticas', 'texto']","['o avanço dos modelos de deep learning tem proporcionado resultados excepcionais em tarefas de visão computacional e processamento de linguagem natural. no entanto, o aumento do tamanho e complexidade desses modelos traz desafios significativos em termos de infraestrutura e custos operacionais. nesse contexto, a técnica de poda em redes neurais profundas surge como uma solução para reduzir o tamanho dos modelos, mantendo níveis similares de acurácia. este estudo investiga o impacto da utilização de métricas de explicabilidade (conductance e layer-wise relevance propagation) como critério de poda, comparando-as com a poda por magnitude de pesos e a poda aleatória. diferentes percentuais de poda são avaliados, considerando tanto a poda de oneshot quanto a poda iterativa. os resultados mostram uma correlação positiva entre o uso de métricas de explicabilidade e a melhoria na qualidade dos modelos podados, incluindo maior acurácia, menor variância e a capacidade de realizar podas mais agressivas sem perda significativa de acurácia. esses métodos promissores têm o potencial de melhorar a operacionalização e reduzir os custos associados aos modelos de deep learning em larga escala.', 'nos últimos anos, avanços na área de inteligência artiicial permitiram desenvolvimento de modelos de processamento de linguagem natural em prol de aplicações em diversos contextos, como a automatização do processo de elaboração de questões sobre temas especíicos. atualmente, existem modelos capazes de formular questões sobre um tópico qualquer após receber como entrada um texto relevante. tais projetos possuem grande potencial auxiliar no contexto educacional, entretanto, ainda existe carência de um sistema que forneça a seus usuários uma maneira fácil e intuitiva de utilizar esses modelos. esse trabalho tem como objetivo o desenvolvimento de uma aplicação web que supra essa necessidade, incorporando modelos de processamento de linguagem natural que recebem como entrada um texto e geram para o usuário uma lista de perguntas relevantes ao tema. a utilização da aplicação web também traz a oportunidade de obter feedback dos usuários sobre a qualidade das perguntas geradas, informação que pode ser utilizada para retroalimentação e aprimoramento dos modelos utilizados.', 'modelos de linguagem de grande escala (llms), como o chatgpt, claude e llama , revolucionaram o processamento de linguagem natural, criando novos casos de uso para aplicações que utilizam esses modelos em seus fluxos de trabalho. no entanto, os altos custos computacionais desses modelos acarretam problemas de custo e latência, impedindo a escalabilidade de funcionalidades baseadas em llm para muitos serviços e produtos, especialmente quando dependem de modelos com melhores capacidades de raciocínio, como o gpt- ou o claude opus. além disso, muitas consultas a esses modelos são duplicadas. o cache tradicional é uma solução natural para esse problema, mas sua incapacidade de determinar se duas consultas são semanticamente equivalentes leva a baixas taxas de cache hit. neste trabalho, propomos explorar o uso de cache semântico, que considera o significado das consultas em vez de sua formulação exata, para melhorar a eficiência de aplicações baseadas em llm. realizamos um experimento usando um conjunto de dados real da alura, uma empresa brasileira de educação, em um cenário onde um aluno responde a uma pergunta e o gpt- corrige a resposta. os resultados mostraram que , % das solicitações feitas ao llm poderiam ter sido atendidas a partir do cache usando um limiar de similaridade de . , com uma melhoria de - vezes na latência. esses resultados demonstram o potencial do cache semântico para melhorar a eficiência de funcionalidades baseadas em llm, reduzindo custos e latência enquanto mantém os benefícios de modelos avançados de linguagem como o gpt- . essa abordagem poderia possibilitar a escalabilidade de funcionalidades baseadas em llm para uma gama mais ampla de aplicações, avançando na adoção desses modelos poderosos em diversos domínios.']"
2,27,2_disciplinas_acadmico_discentes_disciplina,"['disciplinas', 'acadmico', 'discentes', 'disciplina', 'graduao', 'cincia', 'perodo', 'cincia computao', 'ensino', 'vagas']","['durante o período da pandemia promovida pelo covid- , a universidade federal de campina grande (ufcg) realizou quatro períodos letivos de forma remota para continuar as atividades de ensino. este trabalho analisa o impacto dessa modalidade de ensino e sua influência no desempenho e no nível de aprendizado dos alunos do curso de ciência da computação. a pesquisa utilizou dados anonimizados de registro de matrículas de a , concentrando-se nas disciplinas obrigatórias do curso. inicialmente, o estudo analisa a evolução das médias das notas dos alunos ao longo dos períodos acadêmicos, destacando um aumento nas médias durante os períodos remotos. além disso, a análise mostra uma diminuição no número de reprovações durante a pandemia em comparação com os períodos presenciais. o estudo também investiga, no regime remoto, as relações entre as disciplinas e o aproveitamento do aprendizado dos alunos. utilizando métodos estatísticos, foram identificadas as disciplinas mais afetadas pelo ensino remoto, tanto positivamente quanto negativamente. disciplinas como teoria da computação e estatística aplicada mostraram uma queda no desempenho, enquanto teoria dos grafos apresentou uma melhoria. em conclusão, o estudo aponta para um impacto negativo no desempenho dos alunos após o período de ensino remoto, sugerindo que fatores como eventuais irregularidades nas avaliações remotas podem ter contribuído para esse resultado.', 'ao ingressar na universidade, muitos alunos desconhecem os múltiplos campos profissionais vinculados ao curso, as horas complementares que devem ser cumpridas e a relevância das disciplinas oferecidas. atualmente, no curso de ciência da computação da ufcg, mesmo que algumas dessas questões estejam dispostas em portais oficiais do curso e de ser possível alcançá-las por meio do diálogo, elas ainda não são apresentadas de forma simples e centralizada. esse contexto é problemático por diversos motivos, dentre eles, a disparidade de conhecimento entre as pessoas, a facilidade de propagação de afirmações incorretas e o consequente mau planejamento curricular. a fim de contribuir com a diminuição desse cenário de déficit informacional, este trabalho propõe um sistema web que apresenta áreas profissionais de acordo com as disciplinas ofertadas no curso, que interage com o aluno para oferecer informações individuais sobre horas complementares e disciplinas optativas, bem como provê um ambiente colaborativo e saudável de comentários sobre as disciplinas. os resultados do sistema em uso refletem uma elevada satisfação com a facilidade na execução das tarefas e com a proposta da aplicação, contudo, indicam que a comunicação com o usuário pode ser melhor estabelecida e que são desejadas mais funcionalidades no sistema.', 'ao longo de todo o regime acadêmico é necessário que os discentes façam diversas matrículas, a fim de efetuar a inscrição em disciplinas do período acadêmico vigente. nesse contexto, principalmente com o grande volume de matrículas realizadas, se faz necessário o melhoramento da organização, do gerenciamento, do controle e do acompanhamento das matrículas acadêmicas. atualmente, mesmo diante de uma crescente modernização sistemática, o sistema de matrículas universitárias da universidade federal de campina grande é muito dependente do coordenador acadêmico, que deve manualmente: inscrever turmas, modificar quantidades de vagas e efetuar todo o planejamento de turmas manualmente. além disso, o sistema não avisa aos estudantes sobre turmas ideais para suas matrículas e nem sobre o horário inicial da abertura do período de inscrição das disciplinas. nesse viés, o eureca dashboard, surge como uma ferramenta facilitadora, na qual o coordenador acadêmico pode visualizar a oferta de vagas ideal para as disciplinas, modificar a disponibilização das disciplinas e acompanhar a inscrição dos discentes, tudo isso de forma unificada e centralizada, com um acesso facilitado e seguro. com isso, o trabalho desses gerenciadores será facilitado, e através de uma entrevista, com um usuário alvo, será possível medir o real impacto da plataforma e se ela foi fundamental no gerenciamento de tempo desses profissionais.']"
