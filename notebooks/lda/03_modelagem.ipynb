{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8003818e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checagem de ambiente\n",
    "\n",
    "import sys, platform, warnings, os, json, random, math\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel, CoherenceModel\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 120\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"OS:\", platform.platform())\n",
    "print(\"gensim:\", gensim.__version__)\n",
    "print(\"pyLDAvis:\", pyLDAvis.__version__)\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"matplotlib:\", matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd61f198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição de paths\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def find_repo_root(start: Path = Path.cwd()) -> Path:\n",
    "    for p in [start, *start.parents]:\n",
    "        target = p / \"data\" / \"interim\" / \"lda\" / \"vocab_bow.dict\"\n",
    "        if target.exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(\n",
    "        \"Raiz do projeto não encontrada. \"\n",
    "        \"Verifique se existe 'data/interim/lda/vocab_bow.dict' a partir da raiz.\"\n",
    "    )\n",
    "\n",
    "REPO = find_repo_root()\n",
    "print(\"REPO =\", REPO)\n",
    "\n",
    "# Entradas\n",
    "PATH_BOW_MM         = REPO / \"data\" / \"interim\" / \"lda\" / \"bow.mm\"\n",
    "PATH_VOCAB_DICT     = REPO / \"data\" / \"interim\" / \"lda\" / \"vocab_bow.dict\"\n",
    "PATH_BOW_INDEX_CSV  = REPO / \"data\" / \"interim\" / \"lda\" / \"bow_index.csv\"\n",
    "PATH_VOCAB_TERMS    = REPO / \"data\" / \"interim\" / \"lda\" / \"vocab_terms.csv\"\n",
    "\n",
    "# Saídas\n",
    "DIR_PROCESSED_LDA   = REPO / \"data\" / \"processed\" / \"lda\"\n",
    "DIR_REPORTS_FIGS    = REPO / \"reports\" / \"figs\"\n",
    "DIR_PROCESSED_LDA.mkdir(parents=True, exist_ok=True)\n",
    "DIR_REPORTS_FIGS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for p in [PATH_VOCAB_DICT, PATH_BOW_MM, PATH_BOW_INDEX_CSV, PATH_VOCAB_TERMS]:\n",
    "    print(p, \"EXISTS?\", p.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f5b7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar corpus e dicionário\n",
    "\n",
    "dictionary = corpora.Dictionary.load(str(PATH_VOCAB_DICT))\n",
    "corpus = corpora.MmCorpus(str(PATH_BOW_MM))\n",
    "\n",
    "bow_index = pd.read_csv(PATH_BOW_INDEX_CSV)\n",
    "vocab_df  = pd.read_csv(PATH_VOCAB_TERMS)\n",
    "\n",
    "print(dictionary)\n",
    "print(f\"n_docs (corpus): {len(corpus)}\")\n",
    "bow_index.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870a2d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilitários (treino, coerências, estabilidade)\n",
    "\n",
    "from typing import Dict, List\n",
    "from itertools import combinations\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "def train_lda(k:int,\n",
    "              corpus,\n",
    "              dictionary,\n",
    "              passes:int=10,\n",
    "              iterations:int=400,\n",
    "              chunksize:int=2000,\n",
    "              alpha='auto',\n",
    "              eta='auto',\n",
    "              random_state:int=RANDOM_STATE) -> LdaModel:\n",
    "    return LdaModel(\n",
    "        corpus=corpus,\n",
    "        id2word=dictionary,\n",
    "        num_topics=k,\n",
    "        random_state=random_state,\n",
    "        chunksize=chunksize,\n",
    "        passes=passes,\n",
    "        iterations=iterations,\n",
    "        alpha=alpha,\n",
    "        eta=eta,\n",
    "        eval_every=None\n",
    "    )\n",
    "\n",
    "def compute_coherences(model:LdaModel,\n",
    "                       texts_like_tokens:List[List[str]]|None,\n",
    "                       corpus,\n",
    "                       dictionary,\n",
    "                       topn:int=10,\n",
    "                       window_size:int=110) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calcula U_Mass, C_v e C_npmi com proteção contra NaN/inf.\n",
    "    Força processes=1 (Windows/Py3.12) para evitar instabilidades conhecidas.\n",
    "    \"\"\"\n",
    "    coherences = {}\n",
    "\n",
    "    # UMass\n",
    "    cm_umass = CoherenceModel(model=model, corpus=corpus, dictionary=dictionary,\n",
    "                              coherence='u_mass', topn=topn, processes=1)\n",
    "    val_umass = cm_umass.get_coherence()\n",
    "    coherences['u_mass'] = float(val_umass) if np.isfinite(val_umass) else float('nan')\n",
    "\n",
    "    # C_v\n",
    "    if texts_like_tokens is not None:\n",
    "        cm_cv = CoherenceModel(model=model, texts=texts_like_tokens, dictionary=dictionary,\n",
    "                               coherence='c_v', topn=topn, window_size=window_size, processes=1)\n",
    "    else:\n",
    "        cm_cv = CoherenceModel(model=model, corpus=corpus, dictionary=dictionary,\n",
    "                               coherence='c_v', topn=topn, window_size=window_size, processes=1)\n",
    "    val_cv = cm_cv.get_coherence()\n",
    "    coherences['c_v'] = float(val_cv) if np.isfinite(val_cv) else float('nan')\n",
    "\n",
    "    # C_npmi\n",
    "    if texts_like_tokens is not None:\n",
    "        cm_npmi = CoherenceModel(model=model, texts=texts_like_tokens, dictionary=dictionary,\n",
    "                                 coherence='c_npmi', topn=topn, window_size=window_size, processes=1)\n",
    "        val_npmi = cm_npmi.get_coherence()\n",
    "        coherences['c_npmi'] = float(val_npmi) if np.isfinite(val_npmi) else float('nan')\n",
    "    else:\n",
    "        coherences['c_npmi'] = float('nan')\n",
    "\n",
    "    return coherences\n",
    "\n",
    "def topn_terms_per_topic(model:LdaModel, topn:int=10) -> Dict[int, List[str]]:\n",
    "    return {t: [w for (w, _) in model.show_topic(t, topn=topn)] for t in range(model.num_topics)}\n",
    "\n",
    "def jaccard(a:set, b:set) -> float:\n",
    "    u = len(a | b)\n",
    "    return len(a & b)/u if u else 0.0\n",
    "\n",
    "def stability_score(models:List[LdaModel], topn:int=10) -> float:\n",
    "    if len(models) < 2:\n",
    "        return float('nan')\n",
    "\n",
    "    def pairwise_best_match(m1, m2):\n",
    "        T1 = topn_terms_per_topic(m1, topn=topn)\n",
    "        T2 = topn_terms_per_topic(m2, topn=topn)\n",
    "        used = set()\n",
    "        scores = []\n",
    "        for t1, terms1 in T1.items():\n",
    "            s1 = set(terms1)\n",
    "            best, best_t = 0.0, None\n",
    "            for t2, terms2 in T2.items():\n",
    "                if t2 in used:\n",
    "                    continue\n",
    "                sc = jaccard(s1, set(terms2))\n",
    "                if sc > best:\n",
    "                    best, best_t = sc, t2\n",
    "            if best_t is not None:\n",
    "                used.add(best_t)\n",
    "                scores.append(best)\n",
    "        return float(np.mean(scores)) if scores else 0.0\n",
    "\n",
    "    vals = []\n",
    "    for i, j in combinations(range(len(models)), 2):\n",
    "        vals.append(pairwise_best_match(models[i], models[j]))\n",
    "    return float(np.mean(vals)) if vals else float('nan')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a0093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar tokens para coerência\n",
    "\n",
    "import pickle\n",
    "\n",
    "TOKENS_PATH = REPO / \"data\" / \"interim\" / \"lda\" / \"tokens.pkl\"\n",
    "\n",
    "if TOKENS_PATH.exists():\n",
    "    with open(TOKENS_PATH, \"rb\") as f:\n",
    "        texts_like_tokens = pickle.load(f)\n",
    "    print(\"Tokens carregados:\", len(texts_like_tokens))\n",
    "else:\n",
    "    texts_like_tokens = None\n",
    "    print(\"Aviso: tokens.pkl não encontrado, coerência C_v/C_npmi pode ficar limitada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef71c7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varredura de k\n",
    "\n",
    "K_VALUES = list(range(5, 35, 5))\n",
    "PASSES = 10\n",
    "ITERATIONS = 400\n",
    "CHUNKSIZE = 2000\n",
    "N_RESTARTS = 3\n",
    "random_seeds = [RANDOM_STATE + i for i in range(N_RESTARTS)]\n",
    "\n",
    "results = []\n",
    "best_models_per_k = {}\n",
    "\n",
    "for k in K_VALUES:\n",
    "    models_k, metrics_k = [], []\n",
    "    for seed in random_seeds:\n",
    "        model = train_lda(k, corpus, dictionary,\n",
    "                          passes=PASSES, iterations=ITERATIONS,\n",
    "                          chunksize=CHUNKSIZE, random_state=seed)\n",
    "        coh = compute_coherences(model, texts_like_tokens, corpus, dictionary)\n",
    "        # sanitiza NaN/inf antes de agregar\n",
    "        for mkey in [\"u_mass\", \"c_v\", \"c_npmi\"]:\n",
    "            if (mval := coh.get(mkey, np.nan)) is None or (not np.isfinite(mval)):\n",
    "                coh[mkey] = float('nan')\n",
    "        models_k.append(model)\n",
    "        metrics_k.append(coh)\n",
    "\n",
    "    stab = stability_score(models_k, topn=10)\n",
    "\n",
    "    dfm = pd.DataFrame(metrics_k).replace([np.inf, -np.inf], np.nan)\n",
    "    # modelo \"representativo\" do k: o de maior C_v válido; se todos NaN, fica o primeiro\n",
    "    idx_best = dfm[\"c_v\"].idxmax() if dfm[\"c_v\"].notna().any() else 0\n",
    "    best_models_per_k[k] = models_k[int(idx_best)]\n",
    "\n",
    "    mean_metrics = dfm.mean(numeric_only=True).to_dict()\n",
    "    mean_metrics[\"stability_jaccard_top10\"] = float(stab) if np.isfinite(stab) else float('nan')\n",
    "    mean_metrics[\"k\"] = k\n",
    "    results.append(mean_metrics)\n",
    "\n",
    "metrics_df = pd.DataFrame(results).sort_values(\"k\").reset_index(drop=True)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a521adc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decisor objetivo: C_v primário + estabilidade + parcimônia\n",
    "\n",
    "TOL = 0.003  # tolerância de \"empate\" em C_v (ajuste p/ 0.003–0.005 se desejar)\n",
    "\n",
    "df = metrics_df.replace([np.inf, -np.inf], np.nan).copy()\n",
    "best_cv = df[\"c_v\"].max(skipna=True)\n",
    "df[\"cv_delta_to_best\"] = best_cv - df[\"c_v\"]\n",
    "\n",
    "# Candidatos: C_v dentro da tolerância do melhor\n",
    "cands = df[df[\"cv_delta_to_best\"] <= TOL].copy()\n",
    "\n",
    "if not cands.empty:\n",
    "    # Desempate 1: maior estabilidade; Desempate 2: menor k\n",
    "    max_stab = cands[\"stability_jaccard_top10\"].max(skipna=True)\n",
    "    cands2 = cands[cands[\"stability_jaccard_top10\"] == max_stab]\n",
    "    k_recommended = int(cands2[\"k\"].min())\n",
    "else:\n",
    "    # Sem candidatos próximos ao melhor C_v: usa argmax de C_v (ignorando NaN)\n",
    "    k_recommended = int(df.loc[df[\"c_v\"].idxmax(), \"k\"])\n",
    "\n",
    "display(df.sort_values(\"k\"))\n",
    "print(f\"\\nRecomendação (C_v±{TOL} + estabilidade + parcimônia): k = {k_recommended}\")\n",
    "\n",
    "# Opcional: para forçar o uso desta recomendação em vez do pick_k padrão, descomente:\n",
    "k_star = k_recommended\n",
    "best_model = best_models_per_k[k_star]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b756b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de métricas de coerência e estabilidade em função de k\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(metrics_df[\"k\"], metrics_df[\"c_v\"], marker=\"o\", label=\"C_v\")\n",
    "plt.plot(metrics_df[\"k\"], metrics_df[\"c_npmi\"], marker=\"o\", label=\"C_npmi\")\n",
    "plt.plot(metrics_df[\"k\"], metrics_df[\"u_mass\"], marker=\"o\", label=\"U_Mass\")\n",
    "plt.plot(metrics_df[\"k\"], metrics_df[\"stability_jaccard_top10\"], marker=\"o\", label=\"Estabilidade (Jaccard)\")\n",
    "\n",
    "plt.xlabel(\"Número de tópicos (k)\")\n",
    "plt.ylabel(\"Valor da métrica\")\n",
    "plt.title(\"Métricas de coerência e estabilidade vs k\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "DIAG_PNG = DIR_REPORTS_FIGS / \"lda_k_diagnostics.png\"\n",
    "plt.savefig(DIAG_PNG, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Figura de diagnóstico salva em:\", DIAG_PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21daadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleção do melhor k e salvamento do modelo\n",
    "\n",
    "def pick_k(df:pd.DataFrame) -> int:\n",
    "    \"\"\"\n",
    "    Seleciona k* priorizando C_v (Röder et al., 2015).\n",
    "    Desempate:\n",
    "      1) maior estabilidade_jaccard_top10 (tópicos mais estáveis),\n",
    "      2) menor k (princípio de parcimônia).\n",
    "    Ignora valores inf/NaN em C_npmi no desempate.\n",
    "    \"\"\"\n",
    "    d = df.copy()\n",
    "    d = d.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # 1) filtra linhas com C_v válido\n",
    "    mask_cv = d[\"c_v\"].notna()\n",
    "    if mask_cv.any():\n",
    "        top_cv = d.loc[mask_cv, \"c_v\"].max()\n",
    "        cands = d[(d[\"c_v\"] == top_cv)]\n",
    "        # 1a) desempate por estabilidade (se existir e não-NaN)\n",
    "        if \"stability_jaccard_top10\" in cands and cands[\"stability_jaccard_top10\"].notna().any():\n",
    "            best_idx = cands[\"stability_jaccard_top10\"].idxmax()\n",
    "            return int(d.loc[best_idx, \"k\"])\n",
    "        # 1b) parcimônia: menor k entre os candidatos\n",
    "        return int(cands[\"k\"].min())\n",
    "\n",
    "    # 2) sem C_v válido: tenta C_npmi válido\n",
    "    if \"c_npmi\" in d and d[\"c_npmi\"].notna().any():\n",
    "        top_npmi = d[\"c_npmi\"].max()\n",
    "        cands = d[d[\"c_npmi\"] == top_npmi]\n",
    "        if \"stability_jaccard_top10\" in cands and cands[\"stability_jaccard_top10\"].notna().any():\n",
    "            best_idx = cands[\"stability_jaccard_top10\"].idxmax()\n",
    "            return int(d.loc[best_idx, \"k\"])\n",
    "        return int(cands[\"k\"].min())\n",
    "\n",
    "    # 3) fallback: maior C_v (mesmo NaN geral) ou simplesmente menor k disponível\n",
    "    return int(d[\"k\"].min()) if \"k\" in d else 10\n",
    "\n",
    "k_star = pick_k(metrics_df)\n",
    "best_model = best_models_per_k[k_star]\n",
    "print(f\"Melhor k selecionado: {k_star}\")\n",
    "\n",
    "MODEL_PATH = DIR_PROCESSED_LDA / \"model.lda\"\n",
    "best_model.save(str(MODEL_PATH))\n",
    "\n",
    "METRICS_CSV = DIR_PROCESSED_LDA / \"coherences.csv\"\n",
    "metrics_df.to_csv(METRICS_CSV, index=False)\n",
    "\n",
    "print(\"Modelo salvo em:\", MODEL_PATH)\n",
    "print(\"Métricas salvas em:\", METRICS_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c37c1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise de robustez de k: inspeção da estabilidade relativa\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(metrics_df[\"k\"], metrics_df[\"stability_jaccard_top10\"], marker=\"s\", color=\"darkred\")\n",
    "plt.xlabel(\"Número de tópicos (k)\")\n",
    "plt.ylabel(\"Estabilidade média (Jaccard top-10 termos)\")\n",
    "plt.title(\"Robustez da escolha de k: estabilidade entre reinicializações\")\n",
    "plt.grid(True)\n",
    "\n",
    "ROBUST_PNG = DIR_REPORTS_FIGS / \"lda_k_robustness.png\"\n",
    "plt.savefig(ROBUST_PNG, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Figura de robustez salva em:\", ROBUST_PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b415e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nitidez doc–tópico por k: proporção média do tópico dominante (maior = mais nítido)\n",
    "\n",
    "def dominant_topic_prop(model: LdaModel, corpus) -> float:\n",
    "    vals = []\n",
    "    for bow in corpus:\n",
    "        dist = model.get_document_topics(bow, minimum_probability=0.0)\n",
    "        if not dist:\n",
    "            vals.append(0.0)\n",
    "            continue\n",
    "        probs = np.array([p for _, p in dist], dtype=float)\n",
    "        vals.append(float(probs.max()) if probs.size else 0.0)\n",
    "    return float(np.mean(vals)) if vals else float(\"nan\")\n",
    "\n",
    "sharpness = []\n",
    "for k, m in sorted(best_models_per_k.items()):\n",
    "    sharpness.append({\"k\": k, \"dominant_topic_prop\": dominant_topic_prop(m, corpus)})\n",
    "\n",
    "sharpness_df = pd.DataFrame(sharpness).sort_values(\"k\").reset_index(drop=True)\n",
    "display(sharpness_df)\n",
    "\n",
    "# Plot e salvamento\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(sharpness_df[\"k\"], sharpness_df[\"dominant_topic_prop\"], marker=\"D\")\n",
    "plt.xlabel(\"Número de tópicos (k)\")\n",
    "plt.ylabel(\"Proporção média do tópico dominante\")\n",
    "plt.title(\"Nitidez doc–tópico por k\")\n",
    "plt.grid(True)\n",
    "\n",
    "SHARP_PNG = DIR_REPORTS_FIGS / \"lda_k_sharpness.png\"\n",
    "plt.savefig(SHARP_PNG, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Figura de nitidez salva em:\", SHARP_PNG)\n",
    "\n",
    "SHARP_CSV = DIR_PROCESSED_LDA / \"k_sharpness.csv\"\n",
    "sharpness_df.to_csv(SHARP_CSV, index=False)\n",
    "print(\"Tabela de nitidez salva em:\", SHARP_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b07a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizações estáticas (tópicos e distribuição doc-tópico)\n",
    "\n",
    "# Top termos por tópico\n",
    "def plot_top_terms(model:LdaModel, topn:int=10, maxcols:int=3, figsize=(14, 10), savepath=None):\n",
    "    topics = [model.show_topic(t, topn=topn) for t in range(model.num_topics)]\n",
    "    n = len(topics); ncols = min(maxcols, n); nrows = math.ceil(n / ncols)\n",
    "\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    for i, terms in enumerate(topics, start=1):\n",
    "        ax = plt.subplot(nrows, ncols, i)\n",
    "        labels  = [w for w,_ in terms][::-1]\n",
    "        weights = [v for _,v in terms][::-1]\n",
    "        ax.barh(range(len(labels)), weights)\n",
    "        ax.set_yticks(range(len(labels)))\n",
    "        ax.set_yticklabels(labels)\n",
    "        ax.set_title(f\"Tópico {i-1}\")\n",
    "        ax.set_xlabel(\"Peso\")\n",
    "    plt.tight_layout()\n",
    "    if savepath:\n",
    "        plt.savefig(savepath, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "TOPICS_PNG = DIR_REPORTS_FIGS / \"lda_topics.png\"\n",
    "plot_top_terms(best_model, topn=10, maxcols=3, figsize=(14, 10), savepath=TOPICS_PNG)\n",
    "print(\"Figura salva em:\", TOPICS_PNG)\n",
    "\n",
    "# Distribuição de tópicos por documento (heatmap amostra)\n",
    "def doc_topic_matrix(model:LdaModel, corpus):\n",
    "    n_topics = model.num_topics\n",
    "    rows = []\n",
    "    for bow in corpus:\n",
    "        dist = [0.0]*n_topics\n",
    "        for t, p in model.get_document_topics(bow, minimum_probability=0.0):\n",
    "            dist[t] = p\n",
    "        rows.append(dist)\n",
    "    return np.array(rows)\n",
    "\n",
    "M = doc_topic_matrix(best_model, corpus)\n",
    "print(\"Matriz doc x tópicos:\", M.shape)\n",
    "\n",
    "DOC_DIST_PNG = DIR_REPORTS_FIGS / \"lda_doc_topic_dist.png\"\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(M[:min(200, M.shape[0]), :], aspect=\"auto\")\n",
    "plt.colorbar()\n",
    "plt.title(\"Distribuição de tópicos por documento (amostra)\")\n",
    "plt.xlabel(\"Tópicos\"); plt.ylabel(\"Documentos\")\n",
    "plt.savefig(DOC_DIST_PNG, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Figura salva em:\", DOC_DIST_PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc1f5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDAvis interativo\n",
    "\n",
    "vis_data = gensimvis.prepare(best_model, corpus, dictionary)\n",
    "LDAVIS_HTML = DIR_REPORTS_FIGS / \"lda_vis.html\"\n",
    "pyLDAvis.save_html(vis_data, str(LDAVIS_HTML))\n",
    "print(\"LDAvis salvo em:\", LDAVIS_HTML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f8e314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manifesto de auditoria\n",
    "\n",
    "audit = {\n",
    "    \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n",
    "    \"random_state_base\": RANDOM_STATE,\n",
    "    \"k_grid\": list(K_VALUES),\n",
    "    \"k_selected\": int(k_star),\n",
    "    \"training_params\": {\n",
    "        \"passes\": PASSES, \"iterations\": ITERATIONS, \"chunksize\": CHUNKSIZE,\n",
    "        \"alpha\": \"auto\", \"eta\": \"auto\", \"n_restarts\": N_RESTARTS\n",
    "    },\n",
    "    \"coherence_metrics\": {\n",
    "        \"table_csv\": str(METRICS_CSV.relative_to(REPO)),\n",
    "        \"primary_metric\": \"c_v\", \"tie_breaker\": \"c_npmi\", \"umass_included\": True\n",
    "    },\n",
    "    \"stability\": {\"method\": \"mean_jaccard_top10_best_matching\"},\n",
    "    \"inputs\": {\n",
    "        \"corpus_mm\": str(PATH_BOW_MM.relative_to(REPO)),\n",
    "        \"vocab_dict\": str(PATH_VOCAB_DICT.relative_to(REPO)),\n",
    "        \"bow_index_csv\": str(PATH_BOW_INDEX_CSV.relative_to(REPO)),\n",
    "        \"vocab_terms_csv\": str(PATH_VOCAB_TERMS.relative_to(REPO)),\n",
    "        \"tokens_used_for_cv_npmi\": bool(texts_like_tokens is not None)\n",
    "    },\n",
    "    \"outputs\": {\n",
    "        \"model_lda\": str(MODEL_PATH.relative_to(REPO)),\n",
    "        \"topics_png\": str(TOPICS_PNG.relative_to(REPO)),\n",
    "        \"doc_dist_png\": str(DOC_DIST_PNG.relative_to(REPO)),\n",
    "        \"ldavis_html\": str(LDAVIS_HTML.relative_to(REPO))\n",
    "    },\n",
    "    \"env\": {\n",
    "        \"python\": sys.version,\n",
    "        \"gensim\": gensim.__version__,\n",
    "        \"pyLDAvis\": pyLDAvis.__version__,\n",
    "        \"numpy\": np.__version__\n",
    "    }\n",
    "}\n",
    "AUDIT_JSON = DIR_PROCESSED_LDA / \"audit_modelagem.json\"\n",
    "with open(AUDIT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(audit, f, ensure_ascii=False, indent=2)\n",
    "print(\"Manifesto de auditoria salvo em:\", AUDIT_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032a5e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportação de tabela de tópicos\n",
    "\n",
    "def topics_table(model:LdaModel, topn:int=15) -> pd.DataFrame:\n",
    "    return pd.DataFrame([\n",
    "        {\"topic_id\": t, \"top_terms\": \", \".join([w for w,_ in model.show_topic(t, topn=topn)])}\n",
    "        for t in range(model.num_topics)\n",
    "    ])\n",
    "\n",
    "TOPICS_CSV = DIR_PROCESSED_LDA / \"topics_top_terms.csv\"\n",
    "topics_df = topics_table(best_model, topn=15)\n",
    "topics_df.to_csv(TOPICS_CSV, index=False)\n",
    "print(\"CSV de tópicos salvo em:\", TOPICS_CSV)\n",
    "topics_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lda 3.12)",
   "language": "python",
   "name": "lda-312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
