{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b07d6115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD  : C:\\Users\\User\\Desktop\\TCC\\Notebooks locais\\analise_topicos_tcc\\notebooks\\bertopic\n",
      "ROOT : C:\\Users\\User\\Desktop\\TCC\\Notebooks locais\\analise_topicos_tcc\n",
      "DATA : C:\\Users\\User\\Desktop\\TCC\\Notebooks locais\\analise_topicos_tcc\\data\n",
      "INTERIM: C:\\Users\\User\\Desktop\\TCC\\Notebooks locais\\analise_topicos_tcc\\data\\interim\\bertopic\n",
      "BEST : C:\\Users\\User\\Desktop\\TCC\\Notebooks locais\\analise_topicos_tcc\\data\\exports\\dashboard\\bertopic_best\n",
      "EXPORT: C:\\Users\\User\\Desktop\\TCC\\Notebooks locais\\analise_topicos_tcc\\data\\exports\\dashboard\n"
     ]
    }
   ],
   "source": [
    "# Imports, paths e utilitários\n",
    "\n",
    "from pathlib import Path\n",
    "import re, unicodedata, json\n",
    "\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import pandera as pa\n",
    "from pandera import Column, DataFrameSchema, Check\n",
    "\n",
    "def find_project_root(start: Path) -> Path:\n",
    "    # Sobe até encontrar uma pasta que tenha \"data\" e \"notebooks\"\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / \"data\").exists() and (p / \"notebooks\").exists():\n",
    "            return p\n",
    "    # fallback: assume dois níveis acima (funciona se estiver em notebooks/bertopic/*)\n",
    "    return start.parents[1]\n",
    "\n",
    "CWD = Path.cwd()\n",
    "ROOT = find_project_root(CWD)         # <-- raiz correta do projeto\n",
    "DATA = ROOT / \"data\"\n",
    "INTERIM = DATA / \"interim\" / \"bertopic\"\n",
    "EXPORT = DATA / \"exports\" / \"dashboard\"\n",
    "BEST = EXPORT / \"bertopic_best\"       # artefatos do vencedor consolidados\n",
    "\n",
    "# Não cria nada fora do projeto\n",
    "EXPORT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"CWD  :\", CWD.resolve())\n",
    "print(\"ROOT :\", ROOT.resolve())       # deve imprimir ...\\analise_topicos_tcc\n",
    "print(\"DATA :\", DATA.resolve())\n",
    "print(\"INTERIM:\", INTERIM.resolve())  # ...\\analise_topicos_tcc\\data\\interim\\bertopic\n",
    "print(\"BEST :\", BEST.resolve())       # ...\\analise_topicos_tcc\\data\\exports\\dashboard\\bertopic_best\n",
    "print(\"EXPORT:\", EXPORT.resolve())\n",
    "\n",
    "def slugify(s: str) -> str:\n",
    "    if s is None:\n",
    "        return \"na\"\n",
    "    s = unicodedata.normalize(\"NFKD\", str(s))\n",
    "    s = s.encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    s = re.sub(r\"[^a-zA-Z0-9]+\", \"-\", s).strip(\"-\").lower()\n",
    "    return s or \"na\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdb0a99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'method': 'bertopic',\n",
       " 'run': 'run_20250831T230602Z',\n",
       " 'trial': 'trial_24',\n",
       " 'K': 12,\n",
       " 'c_npmi': 0.007560071814801735,\n",
       " 'c_v': 0.6058599854512132,\n",
       " 'diversity@10': 0.75,\n",
       " 'sep_jsd': 0.789577921470549,\n",
       " 'balance': 0.9262042731060053,\n",
       " 'clarity': 0.6036024422926879,\n",
       " 'outliers_pct': 0.14420803782505912,\n",
       " 'scenario': 'opt',\n",
       " 'RZ_index': 0.6800424648862116,\n",
       " 'GR_index': 0.13238824907920146}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leiotura de entradas: prep.csv e resultados do vencedor\n",
    "\n",
    "# Metadados do corpus (prep.csv)\n",
    "prep_path = INTERIM / \"prep.csv\"\n",
    "assert prep_path.exists(), f\"Arquivo não encontrado: {prep_path}\"\n",
    "\n",
    "prep = pl.read_csv(prep_path, infer_schema_length=10000)\n",
    "\n",
    "# Normaliza tipos mínimos usados no dashboard\n",
    "prep = prep.with_columns([\n",
    "    pl.col(\"DOC_ID\").cast(pl.Int64),\n",
    "    pl.col(\"ano\").cast(pl.Int64),\n",
    "    pl.col(\"titulo\").cast(pl.Utf8),\n",
    "    pl.col(\"autor\").cast(pl.Utf8, strict=False),\n",
    "    pl.col(\"orientador\").cast(pl.Utf8, strict=False).alias(\"orientador\"),\n",
    "    pl.col(\"resumo\").cast(pl.Utf8, strict=False),\n",
    "    pl.col(\"url\").cast(pl.Utf8, strict=False),\n",
    "    pl.col(\"RESUMO_PREP_BERTOPIC\").cast(pl.Utf8, strict=False)\n",
    "])\n",
    "\n",
    "# Artefatos do BERTopic selecionado (consolidados em berTopic_best)\n",
    "topic_info_csv = BEST / \"topic_info.csv\"\n",
    "doc_topics_csv = BEST / \"doc_topics.csv\"\n",
    "selection_json = BEST / \"selection.json\"  # informativo\n",
    "\n",
    "assert topic_info_csv.exists(), f\"Não encontrado: {topic_info_csv}\"\n",
    "assert doc_topics_csv.exists(), f\"Não encontrado: {doc_topics_csv}\"\n",
    "\n",
    "topic_info = pl.read_csv(topic_info_csv)\n",
    "doc_topics_raw = pl.read_csv(doc_topics_csv)\n",
    "\n",
    "# Carrega info de seleção (opcional)\n",
    "sel = {}\n",
    "if selection_json.exists():\n",
    "    try:\n",
    "        sel = json.loads(selection_json.read_text(encoding=\"utf-8\"))\n",
    "    except Exception:\n",
    "        sel = {}\n",
    "sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fbd3dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK -> c:\\Users\\User\\Desktop\\TCC\\Notebooks locais\\analise_topicos_tcc\\data\\exports\\dashboard\\docs.parquet | linhas: 423\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>DOC_ID</th><th>ano</th><th>titulo</th><th>resumo</th><th>url</th><th>autor</th><th>orientador_id</th><th>orientador_nome</th></tr><tr><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>2024</td><td>&quot;AGENDEVC: um sistema de agenda…</td><td>&quot;Gerenciar a agenda e fornecer …</td><td>&quot;http://dspace.sti.ufcg.edu.br:…</td><td>&quot;FERREIRA, Williamberg de Albuq…</td><td>&quot;massoni-tiago-lima&quot;</td><td>&quot;MASSONI, Tiago Lima.&quot;</td></tr><tr><td>1</td><td>2024</td><td>&quot;Análise de técnicas de explica…</td><td>&quot;Doenças oftalmológicas, como c…</td><td>&quot;http://dspace.sti.ufcg.edu.br:…</td><td>&quot;SILVA, Wendson Magalhães da.&quot;</td><td>&quot;gomes-herman-martins&quot;</td><td>&quot;GOMES, Herman Martins.&quot;</td></tr><tr><td>2</td><td>2024</td><td>&quot;O impacto do uso de tags de ra…</td><td>&quot;O presente trabalho busca comp…</td><td>&quot;http://dspace.sti.ufcg.edu.br:…</td><td>&quot;RIBEIRO, Vinicius Trindade Roc…</td><td>&quot;mongiovi-melina&quot;</td><td>&quot;MONGIOVI, Melina.&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 8)\n",
       "┌────────┬──────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────┬────────────┐\n",
       "│ DOC_ID ┆ ano  ┆ titulo      ┆ resumo      ┆ url         ┆ autor       ┆ orientador_ ┆ orientador │\n",
       "│ ---    ┆ ---  ┆ ---         ┆ ---         ┆ ---         ┆ ---         ┆ id          ┆ _nome      │\n",
       "│ i64    ┆ i64  ┆ str         ┆ str         ┆ str         ┆ str         ┆ ---         ┆ ---        │\n",
       "│        ┆      ┆             ┆             ┆             ┆             ┆ str         ┆ str        │\n",
       "╞════════╪══════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╪════════════╡\n",
       "│ 0      ┆ 2024 ┆ AGENDEVC:   ┆ Gerenciar a ┆ http://dspa ┆ FERREIRA,   ┆ massoni-tia ┆ MASSONI,   │\n",
       "│        ┆      ┆ um sistema  ┆ agenda e    ┆ ce.sti.ufcg ┆ Williamberg ┆ go-lima     ┆ Tiago      │\n",
       "│        ┆      ┆ de agenda…  ┆ fornecer …  ┆ .edu.br:…   ┆ de Albuq…   ┆             ┆ Lima.      │\n",
       "│ 1      ┆ 2024 ┆ Análise de  ┆ Doenças oft ┆ http://dspa ┆ SILVA,      ┆ gomes-herma ┆ GOMES,     │\n",
       "│        ┆      ┆ técnicas de ┆ almológicas ┆ ce.sti.ufcg ┆ Wendson     ┆ n-martins   ┆ Herman     │\n",
       "│        ┆      ┆ explica…    ┆ , como c…   ┆ .edu.br:…   ┆ Magalhães   ┆             ┆ Martins.   │\n",
       "│        ┆      ┆             ┆             ┆             ┆ da.         ┆             ┆            │\n",
       "│ 2      ┆ 2024 ┆ O impacto   ┆ O presente  ┆ http://dspa ┆ RIBEIRO,    ┆ mongiovi-me ┆ MONGIOVI,  │\n",
       "│        ┆      ┆ do uso de   ┆ trabalho    ┆ ce.sti.ufcg ┆ Vinicius    ┆ lina        ┆ Melina.    │\n",
       "│        ┆      ┆ tags de ra… ┆ busca comp… ┆ .edu.br:…   ┆ Trindade    ┆             ┆            │\n",
       "│        ┆      ┆             ┆             ┆             ┆ Roc…        ┆             ┆            │\n",
       "└────────┴──────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────┴────────────┘"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construção de docs.parquet\n",
    "\n",
    "# Renomeia 'orientador' -> 'orientador_nome' e cria 'orientador_id' canônico (slug)\n",
    "docs = (prep\n",
    "        .with_columns([\n",
    "            pl.col(\"orientador\").alias(\"orientador_nome\"),\n",
    "            pl.col(\"orientador\").map_elements(slugify).alias(\"orientador_id\"),\n",
    "        ])\n",
    "        .select([\n",
    "            \"DOC_ID\",\"ano\",\"titulo\",\"resumo\",\"url\",\n",
    "            \"autor\",\"orientador_id\",\"orientador_nome\"\n",
    "        ])\n",
    "        .with_columns([\n",
    "            pl.col(\"DOC_ID\").cast(pl.Int64),\n",
    "            pl.col(\"ano\").cast(pl.Int64),\n",
    "        ])\n",
    ")\n",
    "\n",
    "# Persistir\n",
    "docs_out = EXPORT / \"docs.parquet\"\n",
    "docs.write_parquet(docs_out)\n",
    "print(\"OK ->\", docs_out, \"| linhas:\", docs.height)\n",
    "docs.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e8770fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK -> c:\\Users\\User\\Desktop\\TCC\\Notebooks locais\\analise_topicos_tcc\\data\\exports\\dashboard\\topics.parquet | tópicos: 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>topic</th><th>Count</th><th>label</th><th>Representation</th><th>Representative_Docs</th><th>keywords</th><th>coherence</th></tr><tr><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>52</td><td>&quot;0_modelos_dados_linguagem_imag…</td><td>&quot;[&#x27;modelos&#x27;, &#x27;dados&#x27;, &#x27;linguage…</td><td>&quot;[&quot;as redes adversárias generat…</td><td>&quot;0_modelos_dados_linguagem_imag…</td><td>null</td></tr><tr><td>1</td><td>51</td><td>&quot;1_nuvem_recursos_dados_sistema&quot;</td><td>&quot;[&#x27;nuvem&#x27;, &#x27;recursos&#x27;, &#x27;dados&#x27;,…</td><td>&quot;[&#x27;em um mercado globalizado e …</td><td>&quot;1_nuvem_recursos_dados_sistema&quot;</td><td>null</td></tr><tr><td>2</td><td>44</td><td>&quot;2_alunos_computao_programao_si…</td><td>&quot;[&#x27;alunos&#x27;, &#x27;computao&#x27;, &#x27;progra…</td><td>&quot;[&#x27;a unidade acadêmica de siste…</td><td>&quot;2_alunos_computao_programao_si…</td><td>null</td></tr><tr><td>3</td><td>42</td><td>&quot;3_software_projetos_cdigo_bugs&quot;</td><td>&quot;[&#x27;software&#x27;, &#x27;projetos&#x27;, &#x27;cdig…</td><td>&quot;[&#x27;criar projetos de programaçã…</td><td>&quot;3_software_projetos_cdigo_bugs&quot;</td><td>null</td></tr><tr><td>4</td><td>39</td><td>&quot;4_dados_digital_sobre_privacid…</td><td>&quot;[&#x27;dados&#x27;, &#x27;digital&#x27;, &#x27;sobre&#x27;, …</td><td>&quot;[&#x27;o dadosjusbr é um projeto se…</td><td>&quot;4_dados_digital_sobre_privacid…</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌───────┬───────┬─────────────────┬─────────────────┬─────────────────┬────────────────┬───────────┐\n",
       "│ topic ┆ Count ┆ label           ┆ Representation  ┆ Representative_ ┆ keywords       ┆ coherence │\n",
       "│ ---   ┆ ---   ┆ ---             ┆ ---             ┆ Docs            ┆ ---            ┆ ---       │\n",
       "│ i64   ┆ i64   ┆ str             ┆ str             ┆ ---             ┆ str            ┆ str       │\n",
       "│       ┆       ┆                 ┆                 ┆ str             ┆                ┆           │\n",
       "╞═══════╪═══════╪═════════════════╪═════════════════╪═════════════════╪════════════════╪═══════════╡\n",
       "│ 0     ┆ 52    ┆ 0_modelos_dados ┆ ['modelos',     ┆ [\"as redes      ┆ 0_modelos_dado ┆ null      │\n",
       "│       ┆       ┆ _linguagem_imag ┆ 'dados',        ┆ adversárias     ┆ s_linguagem_im ┆           │\n",
       "│       ┆       ┆ …               ┆ 'linguage…      ┆ generat…        ┆ ag…            ┆           │\n",
       "│ 1     ┆ 51    ┆ 1_nuvem_recurso ┆ ['nuvem',       ┆ ['em um mercado ┆ 1_nuvem_recurs ┆ null      │\n",
       "│       ┆       ┆ s_dados_sistema ┆ 'recursos',     ┆ globalizado e … ┆ os_dados_siste ┆           │\n",
       "│       ┆       ┆                 ┆ 'dados',…       ┆                 ┆ ma             ┆           │\n",
       "│ 2     ┆ 44    ┆ 2_alunos_comput ┆ ['alunos',      ┆ ['a unidade     ┆ 2_alunos_compu ┆ null      │\n",
       "│       ┆       ┆ ao_programao_si ┆ 'computao',     ┆ acadêmica de    ┆ tao_programao_ ┆           │\n",
       "│       ┆       ┆ …               ┆ 'progra…        ┆ siste…          ┆ si…            ┆           │\n",
       "│ 3     ┆ 42    ┆ 3_software_proj ┆ ['software',    ┆ ['criar         ┆ 3_software_pro ┆ null      │\n",
       "│       ┆       ┆ etos_cdigo_bugs ┆ 'projetos',     ┆ projetos de     ┆ jetos_cdigo_bu ┆           │\n",
       "│       ┆       ┆                 ┆ 'cdig…          ┆ programaçã…     ┆ gs             ┆           │\n",
       "│ 4     ┆ 39    ┆ 4_dados_digital ┆ ['dados',       ┆ ['o dadosjusbr  ┆ 4_dados_digita ┆ null      │\n",
       "│       ┆       ┆ _sobre_privacid ┆ 'digital',      ┆ é um projeto    ┆ l_sobre_privac ┆           │\n",
       "│       ┆       ┆ …               ┆ 'sobre', …      ┆ se…             ┆ id…            ┆           │\n",
       "└───────┴───────┴─────────────────┴─────────────────┴─────────────────┴────────────────┴───────────┘"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construção de topics.parquet\n",
    "\n",
    "# OBS.: exclui -1 (outlier).\n",
    "\n",
    "# Espera-se que topic_info tenha pelo menos colunas: 'Topic' e 'Name'\n",
    "# 'Name' costuma conter label no estilo \"topic <id>: palavra1, palavra2, ...\"\n",
    "# Vamos usar Name como 'label' e extrair 'keywords' de Name quando possível.\n",
    "\n",
    "def extract_keywords_from_name(name: str) -> str:\n",
    "    if not isinstance(name, str):\n",
    "        return \"\"\n",
    "    # pega sequência após ':' (se existir)\n",
    "    parts = name.split(\":\", 1)\n",
    "    if len(parts) == 2:\n",
    "        return \"; \".join([w.strip() for w in parts[1].split(\",\") if w.strip()])\n",
    "    # fallback: retorna o próprio name\n",
    "    return name\n",
    "\n",
    "topics_df = (topic_info\n",
    "             .rename({\"Topic\":\"topic\", \"Name\":\"label\"})\n",
    "             .with_columns([\n",
    "                 pl.col(\"topic\").cast(pl.Int64),\n",
    "                 pl.col(\"label\").cast(pl.Utf8),\n",
    "             ]))\n",
    "\n",
    "# Exclui -1 (outlier)\n",
    "topics_df = topics_df.filter(pl.col(\"topic\") != -1)\n",
    "\n",
    "# Cria 'keywords' a partir de label (quando disponível)\n",
    "topics_df = topics_df.with_columns(\n",
    "    pl.col(\"label\").map_elements(extract_keywords_from_name).alias(\"keywords\")\n",
    ")\n",
    "\n",
    "# (Opcional) adiciona coluna 'coherence' vazia para contrato estável\n",
    "topics_df = topics_df.with_columns(pl.lit(None).cast(pl.Utf8).alias(\"coherence\"))\n",
    "\n",
    "topics_out = EXPORT / \"topics.parquet\"\n",
    "topics_df.select([\"topic\",\"label\",\"keywords\",\"coherence\"]).sort(\"topic\").write_parquet(topics_out)\n",
    "print(\"OK ->\", topics_out, \"| tópicos:\", topics_df.height)\n",
    "topics_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afe2db76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK -> c:\\Users\\User\\Desktop\\TCC\\Notebooks locais\\analise_topicos_tcc\\data\\exports\\dashboard\\doc_topics.parquet | linhas: 423\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>DOC_ID</th><th>topic</th><th>prob</th></tr><tr><td>i64</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>6</td><td>1.0</td></tr><tr><td>1</td><td>5</td><td>0.190732</td></tr><tr><td>2</td><td>-1</td><td>0.097848</td></tr><tr><td>3</td><td>3</td><td>0.193371</td></tr><tr><td>4</td><td>6</td><td>0.294686</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌────────┬───────┬──────────┐\n",
       "│ DOC_ID ┆ topic ┆ prob     │\n",
       "│ ---    ┆ ---   ┆ ---      │\n",
       "│ i64    ┆ i64   ┆ f64      │\n",
       "╞════════╪═══════╪══════════╡\n",
       "│ 0      ┆ 6     ┆ 1.0      │\n",
       "│ 1      ┆ 5     ┆ 0.190732 │\n",
       "│ 2      ┆ -1    ┆ 0.097848 │\n",
       "│ 3      ┆ 3     ┆ 0.193371 │\n",
       "│ 4      ┆ 6     ┆ 0.294686 │\n",
       "└────────┴───────┴──────────┘"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construção de doc_topics.parquet\n",
    "\n",
    "# OBS.: Mantém -1 (outlier) somente para auditoria.\n",
    "\n",
    "# Espera-se em doc_topics.csv colunas: DOC_ID, topic, prob (ou equivalentes)\n",
    "# Harmoniza nomes comuns encontrados em exportações\n",
    "cand_topic_cols = [c for c in doc_topics_raw.columns if c.lower() in {\"topic\",\"topics\"}]\n",
    "cand_prob_cols  = [c for c in doc_topics_raw.columns if c.lower() in {\"prob\",\"probability\",\"score\"}]\n",
    "cand_doc_cols   = [c for c in doc_topics_raw.columns if c.upper() == \"DOC_ID\" or c.lower()==\"doc_id\"]\n",
    "\n",
    "assert cand_topic_cols, f\"Não encontrei coluna de tópico em {doc_topics_csv}\"\n",
    "assert cand_prob_cols,  f\"Não encontrei coluna de probabilidade em {doc_topics_csv}\"\n",
    "assert cand_doc_cols,   f\"Não encontrei coluna DOC_ID em {doc_topics_csv}\"\n",
    "\n",
    "doc_topics = (doc_topics_raw\n",
    "              .rename({\n",
    "                  cand_topic_cols[0]: \"topic\",\n",
    "                  cand_prob_cols[0]: \"prob\",\n",
    "                  cand_doc_cols[0]: \"DOC_ID\"\n",
    "              })\n",
    "              .select([\"DOC_ID\",\"topic\",\"prob\"])\n",
    "              .with_columns([\n",
    "                  pl.col(\"DOC_ID\").cast(pl.Int64),\n",
    "                  pl.col(\"topic\").cast(pl.Int64),\n",
    "                  pl.col(\"prob\").cast(pl.Float64)\n",
    "              ]))\n",
    "\n",
    "doc_topics_out = EXPORT / \"doc_topics.parquet\"\n",
    "doc_topics.write_parquet(doc_topics_out)\n",
    "print(\"OK ->\", doc_topics_out, \"| linhas:\", doc_topics.height)\n",
    "doc_topics.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1e26815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK -> c:\\Users\\User\\Desktop\\TCC\\Notebooks locais\\analise_topicos_tcc\\data\\exports\\dashboard\\topic_trends.parquet | linhas: 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (8, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>topic</th><th>ano</th><th>n_docs</th><th>share</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>2020</td><td>2</td><td>0.08</td></tr><tr><td>0</td><td>2021</td><td>6</td><td>0.08</td></tr><tr><td>0</td><td>2022</td><td>10</td><td>0.147059</td></tr><tr><td>0</td><td>2023</td><td>19</td><td>0.152</td></tr><tr><td>0</td><td>2024</td><td>15</td><td>0.217391</td></tr><tr><td>1</td><td>2020</td><td>1</td><td>0.04</td></tr><tr><td>1</td><td>2021</td><td>10</td><td>0.133333</td></tr><tr><td>1</td><td>2022</td><td>9</td><td>0.132353</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (8, 4)\n",
       "┌───────┬──────┬────────┬──────────┐\n",
       "│ topic ┆ ano  ┆ n_docs ┆ share    │\n",
       "│ ---   ┆ ---  ┆ ---    ┆ ---      │\n",
       "│ i64   ┆ i64  ┆ i64    ┆ f64      │\n",
       "╞═══════╪══════╪════════╪══════════╡\n",
       "│ 0     ┆ 2020 ┆ 2      ┆ 0.08     │\n",
       "│ 0     ┆ 2021 ┆ 6      ┆ 0.08     │\n",
       "│ 0     ┆ 2022 ┆ 10     ┆ 0.147059 │\n",
       "│ 0     ┆ 2023 ┆ 19     ┆ 0.152    │\n",
       "│ 0     ┆ 2024 ┆ 15     ┆ 0.217391 │\n",
       "│ 1     ┆ 2020 ┆ 1      ┆ 0.04     │\n",
       "│ 1     ┆ 2021 ┆ 10     ┆ 0.133333 │\n",
       "│ 1     ┆ 2022 ┆ 9      ┆ 0.132353 │\n",
       "└───────┴──────┴────────┴──────────┘"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# topic_trends.parquet\n",
    "\n",
    "# Exclui -1; inclui share\n",
    "dt_valid = (\n",
    "    doc_topics\n",
    "    .filter(pl.col(\"topic\") != -1)\n",
    "    .join(docs.select([\"DOC_ID\", \"ano\"]), on=\"DOC_ID\", how=\"inner\")\n",
    ")\n",
    "\n",
    "if dt_valid.is_empty():\n",
    "    # Evita quebrar pipeline caso tudo tenha sido classificado como -1\n",
    "    trends = pl.DataFrame(schema={\"topic\": pl.Int64, \"ano\": pl.Int64, \"n_docs\": pl.Int64, \"share\": pl.Float64})\n",
    "else:\n",
    "    trends = (\n",
    "    dt_valid\n",
    "    .group_by([\"topic\", \"ano\"])\n",
    "    .agg(pl.len().alias(\"n_docs\"))\n",
    "    .with_columns(pl.col(\"n_docs\").cast(pl.Int64))\n",
    "    .sort([\"topic\", \"ano\"])\n",
    ")\n",
    "\n",
    "totais_ano = trends.group_by(\"ano\").agg(pl.col(\"n_docs\").sum().alias(\"n_total_ano\"))\n",
    "trends = (\n",
    "    trends\n",
    "    .join(totais_ano, on=\"ano\")\n",
    "    .with_columns((pl.col(\"n_docs\") / pl.col(\"n_total_ano\")).alias(\"share\"))\n",
    "    .select([\"topic\", \"ano\", \"n_docs\", \"share\"])\n",
    ")\n",
    "\n",
    "trends_out = EXPORT / \"topic_trends.parquet\"\n",
    "trends.write_parquet(trends_out)\n",
    "print(\"OK ->\", trends_out, \"| linhas:\", trends.height)\n",
    "trends.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2b71458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK -> c:\\Users\\User\\Desktop\\TCC\\Notebooks locais\\analise_topicos_tcc\\data\\exports\\dashboard\\advisor_profiles.parquet | linhas: 77\n",
      "OK -> c:\\Users\\User\\Desktop\\TCC\\Notebooks locais\\analise_topicos_tcc\\data\\exports\\dashboard\\advisor_topics.parquet | linhas: 188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(shape: (3, 7)\n",
       " ┌──────────────────┬─────────────────┬────────┬─────────┬─────────┬──────────────┬─────────────────┐\n",
       " │ orientador_id    ┆ orientador_nome ┆ n_tccs ┆ ano_min ┆ ano_max ┆ anos_atuacao ┆ temas_top       │\n",
       " │ ---              ┆ ---             ┆ ---    ┆ ---     ┆ ---     ┆ ---          ┆ ---             │\n",
       " │ str              ┆ str             ┆ i64    ┆ i64     ┆ i64     ┆ str          ┆ str             │\n",
       " ╞══════════════════╪═════════════════╪════════╪═════════╪═════════╪══════════════╪═════════════════╡\n",
       " │ pereira-eanes-to ┆ PEREIRA, Eanes  ┆ 10     ┆ 2021    ┆ 2024    ┆ 2021–2024    ┆ 4_dados_digital │\n",
       " │ rres             ┆ Torres.         ┆        ┆         ┆         ┆              ┆ _sobre_privacid │\n",
       " │                  ┆                 ┆        ┆         ┆         ┆              ┆ …               │\n",
       " │ campelo-claudio- ┆ CAMPELO,        ┆ 15     ┆ 2021    ┆ 2024    ┆ 2021–2024    ┆ 0_modelos_dados │\n",
       " │ elizio-calazan…  ┆ Claudio Elízio  ┆        ┆         ┆         ┆              ┆ _linguagem_imag │\n",
       " │                  ┆ Calaza…         ┆        ┆         ┆         ┆              ┆ …               │\n",
       " │ campos-livia-mar ┆ CAMPOS,  Lívia  ┆ 1      ┆ 2020    ┆ 2020    ┆ 2020–2020    ┆ 2_alunos_comput │\n",
       " │ ia-sampaio       ┆ Maria Sampaio.  ┆        ┆         ┆         ┆              ┆ ao_programao_si │\n",
       " │                  ┆                 ┆        ┆         ┆         ┆              ┆ …               │\n",
       " └──────────────────┴─────────────────┴────────┴─────────┴─────────┴──────────────┴─────────────────┘,\n",
       " shape: (3, 4)\n",
       " ┌───────────────────────────┬───────┬────────┬─────────────────────┐\n",
       " │ orientador_id             ┆ topic ┆ n_docs ┆ share_no_orientador │\n",
       " │ ---                       ┆ ---   ┆ ---    ┆ ---                 │\n",
       " │ str                       ┆ i64   ┆ i64    ┆ f64                 │\n",
       " ╞═══════════════════════════╪═══════╪════════╪═════════════════════╡\n",
       " │ almeida-hyggo-oliveira-de ┆ 5     ┆ 2      ┆ 0.5                 │\n",
       " │ almeida-hyggo-oliveira-de ┆ 3     ┆ 1      ┆ 0.25                │\n",
       " │ almeida-hyggo-oliveira-de ┆ 6     ┆ 1      ┆ 0.25                │\n",
       " └───────────────────────────┴───────┴────────┴─────────────────────┘)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# advisor_profiles.parquet e advisor_topics.parquet\n",
    "\n",
    "# Base: docs + doc_topics (mantendo -1 apenas para listagens, não para agregados)\n",
    "docs_by_advisor = docs.join(doc_topics, on=\"DOC_ID\", how=\"left\")\n",
    "\n",
    "# Perfil por orientador\n",
    "perfil = (\n",
    "    docs\n",
    "    .group_by([\"orientador_id\",\"orientador_nome\"])\n",
    "    .agg([\n",
    "        pl.len().alias(\"n_tccs\"),\n",
    "        pl.col(\"ano\").min().alias(\"ano_min\"),\n",
    "        pl.col(\"ano\").max().alias(\"ano_max\"),\n",
    "    ])\n",
    "    .with_columns([\n",
    "        pl.col(\"n_tccs\").cast(pl.Int64),  # <-- aqui\n",
    "        (pl.col(\"ano_min\").cast(pl.Int64).cast(pl.Utf8) + \"–\" + \n",
    "         pl.col(\"ano_max\").cast(pl.Int64).cast(pl.Utf8)).alias(\"anos_atuacao\")\n",
    "    ])\n",
    ")\n",
    "\n",
    "# advisor_topics (n_docs)\n",
    "advisor_topics = (\n",
    "    docs_by_advisor\n",
    "    .filter(pl.col(\"topic\") != -1)\n",
    "    .group_by([\"orientador_id\",\"topic\"])\n",
    "    .agg(pl.len().alias(\"n_docs\"))\n",
    "    .with_columns(pl.col(\"n_docs\").cast(pl.Int64))   # <-- aqui\n",
    "    .sort([\"orientador_id\",\"n_docs\"], descending=[False, True])\n",
    ")\n",
    "\n",
    "tot_orient = advisor_topics.group_by(\"orientador_id\").agg(pl.col(\"n_docs\").sum().alias(\"n_total\"))\n",
    "advisor_topics = (\n",
    "    advisor_topics\n",
    "    .join(tot_orient, on=\"orientador_id\")\n",
    "    .with_columns((pl.col(\"n_docs\")/pl.col(\"n_total\")).alias(\"share_no_orientador\"))\n",
    "    .select([\"orientador_id\",\"topic\",\"n_docs\",\"share_no_orientador\"])\n",
    ")\n",
    "\n",
    "# Map de topic -> label (para exibir top-k no perfil)\n",
    "topics_map = pl.read_parquet(EXPORT / \"topics.parquet\").select([\"topic\",\"label\"]).to_dict(as_series=False)\n",
    "id2label = dict(zip(topics_map[\"topic\"], topics_map[\"label\"]))\n",
    "\n",
    "def topk_labels_for_advisor(aid: str, k: int = 3) -> str:\n",
    "    sub = advisor_topics.filter(pl.col(\"orientador_id\")==aid).sort(\"n_docs\", descending=True).head(k)\n",
    "    if sub.is_empty():\n",
    "        return \"–\"\n",
    "    labs = []\n",
    "    for r in sub.iter_rows(named=True):\n",
    "        labs.append(id2label.get(int(r[\"topic\"]), f\"Topic {int(r['topic'])}\"))\n",
    "    return \"; \".join(labs)\n",
    "\n",
    "perfil = perfil.with_columns(\n",
    "    pl.col(\"orientador_id\").map_elements(topk_labels_for_advisor).alias(\"temas_top\")\n",
    ")\n",
    "\n",
    "# Persistir\n",
    "advisor_profiles_out = EXPORT / \"advisor_profiles.parquet\"\n",
    "advisor_topics_out = EXPORT / \"advisor_topics.parquet\"\n",
    "\n",
    "perfil.select([\"orientador_id\",\"orientador_nome\",\"n_tccs\",\"temas_top\",\"anos_atuacao\"]).write_parquet(advisor_profiles_out)\n",
    "advisor_topics.write_parquet(advisor_topics_out)\n",
    "\n",
    "print(\"OK ->\", advisor_profiles_out, \"| linhas:\", perfil.height)\n",
    "print(\"OK ->\", advisor_topics_out, \"| linhas:\", advisor_topics.height)\n",
    "\n",
    "perfil.head(3), advisor_topics.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7050425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Validação OK\n"
     ]
    }
   ],
   "source": [
    "# Validação de esquemas\n",
    "import pandera.pandas as pa\n",
    "from pandera import Check\n",
    "import pandas as pd\n",
    "\n",
    "DocsSchema = pa.DataFrameSchema({\n",
    "    \"DOC_ID\": pa.Column(int, Check.ge(0)),\n",
    "    \"ano\": pa.Column(int, Check.in_range(1900, 2100)),\n",
    "    \"titulo\": pa.Column(str),\n",
    "    \"resumo\": pa.Column(object, nullable=True),\n",
    "    \"url\": pa.Column(object, nullable=True),\n",
    "    \"autor\": pa.Column(object, nullable=True),\n",
    "    \"orientador_id\": pa.Column(str),\n",
    "    \"orientador_nome\": pa.Column(str),\n",
    "}, strict=True)\n",
    "\n",
    "TopicsSchema = pa.DataFrameSchema({\n",
    "    \"topic\": pa.Column(int, Check.ge(0)),\n",
    "    \"label\": pa.Column(str),\n",
    "    \"keywords\": pa.Column(str),\n",
    "    \"coherence\": pa.Column(object, nullable=True),\n",
    "}, strict=True)\n",
    "\n",
    "DocTopicsSchema = pa.DataFrameSchema({\n",
    "    \"DOC_ID\": pa.Column(int, Check.ge(0)),\n",
    "    \"topic\": pa.Column(int),  # pode conter -1\n",
    "    \"prob\": pa.Column(float, Check.in_range(0, 1, include_min=True, include_max=True)),\n",
    "}, strict=True)\n",
    "\n",
    "TrendsSchema = pa.DataFrameSchema({\n",
    "    \"topic\": pa.Column(int, Check.ge(0)),\n",
    "    \"ano\": pa.Column(int, Check.in_range(1900, 2100)),\n",
    "    \"n_docs\": pa.Column(int, Check.ge(0)),\n",
    "    \"share\": pa.Column(float, Check.in_range(0, 1, include_min=True, include_max=True)),\n",
    "}, strict=True)\n",
    "\n",
    "AdvisorProfilesSchema = pa.DataFrameSchema({\n",
    "    \"orientador_id\": pa.Column(str),\n",
    "    \"orientador_nome\": pa.Column(str),\n",
    "    \"n_tccs\": pa.Column(int, Check.ge(0)),\n",
    "    \"temas_top\": pa.Column(str),\n",
    "    \"anos_atuacao\": pa.Column(str),\n",
    "}, strict=True)\n",
    "\n",
    "AdvisorTopicsSchema = pa.DataFrameSchema({\n",
    "    \"orientador_id\": pa.Column(str),\n",
    "    \"topic\": pa.Column(int, Check.ge(0)),\n",
    "    \"n_docs\": pa.Column(int, Check.ge(0)),\n",
    "    \"share_no_orientador\": pa.Column(float, Check.in_range(0, 1, include_min=True, include_max=True)),\n",
    "}, strict=True)\n",
    "\n",
    "DocsSchema.validate(pd.read_parquet(EXPORT / \"docs.parquet\"))\n",
    "TopicsSchema.validate(pd.read_parquet(EXPORT / \"topics.parquet\"))\n",
    "DocTopicsSchema.validate(pd.read_parquet(EXPORT / \"doc_topics.parquet\"))\n",
    "TrendsSchema.validate(pd.read_parquet(EXPORT / \"topic_trends.parquet\"))\n",
    "AdvisorProfilesSchema.validate(pd.read_parquet(EXPORT / \"advisor_profiles.parquet\"))\n",
    "AdvisorTopicsSchema.validate(pd.read_parquet(EXPORT / \"advisor_topics.parquet\"))\n",
    "\n",
    "print(\"✔ Validação OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18cce25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidade média do tópico vencedor: 0.535\n",
      "Tópico -1 em topics.parquet?  False\n",
      "Tópico -1 em topic_trends.parquet?  False\n",
      "Cobertura temporal OK.\n"
     ]
    }
   ],
   "source": [
    "# Checagens de sanidade e relatórios\n",
    "\n",
    "docs_df = pl.read_parquet(EXPORT / \"docs.parquet\")\n",
    "dt_df = pl.read_parquet(EXPORT / \"doc_topics.parquet\")\n",
    "topics_df = pl.read_parquet(EXPORT / \"topics.parquet\")\n",
    "trends_df = pl.read_parquet(EXPORT / \"topic_trends.parquet\")\n",
    "\n",
    "# 1) unicidade de DOC_ID\n",
    "assert docs_df[\"DOC_ID\"].n_unique() == docs_df.height, \"DOC_ID duplicados em docs.parquet\"\n",
    "\n",
    "# 2) cobertura: cada DOC_ID aparece ao menos uma vez em doc_topics\n",
    "miss = set(docs_df[\"DOC_ID\"].to_list()) - set(dt_df[\"DOC_ID\"].to_list())\n",
    "assert not miss, f\"DOC_IDs sem atribuição em doc_topics: {sorted(list(miss))[:10]} ...\"\n",
    "\n",
    "# 3) probabilidade média do vencedor\n",
    "prob_mean = float(dt_df[\"prob\"].mean())\n",
    "print(f\"Probabilidade média do tópico vencedor: {prob_mean:.3f}\")\n",
    "\n",
    "# 4) presença de -1 (apenas doc_topics)\n",
    "has_minus1_topics = (topics_df[\"topic\"] == -1).any()\n",
    "has_minus1_trends = (trends_df[\"topic\"] == -1).any()\n",
    "print(\"Tópico -1 em topics.parquet? \", bool(has_minus1_topics))\n",
    "print(\"Tópico -1 em topic_trends.parquet? \", bool(has_minus1_trends))\n",
    "\n",
    "# 5) anos cobertos\n",
    "yrs_docs = docs_df[\"ano\"].drop_nulls().unique().sort().to_list()\n",
    "yrs_trends = trends_df[\"ano\"].drop_nulls().unique().sort().to_list()\n",
    "faltantes = set(yrs_docs) - set(yrs_trends)\n",
    "if faltantes:\n",
    "    print(\"Aviso: anos com zero temas válidos (apenas -1 ou nenhum doc):\", sorted(list(faltantes)))\n",
    "else:\n",
    "    print(\"Cobertura temporal OK.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "957cd583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtypes/docs: [Int64, Int64, String, String, String, String, String, String]\n",
      "dtypes/doc_topics: [Int64, Int64, Float64]\n",
      "dtypes/topics: [Int64, String, String, String]\n",
      "dtypes/topic_trends: [Int64, Int64, Int64, Float64]\n",
      "dtypes/advisor_profiles: [String, String, Int64, String, String]\n",
      "dtypes/advisor_topics: [String, Int64, Int64, Float64]\n",
      "✔ Dtypes congelados.\n"
     ]
    }
   ],
   "source": [
    "# Freezer de dtypes para Parquets do dashboard\n",
    "# Garante que contagens e chaves fiquem sempre em Int64 e floats em Float64.\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "# 1) docs.parquet\n",
    "docs_fp = EXPORT / \"docs.parquet\"\n",
    "docs_fix = (pl.read_parquet(docs_fp)\n",
    "            .with_columns([\n",
    "                pl.col(\"DOC_ID\").cast(pl.Int64),\n",
    "                pl.col(\"ano\").cast(pl.Int64),\n",
    "            ]))\n",
    "docs_fix.write_parquet(docs_fp)\n",
    "print(\"dtypes/docs:\", docs_fix.dtypes)\n",
    "\n",
    "# 2) doc_topics.parquet\n",
    "dt_fp = EXPORT / \"doc_topics.parquet\"\n",
    "dt_fix = (pl.read_parquet(dt_fp)\n",
    "          .with_columns([\n",
    "              pl.col(\"DOC_ID\").cast(pl.Int64),\n",
    "              pl.col(\"topic\").cast(pl.Int64),  # mantém -1\n",
    "              pl.col(\"prob\").cast(pl.Float64),\n",
    "          ]))\n",
    "dt_fix.write_parquet(dt_fp)\n",
    "print(\"dtypes/doc_topics:\", dt_fix.dtypes)\n",
    "\n",
    "# 3) topics.parquet\n",
    "topics_fp = EXPORT / \"topics.parquet\"\n",
    "topics_fix = (pl.read_parquet(topics_fp)\n",
    "              .with_columns([\n",
    "                  pl.col(\"topic\").cast(pl.Int64),\n",
    "                  pl.col(\"label\").cast(pl.Utf8),\n",
    "                  pl.col(\"keywords\").cast(pl.Utf8),\n",
    "              ]))\n",
    "topics_fix.write_parquet(topics_fp)\n",
    "print(\"dtypes/topics:\", topics_fix.dtypes)\n",
    "\n",
    "# 4) topic_trends.parquet\n",
    "trends_fp = EXPORT / \"topic_trends.parquet\"\n",
    "trends_fix = (pl.read_parquet(trends_fp)\n",
    "              .with_columns([\n",
    "                  pl.col(\"topic\").cast(pl.Int64),\n",
    "                  pl.col(\"ano\").cast(pl.Int64),\n",
    "                  pl.col(\"n_docs\").cast(pl.Int64),\n",
    "                  pl.col(\"share\").cast(pl.Float64),\n",
    "              ]))\n",
    "trends_fix.write_parquet(trends_fp)\n",
    "print(\"dtypes/topic_trends:\", trends_fix.dtypes)\n",
    "\n",
    "# 5) advisor_profiles.parquet\n",
    "ap_fp = EXPORT / \"advisor_profiles.parquet\"\n",
    "ap_fix = (pl.read_parquet(ap_fp)\n",
    "          .with_columns([\n",
    "              pl.col(\"n_tccs\").cast(pl.Int64),\n",
    "          ]))\n",
    "ap_fix.write_parquet(ap_fp)\n",
    "print(\"dtypes/advisor_profiles:\", ap_fix.dtypes)\n",
    "\n",
    "# 6) advisor_topics.parquet\n",
    "at_fp = EXPORT / \"advisor_topics.parquet\"\n",
    "at_fix = (pl.read_parquet(at_fp)\n",
    "          .with_columns([\n",
    "              pl.col(\"topic\").cast(pl.Int64),\n",
    "              pl.col(\"n_docs\").cast(pl.Int64),\n",
    "              pl.col(\"share_no_orientador\").cast(pl.Float64),\n",
    "          ]))\n",
    "at_fix.write_parquet(at_fp)\n",
    "print(\"dtypes/advisor_topics:\", at_fix.dtypes)\n",
    "\n",
    "print(\"✔ Dtypes congelados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76dc4c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK -> c:\\Users\\User\\Desktop\\TCC\\Notebooks locais\\analise_topicos_tcc\\data\\exports\\dashboard\\_manifest.json\n",
      "{\n",
      "  \"generated_at\": \"2025-09-04T20:13:37\",\n",
      "  \"paths\": {\n",
      "    \"root\": \"C:\\\\Users\\\\User\\\\Desktop\\\\TCC\\\\Notebooks locais\\\\analise_topicos_tcc\",\n",
      "    \"export_dir\": \"C:\\\\Users\\\\User\\\\Desktop\\\\TCC\\\\Notebooks locais\\\\analise_topicos_tcc\\\\data\\\\exports\\\\dashboard\",\n",
      "    \"best_dir\": \"C:\\\\Users\\\\User\\\\Desktop\\\\TCC\\\\Notebooks locais\\\\analise_topicos_tcc\\\\data\\\\exports\\\\dashboard\\\\bertopic_best\"\n",
      "  },\n",
      "  \"selection\": {\n",
      "    \"method\": \"bertopic\",\n",
      "    \"run\": \"run_20250831T230602Z\",\n",
      "    \"trial\": \"trial_24\",\n",
      "    \"K\": 12,\n",
      "    \"metrics\": {\n",
      "      \"c_npmi\": 0.007560071814801735,\n",
      "      \"c_v\": 0.6058599854512132,\n",
      "      \"\n",
      "…\n"
     ]
    }
   ],
   "source": [
    "# Manifesto de exportação para reprodutibilidade\n",
    "from datetime import datetime\n",
    "import json, hashlib\n",
    "\n",
    "docs = pl.read_parquet(EXPORT / \"docs.parquet\")\n",
    "topics = pl.read_parquet(EXPORT / \"topics.parquet\")\n",
    "dt = pl.read_parquet(EXPORT / \"doc_topics.parquet\")\n",
    "\n",
    "# Básicos\n",
    "n_docs = docs.height\n",
    "anos = docs[\"ano\"].drop_nulls()\n",
    "anos_min = int(anos.min()) if anos.len() > 0 else None\n",
    "anos_max = int(anos.max()) if anos.len() > 0 else None\n",
    "n_topics = topics.height  # sem -1\n",
    "\n",
    "# Seleção do vencedor (se existir)\n",
    "sel = {}\n",
    "sel_fp = BEST / \"selection.json\"\n",
    "if sel_fp.exists():\n",
    "    try:\n",
    "        sel = json.loads(sel_fp.read_text(encoding=\"utf-8\"))\n",
    "    except Exception:\n",
    "        sel = {}\n",
    "\n",
    "# Outliers\n",
    "outliers_count = dt.filter(pl.col(\"topic\") == -1).height\n",
    "outliers_pct = float(outliers_count / n_docs) if n_docs else 0.0\n",
    "# Se selection.json tiver outliers_pct, mantém como \"reported\" e registra \"observed\"\n",
    "reported_outliers_pct = sel.get(\"outliers_pct\", None)\n",
    "\n",
    "# Pequeno hash dos arquivos principais (para rastreio)\n",
    "def file_sha1(path: Path) -> str:\n",
    "    h = hashlib.sha1()\n",
    "    with open(path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(1<<20), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "hashes = {}\n",
    "for p in [\"docs.parquet\", \"topics.parquet\", \"doc_topics.parquet\", \"topic_trends.parquet\",\n",
    "          \"advisor_profiles.parquet\", \"advisor_topics.parquet\"]:\n",
    "    fp = EXPORT / p\n",
    "    if fp.exists():\n",
    "        hashes[p] = file_sha1(fp)\n",
    "\n",
    "manifest = {\n",
    "    \"generated_at\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "    \"paths\": {\n",
    "        \"root\": str(ROOT.resolve()),\n",
    "        \"export_dir\": str(EXPORT.resolve()),\n",
    "        \"best_dir\": str(BEST.resolve()),\n",
    "    },\n",
    "    \"selection\": {\n",
    "        \"method\": sel.get(\"method\"),\n",
    "        \"run\": sel.get(\"run\"),\n",
    "        \"trial\": sel.get(\"trial\"),\n",
    "        \"K\": sel.get(\"K\"),\n",
    "        \"metrics\": {\n",
    "            \"c_npmi\": sel.get(\"c_npmi\"),\n",
    "            \"c_v\": sel.get(\"c_v\"),\n",
    "            \"diversity@10\": sel.get(\"diversity@10\"),\n",
    "            \"sep_jsd\": sel.get(\"sep_jsd\"),\n",
    "            \"balance\": sel.get(\"balance\"),\n",
    "            \"clarity\": sel.get(\"clarity\"),\n",
    "            \"RZ_index\": sel.get(\"RZ_index\"),\n",
    "            \"GR_index\": sel.get(\"GR_index\"),\n",
    "        },\n",
    "        \"reported_outliers_pct\": reported_outliers_pct,\n",
    "    },\n",
    "    \"corpus\": {\n",
    "        \"n_docs\": n_docs,\n",
    "        \"years\": {\"min\": anos_min, \"max\": anos_max},\n",
    "    },\n",
    "    \"topics\": {\n",
    "        \"n_topics\": int(n_topics),  # sem -1\n",
    "    },\n",
    "    \"outliers\": {\n",
    "        \"count\": int(outliers_count),\n",
    "        \"observed_pct\": outliers_pct,\n",
    "    },\n",
    "    \"artifacts_sha1\": hashes,\n",
    "}\n",
    "\n",
    "manifest_fp = EXPORT / \"_manifest.json\"\n",
    "manifest_fp.write_text(json.dumps(manifest, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "print(\"OK ->\", manifest_fp)\n",
    "print(json.dumps(manifest, ensure_ascii=False, indent=2)[:600] + \"\\n…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d6f6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers (topic = -1): 61/423 = 14.42%\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'groupby'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOutliers (topic = -1): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_outliers\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_total\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpct\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_outliers > \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     by_year = (\u001b[43moutliers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mano\u001b[39m\u001b[33m\"\u001b[39m).agg(pl.len().alias(\u001b[33m\"\u001b[39m\u001b[33mn_docs\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     15\u001b[39m                         .sort(\u001b[33m\"\u001b[39m\u001b[33mano\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     16\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mDistribuição por ano:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m     display(by_year.to_pandas())\n",
      "\u001b[31mAttributeError\u001b[39m: 'DataFrame' object has no attribute 'groupby'"
     ]
    }
   ],
   "source": [
    "# === Relatório rápido de outliers ===\n",
    "dt = pl.read_parquet(EXPORT / \"doc_topics.parquet\")\n",
    "docs = pl.read_parquet(EXPORT / \"docs.parquet\")\n",
    "\n",
    "outliers = dt.filter(pl.col(\"topic\") == -1).join(docs.select([\"DOC_ID\",\"ano\",\"titulo\",\"orientador_nome\"]), on=\"DOC_ID\", how=\"left\")\n",
    "\n",
    "n_outliers = outliers.height\n",
    "n_total = dt.height\n",
    "pct = (n_outliers / n_total) if n_total else 0.0\n",
    "\n",
    "print(f\"Outliers (topic = -1): {n_outliers}/{n_total} = {pct:.2%}\")\n",
    "\n",
    "if n_outliers > 0:\n",
    "    by_year = (outliers.group_by(\"ano\").agg(pl.len().alias(\"n_docs\"))\n",
    "                        .sort(\"ano\"))\n",
    "    print(\"\\nDistribuição por ano:\")\n",
    "    display(by_year.to_pandas())\n",
    "\n",
    "    print(\"\\nAmostra (até 5 docs):\")\n",
    "    display(outliers.select([\"DOC_ID\",\"ano\",\"titulo\"]).head(5).to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a11020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Versionamento dos artefatos de tópicos ===\n",
    "from shutil import copyfile\n",
    "import re\n",
    "\n",
    "topics_src = EXPORT / \"topics.parquet\"\n",
    "topics_current = EXPORT / \"topics_current.parquet\"\n",
    "\n",
    "# Determina próximo N para topics_v{N}.parquet\n",
    "existing = [p.name for p in EXPORT.glob(\"topics_v*.parquet\")]\n",
    "nums = []\n",
    "for name in existing:\n",
    "    m = re.match(r\"topics_v(\\d+)\\.parquet$\", name)\n",
    "    if m:\n",
    "        nums.append(int(m.group(1)))\n",
    "next_n = (max(nums) + 1) if nums else 1\n",
    "topics_versioned = EXPORT / f\"topics_v{next_n}.parquet\"\n",
    "\n",
    "# Copia snapshot e atualiza \"current\"\n",
    "copyfile(topics_src, topics_versioned)\n",
    "copyfile(topics_src, topics_current)\n",
    "\n",
    "print(\"Criado snapshot:\", topics_versioned.name)\n",
    "print(\"Atualizado:\", topics_current.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f186aff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Smoke test final: 3 linhas de cada saída ===\n",
    "for name in [\"docs.parquet\",\"topics.parquet\",\"doc_topics.parquet\",\"topic_trends.parquet\",\n",
    "             \"advisor_profiles.parquet\",\"advisor_topics.parquet\",\"_manifest.json\",\"topics_current.parquet\"]:\n",
    "    fp = EXPORT / name\n",
    "    if not fp.exists():\n",
    "        print(f\"[faltando] {name}\")\n",
    "        continue\n",
    "    print(\"\\n==>\", name)\n",
    "    if name.endswith(\".json\"):\n",
    "        print((EXPORT / name).read_text(encoding=\"utf-8\")[:400] + \"\\n…\")\n",
    "    else:\n",
    "        df = pl.read_parquet(fp)\n",
    "        print(df.head(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TCC - Compare (py3.12)",
   "language": "python",
   "name": "tcc-compare"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
